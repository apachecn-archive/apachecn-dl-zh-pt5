

# 七、深度学习模型揭秘

到目前为止，我们已经描述了如何构建和高效训练一个**深度学习**(**D1**)模型。然而，模型训练通常涉及多次迭代，因为只存在关于如何为给定任务正确配置训练的粗略指导。

在本章中，我们将介绍超参数调整，这是找到正确训练配置的最标准的过程。当我们指导您完成超参数调整的步骤时，我们将介绍调整过程中采用的流行搜索算法(网格搜索、随机搜索和贝叶斯优化)。我们还将研究可解释的人工智能领域，这是理解模型在预测过程中做什么的过程。我们将描述这个领域中最常见的三种技术:**置换特征重要性** ( **PFI** )、**沙普利加法解释** ( **SHAP** )、**局部可解释模型不可知解释** ( **LIME** )。

在本章中，我们将讨论以下主要话题:

*   使用超参数调整获得最佳性能模型
*   用可解释的人工智能理解模型的行为

# 技术要求

你可以从本书的 GitHub 资源库下载本章的补充材料，网址为[https://GitHub . com/packt publishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter _ 7](https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter_7)。

# 使用超参数调整获得最佳性能模型

正如 [*第三章*](B18522_03.xhtml#_idTextAnchor062)*中所描述的开发一个强大的深度学习模型*，要获得一个为底层任务提取正确模式的 DL 模型，需要适当配置多个组件。虽然构建正确的模型架构通常会引入许多困难，但是设置适当的模型训练是大多数人都在努力应对的另一个挑战。

在**机器学习**(**ML**)*a***超参数** *是指控制学习过程*的任何参数。在许多情况下，数据科学家通常关注与模型相关的超参数，如特定类型的层数、学习率或优化器类型。然而，超参数还包括数据相关的配置，如应用的增强类型和模型训练的采样策略。改变一组超参数并了解性能变化，从而为目标任务找到正确的一组超参数的迭代过程称为*超参数调整*。准确地说，您将拥有一组想要探索的超参数。对于每次迭代，一个或多个超参数将被不同地配置，一个新的模型将用调整后的设置进行训练。在迭代过程之后，用于最佳模型的超参数配置将是最终输出。

在本章中，我们将学习超参数调整的各种技术和工具。

## 超参数调优技术

*超参数调优技术可能因目标超参数值的选择方式而异*。在各种技术中，我们将集中在最常见的技术上:**网格搜索**、**随机搜索**和**贝叶斯优化**。

### 网格搜索

最基本的方法是被称为网格搜索的，其中每个可能的值被逐一评估*。例如，如果您想探索一个从 0 到 1、增量为 0.25 的学习率，那么网格搜索将为每个可能的学习率(0.25、0.5、0.75 和 1)训练模型，并选择生成最佳模型的学习率。*

### 随机搜索

另一方面，*随机搜索为超参数生成随机值，并重复训练，直到达到最大实验次数*。如果我们将上一节中的示例转换为随机搜索，我们必须定义最大实验次数和学习率的界限。在这个例子中，我们将设置最大值为 5，边界为 0 到 1。然后，随机搜索将在 0 和 1 之间选择一个随机值，并用选择的学习率训练一个模型。这个过程将重复 5 次，并且产生最佳模型的学习率将被选择作为超参数调整的输出。

为了帮助您理解，下图总结了网格搜索和随机搜索之间的区别:

![Figure 7.1 – The difference between grid search and random search
](img/B18522_07_01.jpg)

图 7.1-网格搜索和随机搜索的区别

在上图中， *x* 和 *y* 表示两个不同的超参数。每个轴上的紫色和绿色图形表示每个超参数的模型性能变化。

虽然网格搜索和随机搜索易于实现，但它们都有一个共同的限制:它们不能保证目标超参数的最佳值。这个问题主要来自于在选择下一个要探索的值时没有考虑前面的结果。为了克服这个问题，一种新的搜索算法被引入:贝叶斯优化。

### 贝叶斯优化

贝叶斯优化的思想很简单:*在整个超参数调整过程中，构建并调整映射超参数和底层模型之间关系的代理模型，以便我们可以选择最有可能引导我们从下面的实验*中更好地理解关系的超参数值。使用生成的代理模型，我们可以选择超参数值，这可能会给我们一个更好的模型。

有很多方法可以建立一个代理模型。如果我们假设该关系可以表示为线性函数，那么代理模型生成过程将简单地是线性回归。在现实中，关系要复杂得多，最成功的技术是使用高斯过程回归。这里，我们假设这种关系可以用一组正态分布来表示。换句话说，我们选择的每个值都是从多元正态分布中随机选取的。如果我们想了解贝叶斯优化的每个细节，我们需要引入多个概率和数学术语。我们相信，本节中的高级描述和下一节中的完整示例将足以让您使用贝叶斯优化来应用超参数调优。如果你想了解贝叶斯优化背后的理论，请前往[https://ieeexplore.ieee.org/abstract/document/7352306](https://ieeexplore.ieee.org/abstract/document/7352306)。

## 超参数调整工具

由于超参数调整在 ML 项目中起着重要的作用，许多库被设计成简化该过程。热门如下:

*   **Scikit-Optimize**:[https://Scikit-Optimize . github . io](https://scikit-optimize.github.io)
*   **Optuna**:【https://optuna.org 
*   **hyperpt**:[http://hyperpt . github . io](http://hyperopt.github.io)
*   **雷调**:[https://docs.ray.io/en/latest/tune/index.html](https://docs.ray.io/en/latest/tune/index.html)
*   **贝叶斯优化**:[https://github.com/fmfn/BayesianOptimization](https://github.com/fmfn/BayesianOptimization)
*   **公制优化引擎** ( **教育部**):[https://github.com/Yelp/MOE](https://github.com/Yelp/MOE)
*   **留兰香**:[https://github.com/HIPS/Spearmint](https://github.com/HIPS/Spearmint)
*   **GPyOpt**:[https://github.com/SheffieldML/GPyOpt](https://github.com/SheffieldML/GPyOpt)
*   **SigOpt**:[https://sigopt.com](https://sigopt.com/)
*   **弗拉姆**:[https://github.com/microsoft/FLAML](https://github.com/microsoft/FLAML)
*   **https://github.com/dragonfly/dragonfly**:[蜻蜓](https://github.com/dragonfly/dragonfly)
*   https://github.com/automl/HpBandSter
*   **奈弗格勒**:[https://github.com/facebookresearch/nevergrad](https://github.com/facebookresearch/nevergrad)
*   **ZOOpt**:[https://github.com/polixir/ZOOpt](https://github.com/polixir/ZOOpt)
*   **https://github.com/huawei-noah/HEBO/tree/master/HEBO**:[何波](https://github.com/huawei-noah/HEBO/tree/master/HEBO)
*   **SageMaker**:[https://docs . AWS . Amazon . com/SageMaker/latest/DG/automatic-model-tuning-how-it-works . html](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html)

在各种工具中，我们将查看 Ray Tune，因为我们在 [*第 6 章*](B18522_06.xhtml#_idTextAnchor133) 、*高效模型训练*、*使用 Ray* 训练模型一节中介绍了如何使用 Ray 进行分布式训练。

### 使用光线调节的超参数调节

作为为跨机器扩展 Python 工作负载而开发的框架 Ray 的一部分，Ray Tune 是为大规模实验执行和超参数调优而设计的。在本节中，我们将带您了解如何使用**射线调节**来配置和安排超参数调节。尽管这些示例是为模型训练功能的抽象表示而设计的，但 Ray Tune 的设置和文档足够清晰，以至于在本节的最后自然会出现 **PyTorch** 和**tensor flow**(**TF**)集成。

首先，我们将看看光线调的基础。Ray Tune 的核心功能来自于`tune.run`函数，它管理所有的实验、日志和检查点。下面的代码片段演示了`tune.run`函数的基本用法:

```

from ray import tune

def tr_function(conf):

    num_iterations = conf["num_it"]

    for i in range(num_iterations):

        … // training logic

        tune.report(mean_accuracy=acc)

tune.run(

    run_or_experiment=tr_function

    conf={"num_it": tune.grid_search([10, 20, 30, 40])})
```

`tune.run`函数接收`run_or_experiment`和`conf`，前者定义训练逻辑，后者配置超参数调整。实验的数量取决于`conf`中为每个超参数提供的搜索功能的类型。在前面的例子中，我们有`tune.grid_search([10, 20, 30, 40])`，它将启动四个实验，每个实验都运行为`run_or_experiment` ( `tr_function`)提供的函数，其值为`num_iterations`。在`tr_function`中，我们可以通过`conf`参数访问分配的超参数。值得一提的是，Ray Tune 提供了大量的采样方法([https://docs . Ray . io/en/latest/Tune/API _ docs/search _ space . html # Tune-sample-docs](https://docs.ray.io/en/latest/tune/api_docs/search_space.html#tune-sample-docs))。

作为`tune.suggest`的一部分，Ray Tune 集成了许多开源优化库，为超参数调整提供了各种最先进的搜索算法。流行的包括 HyperOpt，贝叶斯优化，Scitkit-Optimize 和 Optuna。完整的名单可以在 https://docs.ray.io/en/latest/tune/api_docs/suggestion.html 找到。在下面的例子中，我们将描述如何使用`BayesOptSearch`，顾名思义，它实现了贝叶斯优化:

```

from ray import tune

from ray.tune.suggest.bayesopt import BayesOptSearch

conf = {"num_it": tune.randint(100, 200)}

bayesopt = BayesOptSearch(metric="mean_accuracy", mode="max")

tune.run(

    run_or_experiment=tr_function

    config = conf,

    search_alg = bayesopt)
```

在前面的代码片段中，我们为`search_alg`参数提供了一个`BayesOptSearch`的实例。这个例子将尝试找到`num_iterations`，这将为我们提供一个最高`mean_accuracy`的模型。

`tune.run`的另一个关键参数是`stop`。这个参数可以接受一个字典、一个函数或者一个定义停止标准的`Stopper`对象。如果是字典，key 必须是`run_or_experiment`函数返回结果中的字段之一。如果它是一个函数，它应该返回一个布尔值，一旦满足停止条件，这个布尔值就变成`True`。以下示例描述了这两种情况:

```

# dictionary-based stop

tune.run(tr_function,

        stop={"training_iteration": 20, 

              "mean_accuracy": 0.96})

# function-based stop

def stp_function(trial_id, result):

    return result["training_iteration"] > 20 or

           result["mean_accuracy"] > 0.96

tune.run(tr_function, stop=stp_function)
```

在基于字典的示例中，如果完成 10 次迭代或`mean_accuracy`达到指定值`0.96`，则每次试验将停止。基于函数的例子实现了相同的逻辑，但是使用了`stp_function`函数。关于`stopper`类用例，可以参考[https://docs . ray . io/en/latest/tune/tutorials/tune-stopping . html # stopping-with-a-class](https://docs.ray.io/en/latest/tune/tutorials/tune-stopping.html#stopping-with-a-class)。

*试验是 Ray Tune 的内部数据结构，包含关于每个实验的元数据*([https://docs . Ray . io/en/latest/Tune/API _ docs/internals . html # trial-objects](https://docs.ray.io/en/latest/tune/api_docs/internals.html#trial-objects))。每个试验都有一个唯一的 ID ( `trial.trial_id`)，可以通过到`trial.config`检查其超参数设置。有趣的是，通过`tune.run`和`trial.placement_group_factory`的`resources_per_trial`参数，可以为每次试验分配不同规模的机器资源。此外，`num_samples`参数可用于控制试验次数。

您的实验总结可以使用从`ray.tune`返回的`Analysis`实例获得。以下代码片段描述了您可以从`Analysis`实例中检索的一组信息:

```

# last reported results

df = analysis.results_df

# list of trials

trs = analysis.trials

# max accuracy 

max_acc_df = analysis.dataframe(metric="mean_accuracy", mode="max")

# dict mapping for all trials in the experiment

all_dfs = analysis.trial_dataframes
```

您还可以从一个`Analysis`实例中检索其他有用的信息。完整的细节可以在 https://docs.ray.io/en/latest/tune/api_docs/analysis.html 找到。

这就完成了 Ray Tune 的核心组件。如果您想要为您的 PyTorch 或 TF 模型训练集成 Ray Tune，您必须做的就是调整示例中的`tr_function`，以便它在记录相关性能指标时训练您的模型。

总的来说，我们已经探索了超参数调整的不同选项。我们在本节中介绍的工具应该可以帮助我们有效地找到 DL 模型的最佳配置。

要记住的事情

a.为一个特定的任务获得一个工作的 DL 模型需要找到正确的模型架构并使用适当的训练配置。寻找最佳组合的过程称为超参数调整。

b.三种最流行的超参数调整技术是网格搜索、随机搜索和贝叶斯优化。

c.流行的超参数调优工具包括 Scikit-Optimize、Optuna、Hyperopt、Ray Tune、Bayesian Optimization、MOE、Spearmint、GpyOpt 和 SigOpt。

到目前为止，我们将 DL 模型视为黑盒。超参数调整包括搜索一个未知空间，该空间不能解释模型如何找到基础模式。在下一节中，我们将看看研究人员最近为理解 DL 的灵活性所做的工作。

# 用可解释的人工智能理解模型的行为

**交代 AI** 是研究的一个非常活跃的领域。在商业环境中，理解人工智能模型很容易带来独特的竞争优势。所谓的*黑盒模型(复杂算法模型)*，尽管它们带来了异常的结果，但由于其隐藏的逻辑而受到普遍批评。高层管理人员很难完全设计基于人工智能的核心业务，因为解释模型和预测不是一件容易的事情。你如何让你的商业伙伴相信一个人工智能模型总是会带来预期的结果？如何确保模型在新数据上仍然有效？模型是如何产生结果的？可解释的人工智能帮助我们解决这些问题。

在我们继续之前，让我们先来看两个重要的概念:**可解释性**和**可解释性**。起初，它们听起来可能相似。可解释性告诉我们为什么特定的输入会产生特定的模型输出:特定变量对结果的影响。可解释性超越了可解释性；它不仅关注输入和输出之间的因果关系，而且帮助我们理解一个模型作为一个整体是如何工作的，包括它的所有子元素。可解释性也是由三个基本概念驱动的:透明性、再现性和可转移性。这意味着我们应该能够完全理解我们的模型做什么，当数据通过时如何影响模型，并且能够再现结果。

可解释的人工智能在 ML 项目的每个步骤中都发挥着作用——开发(解释模型架构和每个超参数的意义)、训练(整个训练过程中模型内的变化)以及推理(结果解释)。在 DL 模型的情况下，由于网络架构的复杂性、高算法复杂性以及在初始化权重、偏差、正则化和超参数优化时使用随机数，很难实现可解释性。

在本节中，我们将讨论一些常用于在 DL 模型背后构建额外可信度的方法:**置换特征重要性** ( **PFI** )、**特征重要性** ( **FI** )、 **SHapley 加法解释** ( **SHAP** )和**局部可解释模型不可知解释** ( **LIME** )。所有这些方法都是模型不可知的；它们可以应用于 DL 模型以及通常用于设置基线评估度量的其他支持 ML 模型。

## 排列特征重要性

神经网络缺乏理解输入特征对预测(模型输出)的影响所需的内在属性。然而，有一种称为**置换特征重要性** ( **PFI** )的模型不可知方法是为这种困难设计的。*PFI 的思想来源于输入特征和输出之间的关系:对于与输出变量高度相关的输入特征，改变其值会增加模型的预测误差*。如果关系较弱，模型性能不会受到太大影响。关系强了，业绩就降级了。PFI 通常应用于测试集，以更广泛地了解模型对看不见的数据的可解释性。

PFI 的主要缺点是，当数据包含一组相关的输入要素时，它将无法正常工作。在这种情况下，即使更改组中的一个特征，模型性能也不会有太大变化，因为其他特征将保持不变。

根据这个想法，我们可以完全删除该特性，并测量模型性能。这种方法称为**特征重要性** ( **FI** )，也称为**排列重要性** ( **PI** )或**表示降低精确度** ( **MDA** )。让我们来看看如何为任何黑盒模型实现 FI。

## 功能重要性

在本节中，我们将使用 *ELI5* Python 包([https://Eli 5 . readthedocs . io](https://eli5.readthedocs.io))来执行 FI 分析。它在 FI 领域脱颖而出，因为它使用起来非常简单。让我们看一个带有 Keras 定义模型的 TF 的最小代码示例(参见 [*第 3 章*](B18522_03.xhtml#_idTextAnchor062) ，*开发一个强大的深度学习模型*，了解模型定义的详细信息):

```

import eli5

from eli5.sklearn import PermutationImportance

def score(self, x, y_true):

    y_pred = model.predict(x)

    return tf.math.sqrt( tf.math.reduce_mean( tf.math.square(y_pred-y_true), axis=-1)) 

perm = PermutationImportance(model, random_state=1, scoring=score).fit(features, labels)

fi_perm=perm.feature_importances_

fi_std=perm.feature_importances_std_
```

如您所见，代码几乎是不言自明的。首先，我们需要为计算目标评估度量的 score 函数创建一个包装器。然后，`tf.keras`模型被传递给`PermutationImportance`类的构造函数。`fit`函数接受特征和标签，处理 FI 计算。在此计算之后，我们可以访问每个特征的平均 FI(`fi_perm`)和置换结果的标准偏差(`fi_std`)。以下代码片段显示了如何将排列重要性的结果可视化为条形图:

```

plt.figure()

for index, row in enumerate(fi_perm):

    plt.bar(index, 

            fi_perm[index], 

            color="b", 

            yerr=fi_std[index], 

            align="center")

plt.show()
```

如果模型既不是基于 scikit-learn 也不是基于 Keras，则需要使用`permutation_importance.get_score_importance`函数。以下代码片段描述了如何在 PyTorch 模型中使用该函数:

```

import numpy as np

from eli5.permutation_importance import get_score_importances

# A trained PyTorch model

black_box_model = ...

def score(X, y):

    y_pred = black_box_model.predict(X)

    return accuracy_score(y, y_pred)

base_score, score_decreases = get_score_importances(score, X, y)

feature_importances = np.mean(score_decreases, axis=0)
```

与`PermutationImportance`类不同，`get_score_importances`函数同时接受评分函数、特征和标签。

接下来，我们将看看**沙普利附加解释** ( **SHAP** )，这也是一种模型不可知的方法。

## 沙普利加法解释(SHAP)

SHAP 是一种解释方法，利用 Shapley 值来理解给定的黑盒模型。我们不会讨论 SHAP 所基于的合作博弈理论，但是我们会在一个高层次上讨论这个过程。首先，我们来看看 Shapley 值的定义:*不同模拟上所有可能联盟的边际贡献平均值*。这到底是什么意思？假设一组四个朋友( *f1* 、 *f2* 、 *f3* 和 *f4* )正在一起努力为一个在线游戏获得最高分。为了计算一个人的 Shapley 值，我们需要计算边际贡献，这是这个人玩游戏和不玩游戏时得分的差异。必须对所有可能的子组进行这种计算(**联盟**)。

让我们仔细看看。为了计算朋友联盟 *f2* 、 *f3* 和 *f4* 的边际贡献 *f1* ，我们需要做以下事情:

1.  计算所有好友( *f1* 、 *f2* 、 *f3* 、 *f4* )产生的分数( *s1* )。
2.  计算好友 *f2* 、 *f3* 、 *f4* 产生的分数( *s2* )。
3.  最后，朋友 *f1* 对于朋友联盟 *f2* 、 *f3* 、 *f4* 、【v】的边际贡献等于 *s1-s2* 。

现在，我们需要计算所有子群的边际贡献(不仅仅是朋友联盟；即 *f2* 、 *f3* 、 *f4* 。以下是所有可能的组合:

1.  *f1* 对*没人*出力( *v1* )
2.  *f1* 和 *f2* 对 *f2* ( *v2* )
3.  *f1* 和 *f3* 对 *f3* ( *v3* )
4.  *f1* 和 *f4* 对 *f4* ( *v4* )
5.  *f1* 和 *f2* 和 *f3* 对 *f2* 和 *f3* ( *v5* )
6.  *f1* 和 *f2* 和 *f4* 对 *f2* 和 *f4* ( *v6* )
7.  *f1* 和 *f3* 和 *f4* 对 *f3* 和 *f4* ( *v7* )
8.  *f1* 和 *f2* 和 *f3* 和 *f4* 对 *f2* 和 *f3* 和 *f4* ( *v8* )

总的来说， *f1* 的 Shapley 值( *SV* )为 *(v1+v2+...+v8) / 8* 。

为了让我们的结果在统计上合理，我们需要通过多次模拟运行这些计算。你可以看到，如果我们扩展朋友的数量，计算变得极其复杂，导致计算资源的高消耗。所以使用了特定的近似，导致了`shap`库([https://shap.readthedocs.io/en/latest/index.html](https://shap.readthedocs.io/en/latest/index.html))中不同类型的所谓解释器(Shapley 值的近似器)。对比沙普利对所有朋友的价值观，可以发现个人对最终得分的贡献。

如果我们回到 DL 模型的解释，我们可以看到朋友成为一组特征，分数就是模型性能。考虑到这一点，我们来看看 SHAP 的解释器，它可以用于 DL 模型:

*   `KernelExplainer`:这是最流行的方法，并且与模型无关。它基于**局部可解释的模型不可知解释** ( **LIME** )，我们将在下一节讨论。
*   `DeepExplainer`:这种方法基于深度列表方法，将输出分解到特定的输入上([https://arxiv.org/abs/1704.02685](https://arxiv.org/abs/1704.02685))。
*   `GradientExplainer`:该方法基于积分梯度的扩展([https://arxiv.org/abs/1703.01365](https://arxiv.org/abs/1703.01365))。

例如，我们将给出一个将 SHAP 应用于 TF 模型的极简代码示例。完整的细节可以在 https://shap-lrjball.readthedocs.io/en/latest/index.html 的官方文档中找到:

```

import shap

# initialize visualization

shap.initjs()

model = … # tf.keras model or PyTorch model (nn.Module) 

explainer = shap.KernelExplainer(model, sampled_data)

shap_values = explainer.shap_values(data, nsamples=300)

shap.force_plot(explainer.expected_value, shap_values, data)

shap.summary_plot(shap_values, sampled_data, feature_names=names, plot_type="bar")
```

对于 PyTorch 模型，您需要将您的模型包装在一个包装器中，以将输入和输出转换成正确的类型(`f=lambda x: model(torch.autograd.Variable(torch.from_numpy(x))).detach().numpy()`)。在前面的例子中，我们已经定义了`KernelExplainer`，它接受一个 DL 模型和`sampled_data`作为输入。接下来，我们使用`explainer.shap_values`函数计算 SHAP 值(Shapley 值的近似值)。在这个例子中，我们使用`300`扰动样本来估计给定预测的 SHAP 值。如果我们的`sampled_data`包含`100`示例，我们将执行 100*300 个模型评估。同样，你可以用`GradientExplainer` ( `shap.GradientExplainer(model, sampled_data)`)或者`DeepExplainer` ( `shap.DeepExplainer(model, sampled_data)`)。`sampled_data`的大小需要足够大以正确表示分布。在最后几行中，我们使用`shap.force_plot`功能在附加力布局中可视化 SHAP 值，使用`shap.summary_plot`功能创建全局模型解释图。

现在，让我们看看石灰法。

## 本地可解释的模型不可知解释(LIME)

LIME 是一种训练本地代理模型来解释模型预测的方法。首先，你需要准备一个你想要解读的模型和一个样本。LIME 使用您的模型从一组扰动数据中收集预测，并将它们与原始样本进行比较，以分配相似性权重(如果预测与原始样本上的预测越接近，权重越高)。LIME 使用由相似性权重加权的特定数量的特征在采样数据上拟合本质上可解释的替代模型。最后，LIME 将代理模型解释视为您所选示例的黑盒模型的解释。要执行 LIME 分析，我们可以使用`lime`包([https://LIME-ml . readthedocs . io](https://lime-ml.readthedocs.io))。

让我们来看一个为 DL 模型设计的示例:

```

from lime.lime_tabular import LimeTabularExplainer as Lime

from matplotlib import pyplot as plt

expl = Lime(features, mode='classification', class_names=[0, 1])

# explain first sample

exp = expl.explain_instance(x[0], model.predict, num_features=5, top_labels=1)

# show plot

exp.show_in_notebook(show_table=True, show_all=False) 
```

在前面的例子中，我们使用了`LimeTabularExplainer`类。构造器接受训练集、特性、类名和模式类型(`'classification'`)。类似地，您可以通过提供`'regression'`模式类型来设置回归问题的时间。然后，通过展示五个最重要的特征及其影响，我们解释来自测试集的第一个预测(`x[0]`)。最后，我们从计算的时间解释生成一个图。

要记住的事情

a.模型可解释性和可解释性是可解释人工智能中的两个关键概念。

b.可解释人工智能中流行的模型不可知技术有 PFI、FI、SHAP 和 LIME。

c.PFI、FI 和 SHAP 是允许您在局部(单个样本)和全局(一组样本)水平上解释模型的方法。另一方面，LIME 侧重于单个样本和相应的模型预测。

在这一节中，我们解释了可解释人工智能的概念和四种最常见的技术:PFI、FI、SHAP 和 LIME。

# 总结

我们从超参数调优开始这一章。我们描述了用于超参数调优的三种基本搜索算法(网格搜索、随机搜索和贝叶斯优化)，并介绍了许多可以集成到项目中的工具。在我们列出的工具中，我们讨论了 Ray Tune，因为它支持分布式超参数调整，并实现了许多现成的最先进的搜索算法。

然后，我们讨论了可解释的人工智能。我们解释了最标准的技术(PFI、FI、SHAP 和 LIME)以及如何使用它们来找出模型的行为如何相对于数据集中的每个要素发生变化。

在下一章中，我们将把重点转向部署。我们将学习 ONNX，一种 ML 模型的开放格式，并了解如何将 TF 或 PyTorch 模型转换为 ONNX 模型。