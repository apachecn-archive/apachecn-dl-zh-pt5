<html><head/><body>





	

		<title>B18522_04</title>

		

	

	

		<div><h1 id="_idParaDest-84" class="chapter-number"><a id="_idTextAnchor087"/> 4</h1>

			<h1 id="_idParaDest-85"><a id="_idTextAnchor088"/>实验跟踪、模型管理和数据集版本化</h1>

			<p><a id="_idTextAnchor089"/>在这一章中，我们将介绍一套用于实验跟踪、模型管理和数据集版本化的有用工具，它可以让你有效地管理<strong class="bold">深度学习</strong> ( <strong class="bold"> DL </strong>)项目。我们将在本章中讨论的工具可以帮助我们跟踪许多实验并更有效地解释结果，这自然会导致运营成本的降低并加快开发周期。在本章结束时，你将拥有使用最流行工具的实践经验，并能够为你的项目选择合适的工具集。</p>

			<p>在本章中，我们将讨论以下主要话题:</p>

			<ul>

				<li>DL项目跟踪概述</li>

				<li>带权重和偏差的DL项目跟踪</li>

				<li>使用MLflow和DVC跟踪DL项目</li>

				<li>数据集版本化——超越权重和偏差、MLflow和DVC</li>

			</ul>

			<h1 id="_idParaDest-86"><a id="_idTextAnchor090"/>技术要求</h1>

			<p>你可以从本书的GitHub资源库下载本章的补充材料，网址为<a href="https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter_4">https://GitHub . com/packt publishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter _ 4</a>。</p>

			<h1 id="_idParaDest-87"><a id="_idTextAnchor091"/>DL项目跟踪概述</h1>

			<p><a id="_idTextAnchor092"/>训练DL模型是一个消耗大量时间和资源的迭代<a id="_idIndexMarker343"/>过程。因此，跟踪所有实验并一致地组织它们可以防止我们将时间浪费在不必要的操作上，例如在同一组数据上重复训练相似的模型。换句话说，拥有所有模型架构及其<a id="_idTextAnchor093"/>超参数集的完整记录，以及<a id="_idIndexMarker344"/>实验期间使用的数据版本，可以帮助我们从实验中得出正确的结论，这自然会导致项目成功。</p>

			<h2 id="_idParaDest-88"><a id="_idTextAnchor094"/>DL项目跟踪的组成部分</h2>

			<p><strong class="bold"> DL项目跟踪</strong>的基本<a id="_idIndexMarker345"/>组件是<strong class="bold">实验跟踪</strong>、<strong class="bold">模型管理</strong>和<strong class="bold">数据集版本</strong>。让我们详细看看每个组件。</p>

			<h3>实验跟踪</h3>

			<p>实验跟踪背后的概念很简单:存储每个实验的描述和动机，这样我们就不会为了同样的目的运行另一组实验。总的来说，有效的实验跟踪将节省我们的运营成本，并使我们能够从最少的实验结果中得出正确的结论。有效实验跟踪的基本方法之一是为每个实验添加一个唯一的标识符。我们需要为每个实验跟踪的信息包括项目依赖性、模型架构的定义、使用的参数和评估度量。实验跟踪还包括实时可视化正在进行的实验，并能够直观地比较一组实验。例如，如果我们可以在模型训练时检查每个时期的训练和验证损失，我们就可以更快地识别过度拟合，从而节省一些资源。此外，通过比较两个实验之间的结果和一组更改，我们可以了解这些更改如何影响模型性能。</p>

			<h3>模型管理</h3>

			<p>模型管理超越了<a id="_idIndexMarker348"/>实验跟踪，因为它<a id="_idIndexMarker349"/>覆盖了模型的整个生命周期:数据集信息、工件(从训练模型中生成的任何数据)、模型的实现、评估指标和管道信息(例如开发、测试、试运行和生产)。模型管理允许我们快速选择感兴趣的模型，并有效地设置模型的使用环境。</p>

			<h3>数据集版本化</h3>

			<p>DL项目跟踪<a id="_idIndexMarker350"/>的最后一个组件是数据集版本化。在许多项目中，数据集会随着时间而变化。更改可能来自数据模式(数据组织方式的蓝图)、文件位置，甚至来自应用于数据集<a id="_idIndexMarker351"/>的过滤器，这些过滤器操纵底层数据的含义。行业中发现的许多数据集以复杂的方式构建，并且通常以各种数据格式存储在多个位置。因此，变化可能比您预期的更剧烈，也更难跟踪。因此，记录变更对于在整个项目中重现一致的结果是至关重要的。</p>

			<p>数据集跟踪可以总结如下:当底层数据被修改时，存储为工件的数据集应该成为工件的新版本。话虽如此，每个工件都应该有元数据，元数据由数据集的重要信息组成:它是何时创建的，是谁创建的，以及它与以前的版本有何不同。</p>

			<p>例如，具有数据集版本控制的数据集应该用如下公式表示。数据集的名称中应该有时间戳:</p>

			<pre class="source-code">

dataset_&lt;timestamp&gt;

&gt; metadata.json

&gt; img1.png

&gt; img2.png

&gt; img3.png</pre>

			<p>如前所述，元数据应该包含关于数据集的关键信息:</p>

			<pre class="source-code">

{

   "created_by": "Adam"

   "created_on": "2022-01-01"

   "labelled_by": "Bob"

   "number_of_samples": 3

}</pre>

			<p>请注意，<a id="_idIndexMarker353"/>元数据跟踪的<a id="_idIndexMarker352"/>组信息对于每个项目可能是不同的。</p>

			<h2 id="_idParaDest-89"><a id="_idTextAnchor095"/>DL项目跟踪工具</h2>

			<p>DL跟踪可以通过多种方式<a id="_idIndexMarker354"/>实现，从文本文件中的简单笔记开始，通过电子表格，将信息保存在GitHub或专用网页中，到自建平台和外部工具。模型和数据工件可以按原样存储，或者可以应用更复杂的方法来避免冗余并提高效率。</p>

			<p>DL项目跟踪领域发展迅速，并且不断引入新的工具。因此，为底层项目选择合适的工具并不是一件容易的事情。我们必须考虑业务和技术约束。虽然定价模型是一个基本模型，但现有的开发环境可能会引入其他约束；集成现有工具应该很容易，并且基础设施必须易于维护。考虑MLOps团队的工程能力也很重要。话虽如此，当您为项目选择工具时，下面的列表将是一个很好的起点。</p>

			<ul>

				<li>tensor board(【https://www.tensorflow.org/tensorboard】):<ul><li>TensorFlow团队开发的开源可视化工具<a id="_idIndexMarker356"/></li><li>跟踪和<a id="_idIndexMarker357"/>可视化实验结果的标准工具</li></ul></li>

				<li>权重与偏差(<a href="https://wandb.ai/site/experiment-tracking"> https://wandb.ai </a>):<ul><li>一个基于云的服务<a id="_idIndexMarker358"/>带有一个<a id="_idIndexMarker359"/>有效的交互式仪表盘，用于可视化和组织实验结果</li><li>服务器可以在本地运行，也可以托管在私有云中</li><li>它提供了自动<a id="_idIndexMarker360"/>超参数调整功能，称为扫描</li><li>个人<a id="_idIndexMarker361"/>项目免费。定价基于跟踪时间和存储空间</li></ul></li>

				<li>海王星(<a href="https://neptune.ai/product"> https://neptune.ai </a>):<ul><li>用于<a id="_idIndexMarker362"/>监控和存储来自<a id="_idIndexMarker363"/>机器学习(ML)实验的工件的在线工具</li><li>它可以很容易地与其他ML工具集成</li><li>它以强大的仪表盘闻名，可以实时总结实验</li></ul></li>

				<li>https://mlflow.org:<ul><li>一个提供端到端ML生命周期管理的开源平台</li><li>它支持Python和基于R的系统。通常<a id="_idIndexMarker368"/>与<strong class="bold">数据版本控制</strong> ( <strong class="bold"> DVC </strong>)结合使用</li></ul></li>

				<li>萨格马克工作室(<a href="https://aws.amazon.com/sagemaker/studio/">https://aws.amazon.com/sagemaker/studio/</a>):<ul><li>基于网络的<a id="_idIndexMarker369"/>可视化界面，用于管理使用SageMaker设置的ML实验<a id="_idIndexMarker370"/></li><li>该工具通过提供与AWS其他有用功能的简单集成，允许用户高效地构建、训练和部署模型</li></ul></li>

				<li>库伯弗洛(【https://www.kubeflow.org】T4):<ul><li>Google设计的一个开源平台<a id="_idIndexMarker371"/>用于端到端的ML编排<a id="_idIndexMarker372"/>和管理</li><li>它也是为高效地将ML系统部署到各种开发和生产环境而设计的</li></ul></li>

				<li>瓦罗海(<a href="https://valohai.com/product/">https://valohai.com</a>):<ul><li>设计用于自动机器<a id="_idIndexMarker375"/>编排、版本控制和数据<a id="_idIndexMarker376"/>流水线管理的DL管理平台<a id="_idIndexMarker374"/></li><li>它不是自由软件，因为它是为企业设计的</li><li>它因不依赖技术和拥有响应迅速的支持团队而越来越受欢迎</li></ul></li>

			</ul>

			<p>在各种工具中，我们<a id="_idIndexMarker377"/>将涵盖两个最常用的设置:权重&amp;偏差和MLflow结合DVC。</p>

			<p class="callout-heading">要记住的事情</p>

			<p class="callout">a.DL跟踪的基本组件是实验跟踪、模型管理和数据集版本控制。最近的DL跟踪工具通常具有总结实验结果的用户友好的仪表板。</p>

			<p class="callout">b.该领域正在发展，有许多具有不同优势的工具。选择正确的工具需要了解业务和技术约束。</p>

			<p>首先，我们来看看用<strong class="bold">权重&amp;偏差</strong> ( <strong class="bold"> W &amp; B </strong>)进行的DL项目跟踪。</p>

			<h1 id="_idParaDest-90"><a id="_idTextAnchor096"/>带权重的DL项目跟踪&amp;偏差</h1>

			<p>W&amp;B是一个实验性的<a id="_idIndexMarker378"/>管理平台，为模型和数据提供<a id="_idIndexMarker379"/>版本控制。</p>

			<p>W&amp;B提供了一个交互式仪表板，可以嵌入到Jupyter笔记本电脑中，也可以用作独立的网页。简单的Python API也为简单的集成提供了可能性。此外，其功能集中于简化DL实验管理:记录和监控模型和数据版本、超参数值、评估指标、工件和<a id="_idIndexMarker380"/>其他相关信息。</p>

			<p>W&amp;B的另一个有趣的功能是它的<a id="_idIndexMarker381"/>内置超参数<a id="_idIndexMarker382"/>搜索功能，称为<strong class="bold">扫描</strong>(<a href="https://docs.wandb.ai/guides/sweeps">https://docs.wandb.ai/guides/sweeps</a>)。使用Python API可以很容易地设置扫描，并且可以在web页面上交互地比较结果和模型。</p>

			<p>最后，W&amp;B会自动为您创建报告，直观地总结和组织一组实验(<a href="https://docs.wandb.ai/guides/reports">https://docs.wandb.ai/guides/reports</a>)。</p>

			<p>总体而言，W &amp; B的关键<a id="_idIndexMarker383"/>功能可总结如下:</p>

			<ul>

				<li><strong class="bold">实验跟踪与管理</strong></li>

				<li><strong class="bold">神器管理</strong></li>

				<li><strong class="bold">模型评估</strong></li>

				<li><strong class="bold">模型优化</strong></li>

				<li><strong class="bold">协同分析</strong></li>

			</ul>

			<p>W&amp;B是一项基于订阅的服务，但个人账户是免费的。</p>

			<h2 id="_idParaDest-91"><a id="_idTextAnchor097"/>设置W &amp; B</h2>

			<p>W&amp;B有一个Python API，<a id="_idIndexMarker384"/>为很多DL框架提供了简单的集成方法，包括TensorFlow和PyTorch。记录的信息，例如项目、团队和运行列表，可以在线或在自托管服务器上管理和查看。</p>

			<p>设置W&amp;B的第一步是安装Python API并登录W&amp;B服务器。您必须事先通过<a href="https://wandb.ai"> https://wandb.ai </a>创建一个账户<a id="_idIndexMarker385"/>:</p>

			<pre>pip install wandb
wandb login</pre>

			<p>在您的Python代码中，您可以通过以下代码行注册一个名为<code>run-1</code>的实验:</p>

			<pre class="source-code">

import wandb

run_1 = wandb.init(project="example-DL-Book", name="run-1") </pre>

			<p>更准确地说，<code>wandb.init</code>函数<a id="_idIndexMarker386"/>在一个名为<code>example-DL-Book</code>的项目中创建了一个名为<code>run_1</code>的新的<code>wandb.Run</code>实例。如果没有提供名字，W &amp; B会为你随机生成一个两个字的名字。如果项目名称为空，W &amp; B会将您的跑步记录放入<code>Uncategorized</code>项目中。<code>wandb.init</code>的所有参数都在<a href="https://docs.wandb.ai/ref/python/init">https://docs.wandb.ai/ref/python/init</a>中列出，但我们想介绍您最常与之交互的参数:</p>

			<ul>

				<li><code>id</code>为您的跑步设置唯一的ID</li>

				<li><code>resume</code>允许您在不创建新运行的情况下恢复实验</li>

				<li><code>job_type</code>允许您将跑步分配到特定类型，如训练、测试、验证、探索或任何其他可用于对跑步分组的名称</li>

				<li><code>tags</code>让您更加灵活地组织跑步</li>

			</ul>

			<p>当<code>wandb.init</code>功能被触发时，关于运行的信息将开始出现在W &amp; B仪表板上。您可以在W &amp; B网页上或直接在Jupyter笔记本环境中监控仪表板，如以下截图所示:</p>

			<div><div><img src="img/B18522_02_01.jpg" alt="Figure 4.1 – The W&amp;B dashboard inside a Jupyter notebook environment&#13;&#10;"/>

				</div>

			</div>

			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图4.1–Jupyter笔记本电脑环境中的W&amp;B仪表板</p>

			<p>当运行被创建时，你<a id="_idIndexMarker387"/>可以开始记录信息；<code>wandb.log</code>功能允许您记录任何想要的数据。例如，您可以通过在训练循环中添加<code>wandb.log({"custom_loss": custom_loss})</code>来记录训练过程中的损耗。类似地，您可以记录验证失败和任何其他想要跟踪的详细信息。</p>

			<p>有趣的是，W&amp;B通过为DL模型提供内置的日志功能，使得这个过程更加简单。在撰写本文时，您可以找到大多数框架的集成，包括Keras、PyTorch、PyTorch Lightning、TensorFlow、fast.ai、scikit-learn、SageMaker、Kubeflow、Docker、Databricks和Ray Tune(详细信息请参见<a href="https://docs.wandb.ai/guides/integrations">https://docs.wandb.ai/guides/integrations</a>)。</p>

			<p><code>wandb.config</code>是追踪模型超参数的绝佳地点。对于实验中的任何工件，您可以使用<code>wandb.log_artifact</code>方法(更多细节，请参见s<a id="_idTextAnchor098"/>ee<a href="https://docs.wandb.ai/guides/artifacts">https://docs.wandb.ai/guides/artifacts</a>)。在记录工件时，您需要定义一个文件路径，然后分配工件的名称和类型，如下面的<a id="_idIndexMarker388"/>代码片段所示:</p>

			<pre class="source-code">

wandb.log_artifact(file_path, name='new_artifact', type='my_dataset')</pre>

			<p>然后，您可以重用已经存储的工件，如下所示:</p>

			<pre class="source-code">

run = wandb.init(project="example-DL-Book")

artifact = run.use_artifact('example-DL-Book/new_artifact:v0', type='my_dataset')

artifact_dir = artifact.download()</pre>

			<p>到目前为止，您已经学习了如何为您的项目设置<code>wandb</code>,并在整个培训中单独记录您选择的度量和工件。有趣的是，<code>wandb</code>为很多DL框架提供了自动日志记录。在这一章中，我们将详细了解Keras和<strong class="bold"> PyTorch照明</strong> ( <strong class="bold"> PL </strong>)的W &amp; B集成。</p>

			<h3>将W&amp;B集成到Keras项目中</h3>

			<p>在Keras的例子中，集成可以通过<code>WandbCallback</code>类<a id="_idIndexMarker390"/>实现<a id="_idIndexMarker389"/>。完整版本可以在本书的GitHub资源库中找到:</p>

			<pre class="source-code">

import wandb

from wandb.keras import WandbCallback

from tensorflow import keras

from tensorflow.keras import layers

wandb.init(project="example-DL-Book", name="run-1")

wandb.config = {

   "learning_rate": 0.001,

   "epochs": 50,

   "batch_size": 128

}

model = keras.Sequential()

logging_callback = WandbCallback(log_evaluation=True)

model.fit(

   x=x_train, y=y_train,

   epochs=wandb.config['epochs'],

   batch_size=wandb.config['batch_size'], 

   verbose='auto', 

   validation_data=(x_valid, y_valid),

   callbacks=[logging_callback])</pre>

			<p>如<a id="_idIndexMarker391"/>上一节所述，关于车型的关键信息<a id="_idIndexMarker392"/>被记录下来，并在W &amp; B仪表板上可用。您可以监控损失、评估指标和超参数。<em class="italic">图4.2 </em>显示了W &amp; B通过前面的代码自动生成的样图:</p>

			<div><div><img src="img/B18522_04_02.jpg" alt="Figure 4.2 – Sample plots generated by W&amp;B from logged metrics&#13;&#10;"/>

				</div>

			</div>

			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">  </p>

			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图4.2–W &amp; B根据记录的指标生成的样本图</p>

			<p>将W&amp;B整合到PL <a id="_idIndexMarker393"/>项目中类似于将W &amp; B整合到Keras项目中。</p>

			<h3>将W&amp;B整合到PyTorch闪电项目中</h3>

			<p>对于一个基于PL的项目，W&amp;B提供了一个<a id="_idIndexMarker395"/>定制日志<a id="_idIndexMarker396"/>并隐藏了大部分样板代码。您需要做的就是实例化<code>WandbLogger</code>类，并通过<code>logger</code>参数将其传递给<code>Trainer</code>实例:</p>

			<pre class="source-code">

import pytorch_lightning as pl

from pytorch_lightning.loggers import WandbLogger

wandb_logger = WandbLogger(project="example-DL-Book")

trainer = Trainer(logger=wandb_logger)

class LitModule(LightningModule):

   def __init__(self, *args, **kwarg):

       self.save_hyperparameters()

   def training_step(self, batch, batch_idx):

       self.log("train/loss", loss)</pre>

			<p>关于整合的详细解释可以在<a href="https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html">https://py torch-lightning . readthedocs . io/en/stable/extensions/generated/py torch _ lightning . loggers . wandblogger . html</a>找到。</p>

			<p class="callout-heading">要记住的事情</p>

			<p class="callout">a.W&amp;B是一个实验管理平台，帮助跟踪不同版本的模型和数据。它还支持存储配置、超参数、数据和模型工件，同时提供实时实验跟踪。</p>

			<p class="callout">b.W&amp;B很容易建立。它为许多DL框架提供了内置的集成特性，包括TensorFlow和PyTorch。</p>

			<p class="callout">c.W&amp;B可用于执行超参数调整/模型优化。</p>

			<p>虽然W&amp;B已经<a id="_idIndexMarker397"/>主导了DL项目跟踪的<a id="_idIndexMarker398"/>领域，但MLflow和DVC的结合是DL项目的另一种流行设置。</p>

			<h1 id="_idParaDest-92"><a id="_idTextAnchor099"/>使用MLflow和DVC跟踪DL项目</h1>

			<p>MLflow是一个流行的框架，<a id="_idIndexMarker399"/>支持跟踪技术<a id="_idIndexMarker400"/>依赖、模型参数、度量和工件。MLflow的关键组件如下:</p>

			<ul>

				<li><strong class="bold">跟踪</strong>:每次模型运行时跟踪<a id="_idIndexMarker401"/>结果变化</li>

				<li><strong class="bold">项目</strong>:它以可复制的方式打包模型<a id="_idIndexMarker402"/>代码</li>

				<li><strong class="bold">模型</strong>:组织模型工件<a id="_idIndexMarker403"/>以方便将来的部署</li>

				<li><strong class="bold">模型注册中心</strong>:它管理一个MLflow模型的整个生命周期<a id="_idIndexMarker404"/></li>

				<li><strong class="bold">插件</strong> : <a id="_idIndexMarker405"/>它提供了灵活的插件，可以很容易地与其他DL框架集成</li>

			</ul>

			<p>你可能已经注意到了，W &amp; B和MLflow有一些相似之处。然而，在MLflow中，每个实验都与一组Git提交相关联。Git并不阻止我们保存数据集，但是当数据集很大时，它显示出许多限制，即使有为大文件构建的扩展(Git LFS)。因此，MLflow通常<a id="_idIndexMarker407"/>与解决Git局限性的<a id="_idIndexMarker408"/>开源版本控制系统DVC相结合。</p>

			<h2 id="_idParaDest-93"><a id="_idTextAnchor100"/>设置MLflow</h2>

			<p>MLflow可以使用<code>pip</code>安装<a id="_idIndexMarker409"/>:</p>

			<pre>pip install mlflow</pre>

			<p>与W&amp;B类似，MLflow也提供了一个Python API，允许您跟踪超参数(<code>log_param</code>)、评估指标(<code>log_metric</code>)和工件(<code>log_artifacts</code>):</p>

			<pre class="source-code">

import os

import mlflow

from mlflow import log_metric, log_param, log_artifacts

log_param("epochs", 30)

log_metric("custom", 0.6)

log_metric("custom", 0.75) # metrics can be updated

if not os.path.exists("artifact_dir"):

   os.makedirs("artifact_dir")

with open("artifact_dir/test.txt", "w") as f:

   f.write("simple example")

log_artifacts("artifact_dir")</pre>

			<p>实验<a id="_idIndexMarker410"/>定义可以用以下代码初始化和标记:</p>

			<pre class="source-code">

exp_id = mlflow.create_experiment("DLBookModel_1")

exp = mlflow.get_experiment(exp_id)

with mlflow.start_run(experiment_id=exp.experiment_id, run_name='run_1') as run:

   # logging starts here

   mlflow.set_tag('model_name', 'model1_dev')</pre>

			<p>MLflow已经提供了一套介绍其API的教程:<a href="https://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.html">https://www . ml flow . org/docs/latest/tutorials-and-examples/tutorial . html</a>。</p>

			<p>现在您已经熟悉了MLflow的基本用法，我们将描述它如何集成到Keras和PL项目中。</p>

			<h3>将MLflow集成到Keras项目中</h3>

			<p>首先，我们来看看Keras <a id="_idIndexMarker411"/>集成。使用MLflow记录<a id="_idIndexMarker412"/> Keras模型的细节可以通过<code>log_model</code>函数实现:</p>

			<pre class="source-code">

history = keras_model.fit(...)

mlflow.keras.log_model(keras_model, model_dir)</pre>

			<p><code>mlflow.keras</code>和<code>mlflow.tensorflow</code>模块提供了一组API，分别用于记录关于Keras和TensorFlow模型的各种信息。更多详情，请查看<a href="https://www.mlflow.org/docs/latest/python_api/index.html">https://www.mlflow.org/docs/latest/python_api/index.html</a>。</p>

			<h3>将MLflow集成到PyTorch Lightning项目中</h3>

			<p>类似于W&amp;B如何支持<a id="_idIndexMarker413"/> PL项目，MLflow也提供了一个<code>MLFlowLogger</code>类。这可以传递给一个<code>Trainer</code>实例，用于记录MLflow中的模型细节:</p>

			<pre class="source-code">

import pytorch_lightning as pl 

from pytorch_lightning import Trainer

from pytorch_lightning.loggers import MLFlowLogger

mlf_logger = MLFlowLogger(experiment_name="example-DL-Book ", tracking_uri="file:./ml-runs")

trainer = Trainer(logger=mlf_logger)

class DLBookModel(pl.LightningModule):

   def __init__(self):

       super(DLBookModel, self).__init__()

       ...

   def training_step(self, batch, batch_nb):

       loss = self.log("train_loss", loss, on_epoch=True)</pre>

			<p>在前面的代码中，我们传递了一个<code>MLFlowLogger</code>的实例来替换PL的默认记录器。<code>tracking_uri</code>参数控制记录数据的去向。</p>

			<p>关于PyTorch集成的其他细节可以在官网找到:<a href="https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.loggers.mlflow.html">https://py torch-lightning . readthe docs . io/en/stable/API/py torch _ lightning . loggers . ml flow . html</a>。</p>

			<h2 id="_idParaDest-94"><a id="_idTextAnchor101"/>使用DVC设置MLflow</h2>

			<p>要使用DVC来管理<a id="_idIndexMarker415"/>大型数据集，您需要使用<a id="_idIndexMarker416"/> packag <a id="_idTextAnchor102"/> e管理器来安装它，例如<code>pip</code>、<code>conda</code>或<code>brew</code>(针对macOS用户):</p>

			<pre>pip install dvc</pre>

			<p>所有的安装选项都可以在<a href="https://dvc.org/doc/install/">https://dvc.org/doc/install</a>找到。</p>

			<p>使用DVC管理数据集<a id="_idIndexMarker417"/>需要一组以特定顺序执行的命令:</p>

			<ol>

				<li>第一步是用DVC建立一个Git存储库:<pre><strong class="bold">git init</strong> <strong class="bold">dvc init</strong> <strong class="bold">git commit -m 'initialize repo'</strong></pre></li>

				<li>现在，我们需要为DVC配置远程存储:<pre><strong class="bold">dvc remote add -d myremote /tmp/dvc-storage</strong> <strong class="bold">git commit .dvc/config -m "Added local remote storage"</strong></pre></li>

				<li>让我们创建一个示例数据目录，并用一些示例数据填充它:<pre><strong class="bold">mkdir data</strong> <strong class="bold">cp example_data.csv data/</strong></pre></li>

				<li>在这个阶段，我们<a id="_idIndexMarker418"/>准备好开始跟踪数据集。我们只需要将我们的文件添加到DVC。此操作将创建一个附加文件<code>example_data.csv.dvc</code>。此外，<code>example_data.csv</code>文件会自动添加到<code>.gitignore</code>中，这样Git就不再跟踪原始文件:<pre><strong class="bold">dvc add data/example_data.csv</strong></pre></li>

				<li>接下来，您需要提交并上传<code>example_data.csv.dvc</code>和<code>.gitignore</code>文件。我们将第一个数据集标记为<code>v1</code> : <pre><strong class="bold">git add data/.gitignore data/example_data.csv.dvc</strong> <strong class="bold">git commit -m 'data tracking'</strong> <strong class="bold">git tag -a 'v1' -m 'test_data'</strong> <strong class="bold">dvc push</strong></pre></li>

				<li>使用<code>dvc push</code>命令后，我们的数据将在远程存储上可用。这意味着我们可以删除本地版本。要恢复<code>example_data.csv</code>，只需调用<code>dvc pull</code> : <pre><strong class="bold">dvc pull data/example_data.csv.dvc</strong></pre></li>

				<li>当<code>example_data.csv</code>被修改时，我们<a id="_idIndexMarker421"/>需要添加并再次推送以更新远程存储上的版本。我们将修改后的数据集标记为<code>v2</code> : <pre><strong class="bold">dvc add data/example_data.csv</strong> <strong class="bold">git add data/example_data.csv.dvc</strong> <strong class="bold">git commit -m 'data modification description'</strong> <strong class="bold">git tag -a 'v2' -m 'modified test_data'</strong> <strong class="bold">dvc push</strong></pre></li>

			</ol>

			<p>执行这些命令后，Git和DVC将会跟踪同一个数据集的两个版本:<code>v1</code>和<code>v2</code>。</p>

			<p>接下来，我们来看看MLflow如何与DVC结合:</p>

			<pre class="source-code">

import mlflow

import dvc.api

import pandas as pd

data_path='data/example_data.csv'

repo='/Users/BookDL_demo/'

version='v2'

data_url=dvc.api.get_url(path=path, repo=repo, rev=version)

# this will fetch the right version of our data file

data = pd.read_csv(data_url)

# log important information using mlflow

mlflow.start_run()

mlflow.log_param("data_url", data_url)

mlflow.log_artifact(...)</pre>

			<p>在前面的<a id="_idIndexMarker422"/>代码片段中，<code>mlflow.log_artifact</code>用于保存实验中特定列的信息。</p>

			<p>总的来说，我们可以通过MLflow用DVC跟踪的数据集的不同版本运行多个<a id="_idIndexMarker423"/>实验。与W &amp; B类似，MLflow也提供了一个网页，我们可以在那里比较我们的实验。您只需要在终端中键入以下命令:</p>

			<pre>mlflow ui </pre>

			<p>该命令将启动一个web服务器，该服务器在<a href="http://127.0.0.1:5000"> http://127.0.0.1:5000 </a>上托管一个网页。以下屏幕截图显示了MLflow仪表板:</p>

			<div><div><img src="img/B18522_04_03.jpg" alt="Figure 4.3 – The MLflow dashboard; new runs will be populated at the bottom of the page&#13;&#10;"/>

				</div>

			</div>

			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">图4.3–ml flow仪表板；新运行将在页面底部填充</p>

			<p class="callout-heading">要记住的事情</p>

			<p class="callout">a.MLflow可以跟踪依赖关系、模型参数、度量和工件。它通常与DVC结合使用，以实现高效的数据集版本控制。</p>

			<p class="callout">b.MLflow可以很容易地与DL框架集成，包括Keras、TensorFlow和PyTorch。</p>

			<p class="callout">c.MLflow提供了一个交互式的可视化界面，可以同时分析多个实验。</p>

			<p>到目前为止，我们已经学习了如何在W &amp; B和MLflow和<a id="_idIndexMarker425"/> DVC管理DL项目。在下一节中，我们将介绍流行的数据集版本化工具。</p>

			<h1 id="_idParaDest-95"><a id="_idTextAnchor103"/>数据集版本化–超越权重&amp;偏差、MLflow和DVC</h1>

			<p>在这一章中，我们已经看到了DL项目跟踪工具是如何管理数据集的。在W&amp;B的情况下，我们可以使用工件，而在MLflow和DVC的情况下，DVC运行在Git存储库之上，以跟踪数据集的不同版本，从而解决Git的局限性。</p>

			<p>对于数据集版本控制，还有其他有用的方法和/或工具吗？简单的答案是肯定的，但是更精确的答案取决于上下文。要做出正确的选择，您必须考虑各个方面，包括成本、易用性和集成难度。在本节中，我们将提到几个工具，如果数据集版本化是您项目的<a id="_idIndexMarker426"/>关键组件之一，我们认为这些工具是值得探索的:</p>

			<ul>

				<li><strong class="bold">Neptune</strong>(<a href="https://docs.neptune.ai/">https://docs . Neptune . ai</a>)是MLOps的元数据存储。Neptune工件允许对本地存储的<a id="_idIndexMarker427"/>数据集或云中存储的<a id="_idIndexMarker428"/>数据集进行版本控制。</li>

				<li><strong class="bold">Delta Lake</strong>(<a href="https://delta.io/">https://Delta . io</a>)是一个开源的<a id="_idIndexMarker429"/>存储抽象，它在数据湖之上运行<a id="_idIndexMarker430"/>。Delta Lake使用Apache Spark APIs，并使用分布式处理来提高吞吐量和效率。</li>

			</ul>

			<p class="callout-heading">要记住的事情</p>

			<p class="callout">a.市场上有许多数据版本化工具。要选择正确的工具，您必须考虑各个方面，包括成本、易用性和集成难度。</p>

			<p class="callout">b.W&amp;B、MLflow、DVC、Neptune和Delta Lake等工具可以帮助您进行数据集版本化。</p>

			<p>因此，我们引入了流行的数据集版本化工具。合适的工具因项目而异。因此，在将一个工具集成到您的项目中之前，您必须评估每个工具的优缺点。</p>

			<h1 id="_idParaDest-96"><a id="_idTextAnchor104"/>总结</h1>

			<p>由于DL项目涉及许多训练模型和评估的迭代，有效地管理实验、模型和数据集可以帮助团队更快地达到目标。在这一章中，我们看了两个最流行的DL项目跟踪设置:W&amp;B和与DVC集成的MLflow。这两种设置都提供了对Keras和PL的内置支持，这是两种最流行的DL框架。我们还花了一些时间描述更加强调数据集版本化的工具:Neptune和Delta Lake。请记住，您必须彻底评估每个工具，以便为您的项目选择正确的工具。</p>

			<p>至此，您已经熟悉了构建概念证明和培训必要的DL模型的框架和流程。从下一章开始，我们将讨论如何通过将DL管道的单个组件迁移到云中来实现纵向扩展。</p>

		</div>

	



</body></html>