

# 十二、在生产中监控深度学习端点

由于开发和生产设置的差异，**深度学习** ( **DL** )模型一旦部署，很难保证其性能。如果模型行为中存在任何差异，必须在合理的时间内捕获；否则，它会对下游应用产生负面影响。

在这一章中，我们的目标是解释在生产中监控 DL 模型行为的现有解决方案。我们将首先清楚地描述监控的好处，以及保持整个系统稳定运行需要做些什么。然后，我们将讨论用于监控 DL 模型和警报的流行工具。在我们介绍的各种工具中，我们会用 **CloudWatch** 来弄脏自己的手。我们将从 CloudWatch 的基础知识开始，讨论如何将 CloudWatch 集成到运行在 **SageMaker** 和**Elastic Kubernetes Service**(**EKS**)集群上的端点中。

在本章中，我们将讨论以下主要话题:

*   生产中的 DL 终点监控简介
*   使用 CloudWatch 进行监控
*   使用 CloudWatch 监控 SageMaker 端点
*   使用 CloudWatch 监控 EKS 端点

# 技术要求

你可以从本书的 GitHub 资源库下载本章的补充资料:[https://GitHub . com/packt publishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter _ 12](https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter_12)

# 生产中的 DL 终点监控简介

我们将从开始本章，描述 DL 模型监控对已部署端点的好处。理想情况下，我们应该分析与传入数据、传出数据、模型度量和流量相关的信息。监控所列数据的系统可以为我们提供以下好处。

首先，*模型的输入和输出信息可以保存在数据存储解决方案中(例如，一个简单的存储服务(S3)桶),以便理解数据分布*。对输入数据和预测的详细分析有助于确定下游流程的潜在改进。例如，监控传入的数据可以帮助我们识别模型预测中的偏差。在处理传入的请求时，模型可以偏向特定的功能组。这些信息可以指导我们在为下面的部署训练新模型时应该考虑什么。另一个好处来自模型的可解释性。出于商业或法律目的，需要解释模型预测背后的推理。这涉及到我们在第九章[](B18522_09.xhtml#_idTextAnchor187)**中描述的技术，扩展深度学习管道*。*

 *我们应该跟踪的另一个关键指标是终端的**吞吐量**，这可以帮助我们提高用户满意度。*模型的行为可能会根据传入请求的数量和底层机器的计算能力而变化*。我们可以监控传入流量的推理延迟，为用户构建稳定高效的推理端点。

在高层次上，对 DL 模型的监控可以分为两个区域:**端点监控**和**模型监控**。在前一个领域，我们的目标是收集与目标端点的端点延迟和吞吐量相关的数据。后一个领域侧重于提高模型性能；我们需要收集输入数据、预测和模型性能，以及推理延迟。虽然模型监控的许多用例是在运行端点上以在线方式实现的，但它也以离线方式应用于培训和验证过程，目的是在部署之前了解模型的行为。

在下一节中，我们将介绍用于监控 DL 模型的流行工具。

## 探索监控工具

监控工具根据其设计用途主要可以分为两类:**监控工具**和**告警工具**。明确涵盖所有工具超出了本书的范围；然而，我们将简要介绍其中的几个，以解释监控和警报工具旨在提供的好处。请注意，边界通常不清楚，可能会构建一些工具来支持这两种功能。

让我们先来看看监控工具。

### 普罗米修斯

**Prometheus** 是一款开源的监控和报警工具( [https://prometheus.io](https://prometheus.io/) )。普罗米修斯将应用程序发送的数据存储在本地存储器中。它使用一个时序数据库来存储、聚集和检索指标，这与监控任务的性质非常一致。与 Prometheus 交互涉及使用 **Prometheus 查询语言**(**PromQL**)([https://Prometheus . io/docs/Prometheus/latest/Query/basics](https://prometheus.io/docs/prometheus/latest/querying/basics/))。Prometheus 旨在处理指标，如中央处理器**、** ( **CPU** )使用率、内存使用率和延迟。此外，可以获取模型性能或传入和传出数据的分布等自定义指标进行监控。

### 云观察

**CloudWatch** 是由**亚马逊网络服务**(**AWS**)([https://aws.amazon.com/cloudwatch](https://aws.amazon.com/cloudwatch/))设计的监控和可观测性服务。与设置专用的 Prometheus 服务相比，CloudWatch 易于设置，因为它在后台处理数据存储管理。默认情况下，大多数 AWS 服务(如 AWS Lambda 和 EKS 集群)使用 CloudWatch 来保存指标以供进一步分析。此外，CloudWatch 可以支持通过电子邮件或 Slack 消息向用户发出警报，提醒他们所监控指标的异常变化。例如，您可以为指标设置一个阈值，当它高于或低于预定义的阈值时，您会收到通知。有关警报功能的详细信息，请访问[https://docs . AWS . Amazon . com/Amazon cloud watch/latest/monitoring/alarmthatsendsemail . html](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html)。

### 格拉夫纳

**Grafana** 是一个流行的工具，设计用于可视化从监控工具([https://grafana.com](https://grafana.com/))收集的指标。Grafana 可以读取来自 CloudWatch 或 AWS 管理的 Prometheus 的指标数据进行可视化。有关这些配置的完整描述，我们建议您阅读[https://grafana . com/docs/grafana/latest/data sources/AWS-cloud watch](https://grafana.com/docs/grafana/latest/datasources/aws-cloudwatch/)和[https://docs . AWS . Amazon . com/Prometheus/latest/user guide/AMP-on board-query-standalone-grafana . html](https://docs.aws.amazon.com/prometheus/latest/userguide/AMP-onboard-query-standalone-grafana.html)。

### 数据狗

一个流行的专有解决方案是**Datadog**(【https://www.datadoghq.com】T2)。这个工具提供了广泛的监控特性:日志监控、应用程序性能监控、网络流量监控和实时用户监控。

### SageMaker 澄清

SageMaker 内置了对从 SageMaker 创建的监控端点的支持，**sage maker Clarify**([https://aws.amazon.com/sagemaker/clarify](https://aws.amazon.com/sagemaker/clarify/))。SageMaker Clarify 带有一个**软件开发包** ( **SDK** )，它有助于理解模型的性能及其在预测中的偏差。有关 SageMaker Clarify 的详细信息，请访问[https://docs . AWS . Amazon . com/sage maker/latest/DG/model-monitor . html](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html)。

在下一节中，我们将介绍警报工具。

## 探索警报工具

*事件*是需要后续行动的事件，例如失败的工作或构建。虽然监控工具可以捕捉异常变化，但它们通常缺乏事件管理和响应流程的自动化。警报工具通过提供许多现成的功能填补了这一空白。因此，许多公司经常集成明确的警报工具，以便及时响应事件。

在本节中，我们将介绍两个最流行的警报工具:PagerDuty 和 Dynatrace。

### 寻呼机关税

作为警报和管理**事件响应** ( **IR** )过程的工具，许多 compa[nie 集成了**page duty**](https://www.pagerduty.com/)([https://www.pagerduty.com](https://www.pagerduty.com/))。在基本警报功能的基础上，PagerDuty 支持根据事件的类型和严重性为其分配优先级。page duty 可以从 Prometheus 和 Datadog 等几个流行的监控软件[中读取数据(https://AWS . Amazon . com/blogs/mt/using-Amazon-managed-service-for-Prometheus-alert-manager-to-re](https://aws.amazon.com/blogs/mt/using-amazon-managed-service-for-prometheus-alert-manager-to-receive-alerts-with-pagerduty/)receive-alerts-with-page duty)。也可以通过最小的代码改动([https://support . page duty . com/docs/AWS-cloud watch-integration-guide](https://support.pagerduty.com/docs/aws-cloudwatch-integration-guide))与 CloudWatch 集成。

### Dynatrace

**Dynatrace** 是另一个专有工具，用于监控整个集群或网络[并向包括](https://www.dynatrace.com/)nts([https://www.dynatrace.com](https://www.dynatrace.com/))在内的所有网络发出警报。与资源使用、流量和运行进程的响应时间相关的信息可以很容易地被监控。Dynatrace 有一个基于警报配置文件的独特警报系统。这些配置文件定义了系统如何在整个组织内发送通知。Dynatrace 具有内置的推送通知，但它可以与提供通知功能的其他系统集成，如 Slack 和 PagerDuty。

要记住的事情

a.监控与端点的传入数据、传出数据、模型指标和流量相关的信息，可以让我们了解端点的行为，并帮助我们确定潜在的改进。

b.Prometheus 是一个开源的监控和警报系统，可用于监控 DL 端点的指标。CloudWatch 是 AWS 的一项监控服务，旨在记录一组数据并跟踪进出流量的异常变化。

c.PagerDuty 是一种流行的警报工具，可以处理事件的整个生命周期。

在这一节中，我们研究了为什么需要监控 DL 端点，并提供了可用工具的列表。在本章的剩余部分，我们将详细介绍最常见的监控工具 CloudWatch，因为它已经很好地集成到 AWS 的大多数服务中(例如 SageMaker)。

# 使用 CloudWatch 进行监控

首先，我们将介绍 CloudWatch 中的几个关键概念:日志、指标、警报和仪表板。 **CloudWatch** 以日志或由时间戳组织的指标的形式持久保存摄取的数据。顾名思义，*日志*指的是贯穿程序生命周期的文本数据。另一方面，*指标*表示有组织的数字数据，比如 CPU 或内存利用率。由于指标是以有组织的方式存储的，CloudWatch 支持聚合指标并从收集的数据中创建直方图。如果目标指标出现异常变化，可设置*警报*向报警。此外，可以设置一个*仪表板*来直观地查看所选指标和发出的警报。

在下面的例子中，我们将描述如何使用来自`boto3`库的 CloudWatch 服务客户端记录度量数据。指标数据以字典的形式组织，由指标名称、维度和值组成。维度的概念是捕捉关于指标的事实信息。例如，指标名称 city 的值可以是纽约市。然后，维度可以捕获特定的信息，如每小时的火灾或盗窃次数:

```

import boto3

# create CloudWatch client using boto3 library

cloudwatch = boto3.client('cloudwatch')

# metrics data to ingest

data_metrics=[

    {

       'MetricName': 'gross_merchandise_value',

       'Dimensions': [

          {

             'Name': 'num_goods_sold',

             'Value': '369'

          } ],

       'Unit': 'None',

       'Value': 900000.0

    } ]

# ingest the data for monitoring 

cloudwatch.put_metric_data(

    MetricData=data_metrics, # data for metrics 

    Namespace='ECOMMERCE/Revenue' # namespace to separate domain/projects)
```

在前面的代码片段中，我们首先使用`boto3.client`函数为 CloudWatch 创建一个`cloudwatch`服务客户端。这个实例将允许我们从 Python 环境中与 CloudWatch 通信。记录一组数据的关键方法是`put_metric_data`。来自 CloudWatch 客户端实例的这个函数`put_metric_data`方法接收`MetricData`(接收到 CloudWatch 的目标指标数据:`data_metrics`)和`Namespace`(指标数据:`ECOMMERCE/Revenue`’的容器)。来自不同名称空间的数据被分开管理，以支持高效的聚合。

在本例中，`data_metrics`度量数据包含一个值为`900000.0`的`gross_merchandise_value`字段`MetricName`。`gross_merchandise_value`的单位定义为`None`。此外，我们将提供售出商品的数量(`num_goods_sold`)作为额外的尺寸信息。

关于 CloudWatch 概念的完整描述[，请参考 https://docs.aws.amazon.com/AmazonCloudWatch/la](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html)测试/监控/cloudwatch_concepts.html

要记住的事情

a.CloudWatch 以日志或由时间戳组织的指标的形式持久保存摄取的数据。它支持为异常变化设置警报，并通过仪表板提供有效的可视化。

b.使用`boto3`库可以很容易地将指标记录到 CloudWatch。它为 CloudWatch 提供了一个服务客户端，支持通过`put_metric_data`函数进行日志记录。

虽然 CloudWatch 的日志记录可以像本节中描述的那样显式完成，但是 SageMaker 为一些现成的指标提供了内置的日志记录特性。让我们仔细看看它们。

# 使用 CloudWatch 监控 SageMaker 端点

作为机器学习**的端到端服务**，SageMaker 是我们用来实现 DL 项目各个步骤的主要工具之一。在本节中，我们将描述最后一个缺失的部分:监控用 SageMaker 创建的端点。首先，我们将解释如何为培训设置基于 CloudWatch 的监控，在这种情况下，可以离线批量报告指标。接下来，我们将讨论如何监控活动端点。

本节中的代码片段是为在 SageMaker Studio 上运行而设计的。因此，我们首先需要定义一个 AWS **身份和访问管理** ( **IAM** )角色和一个会话对象。让我们来看看第一段代码:

```

import sagemaker

# IAM role of the notebook

role_exec=sagemaker.get_execution_role()

# a sagemaker session object

sag_sess=sagemaker.session()
```

在前面的代码片段中，`get_execution_role`函数为笔记本提供了 IAM 角色。`role_exec`。`sagemaker.session`提供了作业配置所需的 SageMaker `sag_sess` SageMaker session 对象。

## 在 SageMaker 的整个培训过程中监控模型

模型训练期间的测井涉及 SageMaker 的`Estimator`课。它可以使用`regex`表达式处理打印的消息，并将它们存储为度量。你可以在这里看到一个例子:

```

import sagemaker

from sagemaker.estimator import Estimator

# regex pattern for capturing error metrics 

reg_pattern_metrics=[

   {'Name':'train:error','Regex':'Train_error=(.*?);'},

   {'Name':'validation:error','Regex':'Valid_error=(.*?)'}]

# Estimator instance for model training

estimator = Estimator(

   image_uri=...,

   role=role_exec,

   sagemaker_session=sag_sess,

   instance_count=...,

   instance_type=...,

   metric_definitions=reg_pattern_metrics)
```

在前面的代码片段中，我们创建了`estimator`，这是一个用于训练的`Estimator`实例。关于大部分参数的解释可以在 [*第六章*](B18522_06.xhtml#_idTextAnchor133) 、*高效模型训练*中找到。我们在这个例子中定义的附加参数是`metric_definitions`。我们传入的是`reg_pattern_metrics`，它定义了一组`Train_error=(.*?)`和`Valid_error=(.*?)`，训练和评估日志。匹配给定模式的文本将作为度量标准保存在 CloudWatch 中。有关使用`Estimator`类在整个模型培训过程中离线度量记录的完整详细信息，请参考[https://docs . AWS . Amazon . com/sage maker/latest/DG/training-metrics . html](https://docs.aws.amazon.com/sagemaker/latest/dg/training-metrics.html)。我们要提到的是，具体的培训工作指标(比如内存、CPU、**图形处理单元** ( **GPU** )，以及磁盘利用率)都是自动记录的，你可以通过 CloudWatch 或者 SageMaker 控制台进行监控。

## 监控来自 SageMaker 的实时推理端点

在本节中，我们将描述 SageMaker 基于 CloudWatch 的端点监控特性。在下面的代码片段中，我们展示了一个带有`output_handler`函数的示例`inference.py`脚本。该文件分配给 SageMaker 的`Model`或`Estimator`类的`entry_point`参数，以定义附加的预处理和后处理逻辑。`inference.py`的细节可以在 [*第九章*](B18522_09.xhtml#_idTextAnchor187) 、*缩放深度学习管道*中找到。`output_handler`功能旨在使用`print`功能处理模型预测并记录指标数据。打印出来的消息作为日志存储在 CloudWatch 中:

```

# inference.py

def output_handler(data, context):

    # retrieve the predictions

    results=data.content

    # data that will be ingested to CloudWatch

    data_metrics=[

       {

          'MetricName': 'model_name',

          'Dimensions': [

             {

                'Name': 'classify',

                'Value': results

              } ],

          'Unit': 'None',

          'Value': "classify_applicant_risk"

      } ]

    # print will ingest information into CloudWatch

    print(data_metrics)
```

在前面的推理代码中，我们首先获得一个模型预测(`results`)并为度量数据构建一个字典(`data_metrics`)。字典已经有一个值为`model_name`的`MetricName`和一个名为`classify`的维度。将为`classify`尺寸指定模型预测。SageMaker 将收集打印的指标数据，并将其导入 CloudWatch。https://sage maker-examples . readthedocs . io/en/latest/sage maker _ model_ monitor/model _ quality/model _ quality _ churn _ SDK . html 在线描述了一种持续监控 m 型产品质量偏差的示例方法。该页面详细解释了如何在这种情况下利用 CloudWatch。

要记住的事情

a.SageMaker 的`Estimator`类在训练期间为基于 CloudWatch 的监控提供了内置支持。在构造实例时，需要将一组正则表达式模式传递给参数`metric_definitions`。

b.来自 SageMaker 端点的打印消息存储为 CloudWatch 日志。因此，我们可以通过一个`entry_point`脚本记录度量数据来实现监控。

在本节中，我们解释了 SageMaker 如何支持基于 CloudWatch 的监控。让我们看看 EKS 如何支持对推理端点的监控。

# 使用 CloudWatch 监控 EKS 端点

除了 SageMaker，我们还在第九章*中 [*描述了基于 EKS 的端点*。在本节中，我们将介绍适用于 EKS 的](B18522_09.xhtml#_idTextAnchor187)基于 CloudWatch 的监控。首先，我们将了解如何记录容器中的 EKS 指标以进行监控。接下来，我们将解释如何从 EKS 推理端点记录与模型相关的度量。*

让我们首先看看如何设置 CloudWatch 来监控 EKS 集群。最简单的方法是在容器中安装一个 CloudWatch 代理。此外，您可以安装 **Fluent Bit** ，这是一个开放的[源代码工具，可以进一步增强测井过程。关于 CloudWatch 代理和 Fluent Bit 的完整解释，请阅读](http://www.fluentbit.io)[https://docs . AWS . Amazon . com/Amazon cloud watch/latest/monitoring/Container-Insights-setup-EKS-quick start . html](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Insights-setup-EKS-quickstart.html)。

另一种选择是保持由 EKS 控制平面发送的默认度量。这可以从 EKS web 控制台([https://docs . AWS . Amazon . com/eks/latest/user guide/control-plane-logs . html](https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html))轻松实现。从 EKS 控制平面发出的指标的完整列表可以在[https://AWS . github . io/AWS-eks-best-practices/reliability/docs/control plane](https://aws.github.io/aws-eks-best-practices/reliability/docs/controlplane/)找到。例如，如果您对记录延迟相关的指标感兴趣，您可以使用`apiserver_request_duration_seconds*`。

为了在模型推断期间记录与模型相关的指标，您需要在代码中实例化`boto3`的 CloudWatch 服务客户端并显式记录它们。上一节中的代码片段*使用 CloudWatch* 监控 SageMaker 端点应该是一个很好的起点。

要记住的事情

a.通过使用 CloudWatch 代理或持久化由 EKS 控制平面发送的默认指标，可以从 EKS 集群记录端点相关指标。

b.需要使用`boto3`库明确记录与模型相关的指标。

作为本节的最后一个主题，我们解释了如何将各种指标从 EKS 集群记录到 CloudWatch。

# 总结

我们在这一章的目标是解释为什么需要监控运行 DL 模型的端点，并介绍这一领域的流行工具。我们在本章中介绍的工具旨在监控来自终端的一组信息，并在监控指标发生突然变化时发出事件警报。我们介绍的工具有 CloudWatch、Prometheus、Grafana、Datadog、SageMaker Clarify、PagerDuty 和 Dynatrace。为了完整起见，我们研究了如何将 CloudWatch 集成到 SageMaker 和 EKS 中，以监控端点和模型性能。

在下一章，也是本书的最后一章，我们将探索评估一个已完成项目的过程，并讨论潜在的改进。*