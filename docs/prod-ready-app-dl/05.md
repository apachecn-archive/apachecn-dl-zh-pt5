<title>B18522_04</title>

# 4

# 实验跟踪、模型管理和数据集版本化

在这一章中，我们将介绍一套用于实验跟踪、模型管理和数据集版本化的有用工具，它可以让你有效地管理**深度学习** ( **DL** )项目。我们将在本章中讨论的工具可以帮助我们跟踪许多实验并更有效地解释结果，这自然会导致运营成本的降低并加快开发周期。在本章结束时，你将拥有使用最流行工具的实践经验，并能够为你的项目选择合适的工具集。

在本章中，我们将讨论以下主要话题:

*   DL 项目跟踪概述
*   带权重和偏差的 DL 项目跟踪
*   使用 MLflow 和 DVC 跟踪 DL 项目
*   数据集版本化——超越权重和偏差、MLflow 和 DVC

# 技术要求

你可以从本书的 GitHub 资源库下载本章的补充材料，网址为[https://GitHub . com/packt publishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter _ 4](https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter_4)。

# DL 项目跟踪概述

训练 DL 模型是一个消耗大量时间和资源的迭代过程。因此，跟踪所有实验并一致地组织它们可以防止我们将时间浪费在不必要的操作上，例如在同一组数据上重复训练相似的模型。换句话说，拥有所有模型架构及其超参数集的完整记录，以及实验期间使用的数据版本，可以帮助我们从实验中得出正确的结论，这自然会导致项目成功。

## DL 项目跟踪的组成部分

**DL 项目跟踪**的基本组件是**实验跟踪**、**模型管理**和**数据集版本**。让我们详细看看每个组件。

### 实验跟踪

实验跟踪背后的概念很简单:存储每个实验的描述和动机，这样我们就不会为了同样的目的运行另一组实验。总的来说，有效的实验跟踪将节省我们的运营成本，并使我们能够从最少的实验结果中得出正确的结论。有效实验跟踪的基本方法之一是为每个实验添加一个唯一的标识符。我们需要为每个实验跟踪的信息包括项目依赖性、模型架构的定义、使用的参数和评估度量。实验跟踪还包括实时可视化正在进行的实验，并能够直观地比较一组实验。例如，如果我们可以在模型训练时检查每个时期的训练和验证损失，我们就可以更快地识别过度拟合，从而节省一些资源。此外，通过比较两个实验之间的结果和一组更改，我们可以了解这些更改如何影响模型性能。

### 模型管理

模型管理超越了实验跟踪，因为它覆盖了模型的整个生命周期:数据集信息、工件(从训练模型中生成的任何数据)、模型的实现、评估指标和管道信息(例如开发、测试、试运行和生产)。模型管理允许我们快速选择感兴趣的模型，并有效地设置模型的使用环境。

### 数据集版本化

DL 项目跟踪的最后一个组件是数据集版本化。在许多项目中，数据集会随着时间而变化。更改可能来自数据模式(数据组织方式的蓝图)、文件位置，甚至来自应用于数据集的过滤器，这些过滤器操纵底层数据的含义。行业中发现的许多数据集以复杂的方式构建，并且通常以各种数据格式存储在多个位置。因此，变化可能比您预期的更剧烈，也更难跟踪。因此，记录变更对于在整个项目中重现一致的结果是至关重要的。

数据集跟踪可以总结如下:当底层数据被修改时，存储为工件的数据集应该成为工件的新版本。话虽如此，每个工件都应该有元数据，元数据由数据集的重要信息组成:它是何时创建的，是谁创建的，以及它与以前的版本有何不同。

例如，具有数据集版本控制的数据集应该用如下公式表示。数据集的名称中应该有时间戳:

```

dataset_<timestamp>

> metadata.json

> img1.png

> img2.png

> img3.png
```

如前所述，元数据应该包含关于数据集的关键信息:

```

{

   "created_by": "Adam"

   "created_on": "2022-01-01"

   "labelled_by": "Bob"

   "number_of_samples": 3

}
```

请注意，元数据跟踪的组信息对于每个项目可能是不同的。

## DL 项目跟踪工具

DL 跟踪可以通过多种方式实现，从文本文件中的简单笔记开始，通过电子表格，将信息保存在 GitHub 或专用网页中，到自建平台和外部工具。模型和数据工件可以按原样存储，或者可以应用更复杂的方法来避免冗余并提高效率。

DL 项目跟踪领域发展迅速，并且不断引入新的工具。因此，为底层项目选择合适的工具并不是一件容易的事情。我们必须考虑业务和技术约束。虽然定价模型是一个基本模型，但现有的开发环境可能会引入其他约束；集成现有工具应该很容易，并且基础设施必须易于维护。考虑 MLOps 团队的工程能力也很重要。话虽如此，当您为项目选择工具时，下面的列表将是一个很好的起点。

*   tensor board(【https://www.tensorflow.org/tensorboard】):
    *   TensorFlow 团队开发的开源可视化工具
    *   跟踪和可视化实验结果的标准工具
*   权重与偏差( [https://wandb.ai](https://wandb.ai/site/experiment-tracking) ):
    *   一个基于云的服务带有一个有效的交互式仪表盘，用于可视化和组织实验结果
    *   服务器可以在本地运行，也可以托管在私有云中
    *   它提供了自动超参数调整功能，称为扫描
    *   个人项目免费。定价基于跟踪时间和存储空间
*   海王星( [https://neptune.ai](https://neptune.ai/product) ):
    *   用于监控和存储来自机器学习(ML)实验的工件的在线工具
    *   它可以很容易地与其他 ML 工具集成
    *   它以强大的仪表盘闻名，可以实时总结实验
*   https://mlflow.org:
    *   一个提供端到端 ML 生命周期管理的开源平台
    *   它支持 Python 和基于 R 的系统。通常与**数据版本控制** ( **DVC** )结合使用
*   萨格马克工作室([https://aws.amazon.com/sagemaker/studio/](https://aws.amazon.com/sagemaker/studio/)):
    *   基于网络的可视化界面，用于管理使用 SageMaker 设置的 ML 实验
    *   该工具通过提供与 AWS 其他有用功能的简单集成，允许用户高效地构建、训练和部署模型
*   库伯弗洛(【https://www.kubeflow.org】T4):
    *   Google 设计的一个开源平台用于端到端的 ML 编排和管理
    *   它也是为高效地将 ML 系统部署到各种开发和生产环境而设计的
*   瓦罗海([https://valohai.com](https://valohai.com/product/)):
    *   设计用于自动机器编排、版本控制和数据流水线管理的 DL 管理平台
    *   它不是自由软件，因为它是为企业设计的
    *   它因不依赖技术和拥有响应迅速的支持团队而越来越受欢迎

在各种工具中，我们将涵盖两个最常用的设置:权重&偏差和 MLflow 结合 DVC。

要记住的事情

a.DL 跟踪的基本组件是实验跟踪、模型管理和数据集版本控制。最近的 DL 跟踪工具通常具有总结实验结果的用户友好的仪表板。

b.该领域正在发展，有许多具有不同优势的工具。选择正确的工具需要了解业务和技术约束。

首先，我们来看看用**权重&偏差** ( **W & B** )进行的 DL 项目跟踪。

# 带权重的 DL 项目跟踪&偏差

W&B 是一个实验性的管理平台，为模型和数据提供版本控制。

W&B 提供了一个交互式仪表板，可以嵌入到 Jupyter 笔记本电脑中，也可以用作独立的网页。简单的 Python API 也为简单的集成提供了可能性。此外，其功能集中于简化 DL 实验管理:记录和监控模型和数据版本、超参数值、评估指标、工件和其他相关信息。

W&B 的另一个有趣的功能是它的内置超参数搜索功能，称为**扫描**([https://docs.wandb.ai/guides/sweeps](https://docs.wandb.ai/guides/sweeps))。使用 Python API 可以很容易地设置扫描，并且可以在 web 页面上交互地比较结果和模型。

最后，W&B 会自动为您创建报告，直观地总结和组织一组实验([https://docs.wandb.ai/guides/reports](https://docs.wandb.ai/guides/reports))。

总体而言，W & B 的关键功能可总结如下:

*   **实验跟踪与管理**
*   **神器管理**
*   **模型评估**
*   **模型优化**
*   **协同分析**

W&B 是一项基于订阅的服务，但个人账户是免费的。

## 设置 W & B

W&B 有一个 Python API，为很多 DL 框架提供了简单的集成方法，包括 TensorFlow 和 PyTorch。记录的信息，例如项目、团队和运行列表，可以在线或在自托管服务器上管理和查看。

设置 W&B 的第一步是安装 Python API 并登录 W&B 服务器。您必须事先通过 [https://wandb.ai](https://wandb.ai) 创建一个账户:

```
pip install wandb
wandb login
```

在您的 Python 代码中，您可以通过以下代码行注册一个名为`run-1`的实验:

```

import wandb

run_1 = wandb.init(project="example-DL-Book", name="run-1") 
```

更准确地说，`wandb.init`函数在一个名为`example-DL-Book`的项目中创建了一个名为`run_1`的新的`wandb.Run`实例。如果没有提供名字，W & B 会为你随机生成一个两个字的名字。如果项目名称为空，W & B 会将您的跑步记录放入`Uncategorized`项目中。`wandb.init`的所有参数都在[https://docs.wandb.ai/ref/python/init](https://docs.wandb.ai/ref/python/init)中列出，但我们想介绍您最常与之交互的参数:

*   `id`为您的跑步设置唯一的 ID
*   `resume`允许您在不创建新运行的情况下恢复实验
*   `job_type`允许您将跑步分配到特定类型，如训练、测试、验证、探索或任何其他可用于对跑步分组的名称
*   `tags`让您更加灵活地组织跑步

当`wandb.init`功能被触发时，关于运行的信息将开始出现在 W & B 仪表板上。您可以在 W & B 网页上或直接在 Jupyter 笔记本环境中监控仪表板，如以下截图所示:

![Figure 4.1 – The W&B dashboard inside a Jupyter notebook environment
](img/B18522_02_01.jpg)

图 4.1–Jupyter 笔记本电脑环境中的 W&B 仪表板

当运行被创建时，你可以开始记录信息；`wandb.log`功能允许您记录任何想要的数据。例如，您可以通过在训练循环中添加`wandb.log({"custom_loss": custom_loss})`来记录训练过程中的损耗。类似地，您可以记录验证失败和任何其他想要跟踪的详细信息。

有趣的是，W&B 通过为 DL 模型提供内置的日志功能，使得这个过程更加简单。在撰写本文时，您可以找到大多数框架的集成，包括 Keras、PyTorch、PyTorch Lightning、TensorFlow、fast.ai、scikit-learn、SageMaker、Kubeflow、Docker、Databricks 和 Ray Tune(详细信息请参见[https://docs.wandb.ai/guides/integrations](https://docs.wandb.ai/guides/integrations))。

`wandb.config`是追踪模型超参数的绝佳地点。对于实验中的任何工件，您可以使用`wandb.log_artifact`方法(更多细节，请参见 see[https://docs.wandb.ai/guides/artifacts](https://docs.wandb.ai/guides/artifacts))。在记录工件时，您需要定义一个文件路径，然后分配工件的名称和类型，如下面的代码片段所示:

```

wandb.log_artifact(file_path, name='new_artifact', type='my_dataset')
```

然后，您可以重用已经存储的工件，如下所示:

```

run = wandb.init(project="example-DL-Book")

artifact = run.use_artifact('example-DL-Book/new_artifact:v0', type='my_dataset')

artifact_dir = artifact.download()
```

到目前为止，您已经学习了如何为您的项目设置`wandb`,并在整个培训中单独记录您选择的度量和工件。有趣的是，`wandb`为很多 DL 框架提供了自动日志记录。在这一章中，我们将详细了解 Keras 和 **PyTorch 照明** ( **PL** )的 W & B 集成。

### 将 W&B 集成到 Keras 项目中

在 Keras 的例子中，集成可以通过`WandbCallback`类实现。完整版本可以在本书的 GitHub 资源库中找到:

```

import wandb

from wandb.keras import WandbCallback

from tensorflow import keras

from tensorflow.keras import layers

wandb.init(project="example-DL-Book", name="run-1")

wandb.config = {

   "learning_rate": 0.001,

   "epochs": 50,

   "batch_size": 128

}

model = keras.Sequential()

logging_callback = WandbCallback(log_evaluation=True)

model.fit(

   x=x_train, y=y_train,

   epochs=wandb.config['epochs'],

   batch_size=wandb.config['batch_size'], 

   verbose='auto', 

   validation_data=(x_valid, y_valid),

   callbacks=[logging_callback])
```

如上一节所述，关于车型的关键信息被记录下来，并在 W & B 仪表板上可用。您可以监控损失、评估指标和超参数。*图 4.2* 显示了 W & B 通过前面的代码自动生成的样图:

![Figure 4.2 – Sample plots generated by W&B from logged metrics
](img/B18522_04_02.jpg)

图 4.2–W & B 根据记录的指标生成的样本图

将 W&B 整合到 PL 项目中类似于将 W & B 整合到 Keras 项目中。

### 将 W&B 整合到 PyTorch 闪电项目中

对于一个基于 PL 的项目，W&B 提供了一个定制日志并隐藏了大部分样板代码。您需要做的就是实例化`WandbLogger`类，并通过`logger`参数将其传递给`Trainer`实例:

```

import pytorch_lightning as pl

from pytorch_lightning.loggers import WandbLogger

wandb_logger = WandbLogger(project="example-DL-Book")

trainer = Trainer(logger=wandb_logger)

class LitModule(LightningModule):

   def __init__(self, *args, **kwarg):

       self.save_hyperparameters()

   def training_step(self, batch, batch_idx):

       self.log("train/loss", loss)
```

关于整合的详细解释可以在[https://py torch-lightning . readthedocs . io/en/stable/extensions/generated/py torch _ lightning . loggers . wandblogger . html](https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html)找到。

要记住的事情

a.W&B 是一个实验管理平台，帮助跟踪不同版本的模型和数据。它还支持存储配置、超参数、数据和模型工件，同时提供实时实验跟踪。

b.W&B 很容易建立。它为许多 DL 框架提供了内置的集成特性，包括 TensorFlow 和 PyTorch。

c.W&B 可用于执行超参数调整/模型优化。

虽然 W&B 已经主导了 DL 项目跟踪的领域，但 MLflow 和 DVC 的结合是 DL 项目的另一种流行设置。

# 使用 MLflow 和 DVC 跟踪 DL 项目

MLflow 是一个流行的框架，支持跟踪技术依赖、模型参数、度量和工件。MLflow 的关键组件如下:

*   **跟踪**:每次模型运行时跟踪结果变化
*   **项目**:它以可复制的方式打包模型代码
*   **模型**:组织模型工件以方便将来的部署
*   **模型注册中心**:它管理一个 MLflow 模型的整个生命周期
*   **插件** : 它提供了灵活的插件，可以很容易地与其他 DL 框架集成

你可能已经注意到了，W & B 和 MLflow 有一些相似之处。然而，在 MLflow 中，每个实验都与一组 Git 提交相关联。Git 并不阻止我们保存数据集，但是当数据集很大时，它显示出许多限制，即使有为大文件构建的扩展(Git LFS)。因此，MLflow 通常与解决 Git 局限性的开源版本控制系统 DVC 相结合。

## 设置 MLflow

MLflow 可以使用`pip`安装:

```
pip install mlflow
```

与 W&B 类似，MLflow 也提供了一个 Python API，允许您跟踪超参数(`log_param`)、评估指标(`log_metric`)和工件(`log_artifacts`):

```

import os

import mlflow

from mlflow import log_metric, log_param, log_artifacts

log_param("epochs", 30)

log_metric("custom", 0.6)

log_metric("custom", 0.75) # metrics can be updated

if not os.path.exists("artifact_dir"):

   os.makedirs("artifact_dir")

with open("artifact_dir/test.txt", "w") as f:

   f.write("simple example")

log_artifacts("artifact_dir")
```

实验定义可以用以下代码初始化和标记:

```

exp_id = mlflow.create_experiment("DLBookModel_1")

exp = mlflow.get_experiment(exp_id)

with mlflow.start_run(experiment_id=exp.experiment_id, run_name='run_1') as run:

   # logging starts here

   mlflow.set_tag('model_name', 'model1_dev')
```

MLflow 已经提供了一套介绍其 API 的教程:[https://www . ml flow . org/docs/latest/tutorials-and-examples/tutorial . html](https://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.html)。

现在您已经熟悉了 MLflow 的基本用法，我们将描述它如何集成到 Keras 和 PL 项目中。

### 将 MLflow 集成到 Keras 项目中

首先，我们来看看 Keras 集成。使用 MLflow 记录 Keras 模型的细节可以通过`log_model`函数实现:

```

history = keras_model.fit(...)

mlflow.keras.log_model(keras_model, model_dir)
```

`mlflow.keras`和`mlflow.tensorflow`模块提供了一组 API，分别用于记录关于 Keras 和 TensorFlow 模型的各种信息。更多详情，请查看[https://www.mlflow.org/docs/latest/python_api/index.html](https://www.mlflow.org/docs/latest/python_api/index.html)。

### 将 MLflow 集成到 PyTorch Lightning 项目中

类似于 W&B 如何支持 PL 项目，MLflow 也提供了一个`MLFlowLogger`类。这可以传递给一个`Trainer`实例，用于记录 MLflow 中的模型细节:

```

import pytorch_lightning as pl 

from pytorch_lightning import Trainer

from pytorch_lightning.loggers import MLFlowLogger

mlf_logger = MLFlowLogger(experiment_name="example-DL-Book ", tracking_uri="file:./ml-runs")

trainer = Trainer(logger=mlf_logger)

class DLBookModel(pl.LightningModule):

   def __init__(self):

       super(DLBookModel, self).__init__()

       ...

   def training_step(self, batch, batch_nb):

       loss = self.log("train_loss", loss, on_epoch=True)
```

在前面的代码中，我们传递了一个`MLFlowLogger`的实例来替换 PL 的默认记录器。`tracking_uri`参数控制记录数据的去向。

关于 PyTorch 集成的其他细节可以在官网找到:[https://py torch-lightning . readthe docs . io/en/stable/API/py torch _ lightning . loggers . ml flow . html](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.loggers.mlflow.html)。

## 使用 DVC 设置 MLflow

要使用 DVC 来管理大型数据集，您需要使用 packag e 管理器来安装它，例如`pip`、`conda`或`brew`(针对 macOS 用户):

```
pip install dvc
```

所有的安装选项都可以在[https://dvc.org/doc/install](https://dvc.org/doc/install/)找到。

使用 DVC 管理数据集需要一组以特定顺序执行的命令:

1.  第一步是用 DVC 建立一个 Git 存储库:

    ```
    git init dvc init git commit -m 'initialize repo'
    ```

2.  现在，我们需要为 DVC 配置远程存储:

    ```
    dvc remote add -d myremote /tmp/dvc-storage git commit .dvc/config -m "Added local remote storage"
    ```

3.  让我们创建一个示例数据目录，并用一些示例数据填充它:

    ```
    mkdir data cp example_data.csv data/
    ```

4.  在这个阶段，我们准备好开始跟踪数据集。我们只需要将我们的文件添加到 DVC。此操作将创建一个附加文件`example_data.csv.dvc`。此外，`example_data.csv`文件会自动添加到`.gitignore`中，这样 Git 就不再跟踪原始文件:

    ```
    dvc add data/example_data.csv
    ```

5.  接下来，您需要提交并上传`example_data.csv.dvc`和`.gitignore`文件。我们将第一个数据集标记为`v1` :

    ```
    git add data/.gitignore data/example_data.csv.dvc git commit -m 'data tracking' git tag -a 'v1' -m 'test_data' dvc push
    ```

6.  使用`dvc push`命令后，我们的数据将在远程存储上可用。这意味着我们可以删除本地版本。要恢复`example_data.csv`，只需调用`dvc pull` :

    ```
    dvc pull data/example_data.csv.dvc
    ```

7.  当`example_data.csv`被修改时，我们需要添加并再次推送以更新远程存储上的版本。我们将修改后的数据集标记为`v2` :

    ```
    dvc add data/example_data.csv git add data/example_data.csv.dvc git commit -m 'data modification description' git tag -a 'v2' -m 'modified test_data' dvc push
    ```

执行这些命令后，Git 和 DVC 将会跟踪同一个数据集的两个版本:`v1`和`v2`。

接下来，我们来看看 MLflow 如何与 DVC 结合:

```

import mlflow

import dvc.api

import pandas as pd

data_path='data/example_data.csv'

repo='/Users/BookDL_demo/'

version='v2'

data_url=dvc.api.get_url(path=path, repo=repo, rev=version)

# this will fetch the right version of our data file

data = pd.read_csv(data_url)

# log important information using mlflow

mlflow.start_run()

mlflow.log_param("data_url", data_url)

mlflow.log_artifact(...)
```

在前面的代码片段中，`mlflow.log_artifact`用于保存实验中特定列的信息。

总的来说，我们可以通过 MLflow 用 DVC 跟踪的数据集的不同版本运行多个实验。与 W & B 类似，MLflow 也提供了一个网页，我们可以在那里比较我们的实验。您只需要在终端中键入以下命令:

```
mlflow ui 
```

该命令将启动一个 web 服务器，该服务器在 [http://127.0.0.1:5000](http://127.0.0.1:5000) 上托管一个网页。以下屏幕截图显示了 MLflow 仪表板:

![Figure 4.3 – The MLflow dashboard; new runs will be populated at the bottom of the page
](img/B18522_04_03.jpg)

图 4.3–ml flow 仪表板；新运行将在页面底部填充

要记住的事情

a.MLflow 可以跟踪依赖关系、模型参数、度量和工件。它通常与 DVC 结合使用，以实现高效的数据集版本控制。

b.MLflow 可以很容易地与 DL 框架集成，包括 Keras、TensorFlow 和 PyTorch。

c.MLflow 提供了一个交互式的可视化界面，可以同时分析多个实验。

到目前为止，我们已经学习了如何在 W & B 和 MLflow 和 DVC 管理 DL 项目。在下一节中，我们将介绍流行的数据集版本化工具。

# 数据集版本化–超越权重&偏差、MLflow 和 DVC

在这一章中，我们已经看到了 DL 项目跟踪工具是如何管理数据集的。在 W&B 的情况下，我们可以使用工件，而在 MLflow 和 DVC 的情况下，DVC 运行在 Git 存储库之上，以跟踪数据集的不同版本，从而解决 Git 的局限性。

对于数据集版本控制，还有其他有用的方法和/或工具吗？简单的答案是肯定的，但是更精确的答案取决于上下文。要做出正确的选择，您必须考虑各个方面，包括成本、易用性和集成难度。在本节中，我们将提到几个工具，如果数据集版本化是您项目的关键组件之一，我们认为这些工具是值得探索的:

*   **Neptune**([https://docs . Neptune . ai](https://docs.neptune.ai/))是 MLOps 的元数据存储。Neptune 工件允许对本地存储的数据集或云中存储的数据集进行版本控制。
*   **Delta Lake**([https://Delta . io](https://delta.io/))是一个开源的存储抽象，它在数据湖之上运行。Delta Lake 使用 Apache Spark APIs，并使用分布式处理来提高吞吐量和效率。

要记住的事情

a.市场上有许多数据版本化工具。要选择正确的工具，您必须考虑各个方面，包括成本、易用性和集成难度。

b.W&B、MLflow、DVC、Neptune 和 Delta Lake 等工具可以帮助您进行数据集版本化。

因此，我们引入了流行的数据集版本化工具。合适的工具因项目而异。因此，在将一个工具集成到您的项目中之前，您必须评估每个工具的优缺点。

# 总结

由于 DL 项目涉及许多训练模型和评估的迭代，有效地管理实验、模型和数据集可以帮助团队更快地达到目标。在这一章中，我们看了两个最流行的 DL 项目跟踪设置:W&B 和与 DVC 集成的 MLflow。这两种设置都提供了对 Keras 和 PL 的内置支持，这是两种最流行的 DL 框架。我们还花了一些时间描述更加强调数据集版本化的工具:Neptune 和 Delta Lake。请记住，您必须彻底评估每个工具，以便为您的项目选择正确的工具。

至此，您已经熟悉了构建概念证明和培训必要的 DL 模型的框架和流程。从下一章开始，我们将讨论如何通过将 DL 管道的单个组件迁移到云中来实现纵向扩展。