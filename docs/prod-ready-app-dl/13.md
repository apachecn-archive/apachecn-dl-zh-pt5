<title>B18522_10</title>

# 10

# 提高推理效率

当一个**深度学习** ( **DL** )模型部署在边缘设备上时，推理效率往往不尽如人意。这些问题主要来自训练网络的规模，因为它需要大量的计算。因此，当在边缘设备上部署 DL 模型时，许多工程师和科学家经常为了速度而牺牲准确性。此外，由于边缘设备通常具有有限的存储空间，他们专注于减小模型大小。

在这一章中，我们将介绍在尽可能保持原有性能的同时改善推理延迟的技术。首先，我们将介绍**网络量化**，这是一种通过对模型参数使用较低精度的数据格式来减小网络规模的技术。接下来我们就来说说**权重分享**，也就是大家熟知的权重聚类。这是一个非常有趣的概念，其中一些模型权重值在整个网络中共享，减少了存储训练模型所需的磁盘空间。我们还将讨论**网络修剪**，它涉及到消除网络中不必要的连接。虽然这三种技术是最受欢迎的，但我们还将介绍另外两个有趣的主题:**知识提炼**和**网络架构搜索**。这两种技术通过在训练期间直接修改网络体系结构来实现模型尺寸减小和推理延迟改进。

在本章中，我们将讨论以下主要话题:

*   网络量化——减少用于模型参数的位数
*   重量共享–减少不同重量值的数量
*   网络修剪–消除网络中不必要的连接
*   知识提炼——通过模仿预测获得一个更小的网络
*   网络架构搜索–寻找最高效的网络架构

# 技术要求

你可以从本书的 GitHub 资源库下载本章的补充材料，网址为[https://GitHub . com/packt publishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter _ 10](https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/tree/main/Chapter_10)。

在我们深入研究个别技术之前，我们想介绍两个构建在 **TensorFlow** ( **TF** )之上的库。第一个是**tensor flow Lite**(**TF Lite**)，处理移动、微控制器和其他边缘设备上的 TF 模型部署([https://www.tensorflow.org/lite](https://www.tensorflow.org/lite))。我们将要描述的一些技术只适用于 TF Lite。另一个库叫做 TensorFlow 模型优化工具包。该库旨在为 TF 模型([https://www.tensorflow.org/model_optimization](https://www.tensorflow.org/model_optimization))提供各种优化技术。

# 网络量化–减少用于模型参数的位数

如果我们详细查看 DL 模型训练，您会注意到模型学习处理有噪声的输入。换句话说，该模型试图为其训练的数据构建一个泛化，以便即使传入的数据中有一些噪声，它也可以生成合理的预测。此外，DL 模型在训练后使用特定范围的数值进行推理。按照这种思路，网络量化旨在对这些值使用更简单的表示法。

如图*图 10.1* 所示，网络量化，也称为模型量化，是将模型与之交互的一系列数值重新映射到可以用更少比特表示的数系的过程——例如，用 8 比特而不是 32 比特来表示一个浮点数。这种修改在 DL 模型部署中带来了额外的优势，因为边缘设备通常缺少对基于 32 位浮点数的算法的稳定支持:

![Figure 10.1 – An illustration of the number system remapping from float 32 to int 8 in network quantization
](img/B18522_10_01.jpg)

图 10.1–网络量化中从浮点数 32 到整数 8 的数字系统重映射示意图

不幸的是，网络量化不仅仅是将一个数字从高精度转换成低精度。这是因为 DL 模型推理涉及到的算法产生的数字比输入的精度更高。在这一章中，我们将看看网络量化中以不同方式克服挑战的各种选项。如果你有兴趣学习更多关于网络量化的知识，我们推荐*戈拉米等人的《高效神经网络推理量化方法综述*。

网络量化技术可以分为两个领域。第一种是训练后量化，另一种是量化感知训练。前者被设计成量化已经被训练的模型，而后者通过训练具有较低精度的模型来最小化由于量化过程导致的精度下降。

幸运的是，这两种技术在标准 DL 框架中都可用:TF 和 PyTorch。在下面的章节中，我们将看看如何在这些框架中执行网络量化。

## 进行训练后量化

首先，我们将看看TF 和 PyTorch 如何支持训练后量化。修改很简单，因为它只需要几行额外的代码。先说 TF。

### 在 TensorFlow 中执行训练后量化

默认情况下，DL 模型使用 32 位的浮点用于必要的计算和变量。在下面的例子中，我们将演示动态范围量化，其中只有固定参数(如权重)被量化为使用 16 位而不是 32 位。请注意，您将需要安装 TF Lite，以便在 TF:

```

import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)

converter.optimizations = [tf.lite.Optimize.DEFAULT]

converter.target_spec.supported_types = [tf.float16]

tflite_quant_model = converter.convert()
```

通过量子化，我们得到一个 TF Lite 模型。在前面的代码片段中，我们使用了`tf.lite.TFLiteConverter.from_saved_model`函数来加载一个经过训练的 TF 模型，并获得一个量化的 TF Lite 模型。在我们触发转换之前，我们需要配置一些东西。首先要设置量化模型权重的优化策略(`converter.optimizations = [tf.lite.Optimize.DEFAULT]`)。然后，我们需要指定我们想要来自量化的 16 位权重(`converter.target_spec.supported_types = [tf.float16]`)。当`convert`功能被触发时，实际的量化发生。在前面的代码中，如果我们没有为`supported_types`指定一个 16 位的浮点类型，我们将量化模型使用 8 位的整数。

接下来，我们将引入全整数量化，其中模型推理的每个组件(输入、激活以及权重)都被量化到较低的精度。对于这种类型的量化，您需要提供一个代表性的数据集来估计激活的范围。让我们看看下面的例子:

```

import tensorflow as tf

# A set of data for estimating the range of numbers that the inference requires

representative_dataset = …

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)

converter.optimizations = [tf.lite.Optimize.DEFAULT]

converter.representative_dataset = representative_dataset

converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

converter.inference_input_type = tf.int8  # or tf.uint8

converter.inference_output_type = tf.int8  # or tf.uint8

tflite_quant_model = converter.convert()
```

前面的代码几乎是不言自明的。同样，我们使用`TFLiteConverter`类进行量化。首先，我们配置优化策略(`converter.optimizations = [tf.lite.Optimize.DEFAULT]`)并提供一个代表性的数据集(`converter.representative_dataset = representative_dataset`)。接下来，我们将 TF 优化设置为在整数表示中执行。此外，我们需要通过配置`target_spec`、`inference_input_type`和`inference_output_type`来指定输入和输出数据类型。最后一行中的`convert`函数再次触发量化过程。

TF 中的两种训练后量化在[https://www . tensor flow . org/model _ optimization/guide/quantization/post _ training](https://www.tensorflow.org/model_optimization/guide/quantization/post_training)中有透彻的解释。

接下来我们来看看 PyTorch 是如何实现训练后量化的。

### 在 PyTorch 中执行训练后量化

在 PyTorch 的情况下，有两种不同的后训练量化方法:**动态量化**和**静态量化**。它们因量化发生的时间而不同，并且具有不同的优点和缺点。在本节中，我们将提供每个算法的高级描述，以及代码示例。

#### 动态量化——在运行时量化模型

首先，我们来看看动态量化，PyTorch 中最简单的量化形式。这种类型的算法提前对权重应用量化，而对激活的量化在推断期间动态发生。因此，在模型执行主要通过加载权重来抑制而计算矩阵乘法不成问题的情况下，通常使用动态量化。这种类型的量化通常用于 LSTM 或变压器网络。

给定一个训练好的模型，动态量化可以如下实现。完整的示例可从 https://py torch . org/tutorials/recipes/recipes/dynamic _ quantization . html 获得:

```

import torch

model = …

quantized_model = torch.quantization.quantize_dynamic(

    model,  # the original model

    qconfig_spec={torch.nn.Linear},  # a set of layers to quantize

    dtype=torch.qint8)  # data type which the quantized tensors will be
```

要应用动态量化，需要将训练好的模型传递给`torch.quantization.quantize_dynamic`函数。另外两个参数指的是将应用量化的一组模块(`qconfig_spec={torch.nn.Linear}`)和量化张量的目标数据类型(`dtype=torch.qint8`)。在这个例子中，我们将量化`Linear`层以使用 8 位整数。

接下来，我们来看静态量化。

#### 静态量化–使用代表性数据集确定最佳量化参数

另一种类型的量化称为静态量化。像TF 的全整数量化一样，这种类型的量化通过使用代表性数据集估计模型与之交互的数字范围，最大限度地降低了模型性能的下降。

不幸的是，静态量化比动态量化需要更多的编码。首先，您需要在网络之前和之后分别插入`torch.quantization.QuantStub`和`torch.quantization.DeQuantStub`运算，以进行必要的张量转换:

```

import torch

# A model with few layers

class OriginalModel(torch.nn.Module):

    def __init__(self):

        super(M, self).__init__()

        # QuantStub converts the incoming floating point tensors into a quantized tensor

        self.quant = torch.quantization.QuantStub()

        self.linear = torch.nn.Linear(10, 20)

        # DeQuantStub converts the given quantized tensor into a tensor in floating point

        self.dequant = torch.quantization.DeQuantStub()

    def forward(self, x):

        # using QuantStub and DeQuantStub operations, we can indicate the region for quantization

        # point to quantized in the quantized model

        x = self.quant(x)

        x = self.linear(x)

        x = self.dequant(x)

        return x
```

在前面的网络中，我们有一个单一的`Linear`层，但也有两个额外的操作在`__init__`函数中初始化:`torch.quantization.QuantStub`和`torch.quantization.DeQuantStub`。前一个操作被应用于输入张量以指示量化的开始。后一个操作作为`forward`功能中的最后一个操作，用于指示量化的结束。以下代码片段描述了静态量化的第一步——校准过程:

```

# model is instantiated and trained

model_fp32 = OriginalModel()

…

# Prepare the model for static quantization

model_fp32.eval()

model_fp32.qconfig = torch.quantization.get_default_qconfig('fbgemm')

model_fp32_prepared = torch.quantization.prepare(model_fp32)

# Determine the best quantization settings by calibrating the model on a representative dataset.

calibration_dataset = …

model_fp32_prepared.eval()

for data, label in calibration_dataset:

    model_fp32_prepared(data)
```

前面的代码片段从一个经过训练的模型`model_fp32`开始。为了将模型转换成校准过程的中间格式，您需要附加一个量化配置(`model_fp32.qconfig`)并将模型传递给`torch.quantization.prepare`方法。如果模型推理在服务器实例上运行，您必须将模型的`qconfig`属性设置为`torch.quantization.get_default_qconfig('fbgemm')`。如果目标环境是一个移动设备，您必须将`'qnnpack'`传递给`get_default_qconfig`函数。校准过程可以通过将代表性数据集传递给生成的模型`model_fp32_prepared`来实现。

最后一步是将校准模型转换成量化模型:

```

model_int8 = torch.quantization.convert(model_fp32_prepared)
```

前面一行代码中的`torch.quantization.convert`操作量化校准模型(`model_fp32_prepared`)并生成模型的量化版本(`model_int8`)。

关于静态量化的其他细节可以在[https://py torch . org/tutorials/advanced/static _ quantization _ tutorial . html](https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html)找到。

在下一节中，我们将描述如何在 TF 和 PyTorch 中执行量化感知训练。

## 执行量化感知训练

训练后量化可以显著减小模型的大小。但是，这也可能会显著降低模型的准确性。因此，下面的问题出现了:我们能恢复一些损失的准确性吗？这个问题的答案可能是**量化感知训练** ( **QAT** )。在这种情况下，模型在训练之前被量化，以便它可以使用较低精度的权重和激活直接学习泛化。

首先，我们来看看如何在 TF 中实现这一点。

### 张量流中的量化感知训练

TF 通过 TensorFlow 模型优化工具包提供 QAT。下面的代码片段描述了如何在 TF 中设置 QAT:

```

import tensorflow_model_optimization as tfmot

# A TF model

model = … 

q_aware_model = tfmot.quantization.keras.quantize_model(model)

q_aware_model.compile(

              optimizer=...,

              loss=...,

              metrics=['accuracy'])

q_aware_model.fit(...)
```

正如您所看到的，我们已经使用了`tfmot.quantization.keras.quantize_model`函数为 QAT 建立了一个模型。输出模型需要使用`compile`函数进行编译，并且可以使用`fit`函数进行训练，就像普通的 TF 模型一样。令人惊讶的是，这正是你所需要的。经过训练的模型将已经被量化，并且应该提供比从训练后量化生成的模型更高的精度。

更多详情请参考原文档:[https://www . tensor flow . org/model _ optimization/guide/quantization/training _ comprehensive _ guide](https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide)。

接下来，我们将看看 PyTorch 案例。

### PyTorch 中的量化感知训练

PyTorch 中的 QAT 经历类似的过程。在整个训练过程中，必要的计算是实现被箝位和舍入的数字，以模拟量化的效果。完整的细节可以在[https://py torch . org/docs/stable/quantization . html # quantization-aware-training-for-static-quantization](https://pytorch.org/docs/stable/quantization.html#quantization-aware-training-for-static-quantization)找到。让我们看看如何为 PyTorch 模型设置 QAT。

QAT 的设置几乎与我们在*静态量化——使用代表性数据集确定最佳量化参数*部分所经历的静态量化相同。对于静态量化和 QAT，同样的修改对于模型是必要的；必须将`torch.quantization.QuantStub`和`torch.quantization.DeQuantStub`操作插入到模型定义中，以指示量化的区域。主要区别来自网络的中间表示，因为 QAT 涉及在整个训练过程中更新模型参数。以下代码片段更好地描述了这种差异:

```

model_fp32 = OriginalModel()

# model must be set to train mode for QAT

model_fp32.train()

model_fp32.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')

model_fp32_prepared = torch.quantization.prepare_qat(model_fp32_fused)

# train the model

for data, label in train_dataset:

    pred = model_fp32_prepared(data)

    ...

# Generate quantized version of the trained model

model_fp32_prepared.eval()

model_int8 = torch.quantization.convert(model_fp32_prepared)
```

在前面的示例中，我们使用的是在*静态量化中定义的相同网络——使用代表性数据集*部分确定最佳量化参数:`OriginalModel`。对于 QAT ( `model_fp32.train()`)，模型应处于`train`模式。这里，我们假设模型将被部署在一个服务器实例上:`torch.quantization.get_default_qat_qconfig('fbgemm')`。在 QAT 的情况下，模型的中间表示是通过将原始模型传递给`torch.quantization.prepare_qat`函数来创建的。你需要训练中间表示(`model_fp32_prepared`)而不是原始模型(`model_fp32`)。一旦训练完成，您可以使用`torch.quantization.convert`函数生成量化模型。

总的来说，我们研究了TF 和 PyTorch 如何提供 QAT，以最大限度地降低量化带来的模型精度下降。

要记住的事情

a.网络量化是一种简单的技术，通过以较低的精度表示它所处理的数字来减少推断延迟。

b.有两种类型的网络量化:训练后量化，将量化应用于已训练的模型 QAT，通过以较低精度训练模型来最小化精度下降。

c.TF 和 PyTorch 支持训练后量化和 QAT，只需对训练代码进行最小的修改。

在下一节中，我们将研究另一种改进推理延迟的方法:权重共享。

# 重量共享–减少不同重量值的数量

**权重共享**或**权重聚类**是另一种可以显著减小模型大小的技术。这种技术背后的想法相当简单:让我们将权重分组(或聚类),并使用质心值而不是单个权重值。在这种情况下，我们可以存储每个质心的值，而不是存储权重的每个值。因此，我们可以大大压缩模型大小，并可能加快推理过程。权重共享背后的关键思想在*图 10.2* 中以图形方式呈现(改编自关于权重聚类 API 的 TF 官方博文:[https://blog . tensor flow . org/2020/08/tensor flow-model-optimization-toolkit-weight-clustering-API . html](https://blog.tensorflow.org/2020/08/tensorflow-model-optimization-toolkit-weight-clustering-api.html)):

![Figure 10.2 – An illustration of weight sharing
](img/B18522_10_02.jpg)

图 10.2–重量分担示意图

让我们先学习如何在 TF 中执行重量共享，然后再看如何在 PyTorch 中执行相同的操作。

## 在 TensorFlow 中执行重量共享

TF 通过 TensorFlow 模型优化工具包([https://www . tensor flow . org/Model _ Optimization/guide/clustering/clustering _ example](https://www.tensorflow.org/model_optimization/guide/clustering/clustering_example))为`Sequential`和`Functional` TF 模型提供权重共享。

首先，您需要定义集群配置，如下面的代码片段所示:

```

import tensorflow_model_optimization as tfmot

# A trained model to compress

tf_model = ...

CentroidInitialization = tfmot.clustering.keras.CentroidInitialization

clustering_params = {

  'number_of_clusters': 10,

  'cluster_centroids_init': CentroidInitialization.LINEAR

}

clustered_model = tfmot.clustering.keras.cluster_weights(tf_model, **clustering_params)
```

如您所见，权重聚类涉及到了`tfmot.clustering.keras.cluster_weights`函数。我们需要提供经过训练的模型(`tf_model`)和集群配置(`clustering_params`)。集群配置定义了集群的数量以及如何初始化每个集群。在本例中，我们正在生成 10 个已使用线性质心初始化进行初始化的聚类(聚类质心将在最小值和最大值之间均匀分布)。其他集群初始化选项可以在[https://www . tensor flow . org/model _ optimization/API _ docs/python/TF mot/clustering/keras/centrid initialization](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/clustering/keras/CentroidInitialization)找到。

生成具有聚类权重的模型后，您可以使用`tfmot.clustering.keras.strip_clustering`函数删除所有在推理过程中不需要的变量:

```

final_model = tfmot.clustering.keras.strip_clustering(clustered_model) 
```

接下来，我们将看看如何在 PyTorch 中执行重量共享。

## 在 PyTorch 中执行重量共享

可惜 PyTorch 不支持重量共享。相反，我们将提供一个可能实现的高级描述。在本例中，我们将尝试实现*图 10.2* 中描述的操作。首先，我们将向模型实现添加一个名为`cluster_weights`的自定义函数，您可以在训练后调用它来对权重进行聚类。然后，`forward`方法需要稍微修改，如下面的代码片段所示:

```

from torch.nn import Module

class SampleModel(Module):

# in the case of PyTorch Lighting, we inherit pytorch_lightning.LightningModule class

  def __init__(self):

    self.layer = …

    self.weights_cluster = … # cluster index for each weight

    self.weights_mapping = … # mapping from a cluster index to a centroid value

  def forward(self, input):

    if self.training: # in training mode

      output = self.layer(input)

    else: # in eval mode

      # update weights of the self.layer by reassigning each value based on self.weights_cluster and self.weights_mapping

    output = self.layer(input)

    return output

def cluster_weights(self):

  # cluster weights of the layer 

  # construct a mapping from a cluster index to a centroid value and store at self.weights_mapping

  # find cluster index for each weight value and store at self.weights_cluster

  # drop the original weights to reduce the model size

# First, we instantiate a model to train

model = SampleModel()

# train the model

…

# perform weight sharing

model.cluster_weights()

model.eval()
```

前面的代码应该是不言自明的，因为它是带有注释的伪代码，解释了关键操作。首先，模型被当作普通模型来训练。当`cluster_weights`函数被触发时，权重被聚类，权重共享的必要信息被存储在类内；每个权重的聚类索引是存储在`self.weights_cluster`中的，每个聚类的质心值存储在`self.weights_mapping`中。当模型处于`eval`模式时，`forward`操作使用由`self.weights_cluster`和`self.weights_mapping`构建的一组不同的权重。此外，您可以添加删除现有权重的功能，以在部署期间减小模型大小。我们在我们的存储库中提供了完整的实现:[https://github . com/packt publishing/Production-Ready-Applied-Deep-Learning/blob/main/Chapter _ 10/weight _ sharing _ py torch . ipynb](https://github.com/PacktPublishing/Production-Ready-Applied-Deep-Learning/blob/main/Chapter_10/weight_sharing_pytorch.ipynb)。

要记住的事情

a.权重共享通过将不同的权重值分组并用质心值替换它们来减小模型大小。

b.TF 通过 TensorFlow 模型优化工具包提供权重共享，PyTorch 不提供任何支持。

接下来，让我们了解另一种流行的技术，叫做网络修剪。

# 网络修剪——消除网络中不必要的连接

**网络修剪**是一个优化过程，消除不必要的连接。这种技术可以在训练之后应用，但是也可以在训练期间应用，其中可以进一步减少模型精度的降低。连接越少，需要的权重就越少。因此，我们可以减少模型大小以及推理延迟。在接下来的部分中，我们将介绍如何在 TF 和 PyTorch 中应用网络修剪。

## tensor flow 中的网络修剪

与模型量化和权重共享一样，TF 的网络修剪可通过 TensorFlow 模型优化工具包获得。因此，对于网络修剪，您需要做的第一件事是导入包含以下代码行的工具包:

```

import tensorflow_model_optimization as tfmot
```

要在训练期间应用网络修剪，您必须使用`tfmot.sparsity.keras.prune_low_magnitude`函数修改您的模型:

```

# data and configurations for training

x_train, y_train, x_text, y_test, x_valid, y_valid,  num_examples_train, num_examples_test, num_examples_valid  = …

batch_size = ...

end_step = np.ceil(num_examples_train / batch_size).astype(np.int32) * epochs

# pruning configuration

pruning_params = {

      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.3,

final_sparsity=0.5,

begin_step=0,

end_step=end_step)}

#  Prepare a model that will be pruned

model = ...

model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)
```

在前面的代码中，我们通过向`prune_low_magnitude`函数提供一个模型和一组参数`pruning_params`来配置网络修剪。正如您所看到的，我们已经应用了`PolynomialDecay`修剪，它以特定的稀疏度启动网络(`initial_sparsity`，并在整个训练过程中构建目标稀疏度的网络([https://www . tensor flow . org/model _ optimization/API _ docs/python/TF mot/sparsity/keras/polynomial decay](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/PolynomialDecay))。如最后一行中的所示，`prune_low_magnitude`函数返回另一个在训练期间执行网络修剪的模型。

在我们查看我们需要对训练循环进行的修改之前，我们想介绍另一个修剪配置`tfmot.sparsity.keras.ConstantSparsity`([https://www . tensor flow . org/model _ optimization/API _ docs/python/TF mot/sparsity/keras/constants parsity](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/ConstantSparsity))。这种修剪配置在整个训练过程中应用恒定稀疏修剪。要应用这种类型的网络修剪，您可以简单地修改`pruning_params`,如下面的代码片段所示:

```

pruning_params = {

      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=0, frequency=100) }
```

如下面的代码片段所示，训练循环需要对回调配置进行一次额外的修改；我们需要使用一个 Keras 回调函数，为每个优化器步骤应用修剪——即`tfmot.sparsity.keras.UpdatePruningStep`:

```

model_for_pruning.compile(…)

callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]

model_for_pruning.fit(x_train, y_train,

    batch_size=batch_size, epochs=epochs,     validation_data=(x_valid, y_vallid),

    callbacks=callbacks)
```

前面的代码编译了为网络修剪准备的模型，并执行了训练。请记住，键的改变来自为`fit`函数指定的`tfmot.sparsity.keras.UpdatePruningStep`回调。

最后，您可以通过将模型传递给`tfmot.sparsity.keras.strip_pruning`函数来更新训练的模型，以便只记住稀疏权重。模型推理不需要的所有`tf.Variable`实例将被删除:

```

final_tf_model = tfmot.sparsity.keras.strip_pruning(model_for_pruning)
```

给出的例子可以直接应用于`Functional`和`Sequential` TF 模型。要对模型的特定层或子集应用修剪，需要进行以下修改:

```

def apply_pruning_to_dense(layer):

    if isinstance(layer, tf.keras.layers.Dense):

        return tfmot.sparsity.keras.prune_low_magnitude(layer)

    return layer

model_for_pruning = tf.keras.models.clone_model(model, clone_function=apply_pruning_to_dense)
```

首先，我们定义了一个`apply_pruning_to_dense`包装函数，它将`prune_low_magnitude`函数应用于目标层。然后，我们需要做的就是将原始模型和`apply_pruning_to_dense`函数传递给`tf.keras.models.clone_model`函数，后者通过在给定模型上运行提供的函数来生成新模型。

值得一提的是，`tfmot.sparsity.keras.PrunableLayer`抽象类是存在的，它是为定制网络剪枝而设计的。关于这个的更多细节可以在[https://www . tensor flow . org/model _ optimization/API _ docs/python/TF mot/sparsity/keras/PrunableLayer](https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/PrunableLayer)和[https://www . tensor flow . org/model _ optimization/guide/pruning/comprehensive _ guide # custom _ training _ loop](https://www.tensorflow.org/model_optimization/guide/pruning/comprehensive_guide#custom_training_loop)找到。

接下来，我们将看看如何在 PyTorch 中执行修剪。

## py torch 中的网络修剪

PyTorch 通过`torch.nn.utils.prune`模块支持训练后的网络剪枝。给定一个训练好的网络，可以通过将模型传递给`global_unstructured`函数来实现剪枝。一旦模型被修剪，一个二进制掩码被附加，它代表被修剪的参数集。在`forward`操作之前，屏蔽应用于目标参数，消除不必要的计算。让我们来看一个例子:

```

# model is instantiated and trained

model = …

parameters_to_prune = (

    (model.conv, 'weight'),

    (model.fc, 'weight')

)

prune.global_unstructured(

    parameters_to_prune,

    pruning_method=prune.L1Unstructured, # L1-norm

    amount=0.2

)
```

如前面的代码片段所示，`global_unstructured`函数的第一个参数定义了修剪将应用到的网络组件(`parameters_to_prune`)。第二个参数定义了修剪算法(`pruning_method`)。最后一个参数`amount`表示要删除的参数的百分比。在本例中，我们根据 L1 规范修剪最低的 20%的连接。如果你对其他算法感兴趣，你可以在 https://pytorch.org/docs/stable/nn.html#utilities[找到完整的列表。](https://pytorch.org/docs/stable/nn.html#utilities)

PyTorch 还支持每层修剪，以及迭代修剪。你也可以定义一个自定义的修剪算法。上述功能的必要细节可以在 https://py torch . org/tutorials/intermediate/pruning _ tutorial . html # pruning-tutorial 找到。

要记住的事情

a.网络修剪是一个优化过程，通过消除网络中不必要的连接来减小模型大小。

b.TF 和 PyTorch 都支持模型级和层级网络修剪。

在本节中，我们描述了如何消除网络中不必要的连接，以改善推理延迟。在下一节中，我们将了解一种称为知识提炼的技术，它生成一个新的模型，而不是修改现有的模型。

# 知识提炼——通过模仿预测获得一个更小的网络

2015 年，Hinton 等人在其名为*在神经网络*中提取知识的出版物中首次提出了知识提取的概念。在分类问题中，Softmax 激活通常被用作网络的最后操作，以概率来表示每个类别的置信度。因为具有最高概率的类被用于最终预测，所以其他类的概率被认为是不重要的。然而，作者认为它们仍然由代表模型如何解释输入的有意义的信息组成。例如，如果两个类不断报告多个样本的相似概率，则这两个类可能有许多共同的特征，这使得两者之间的区别变得困难。当网络很深时，这样的信息变得更有成效，因为它可以从它所看到的数据中提取更多的信息。基于这一思想，作者提出了一种将训练模型的知识转移到更小规模模型的技术:知识提取。

知识升华的过程通常被称为教师与学生分享知识；原始模型被称为教师模型，而较小的模型被称为学生模型。如下图所示，学生模型由两个不同的标签训练而成，这两个标签由单个输入构成。一个标签是基本事实标签，被称为硬标签。另一个标签称为软标签。软标签是教师模型的输出概率。知识提炼的主要贡献来自软标签，它填充了硬标签中缺失的信息:

![Figure 10.3 – Overview of the knowledge distillation process
](img/B18522_10_03.jpg)

图 10.3-知识提炼过程概述

从评估知识提炼的益处的许多实验中，已经证明使用较小的网络实现可比较的性能是可能的。令人惊讶的是，更简单的网络架构在某些情况下会导致规范化，并导致学生模型比教师模型表现得更好。

自从这种技术首次出现以来，已经引入了许多变体。第一组变化来自如何定义知识:基于响应的知识(网络输出)、基于特征的知识(中间表示)和基于关系的知识(层或数据样本之间的关系)。另一组变体专注于如何实现知识转移:离线提炼(从预先训练的教师模型中训练学生模型)，在线提炼(在两个模型都被训练时共享知识)，以及自我提炼(在单个网络内共享知识)。我们相信，如果你愿意进一步探索这个领域，由苟等人撰写的一篇名为*知识提炼:一项调查*的论文可以是一个很好的起点。

不幸的是，由于培训设置的复杂性，没有一个框架支持开箱即用的知识提炼。但是，如果模型网络很复杂，而输出结构很简单，那么这仍然是一个很好的选择。

要记住的事情

a.知识提炼是一种将已训练模型的知识转移到更小规模模型的技术。

b.在知识提炼中，原始模型被称为教师模型，而较小的模型被称为学生。学生模型由两个标签训练而成:基础事实标签和教师模型的输出。

最后，我们介绍一种修改网络结构以减少模型参数数量的技术:网络结构搜索。

# 网络架构搜索–寻找最高效的网络架构

**神经架构搜索(NAS)** 是为给定问题寻找各层最佳组织的过程。由于可能的网络架构的搜索空间非常大，因此评估每个可能的网络架构是不可行的。因此，需要一种聪明的方法来识别有前途的网络体系结构并评估候选者。因此，NAS 方法沿着三个不同的方面发展:

*   **搜索空间**:如何构造合理大小的搜索空间
*   **搜索策略**:如何高效探索搜索空间
*   **性能评估策略**:如何在不完全训练模型的情况下高效地评估性能

尽管 NAS 是一个快速发展的研究领域，但有一些工具可用于 TF 和 PyTorch 模型:

*   optuna([https://dz lab . github . io/dl tips/en/tensor flow/hyperoptim-optuna](https://dzlab.github.io/dltips/en/tensorflow/hyperoptim-optuna/))
*   Syne-Tune，可以与 SageMaker([https://AWS . Amazon . com/blogs/machine-learning/run-distributed-hyperparameter-and-neural-architecture-tuning-jobs-with-syne-Tune](https://aws.amazon.com/blogs/machine-learning/run-distributed-hyperparameter-and-neural-architecture-tuning-jobs-with-syne-tune/))一起使用
*   katib([https://www . kube flow . org/docs/components/katib/hyperparameter](https://www.kubeflow.org/docs/components/katib/hyperparameter))，
*   **神经网络智能**(**NNI**)([https://github . com/Microsoft/nni/blob/b 6 cf 7 ce E0 e 72671672 b 7845 ab 24 fcdc 5 aed 9 ed 48/docs/en _ US/general nasinterfaces . MD # example-enas-macro-search-space](https://github.com/Microsoft/nni/blob/b6cf7cee0e72671672b7845ab24fcdc5aed9ed48/docs/en_US/GeneralNasInterfaces.md#example-enas-macro-search-space))
*   SigOpt([https://SigOpt . com/blog/simple-neural-architecture-search-nas-Intel-SigOpt](https://sigopt.com/blog/simple-neural-architecture-search-nas-intel-sigopt/))

NAS 实施的简单版本包括从组织的随机层中定义一个搜索空间。然后，我们只需选择性能最佳的型号。为了减少总的搜索时间，我们可以基于特定的评估度量应用早期停止，这将在评估度量不再变化时快速停止训练。这种设置将 NAS 重新表述为一个超参数调优问题，其中模型架构已经成为一个参数。我们可以通过应用以下技术之一来进一步改进搜索算法:

*   贝叶斯优化
*   **强化学习** ( **RL** )
*   梯度方法
*   基于层次的方法

如果您想进一步探索这一领域，我们建议您自行实施 NAS。首先，您可以利用在 [*第 7 章*](B18522_07.xhtml#_idTextAnchor162) 、*揭示深度学习模型的秘密*中介绍的超参数调整技术。你可以从随机参数搜索或贝叶斯优化方法结合早期停止开始。然后，我们建议研究基于 RL 的实现。我们也推荐阅读一篇名为*神经结构搜索的全面调查:挑战和解决方案*的论文，作者是任等人。

要记住的事情

a.NAS 是为潜在问题寻找最佳网络体系结构的过程。

b.NAS 由三部分组成:搜索空间、搜索策略和性能评估策略。它包括评估不同架构的网络并找到最佳架构。

c.有一些用于 NAS 的工具:Optuna、Syne-Tune、Katib、NNI 和 SigOpt。

在这一部分中，我们介绍了 NAS 以及它如何生成更小规模的网络。

# 总结

在这一章中，我们介绍了一组技术，您可以使用这些技术通过减少模型大小来改善推理延迟。我们介绍了三种最流行的技术，以及 TF 和 PyTorch 中的完整示例:网络量化、权重共享和网络修剪。我们还描述了通过直接修改网络架构来减少模型大小的技术:知识提取和 NAS。

在下一章中，我们将解释如何在移动设备上部署 TF 和 PyTorch 模型，在这一节中描述的技术可能是有用的。