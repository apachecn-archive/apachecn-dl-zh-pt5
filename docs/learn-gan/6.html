<html><head/><body><title>Chapter 6. Taking Machine Learning to Production</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
<!-- kobo-style -->

<script type="text/javascript" src="img/kobo.js"/>
<style type="text/css" id="kobostylehacks">div#book-inner p, div#book-inner div { font-size: 1.0em; } a { color: black; } a:link, a:visited, a:hover, a:active { color: blue; } div#book-inner * { margin-top: 0 !important; margin-bottom: 0 !important;}</style>

<div><div><div><div><div><div><h1 class="title"><a id="ch06"/>第六章。将机器学习应用于生产</h1></div></div></div><p>很多机器学习和深度学习教程、教科书和视频只关注模型的训练和评估。但是，如何将训练好的模型投入生产，并用于实时场景或提供给客户呢？</p><p>在本章中，您将使用<code class="literal">LFW</code>数据集开发一个面部图像校正系统，使用您训练的GAN模型自动校正损坏的图像。然后，您将学习几种在生产中部署机器学习或深度学习模型的技术，包括在数据中心和基于微服务的容器化环境的云上。最后，您将学习在无服务器环境中使用托管云服务运行深度模型的方法。</p><p>我们将在本章中讨论以下主题:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">使用DCGAN构建图像校正系统</li><li class="listitem" style="list-style-type: disc">部署机器学习模型的挑战</li><li class="listitem" style="list-style-type: disc">带有容器的微服务架构</li><li class="listitem" style="list-style-type: disc">部署深度学习模型的各种方法</li><li class="listitem" style="list-style-type: disc">在Docker上提供基于Keras的深度模型</li><li class="listitem" style="list-style-type: disc">使用GKE在云上部署深度模型</li><li class="listitem" style="list-style-type: disc">使用AWS Lambda和Polly的音频无服务器图像识别</li><li class="listitem" style="list-style-type: disc">通过云托管服务运行人脸检测</li></ul></div><div><div><div><div><h1 class="title"><a id="ch06lvl1sec34"/>使用DCGAN构建图像校正系统</h1></div></div></div><p>图像校正和修补是用于填充或完成图像的丢失或损坏部分的相关技术。建立一个能够广泛填补缺失部分的系统需要两条信息:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>上下文信息</strong>:帮助<a id="id273" class="indexterm"/>根据周围像素提供的信息推断缺失的像素</li><li class="listitem" style="list-style-type: disc"><strong>感知信息</strong>:帮助<a id="id274" class="indexterm"/>将填充/完成的部分解释为正常，如在现实生活或其他图片中所见</li></ul></div><p>在本例中，我们将使用DCGAN开发一个图像校正或补全系统，该系统使用野生的 ( <code class="literal">LFW</code>)数据集<a id="id275" class="indexterm"/>中的<strong>标记的人脸。关于DCGAN及其架构，请参考<a class="link" href="ch02.html" title="Chapter 2. Unsupervised Learning with GAN">第2章</a>、<em>GAN无监督学习</em>。</strong></p><p>在进入构建图像校正系统的步骤之前，让我们定义一些符号和<code class="literal">loss</code>函数:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><em> x </em>:图像损坏。</li><li class="listitem" style="list-style-type: disc"><em> M </em>:表示一个二进制掩码，其值为1(表示图像中我们想要保留的部分)或0(表示图像中我们想要完成/校正的部分)。由<img src="img/B08086_06_37.jpg" alt="Building an image correction system using DCGAN"/>表示的两个矩阵<em> x </em>和<em> M </em>之间的逐元素乘法返回图像的原始部分。</li><li class="listitem" style="list-style-type: disc"><em> pdata </em>:采样数据的未知分布。</li></ul></div><p>一旦我们训练了DCGAN的鉴别器<em> D(x) </em>和生成器<em> G(z) </em>，我们就可以利用它来完成图像中的缺失像素，<em> x </em>，方法是在这些缺失像素上最大化<em> D(x) </em>。</p><p>上下文丢失通过从<em> G(z) </em>中按元素减去<em> x </em>中的像素并找出它们之间的差异来惩罚<em> G(z) </em>没有为输入图像中的已知像素位置创建相似图像:</p><div><img src="img/B08086_06_38.jpg" alt="Building an image correction system using DCGAN"/></div><p>感知损失具有在训练DCGAN中使用的相同标准，以确保恢复的图像看起来真实:</p><div><img src="img/B08086_06_39.jpg" alt="Building an image correction system using DCGAN"/></div><p>接下来，我们需要从生成器中找到一个图像，<em> G(z) </em>，它提供了丢失像素的合理重建。然后，完成的像素<img src="img/B08086_06_41.jpg" alt="Building an image correction system using DCGAN"/>可以被添加到<a id="id276" class="indexterm"/>原始像素以生成重建图像:</p><div><img src="img/B08086_06_40.jpg" alt="Building an image correction system using DCGAN"/></div><div><div><h3 class="title"><a id="tip03"/>提示</h3><p>在CPU上训练深度<a id="id277" class="indexterm"/>卷积网络可能会非常慢，因此建议使用支持CUDA的GPU来进行深度学习活动，这些活动涉及带有卷积或转置卷积的图像。</p></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec58"/>构建图像校正系统的步骤</h2></div></div></div><p>确保您已经下载了本章的代码:</p><div><ol class="orderedlist arabic"><li class="listitem"><code class="literal">DCGAN-ImageCorrection</code>项目将具有以下目录结构:<div> <img src="img/B08086_06_01.jpg" alt="Steps for building an image correction system"/> </div></li><li class="listitem">现在从<a class="ulink" href="http://vis-www.cs.umass.edu/lfw">http://vis-www.cs.umass.edu/lfw</a>下载<code class="literal">LFW</code>数据集(与深度漏斗对齐)并提取<code class="literal">lfw</code>目录下的内容:<div> <pre class="programlisting"> <strong>wget http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz </strong> <strong>tar -xvzf lfw-funneled.tgz</strong> </pre> </div></li><li class="listitem">Next, execute <code class="literal">create_tfrecords.py</code> to generate the TensorFlow standard format from the <code class="literal">LFW</code> images. Modify the path of your <code class="literal">LFW</code> image location in the Python file:<div><pre class="programlisting">
<strong>base_path = &lt;Path to lfw directory&gt;</strong>
<strong>python create_tfrecords.py</strong>
</pre></div><p>这将在<code class="literal">data</code>目录下生成<code class="literal">tfrecords</code>文件，如下所示:</p><div><img src="img/B08086_06_02.jpg" alt="Steps for building an image correction system"/></div></li><li class="listitem">Now train the DCGAN model by executing the following command:<div><pre class="programlisting">
<strong>python train_generate.py</strong>
</pre></div><p>您可以<a id="id279" class="indexterm"/>修改Python文件中的<code class="literal">max_itr</code>属性，以确定训练应该持续的最大迭代次数。一旦训练开始，每5000次迭代后，您将在<code class="literal">lfw-gen</code>目录下找到生成的图像，如下所示:</p><div><img src="img/B08086_06_03.jpg" alt="Steps for building an image correction system"/></div></li><li class="listitem">最后，您可以使用经过训练的DCGAN模型来纠正损坏的图像。您需要将损坏的图像放在<code class="literal">complete_src</code>目录下，并执行以下命令:<div> <pre class="programlisting"> <strong>python image_correction.py --is_complete True --latest_ckpt  &lt;checkpoint number&gt;</strong> </pre> </div></li></ol></div><p>您也可以通过在前面的命令中使用<code class="literal">masktype</code>属性指定<code class="literal">center</code>或<code class="literal">random</code>来改变屏蔽的类型。</p><div><img src="img/B08086_06_04.jpg" alt="Steps for building an image correction system"/></div><p>前面的<a id="id280" class="indexterm"/>命令将在完整目录下生成修正或完整的图像，如下所示:</p><div><img src="img/B08086_06_05.jpg" alt="Steps for building an image correction system"/></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec59"/>将模型部署到生产中的挑战</h2></div></div></div><p>大多数研究人员<a id="id281" class="indexterm"/>和机器学习实践者都专注于机器学习或深度学习模型的训练和评估方面。在研究期间构建模型类似于在家里做饭，而在生产中构建或部署模型就像在餐馆里为各种各样的客户(他们的口味会随着时间的推移而变化)做饭。</p><p>在模型的生产部署过程中经常出现的一些常见挑战如下:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>可伸缩性</strong>:现实世界的<a id="id282" class="indexterm"/>生产环境与培训或研究环境大不相同。您通常需要在不影响性能的情况下满足大量请求。您的模型应该根据流量自动放大/缩小，然后在流量较低时缩小/放大。</li><li class="listitem" style="list-style-type: disc"><strong>自动模型训练或更新</strong>:真实世界的数据具有时间动态性，当您的模型进入真实世界的生产环境时，数据开始看起来<a id="id283" class="indexterm"/>与模型最初被训练时的数据不同。这意味着您需要重新训练您的模型(有时是自动的)，然后在模型之间无缝切换。</li><li class="listitem" style="list-style-type: disc"><strong>开发语言之间的互操作</strong>:通常，两个不同的人或团队负责研究(培训)模型和生产模型，并且用于研究的<a id="id284" class="indexterm"/>语言可能不同于用于生产的首选语言。这导致了一系列问题，因为机器学习模型在不同的编程语言中有不同的实现，即使模型本质上是相同的。</li><li class="listitem" style="list-style-type: disc"><strong>关于训练集元数据的知识</strong>:现实世界的生产数据可能会有缺失值<a id="id285" class="indexterm"/>，您需要应用缺失值插补技术来处理这个问题。虽然在生产系统中，您不保存有关训练数据的信息，但是为了正确估算生产测试样本中的缺失值，您必须存储估算所需的训练集统计信息。</li><li class="listitem" style="list-style-type: disc"><strong>模型性能的实时评估</strong>:模型在生产中的性能评估<a id="id286" class="indexterm"/>通常需要您收集基础真实数据(或其他实时指标)，并在模型处理更多数据时生成动态页面。此外，您<a id="id287" class="indexterm"/>可能需要通过部署两个或更多同时提供相同功能的模型来执行<strong> A/B </strong>测试，以评估生产中的性能。</li></ul></div></div></div></div></div></div>
<title>Microservice architecture using containers</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
<!-- kobo-style -->

<script type="text/javascript" src="img/kobo.js"/>
<style type="text/css" id="kobostylehacks">div#book-inner p, div#book-inner div { font-size: 1.0em; } a { color: black; } a:link, a:visited, a:hover, a:active { color: blue; } div#book-inner * { margin-top: 0 !important; margin-bottom: 0 !important;}</style>

<div><div><div><div><div><div><h1 class="title"><a id="ch06lvl1sec35"/>使用容器的微服务架构</h1></div></div></div><p>在传统的<strong>单片</strong>架构中，<a id="id288" class="indexterm"/>应用将其所有功能放入EAR或WAR <a id="id289" class="indexterm"/>等单个包中，并将其部署在应用服务器上(如JBoss、Tomcat或WebLogic)。尽管一个单一的应用程序具有独立的、可区分的组件，但所有组件都封装在一个屋檐下。</p><div><div><div><div><h2 class="title"><a id="ch06lvl2sec60"/>整体架构的缺点</h2></div></div></div><p>单片设计的一些常见缺陷如下:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">单片架构中的功能性<a id="id290" class="indexterm"/>组件被封装在一个应用程序下，并且没有被隔离。因此，更改单个组件需要更新整个应用程序，从而导致整个应用程序停止运行。这在生产场景中是不可取的。</li><li class="listitem" style="list-style-type: disc">扩展一个单一的应用程序是没有效率的，因为要进行扩展，您必须在不同的服务器上部署应用程序的每个副本(WAR或EAR ),这些服务器将使用相同数量的资源。</li><li class="listitem" style="list-style-type: disc">通常，在现实世界中，与其他组件相比，一个或两个功能组件被大量使用。但是在单片设计中，所有的组件都将利用相同的资源，因此很难隔离高度使用的组件来提高整个应用程序的性能。</li></ul></div><p><strong>微服务</strong>是一种将大型软件项目分解成松散耦合的模块/服务的技术，这些模块/服务通过简单的API相互通信。基于微服务的架构将每个功能放入单独的服务中，以克服整体设计的缺点。</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec61"/>微服务架构的优势</h2></div></div></div><p>微服务设计模式的一些优势如下:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>单一责任原则</strong>:微服务架构<a id="id291" class="indexterm"/>确保通过简单的API将每个功能部署或公开为独立的服务<a id="id292" class="indexterm"/>。</li><li class="listitem" style="list-style-type: disc"><strong>高可伸缩性</strong>:高利用率或高要求的服务可以部署在多个服务器上，为大量的请求/流量提供服务，从而提高性能。这对于单一的大型整体服务来说是很难实现的。</li><li class="listitem" style="list-style-type: disc"><strong>提高容错能力</strong>:单个模块/服务<a id="id294" class="indexterm"/>的故障不会影响更大的应用程序，并且您可以快速恢复或带回故障模块，因为该模块是作为单独的服务运行的。而在一个组件/模块中有错误的整体或庞大的服务会影响其他模块/功能。</li><li class="listitem" style="list-style-type: disc"><strong>技术堆栈的自由度</strong>:微服务允许您选择最适合特定功能的技术<a id="id295" class="indexterm"/>，并帮助您在个别服务上尝试新的技术堆栈。</li></ul></div><p>部署基于微服务的应用程序的最佳方式是在容器内部。</p><div><div><div><div><h3 class="title"><a id="ch06lvl3sec06"/>容器</h3></div></div></div><p>容器是可共享的，<a id="id296" class="indexterm"/>轻量级进程位于主机操作系统之上，共享主机操作系统的内核(二进制文件和库)。容器通过抽象层同时解决一系列复杂的问题。容器的流行可以用奇妙的三重奏来形容:<em>隔离</em>！<em>便携性</em>！<em>重复性</em>！。</p></div><div><div><div><div><h3 class="title"><a id="ch06lvl3sec07"/>码头工人</h3></div></div></div><p>Docker是最热门的开源项目之一，是一个非常受欢迎的容器化引擎，它允许一种便捷的方式将您的服务/应用与所有依赖项打包在一起，以部署在本地或云中。</p></div><div><div><div><div><h3 class="title"><a id="ch06lvl3sec08"/> Kubernetes</h3></div></div></div><p>Kubernetes是Google的另一个开源项目，它为容器提供编排，允许自动化的水平伸缩、服务发现、负载平衡等等。简而言之，它自动管理您在云中的容器化应用程序/服务。</p><div><div><h3 class="title"><a id="note09"/>注</h3><p>在本节中，我们将Docker称为容器引擎，尽管其他容器引擎也会提供类似的特性或功能。</p></div></div></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec62"/>使用容器的好处</h2></div></div></div><p>使用容器的一些优点讨论如下:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>持续部署和测试</strong>:通常，涉及不同环境的发布生命周期，<a id="id302" class="indexterm"/>如开发和生产，由于不同的包版本或依赖关系，会有一些<a id="id303" class="indexterm"/>差异。Docker通过维护从开发到生产的所有内部配置和依赖关系来确保一致的环境，从而填补了这一空白。因此，您可以从开发到生产使用同一个容器，没有任何差异或人工干预。</li><li class="listitem" style="list-style-type: disc"><strong>多云平台</strong>:Docker最大的好处之一就是它可以跨各种<a id="id304" class="indexterm"/>环境和平台移植。所有主要的云提供商，如<strong>亚马逊网络服务</strong> ( <strong> AWS </strong>)和<strong>谷歌计算平台</strong> ( <strong> GCP </strong>)，都通过增加个人支持(AWS ECS或谷歌GKE)来支持Docker的可用性。如果主机操作系统支持Docker，Docker容器可以在虚拟机VM实例(Amazon EC2或Google Compute Engine)中运行。</li><li class="listitem" style="list-style-type: disc"><strong>版本控制</strong> : Docker <a id="id305" class="indexterm"/>容器就像<code class="literal">Git</code> / <code class="literal">SVN</code>存储库一样作为一个版本控制系统工作，因此您可以提交对Docker映像和版本控制的更改。</li><li class="listitem" style="list-style-type: disc"><strong>隔离和安全</strong> : Docker确保在容器内运行的应用程序完全隔离，并且彼此<a id="id306" class="indexterm"/>隔离，授予对流量和管理的完全控制权。没有一个Docker容器可以访问另一个容器中运行的进程。从体系结构的角度来看，每个容器都有自己的一组资源。</li></ul></div><p>你可以将先进的机器学习或深度学习应用与容器的部署能力相结合，使系统更加高效和可共享。</p></div></div></div></div>
<title>Various approaches to deploying deep models</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
<!-- kobo-style -->

<script type="text/javascript" src="img/kobo.js"/>
<style type="text/css" id="kobostylehacks">div#book-inner p, div#book-inner div { font-size: 1.0em; } a { color: black; } a:link, a:visited, a:hover, a:active { color: blue; } div#book-inner * { margin-top: 0 !important; margin-bottom: 0 !important;}</style>

<div><div><div><div><div><div><h1 class="title"><a id="ch06lvl1sec36"/>部署深度模型的各种方法</h1></div></div></div><p>机器学习既刺激又有趣！但是，当您希望您的模型服务于真实的人和系统时，无论是在建模阶段还是在部署阶段，它都有其挑战性。</p><p>将机器<a id="id307" class="indexterm"/>学习模型部署到生产中可以通过多种方式完成，而生产<a id="id308" class="indexterm"/>机器学习模型的不同方式实际上受多种因素的控制:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">你希望你的模型是实时流分析还是批量分析的一部分？</li><li class="listitem" style="list-style-type: disc">您希望有多个模型提供相同的功能，还是需要对您的模型执行A/B测试？</li><li class="listitem" style="list-style-type: disc">您希望您的模型多久更新一次？</li><li class="listitem" style="list-style-type: disc">你如何根据流量来扩展你的模型？</li><li class="listitem" style="list-style-type: disc">你如何与其他服务集成或者将ML服务放入管道中？</li></ul></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec63"/>方法1 -离线建模和基于微服务的容器化部署</h2></div></div></div><p>在这种方法中，您将离线训练和评估您的模型，然后使用您的预训练模型构建一个<a id="id309" class="indexterm"/> RESTful服务，并将其部署在一个容器中。接下来，您可以根据成本、安全性、可扩展性和基础设施要求，在您的数据中心或云中运行容器。这种方法非常适合当您的机器学习或深度学习服务将具有连续的流量，并且需要根据请求的峰值动态扩展时。</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec64"/>方法2 -离线建模和无服务器部署</h2></div></div></div><p>在这种方法中，您<a id="id310" class="indexterm"/>将离线训练您的模型，并在AWS Lambda等无服务器环境中部署您的服务(在这种环境中，您只需支付调用API的费用；您不必为按小时/分钟运行容器或VM实例付费)。这种方法非常适合于模型服务不会被持续使用，而是在一段时间后被调用的情况。但是，即使有连续的流量(取决于您命中的请求数量)，与方法1相比，这种方法可能仍然具有成本效益。</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec65"/>方法3 -在线学习</h2></div></div></div><p>有时，您需要通过将您的机器学习服务与<a id="id311" class="indexterm"/>管道集成来执行实时流分析(例如将其放在具有IOT传感器数据的消息队列的消费者端)。在实时流的情况下，数据可能会非常频繁地改变。在这种情况下，离线模型训练不是正确的选择。相反，您需要您的模型自动适应它所看到的数据——也就是说，它将使用类似SGD或其mini batch variant的东西基于数据更新权重/参数。</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec66"/>方法4——使用托管机器学习服务</h2></div></div></div><p>这种方法非常适合当你没有资源或团队成员在内部构建机器学习模型的时候。相反，您可以利用可用的基于云的托管机器学习或深度学习服务，如Google Cloud ML、Azure ML、AWS Rekognition、AWS Polly、Google Cloud Vision等，通过调用简单的API来满足您的需求。</p><p>接下来，我们将通过实际例子来说明前面提到的部署方法。</p></div></div></div></div>
<title>Serving Keras-based deep models on Docker</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
<!-- kobo-style -->

<script type="text/javascript" src="img/kobo.js"/>
<style type="text/css" id="kobostylehacks">div#book-inner p, div#book-inner div { font-size: 1.0em; } a { color: black; } a:link, a:visited, a:hover, a:active { color: blue; } div#book-inner * { margin-top: 0 !important; margin-bottom: 0 !important;}</style>

<div><div><div><div><div><div><h1 class="title"><a id="ch06lvl1sec37"/>在Docker上提供基于Keras的深度模型</h1></div></div></div><p>在本例中，我们将<a id="id313" class="indexterm"/>使用预训练的Keras InceptionV3模型构建一个图像识别<a id="id314" class="indexterm"/>系统，并将其部署在本地机器的一个容器上。有关预训练模型的更多信息，请参考<a class="link" href="ch04.html" title="Chapter 4. Building Realistic Images from Your Text">第4章</a>、<em>从文本中构建真实图像</em>。我们预训练的Keras模型将在Docker容器中运行，该容器使用Flask作为REST API公开。</p><div><img src="img/B08086_06_06.jpg" alt="Serving Keras-based deep models on Docker"/></div><p>确保您有可用的<code class="literal">keras-microservice</code>项目，然后执行以下步骤在<code class="literal">docker</code>容器中运行基于Keras的深度模型:</p><div><ol class="orderedlist arabic"><li class="listitem">首先，检查Docker文件是否在您当前的工作目录中，然后构建一个Docker映像:<div> <pre class="programlisting"> <strong>docker build -t keras-recognition-service .</strong> </pre> </div></li><li class="listitem">Once the <a id="id315" class="indexterm"/>Docker image is built <a id="id316" class="indexterm"/>successfully, use the image to run a container with the <code class="literal">docker run</code> command:<div><pre class="programlisting">
<strong>docker run -it --rm -d -p &lt;host port&gt;:&lt;container port&gt; -v &lt;host path&gt;:&lt;container path&gt; keras-recognition-service</strong>
</pre></div><p>例如:</p><div><pre class="programlisting">
<strong>docker run -it --rm -d -p 5000:80 -v /Users/kuntalg/knowledge:/deep/model keras-recognition-service</strong>
</pre></div><div><div><h3 class="title"><a id="note10"/>注意</h3><p>在<code class="literal">docker</code>容器内，<a id="id317" class="indexterm"/> Keras模型运行在名为<strong> Gunicorn </strong>的WSGI HTTP Python服务器内的端口<code class="literal">5001</code>上，该服务器由端口<code class="literal">80</code>上的<strong> Nginx </strong> <a id="id318" class="indexterm"/>代理服务器进行负载平衡。我们之前使用了<code class="literal">–p</code>属性来映射主机端口和容器端口。此外，我们使用了<code class="literal">-v</code>卷属性来映射主机路径和容器路径，这样我们就可以从这个路径加载预训练的模型。</p></div></div><p>现在是时候通过执行<code class="literal">test.sh</code>脚本来测试我们的图像识别服务了。该脚本包含一个<code class="literal">curl</code>命令来调用和测试我们公开的图像识别服务的REST API:</p><div><pre class="programlisting">#!/bin/bash
echo "Prediction for 1st Image:"
echo "--------------------------------"
(echo -n '{"data": "'; base64 test-1.jpg; echo '"}') | curl -X POST -H "Content-Type: application/json" -d @- http://127.0.0.1:5000

echo "Prediction for 2nd Image:"
echo "--------------------------------"
(echo -n '{"data": "'; base64 test-1.jpg; echo '"}') | curl -X POST -H "Content-Type: application/json" -d @- http://127.0.0.1:5000</pre></div></li><li class="listitem">最后，执行脚本从我们的Keras服务生成一个预测:<div> <pre class="programlisting"> <strong> ./test_requests.sh</strong> </pre> </div> <div> <img src="img/B08086_06_07.jpg" alt="Serving Keras-based deep models on Docker"/> </div></li></ol></div><p>瞧啊。我们已经在一个容器中成功部署了第一个基于Keras的深度学习模型。</p></div></div></div>
<title>Deploying a deep model on the cloud with GKE</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
<!-- kobo-style -->

<script type="text/javascript" src="img/kobo.js"/>
<style type="text/css" id="kobostylehacks">div#book-inner p, div#book-inner div { font-size: 1.0em; } a { color: black; } a:link, a:visited, a:hover, a:active { color: blue; } div#book-inner * { margin-top: 0 !important; margin-bottom: 0 !important;}</style>

<div><div><div><div><div><div><h1 class="title"><a id="ch06lvl1sec38"/>使用GKE在云上部署深度模型</h1></div></div></div><p>一旦深度学习模型被创建、部署在容器内部并在本地生成预测，就该使用Docker和Kubernetes将模型带到云(例如，本例中的Google Cloud)了。</p><p>执行以下步骤<a id="id322" class="indexterm"/>将本地创建的容器化模型带到云中:</p><div><ol class="orderedlist arabic"><li class="listitem">Sign up for a Google Cloud trial account (<a class="ulink" href="https://cloud.google.com/free">https://cloud.google.com/free</a>) and then create a <strong>New Project</strong> by typing a relevant <strong>Project name</strong> of your choice:<div><img src="img/B08086_06_08.jpg" alt="Deploying a deep model on the cloud with GKE"/></div><p>请记下包含您的<strong>项目名称</strong>的<strong>项目ID </strong>以及格式<code class="literal">&lt;project name&gt;-xxxxxx</code>的一些数字。我们将需要<strong>项目ID </strong>来将我们的本地模型部署到c</p></li><li class="listitem">d <a id="id323" class="indexterm"/>SDK on your machine (<a class="ulink" href="https://cloud.google.com/sdk">https://cloud.google.com/sdk</a>). And then install kubectl to<a id="id324" class="indexterm"/> manage the Kubernetes cluster:<div><pre class="programlisting">
<strong>gcloud components install kubectl</strong>
</pre></div><p>Google Cloud SDK中包含了<code class="literal">gcloud</code>命令。</p></li><li class="listitem">用<code class="literal">gcloud</code>命令行工具<code class="literal">config</code>命令设置一些环境变量:<div> <pre class="programlisting"> <strong>gcloud config set project &lt;project ID&gt;</strong> <strong>gcloud config set compute/zone &lt;zone name such as us-central1-b&gt;</strong> <strong>export PROJECT_ID="$(gcloud config get-value project -q)</strong> </pre> </div></li><li class="listitem">Now build the docker image with a tag or version (<code class="literal">v1</code> in this example):<div><pre class="programlisting">
<strong>docker build -t gcr.io/&lt;project ID&gt;/keras-recognition-service:v1 .</strong>
</pre></div><p>例如:</p><div><pre class="programlisting">
<strong>docker build -t gcr.io/deeplearning-123456/keras-recognition-service:v1 .</strong>
</pre></div></li><li class="listitem">Next, upload<a id="id325" class="indexterm"/> the image built previously with the <code class="literal">docker push</code> command to the Google Container Registry:<div><pre class="programlisting">
<strong>gcloud docker -- push gcr.io/&lt;project ID&gt;/keras-recognition-service:v1</strong>
</pre></div><p>例如:</p><div><pre class="programlisting">
<strong>gcloud docker -- push gcr.io/deeplearning-123456/keras-recognition-service:v1</strong>
</pre></div><div><img src="img/B08086_06_09.jpg" alt="Deploying a deep model on the cloud with GKE"/></div></li><li class="listitem">一旦容器映像存储在注册表中，我们需要通过指定计算引擎VM实例的数量来创建容器集群。该集群将由Kubernetes协调和管理。执行以下命令创建一个名为<code class="literal">dl-cluster</code>的双节点集群:<div> <pre class="programlisting"> <strong>gcloud container clusters create dl-cluster --num-nodes=2</strong> </pre> </div></li><li class="listitem">我们将使用Kubernetes <code class="literal">kubectl</code>命令行工具在容器引擎集群上部署和运行应用程序，监听端口<code class="literal">80</code> : <div> <pre class="programlisting"> <strong>gcloud container clusters get-credentials dl-cluster</strong>  <strong>kubectl run keras-recognition-service --image=gcr.io/deeplearning-123456/keras-recognition-service:v1 --port 80</strong> </pre> </div> <div> <img src="img/B08086_06_10.jpg" alt="Deploying a deep model on the cloud with GKE"/> </div></li><li class="listitem">现在将运行在容器集群中的<a id="id326" class="indexterm"/>应用程序连接到负载均衡器，这样我们就可以向真实世界的用户公开我们的图像识别服务:<div> <pre class="programlisting"> <strong>kubectl expose deployment keras-recognition-service --type=LoadBalancer --port 80 --target-port 80</strong> </pre> </div></li><li class="listitem">接下来，运行下面的<code class="literal">kubectl</code>命令来获取我们服务的外部IP:<div><pre class="programlisting"> <strong>kubectl get service</strong> </pre></div></li><li class="listitem">最后，执行下面的命令，从托管在云上的容器集群中的图像识别服务获得一个预测:<div> <pre class="programlisting"> <strong>(echo -n '{"data": "'; base64 test-1.jpeg; echo '"}') | curl -X POST -H "Content-Type: application/json" -d @- http://&lt;External IP&gt;:80</strong> </pre> </div> <div> <img src="img/B08086_06_11.png.jpg" alt="Deploying a deep model on the cloud with GKE"/> </div></li></ol></div></div></div></div>
<title>Serverless image recognition with audio using AWS Lambda and Polly</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
<!-- kobo-style -->

<script type="text/javascript" src="img/kobo.js"/>
<style type="text/css" id="kobostylehacks">div#book-inner p, div#book-inner div { font-size: 1.0em; } a { color: black; } a:link, a:visited, a:hover, a:active { color: blue; } div#book-inner * { margin-top: 0 !important; margin-bottom: 0 !important;}</style>

<div><div><div><div><div><div><h1 class="title"><a id="ch06lvl1sec39"/>使用AWS Lambda和Polly的无服务器音频图像识别</h1></div></div></div><p>在本例中，我们将使用tensor flow pre trained in ception v3模型构建一个<a id="id327" class="indexterm"/>基于音频的图像预测系统，并将它部署在AWS Lambda的无服务器环境中。我们将在AWS Lambda上运行我们的图像预测代码<a id="id329" class="indexterm"/>，并从S3加载我们的预训练模型，然后通过AWS API网关向我们的真实客户公开服务。</p><div><img src="img/B08086_06_12.jpg" alt="Serverless image recognition with audio using AWS Lambda and Polly"/></div><p>执行以下步骤，在无服务器平台上构建基于音频的图像识别系统:</p><div><ol class="orderedlist arabic"><li class="listitem">注册一个<a id="id331" class="indexterm"/> AWS试用账户(<a class="ulink" href="https://aws.amazon.com/free/">https://aws.amazon.com/free/</a>)，然后导航到<strong> IAM </strong>服务，为<a id="id332" class="indexterm"/> AWS Lambda创建一个新角色。在<strong> lambda_basic_execution </strong>的内联策略旁边附加两个新的托管策略:<strong> S3FullAccess </strong>和<strong> PollyFullAccess </strong>。<div> <img src="img/B08086_06_13.png.jpg" alt="Serverless image recognition with audio using AWS Lambda and Polly"/> </div></li><li class="listitem">接下来，创建<a id="id333" class="indexterm"/>一个S3桶，我们将在其中存储我们的lambda代码(由定制的Python包组成，如<code class="literal">numpy</code>、<code class="literal">scipy</code>、<code class="literal">tensorflow</code>等<a id="id334" class="indexterm"/>)。另外<a id="id335" class="indexterm"/>在你的S3桶中创建三个文件夹:<div> <ul class="itemizedlist"> <li class="listitem" style="list-style-type: disc"> <code class="literal">code</code>:我们将<a id="id336" class="indexterm"/>在这里存储我们的lambda环境的代码</li> <li class="listitem" style="list-style-type: disc"> <code class="literal">audio</code>:我们的预测音频将保存在这个位置</li> <li class="listitem" style="list-style-type: disc"> <code class="literal">model</code>:我们将在这个位置</li> </ul> </div> <div> <img src="img/B08086_06_14.png.jpg" alt="Serverless image recognition with audio using AWS Lambda and Polly"/> </div>存储我们的预训练模型</li><li class="listitem">下载<a id="id337" class="indexterm"/>预处理后的TensorFlow <a id="id338" class="indexterm"/>模型(<a class="ulink" href="http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz">http://download . tensor flow . org/models/image/imagenet/inception-2015-12-05 . tgz</a>，提取<a id="id339" class="indexterm"/>后<a id="id340" class="indexterm"/>将以下文件上传到<code class="literal">model</code>目录下的<code class="literal">S3</code>桶<a id="id341" class="indexterm"/>:<div><pre class="programlisting">classify_image_graph_def.pb imagenet_synset_to_human_label_map.txt imagenet_synset_to_human_label_map.txt</pre></div><div><img src="img/B08086_06_15.png.jpg" alt="Serverless image recognition with audio using AWS Lambda and Polly"/></div></li><li class="listitem"><code class="literal">lambda_tensorflow.zip</code>包含一个<code class="literal">classify.py</code>文件，该文件将在<code class="literal">lambda</code>函数<a id="id343" class="indexterm"/>执行期间被调用<a id="id342" class="indexterm"/>。更改桶名，在<code class="literal">classify.py</code>里面，再次压缩，上传到<a id="id345" class="indexterm"/>下的【S3】桶<code class="literal">code</code>目录:<div> <pre class="programlisting">def lambda_handler(event, context):          if not os.path.exists('/tmp/imagenetV3/'):         os.makedirs('/tmp/imagenetV3/')      # imagenet_synset_to_human_label_map.txt:     #   Map from synset ID to a human readable string.     strBucket = 'kg-image-prediction'     strKey = 'models/imagenetV3/imagenet_synset_to_human_label_map.txt'     strFile = '/tmp/imagenetV3/imagenet_synset_to_human_label_map.txt'     downloadFromS3(strBucket,strKey,strFile)       print(strFile)      # imagenet_2012_challenge_label_map_proto.pbtxt:     #   Text representation of a protocol buffer mapping a label to synset ID.          strBucket = 'kg-image-prediction'     strKey = 'models/imagenetV3/imagenet_2012_challenge_label_map_proto.pbtxt'     strFile = '/tmp/imagenetV3/imagenet_2012_challenge_label_map_proto.pbtxt'     downloadFromS3(strBucket,strKey,strFile)     print(strFile)       # classify_image_graph_def.pb:     #   Binary representation of the GraphDef protocol buffer.     strBucket = 'kg-image-prediction'     strKey = 'models/imagenetV3/classify_image_graph_def.pb'     strFile = '/tmp/imagenetV3/classify_image_graph_def.pb'     downloadFromS3(strBucket,strKey,strFile)     print(strFile)     data = base64.b64decode(event['base64Image'])     imageName= event['imageName']          image=io.BytesIO(data)     strBucket = 'kg-image-prediction'          strKey = 'raw-image/tensorflow/'+imageName+'.png'     uploadToS3(image, strBucket, strKey)     print("Image file uploaded to S3")               audioKey=imageName+'.mp3'     print(audioKey)     print("Ready to Run inference")      strBucket = 'kg-image-prediction'     strKey = 'raw-image/tensorflow/'+imageName+'.png'     imageFile = '/tmp/'+imageName+'.png'     downloadFromS3(strBucket,strKey,imageFile)     print("Image downloaded from S3")      strResult = run_inference_on_image(imageFile)      # Invoke AWS Polly to generate Speech from text     polly_client=boto3.client('polly')     response = polly_client.synthesize_speech(Text =strResult,OutputFormat = "mp3",VoiceId = "Joanna")     if "AudioStream" in response:         output = os.path.join("/tmp", audioKey)         with open(output, "wb") as file:             file.write(response["AudioStream"].read())      #Upload speech to S3     print("Ready upload to S3 audio")     strBucket = 'kg-image-prediction'     strKey = 'audio/'+audioKey     strFile = '/tmp/'+audioKey      with open(strFile, 'rb') as data:         uploadToS3(data,strBucket,strKey)     # Clean up directory     os.remove(imageFile)     os.remove(strFile)               return strResult</pre> </div> <div> <img src="img/B08086_06_16.png.jpg" alt="Serverless image recognition with audio using AWS Lambda and Polly"/> </div></li><li class="listitem">现在<a id="id346" class="indexterm"/>从<a id="id348" class="indexterm"/> web控制台导航到<strong> Lambda </strong>服务<a id="id347" class="indexterm"/>，从头开始创建一个新的Lambda函数。为该功能提供<strong>名称* </strong>和<strong>描述</strong>；选择<strong>运行时</strong>作为<strong> Python 2.7 </strong>并将之前创建的<code class="literal">IAM</code>角色附加到这个Lambda函数上。<div> <img src="img/B08086_06_17.png.jpg" alt="Serverless image recognition with audio using AWS Lambda and Polly"/> </div></li><li class="listitem">然后<a id="id349" class="indexterm"/>指定<a id="id350" class="indexterm"/>代码(<code class="literal">lambda_tensorflow.zip</code>)在您的Lambda函数配置中的位置:<div> <img src="img/B08086_06_18.png.jpg" alt="Serverless image recognition with audio using AWS Lambda and Polly"/> </div></li><li class="listitem">同时在<strong>高级设置</strong>选项卡下增加<a id="id351" class="indexterm"/>Lambda函数的<strong>内存(MB) </strong>和<strong>超时</strong>。第一次<a id="id352" class="indexterm"/>时，由于从S3加载预训练模型，lambda执行将需要一些时间。<div><img src="img/B08086_06_19.png.jpg" alt="Serverless image recognition with audio using AWS Lambda and Polly"/>T34】</div></li><li class="listitem">接下来，<a id="id353" class="indexterm"/>通过<a id="id354" class="indexterm"/>导航到<strong> API网关</strong>服务:<div> <img src="img/B08086_06_20.png.jpg" alt="Serverless image recognition with audio using AWS Lambda and Polly"/> </div>来创建新的API</li><li class="listitem">然后，点击<a id="id355" class="indexterm"/>API左侧面板<a id="id356" class="indexterm"/>上的<strong>二进制支持</strong>标签，添加如下内容类型:<div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>image/png</strong></li><li class="listitem" style="list-style-type: disc"><strong>image/JPEG</strong></li></ul></div><div><img src="img/B08086_06_21.png.jpg" alt="Serverless image recognition with audio using AWS Lambda and Polly"/></div></li><li class="listitem">接下来，通过<a id="id357" class="indexterm"/>指定<strong>资源路径</strong>(例如<code class="literal">tensorflow-predict</code> ): <div> <img src="img/B08086_06_22.png.jpg" alt="Serverless image recognition with audio using AWS Lambda and Polly"/> </div>，创建一个<strong>新子资源</strong></li><li class="listitem">接下来，通过从<strong> Action </strong> <a id="id359" class="indexterm"/>菜单中点击<strong> Create Method </strong>，向您的子资源添加一个<a id="id358" class="indexterm"/>方法(<strong> POST </strong>)。用这个API资源将我们之前创建的Lambda函数添加到AMP中。你可能需要指定正确的区域来从下拉列表中找到你的Lambda函数。</li><li class="listitem">一旦<strong> POST </strong>方法被创建，点击<strong>集成请求</strong>并展开<strong>主体映射模板</strong>选项卡。在<strong>请求正文传递</strong>下，当没有定义模板时选择<strong>(推荐)</strong>。然后，在<strong>内容类型</strong>下添加一个image/jpeg，并在<strong>生成模板</strong>部分下添加以下内容:<div> <pre class="programlisting">{ "base64Image": "$input.body", "imageName": "$input.params(imageName)" }</pre> </div> <div> <img src="img/B08086_06_23.png.jpg" alt="Serverless image recognition with audio using AWS Lambda and Polly"/> </div></li><li class="listitem">Finally,<a id="id361" class="indexterm"/> deploy the API from the <strong>Action</strong> menu and define the <strong>Stage name</strong> (for example, <code class="literal">prod</code> or <code class="literal">dev</code>). Once your API is deployed, you will find your API URL as follows:<p><code class="literal">https://&lt;API ID&gt;.execute-api.&lt;region&gt;.amazonaws.com/</code></p></li><li class="listitem">Next, access <a id="id362" class="indexterm"/>your API from<a id="id363" class="indexterm"/> the REST client, such as <strong>POSTMAN</strong> shown in this example, to invoke your image prediction service. In the <strong>API Request</strong>, set the <strong>Content-Type</strong> as <strong>image/jpeg</strong> and add the parameter name <strong>imageName</strong> with a value (such as <code class="literal">animal</code>). Add an image in the body as a <code class="literal">binary</code> file that our service will predict:<p><code class="literal">https://&lt;API ID&gt;.execute-api.&lt;region&gt;.amazonaws.com/prod/tensorflow-predict?imageName=animal</code></p><div><img src="img/B08086_06_24.png.jpg" alt="Serverless image recognition with audio using AWS Lambda and Polly"/></div></li></ol></div><p>瞧啊。您<a id="id364" class="indexterm"/>将在<a id="id366" class="indexterm"/>您的邮递员响应中看到来自无服务器服务的以下<a id="id365" class="indexterm"/>输出:</p><p><strong>“图像识别为大熊猫、熊猫、熊猫、浣熊、大熊猫(得分= 0.89107)”</strong></p><div><img src="img/B08086_06_25.png.jpg" alt="Serverless image recognition with audio using AWS Lambda and Polly"/></div><p>此外，预测响应的音频<a id="id367" class="indexterm"/>将被生成并存储在<code class="literal">audio</code>文件夹下的S3桶中。</p><div><img src="img/B08086_06_26.png.jpg" alt="Serverless image recognition with audio using AWS Lambda and Polly"/></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec67"/>为lambda环境修改代码和包的步骤</h2></div></div></div><p>如果您需要为您的服务添加一个<a id="id368" class="indexterm"/>额外的Python包或更新任何现有的包，请执行以下操作:</p><div><ol class="orderedlist arabic"><li class="listitem">使用<strong>Amazon Linux AMI 2017 . 03 . 1(HVM)，SSD卷类型</strong> : <div> <img src="img/B08086_06_27.png.jpg" alt="Steps to modify code and packages for lambda environments"/> </div>启动EC2实例</li><li class="listitem">登录到EC2实例，并在实例中复制当前的lambda代码。然后，创建一个目录并解压该目录下的ZIP文件:<div> <pre class="programlisting"> <strong>mkdir lambda</strong> <strong>cd lambda</strong> <strong>unzip lambda_tensorflow.zip</strong> </pre> </div> <div> <img src="img/B08086_06_28.png.jpg" alt="Steps to modify code and packages for lambda environments"/> </div></li><li class="listitem">要更新任何现有的<a id="id369" class="indexterm"/>包，首先删除它，然后用<code class="literal">pip</code>命令安装它。添加一个新的包，用<code class="literal">pip</code>安装(如果这个包依赖于共享的<code class="literal">.so</code>库，那么你需要创建一个<code class="literal">lib</code>文件夹，并从<code class="literal">//usr/lib</code>和<code class="literal">/usr/lib64</code>目录中复制这些文件):<div> <pre class="programlisting"> <strong>rm -rf tensorflow*</strong> <strong>pip install tensorflow==1.2.0 -t /home/ec2-user/lambda</strong> </pre> </div></li><li class="listitem">然后创建完整目录的ZIP文件:<div> <pre class="programlisting"> <strong>zip –r lambda_tensorflow.zip *</strong> </pre> </div></li><li class="listitem">最后，将ZIP文件复制到S3，并通过提及S3上的新ZIP文件位置来更新Lambda函数。</li></ol></div><div><div><h3 class="title"><a id="note11"/>注</h3><p>您可能需要从包中剥离一些包或不相关的目录，以确保<code class="literal">code</code>目录中解压缩文件的总大小小于250 MB否则，Lambda不会部署您的代码。</p></div></div><p>有关Lambda <a class="ulink" href="http://docs.aws.amazon.com/lambda/latest/dg/lambda-python-how-to-create-deployment-package.html">上定制包部署的更多信息，请访问以下链接http://docs . AWS . Amazon . com/Lambda/latest/DG/Lambda-python-how-to-create-deployment-package . html</a>。</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec68"/>通过云托管服务运行人脸检测</h2></div></div></div><p>在这个例子中，我们将使用<a id="id370" class="indexterm"/>一个基于深度学习的托管云服务，用于我们的标签识别和人脸检测系统。我们将继续利用无服务器环境AWS Lambda，并利用基于深度学习的云管理服务AWS Rekognition进行面部属性识别。</p><p>执行以下步骤，在无服务器平台上使用托管云深度学习服务构建面部检测系统:</p><div><ol class="orderedlist arabic"><li class="listitem">首先，更新前一个示例中的<a id="id371" class="indexterm"/> IAM Lambda执行角色，并附加一个新的托管策略<strong>AmazonRekognitionFullAccess</strong>，如下所示:<div> <img src="img/B08086_06_29.png.jpg" alt="Running face detection with a cloud managed service"/> </div></li><li class="listitem">接下来，创建一个新的Lambda函数，用于构建面部检测服务。选择<strong> Runtime* </strong>作为<strong> Python 2.7 </strong>并保持所有其他设置为默认。用这个Lambda函数附加更新的IAM角色:<div> <img src="img/B08086_06_30.png.jpg" alt="Running face detection with a cloud managed service"/> </div></li><li class="listitem">然后，在<strong>λ功能代码</strong>部分区域粘贴<a id="id372" class="indexterm"/>以下代码。更新代码<code class="literal">boto3.client</code>中的S3 <strong>桶名</strong>和AWS <strong>区域</strong>信息如下:<div> <pre class="programlisting">from __future__ import print_function  import json import urllib import boto3 import base64 import io  print('Loading function')  s3 = boto3.client('s3') rekognition = boto3.client("rekognition", &lt;aws-region name like us-west-1&gt;)  bucket=&lt;Put your Bucket Name&gt; key_path='raw-image/'  def lambda_handler(event, context):          output={}     try:         if event['operation']=='label-detect':             print('Detecting label')             fileName= event['fileName']             bucket_key=key_path + fileName             data = base64.b64decode(event['base64Image'])             image=io.BytesIO(data)             s3.upload_fileobj(image, bucket, bucket_key)             rekog_response = rekognition.detect_labels(Image={"S3Object": {"Bucket": bucket,"Name": bucket_key,}},MaxLabels=5,MinConfidence=90,)             for label in rekog_response['Labels']:                 output[label['Name']]=label['Confidence']         else:             print('Detecting faces')             FEATURES_BLACKLIST = ("Landmarks", "Emotions", "Pose", "Quality", "BoundingBox", "Confidence")             fileName= event['fileName']             bucket_key=key_path + fileName             data = base64.b64decode(event['base64Image'])             image=io.BytesIO(data)             s3.upload_fileobj(image, bucket, bucket_key)             face_response = rekognition.detect_faces(Image={"S3Object": {"Bucket": bucket,  "Name": bucket_key, }}, Attributes=['ALL'],)             for face in face_response['FaceDetails']:                 output['Face']=face['Confidence']                 for emotion in face['Emotions']:                     output[emotion['Type']]=emotion['Confidence']                 for feature, data in face.iteritems():                     if feature not in FEATURES_BLACKLIST:                         output[feature]=data     except Exception as e:         print(e)         raise e                return output      </pre> </div></li><li class="listitem">一旦<a id="id373" class="indexterm"/>您创建了Lambda函数，我们将为该服务创建一个API网关子资源，如下所示:<div> <img src="img/B08086_06_31.png.jpg" alt="Running face detection with a cloud managed service"/> </div></li><li class="listitem">接下来，我们将<a id="id374" class="indexterm"/>添加一个方法(本例中为<strong> PUT </strong>)到我们新的子资源(<strong> predict </strong>)中，然后点击<strong> PUT </strong>方法的<strong>集成请求</strong>。<div> <img src="img/B08086_06_32.jpg" alt="Running face detection with a cloud managed service"/> </div></li><li class="listitem">现在，附上之前用这个资源方法创建的<strong> Lambda函数</strong>。您需要选择AWS <strong> Lambda区域</strong>，在那里您已经创建了您的<strong> Lambda函数</strong>，以获得下拉列表中的Lambda函数名称:<div> <img src="img/B08086_06_33.png.jpg" alt="Running face detection with a cloud managed service"/> </div></li><li class="listitem">接下来，展开<strong>主体映射模板</strong>部分，当<strong>请求主体传递</strong>部分中没有定义(推荐)模板时，选择<strong>。然后，<a id="id375" class="indexterm"/>在<strong>内容类型</strong>中添加一个映射模板<strong> image/png </strong>，并将下面的代码粘贴到<strong>通用模板</strong>区域:<div> <pre class="programlisting">{ "base64Image": "$input.body", "operation": "$input.params('activity')", "fileName": "$input.params('fileName')" }</pre> </div> <div> <img src="img/B08086_06_34.png.jpg" alt="Running face detection with a cloud managed service"/> </div></strong></li><li class="listitem">Now deploy your API Gateway resource API by clicking <strong>Deploy API</strong> from the <strong>Action</strong> menu. Once your resource is deployed, you will get an API of the gateway that you will use to invoke the face detection service. We will continue to use the REST<a id="id376" class="indexterm"/> client <strong>Postman</strong> (<a class="ulink" href="https://chrome.google.com/webstore/detail/postman/fhbjgbiflinjbdggehcddcbncdddomop?hl=en">https://chrome.google.com/webstore/detail/postman/fhbjgbiflinjbdggehcddcbncdddomop?hl=en</a>) from our previous example, but you can use any other <a id="id377" class="indexterm"/>REST client of your choice as well. The API Gateway URL will look as follows: <p><code class="literal">https://&lt;API ID&gt;.execute-api.&lt;AWS Region&gt;.amazonaws.com/prod/predict</code></p></li><li class="listitem">添加<strong> Content-Type </strong>为<strong> image/png </strong>并在请求中添加两个请求参数activities和filenames。参数<strong>活动</strong>采用两个值(<strong>标签检测</strong>用于图像识别或标签检测)和(<strong>面部检测</strong>用于面部检测)。并且<strong>文件名</strong>参数将被用于以该名称将原始图像保存到S3。<div> <img src="img/B08086_06_35.png.jpg" alt="Running face detection with a cloud managed service"/> </div></li><li class="listitem">现在，调用<a id="id378" class="indexterm"/>您的服务来检测一个标签或面孔，并在JSON中获得如下响应输出:<div> <img src="img/B08086_06_36.png.jpg" alt="Running face detection with a cloud managed service"/> </div></li></ol></div></div></div></div></div>
<title>Summary</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
<!-- kobo-style -->

<script type="text/javascript" src="img/kobo.js"/>
<style type="text/css" id="kobostylehacks">div#book-inner p, div#book-inner div { font-size: 1.0em; } a { color: black; } a:link, a:visited, a:hover, a:active { color: blue; } div#book-inner * { margin-top: 0 !important; margin-bottom: 0 !important;}</style>

<div><div><div><div><div><div><h1 class="title"><a id="ch06lvl1sec40"/>总结</h1></div></div></div><p>到目前为止，您已经学习并实现了部署经过训练的深度模型以及对新数据样本进行预测的各种方法。您还学习了如何使用Docker容器平稳地将您的模型从本地机器或数据中心转移到云中。我希望在整本书中，通过大量使用真实世界公共数据集的实践示例，您已经很好地理解了GANs的概念及其变体架构(SSGAN、BEGAN、DCGAN、CycleGAN、StackGAN、DiscoGAN)。一旦你使用了本书中的代码和例子，我肯定会鼓励你做以下事情:</p><p>参加Kaggle对抗性网络竞赛:<a class="ulink" href="https://www.kaggle.com/c/nips-2017-defense-against-adversarial-attack">https://www . ka ggle . com/c/nips-2017-defense-against-Adversarial-attack</a>。</p><p>通过参加或观看以下会议，保持您关于深度学习和GANs的最新知识:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>神经信息</strong> <strong>离子处理系统</strong><strong>EMS</strong>(<strong>NIPS</strong>):<a class="ulink" href="https://nips.cc/">https://nips.cc/</a></li><li class="listitem" style="list-style-type: disc"><strong>国际学术陈述会议</strong>(ICLR)<a class="ulink" href="HTTP://WWW.ICLR.CC/">HTTP://WWW.ICLR.CC/</a></li></ul></div></div></div></div></body></html>