<html><head/><body><title>Chapter 1. Introduction to Deep Learning</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
<!-- kobo-style -->

<script type="text/javascript" src="img/kobo.js"/>
<style type="text/css" id="kobostylehacks">div#book-inner p, div#book-inner div { font-size: 1.0em; } a { color: black; } a:link, a:visited, a:hover, a:active { color: blue; } div#book-inner * { margin-top: 0 !important; margin-bottom: 0 !important;}</style>

<div><div><div><div><div><div><h1 class="title">第一章。深度学习简介</h1></div></div></div><p>深度神经网络目前能够为各种问题提供人类水平的解决方案，如图像识别、语音识别、机器翻译、自然语言处理等。</p><p>在这一章中，我们将看看神经网络，一种受生物启发的架构是如何进化的。然后，我们将介绍一些与深度学习相关的重要概念和术语，作为后续章节的复习。最后，我们将通过一个生成模型来理解深层网络创造性本质背后的直觉。</p><p>我们将在本章中讨论以下主题:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">深度学习的演变</li><li class="listitem" style="list-style-type: disc">随机梯度下降、ReLU、学习率等等</li><li class="listitem" style="list-style-type: disc">卷积网络、递归神经网络和LSTM</li><li class="listitem" style="list-style-type: disc">判别模型和生成模型的区别</li></ul></div><div><div><div><div><h1 class="title"><a id="ch01lvl1sec08"/>深度学习的进化</h1></div></div></div><p>许多关于<a id="id1" class="indexterm"/>神经网络的重要工作发生在20世纪80年代和90年代，但那时计算机速度很慢，数据集非常小。这项研究并没有在现实世界中找到很多应用。因此，在21世纪的第一个十年，神经网络已经完全从机器学习的世界中消失了。只是在最近几年，首先是在2009年左右的语音识别领域，然后是2012年左右的计算机视觉领域，神经网络才卷土重来(LeNet、AlexNet等等)。什么变了？</p><p>大量数据(大数据)和廉价、快速的GPU。今天，神经网络无处不在。因此，如果你正在做任何与数据、分析或预测有关的事情，深度学习肯定是你想要熟悉的东西。</p><p>见下图:</p><div><img src="img/B08086_01_01.jpg" alt="Evolution of deep learning"/><div><p>图1:深度学习的演变</p></div></div><p>深度学习是机器学习的一个令人兴奋的<a id="id2" class="indexterm"/>分支，它使用数据，大量的数据，来教计算机如何做以前只有人类才能做的事情，例如识别图像中的内容，人们在电话中说什么，将文档翻译成另一种语言，以及帮助机器人探索世界并与之互动。深度学习已经成为解决感知问题的核心工具，它与计算机视觉和语音识别一起达到了最先进的水平。</p><p>今天，许多公司已经将深度学习作为他们机器学习工具包的核心部分——脸书、百度、亚马逊、微软和谷歌都在他们的产品中使用深度学习，因为深度学习在有大量数据和复杂问题需要解决的地方大放异彩。</p><p>深度学习是我们常用的由几层组成的“深度神经网络”的名称。每一层都由节点组成。计算发生在节点中，节点将输入数据与一组参数或权重相结合，这些参数或权重会放大或抑制输入数据。然后对这些输入权重乘积求和，总和通过<code class="literal">activation</code>函数传递，以确定该值在网络中的传播程度，从而影响最终预测，例如分类行为。层由一行节点组成，当输入通过网络时，这些节点会打开或关闭。第一层的输入成为第二层的输入，以此类推。这是一个神经网络的示意图:</p><div><img src="img/B08086_01_22.jpg" alt="Evolution of deep learning"/></div><p>让我们熟悉一下<a id="id3" class="indexterm"/>一些深层神经网络的概念和术语。</p><div><div><div><div><h2 class="title"><a id="ch01lvl2sec07"/>乙状结肠激活</h2></div></div></div><p>在<a id="id4" class="indexterm"/>神经网络中使用的sigmoid激活函数有一个输出边界<em> (0，1) </em>，并且<em> α </em>是设置sigmoid评估为0的值的偏移参数。</p><p>只要输入数据<em> x </em>保持在<a id="id6" class="indexterm"/>限制范围内，sigmoid函数通常对坡度<a id="id5" class="indexterm"/>下降工作良好。对于<em> x </em>的大值，<em> y </em>为常数。因此，导数<em> dy/dx </em>(梯度)等于<em> 0 </em>，这通常被称为<strong>消失梯度</strong>问题。</p><p>这是一个问题，因为当梯度为0时，将其与损失(实际值-预测值)相乘也得到0，最终网络停止学习。</p></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec08"/>整流线性单元(ReLU)</h2></div></div></div><p>可以通过将一些线性分类器与一些非线性函数相结合来构建神经网络。<strong>整流线性单元</strong> ( <strong> ReLU </strong>)在最近几年变得非常流行。它计算<a id="id7" class="indexterm"/>函数<em> f(x)=max(0，x) </em>。换句话说，激活的阈值简单地为零。不幸的是，ReLU单元在训练期间可能很脆弱，可能会死亡，因为ReLU <a id="id8" class="indexterm"/>神经元可能会导致权重更新，使得神经元再也不会在任何数据点上激活，因此从该点开始，流经该单元的梯度将永远为零。</p><p>为了克服这个问题，当<em> x &lt; 0 </em>时，泄漏的<code class="literal">ReLU</code>函数将具有小的负斜率(大约0.01)而不是零:</p><div><img src="img/B08086_01_24.jpg" alt="Rectified Linear Unit (ReLU)"/></div><p>其中<em> αα </em>为小常数。</p><div><img src="img/B08086_01_02.jpg" alt="Rectified Linear Unit (ReLU)"/><div><p>图2:整流线性单元</p></div></div></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec09"/>指数线性单位(ELU)</h2></div></div></div><p>ReLU <a id="id9" class="indexterm"/>激活的平均值不为零，因此有时<a id="id10" class="indexterm"/>使得网络难以学习。当输入<em> x </em>为正时，<strong>指数线性单元</strong> ( <strong> ELU) </strong>类似于ReLU激活函数，但是对于负值，它是由固定值<em> -1 </em>限制的函数，因为<em> α=1 </em>(超参数<em> α </em>控制ELU对于负输入饱和的值)。这种行为有助于将神经元的平均激活更接近于零；这有助于学习对噪声更加鲁棒的表示。</p></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec10"/>随机梯度下降</h2></div></div></div><p>缩放批量梯度下降很麻烦，因为如果数据集很大，它必须进行大量计算，并且根据经验，如果计算您的<a id="id14" class="indexterm"/>损失需要<em> n </em>次浮点运算，则计算其梯度需要大约三倍的时间。</p><p>但在实践中，我们希望能够训练大量的数据，因为在实际问题上，我们使用的数据越多，我们总是会获得更多的收益。由于梯度下降是迭代式的，必须在许多步骤中进行，这意味着为了在一个步骤中更新参数，必须遍历所有数据样本，然后对数据进行数十次或数百次迭代。</p><p>我们可以计算训练数据的非常小的随机部分的平均损失，而不是计算每个步骤的整个数据样本的损失。每次考虑1到1000个训练样本。这项技术被称为<strong>随机梯度下降</strong> ( <strong> SGD </strong>)，是深度学习的核心。这是因为SGD可以很好地适应数据和模型大小。</p><p>SGD以黑魔法而闻名，因为它有许多超级参数可以玩和调整，如初始化参数、学习率参数、衰减和动量，你必须正确地使用它们。</p><p>AdaGrad是对SGD的简单修改，它隐式地自行进行动量和学习率衰减。使用AdaGrad经常使学习对超参数不那么敏感。但是它往往比精确调整的有动量的SDG差一点。不过，如果你只是想让事情正常运转，这仍然是一个很好的选择:</p><p> </p><div><img src="img/B08086_01_04.jpg" alt="Stochastic Gradient Descent (SGD)"/><div><p>图4a:批量梯度下降和SGD中的损失计算</p><p><em>来源</em>:<a class="ulink" href="https://www.coursera.org/learn/machine-learning/lecture/DoRHJ/stochasticgradient- descent">https://www . coursera . org/learn/machine-learning/lecture/DoRHJ/stochasticgradient-descent</a></p></div></div><p>
</p><div><img src="img/B08086_01_05.jpg" alt="Stochastic Gradient Descent (SGD)"/><div><p>图4b:随机梯度下降和AdaGrad</p></div></div><p>您可以从图4a 的<em>中注意到，在批量梯度下降的情况下，<code class="literal">loss</code> / <code class="literal">optimization</code>函数被很好地最小化，而SGD通过在每一步中随机抽取一部分数据来计算损失，并且经常在该点附近振荡。实际操作中，并不是<a id="id15" class="indexterm"/>不好，SGD往往收敛更快。</em></p></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec11"/>学习率调整</h2></div></div></div><p>神经网络的<code class="literal">loss</code>功能可以与一个表面相关，其中网络的权重代表你可以移动的每个<a id="id16" class="indexterm"/>方向。梯度下降提供斜坡当前方向的步数，学习率<a id="id17" class="indexterm"/>给出你每走一步的长度。学习率有助于网络抛弃旧的信念，建立新的信念。</p><p>学习率调整可能非常奇怪。例如，你可能认为使用更高的学习速率意味着你学得更多或者学得更快。那不是真的。其实你可以经常拿一个模型，降低学习率，更快的到一个更好的模型。</p><div><img src="img/B08086_01_03.jpg" alt="Learning rate tuning"/><div><p>图3:学习率</p></div></div><p>你可能会想看看显示损失的学习曲线，看看<a id="id18" class="indexterm"/>网络学习的速度有多快。在这里，较高的学习率开始得更快，但随后就停滞不前了，而较低的学习率会继续下去并变得更好。对于任何训练过神经网络的人来说，这是一幅非常熟悉的画面。永远不要相信你学得有多快。</p></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec12"/>正规化</h2></div></div></div><p>防止<a id="id19" class="indexterm"/>过度拟合的第一种方法是查看<a id="id20" class="indexterm"/>验证集下的表现，一旦表现停止改善，就停止训练。这被称为提前终止，这是防止神经网络在训练集上过度优化的一种方法。另一种方法是应用正则化。正则化意味着在网络上应用人工约束，这些约束隐含地减少了自由参数的数量，同时不会增加优化的难度。</p><div><img src="img/B08086_01_06.jpg" alt="Regularization"/><div><p>图6a:提前终止</p></div></div><p>在图6b 所示的紧身牛仔裤类比中，想想弹力裤。它们同样适合，但是因为它们是灵活的，它们不会使东西更难适应。深度学习的弹力裤有时被称为L2正则化。这个想法是增加另一个损失项，惩罚大的权重。</p><div><img src="img/B08086_01_07.jpg" alt="Regularization"/><div><p>图6b:深度学习的弹力裤类比</p></div></div><div><img src="img/B08086_01_08.jpg" alt="Regularization"/><div><p>图6c: L2特化</p></div></div><p>目前，在深度学习实践中，广泛使用的防止过度拟合的方法是将大量的<a id="id23" class="indexterm"/>数据馈入深度网络。</p></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec13"/>共享权重和共享</h2></div></div></div><p>假设一幅图像中有一只猫，这只猫在图像中的什么位置并不重要，因为它仍然是一幅有一只猫的图像。如果网络必须独立地学习左边角落里的猫和右边角落里的猫，那它必须做大量的工作。但是物体和图像在很大程度上是相同的<a id="id26" class="indexterm"/>,不管它们是在图片的左边还是右边。这就是所谓的<strong>平移不变性</strong>。</p><p>在网络中实现<a id="id27" class="indexterm"/>这一点的方式被称为<strong>权重分配</strong>。当网络知道两个输入可以包含相同类型的<a id="id28" class="indexterm"/>信息时，它可以共享<a id="id29" class="indexterm"/>权重，并为这些输入联合训练权重。这是一个非常重要的想法。统计不变量是在时间或空间上平均不变的东西，无处不在。对于图像，重量共享的想法将使我们研究卷积网络。对于一般的文本和序列，它将把我们引向递归神经网络:</p><div><img src="img/B08086_01_09.jpg" alt="Shared weights and pooling"/><div><p>图7a:翻译差异</p></div></div><div><img src="img/B08086_01_10.jpg" alt="Shared weights and pooling"/><div><p>图7b:重量共享</p></div></div><p>为了减少卷积金字塔中的特征图的空间范围，可以运行一个非常小的步长，并获取邻域中的所有卷积，然后以某种方式将它们组合起来。这被称为<strong>池</strong>。</p><p>在max-pooling as <a id="id30" class="indexterm"/>中，如图7d 中的<em>所示，在特征图中的每个点，查看该点周围的一个小邻域<a id="id31" class="indexterm"/>，并计算其周围所有响应的最大值。使用最大池有一些好处。首先，它不会增加参数的数量。所以，你不会冒过度合身的风险。其次，它通常会产生更精确的模型。然而，由于下面运行的卷积以较低的步幅运行，因此该模型的计算成本变得更高。最大池提取最重要的特征，而平均池有时不能提取好的特征，因为它考虑了所有因素，并产生一个平均值，该平均值对于对象检测类型的任务可能是重要的，也可能是不重要的。</em></p><div><img src="img/B08086_01_11.jpg" alt="Shared weights and pooling"/><div><p>图7c:汇集</p></div></div><div><img src="img/B08086_01_12.jpg" alt="Shared weights and pooling"/><div><p>图7d:最大和平均池</p></div></div></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec14"/>局部感受野</h2></div></div></div><p>对局部结构进行编码的简单方法是将相邻输入神经元的子矩阵连接成属于下一层的一个<a id="id32" class="indexterm"/>单个隐藏神经元。这个隐藏的神经元代表一个局部感受域。让我们<a id="id33" class="indexterm"/>考虑输入特征大小为[32 x 32 x 3]的CIFAR-10图像。如果感受野(或滤波器大小)是4×4，那么卷积层中的每个神经元将具有输入特征中[4×4×3]区域的权重，总共4×4×3 = 48个权重(和+1个偏置参数)。沿深度轴的连通性范围必须为3，因为这是输入要素的深度(或通道数:RGB)。</p></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec15"/>卷积网络(ConvNet)</h2></div></div></div><p><strong>卷积网络</strong> ( <strong>卷积网络</strong>)是在<a id="id34" class="indexterm"/>空间中共享其参数/权重的神经网络。图像<a id="id35" class="indexterm"/>可以表示为具有宽度、高度和深度或通道数量的扁平饼状(对于RGB:具有红色、绿色和蓝色通道，深度为3，而对于灰度，深度为1)。</p><p>现在让我们在不改变权重的情况下，在图像上滑动一个带有K个输出的微型神经网络。</p><div><img src="img/B08086_01_13.jpg" alt="Convolutional network (ConvNet)"/><div><p>图8a:跨空间的重量分配</p></div></div><div><img src="img/B08086_01_14.jpg" alt="Convolutional network (ConvNet)"/><div><p>图8b:具有卷积层的卷积金字塔</p></div></div><p>在输出上，将绘制具有不同宽度、不同高度和不同深度的不同图像(从仅R、G、B颜色通道到通道的<em> K </em>数量<a id="id36" class="indexterm"/>)。这个操作被称为卷积。</p><p>ConvNet基本上是一个深层网络，由多层卷积堆叠在一起形成金字塔状结构。从上图中可以看出，网络将图像作为维度(宽度x高度x深度)的输入，然后对其逐步应用卷积，以减少空间维度，同时增加深度，这大致相当于其语义复杂性。让我们来了解一下女修道院的一些常用术语。</p><p>图像堆栈中的每一层或深度被称为特征图，并且面片或内核被用于将三个特征图映射到<em> K </em>特征图。步长是每次移动滤镜时移动的像素数。根据填充的类型，步长为1会使输出与输入的大小大致相同。步幅为2使其大小减半。在有效填充的情况下，滑动过滤器不会越过图像的边缘，而在相同填充中，它会离开边缘并用零填充，以使输出贴图大小与输入贴图大小完全相同:</p><div><img src="img/B08086_01_15.jpg" alt="Convolutional network (ConvNet)"/></div><div><img src="img/B08086_01_16.jpg" alt="Convolutional network (ConvNet)"/><div><p>图8c:与卷积网络相关的不同术语</p></div></div></div></div></div></div></div>
<title>Deconvolution or transpose convolution</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
<!-- kobo-style -->

<script type="text/javascript" src="img/kobo.js"/>
<style type="text/css" id="kobostylehacks">div#book-inner p, div#book-inner div { font-size: 1.0em; } a { color: black; } a:link, a:visited, a:hover, a:active { color: blue; } div#book-inner * { margin-top: 0 !important; margin-bottom: 0 !important;}</style>

<div><div><div><div><div><div><h1 class="title"><a id="ch01lvl1sec09"/>反卷积或转置卷积</h1></div></div></div><p>在要求最终输出分辨率大于输入分辨率的计算机<a id="id38" class="indexterm"/>视觉应用中，去卷积/转置卷积是事实上的<a id="id39" class="indexterm"/>标准。该层用于非常流行的应用，例如GAN、图像超分辨率、从图像估计表面深度、光流估计等等。</p><p>CNN通常执行下采样，也就是说，它们产生比输入分辨率更低的输出，而在去卷积中，层对图像进行上采样，以获得与输入图像相同的分辨率。注意由于简单的上采样会无意中丢失细节，因此更好的选择是使用可训练的上采样卷积层，其参数会在训练过程中改变。</p><p>张量流方法:<code class="literal">tf.nn.conv2d_transpose(value, filter, output_shape, strides, padding, name)</code></p><div><div><div><div><h2 class="title"><a id="ch01lvl2sec16"/>递归神经网络和LSTM</h2></div></div></div><p><strong>循环神经网络</strong> ( <strong> RNN </strong>)背后的关键思想是随着时间的推移共享参数。想象一下，你有一系列事件，在每个时间点，你都想对这一系列事件中已经发生的事情做出决定。如果序列相当稳定，您可以在每个时间点使用相同的分类器。这已经大大简化了事情。但是既然这是一个序列，你也要考虑到过去——在那一点之前发生的一切。</p><p>RNN将有一个单一的模型负责总结过去，并提供这些信息给你的分类器。它基本上以一个具有相对简单的重复模式的网络结束，一部分分类器在每个时间步连接到输入，另一部分称为循环连接，在每个时间步连接到过去，如下图所示:</p><div><img src="img/B08086_01_18.jpg" alt="Recurrent Neural Networks and LSTM"/><div><p>图9a:递归神经网络</p></div></div><div><img src="img/B08086_01_19.jpg" alt="Recurrent Neural Networks and LSTM"/><div><p>图9b:长短期记忆(LSTM)</p></div></div><p><strong> LSTM </strong>代表<strong>长短期记忆</strong>。现在，从概念上讲，一个递归神经网络由类似这样的简单小单元的<a id="id42" class="indexterm"/>重复组成，它将过去作为输入，一个新的<a id="id43" class="indexterm"/>输入，产生一个新的预测并连接到未来。现在，在这中间的通常是一组简单的层，带有一些权重和线性。</p><p>在LSTM，如图<em>图9b </em>所示，每个门的门限值由输入参数的微小逻辑回归控制。它们中的每一个都有自己的一组共享参数。还有一个额外的双曲线张力，以保持输出在-1和1之间。此外，它始终是可微的，这意味着它可以很容易地优化参数。所有这些小门有助于模型在需要的时候保持更长时间的记忆，并在应该的时候忽略一些事情。</p></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec17"/>深度神经网络</h2></div></div></div><p><a id="id44" class="indexterm"/>深度学习的中心思想是增加更多的层，让你的模型更深。有很多很好的理由这样做。一个是参数效率。通过更深入而不是更广泛，您通常可以用更少的参数获得更高的性能。</p><p>另一个原因是，你可能感兴趣的许多自然现象往往具有层次结构，深度模型自然会捕捉到这种结构。例如，如果你在一个模型中寻找图像，并可视化模型所学的东西，你通常会在最底层发现非常简单的东西，比如线条或边缘。</p><div><img src="img/B08086_01_20.jpg" alt="Deep neural networks"/><div><p>图10a:深度神经网络</p></div></div><div><img src="img/B08086_01_21.jpg" alt="Deep neural networks"/><div><p>图10b:捕捉图像分层结构的网络层</p></div></div><p>一个非常典型的ConvNet架构是几层交替卷积和最大池，然后是顶部的<a id="id45" class="indexterm"/>几个完全连接的层。第一个使用这种架构的著名模型是1998年Yann Lecun为字符识别设计的LeNet-5。</p><p>现代卷积网络，如AlexNet，在2012年赢得了著名的竞争对手ImageNet对象识别挑战赛，使用了非常相似的架构，但有一些问题。另一种值得注意的联营形式是平均联营。不是取最大值，而是取特定位置周围像素窗口的平均值。</p></div><div><div><div><div><h2 class="title"><a id="ch01lvl2sec18"/>判别模型与生成模型</h2></div></div></div><p>判别模型学习条件概率分布<em> p(y|x) </em>，其可以被解释为给定x 的y的<em>概率。鉴别分类器通过观察数据来学习。它对分布做了更少的假设，但是很大程度上依赖于数据的质量。分布<em> p(y|x) </em>简单地将给定的示例x直接分类到标签<em> y </em>中。例如，在逻辑回归中，我们所要做的就是学习使平方损失最小化的权重和偏差。</em></p><p>而生成模型学习联合概率分布<em> p(x，y) </em>，其中<em> x </em>是输入数据，<em> y </em>是你想要分类的标签。基于对数据分布的假设，生成模型可以自己人工生成更多的样本。例如，在朴素贝叶斯模型中，我们可以从数据中学习<em> p(x) </em>以及<em> p(y) </em>先验类别概率，我们还可以使用最大似然法从数据中学习<em> p(x|y) </em>。</p><p>一旦我们有了<em> p(x) </em>、<em> p(y) </em>和<em> p(x|y) </em>、<em> p(x，y) </em>就不难找出。现在利用贝叶斯法则，我们可以将<em> p(y|x) </em>替换为<em> (p(x|y)p(y))/p(x) </em>。由于我们只对<em> arg max </em>感兴趣，分母可以去掉，因为这对每个<em> y </em>都是一样的:</p><div><img src="img/B08086_01_25.jpg" alt="Discriminative versus generative models"/></div><p>这是我们在生成模型中使用的等式，如<em> p(x，y) = p(x | y) p(y) </em>，它显式地对每个类的实际分布进行建模。</p><p>在实践中，鉴别模型在分类任务中通常优于生成模型，但是生成模型在创造性/生成任务中胜过鉴别模型。</p></div></div></div></div>
<title>Summary</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
<!-- kobo-style -->

<script type="text/javascript" src="img/kobo.js"/>
<style type="text/css" id="kobostylehacks">div#book-inner p, div#book-inner div { font-size: 1.0em; } a { color: black; } a:link, a:visited, a:hover, a:active { color: blue; } div#book-inner * { margin-top: 0 !important; margin-bottom: 0 !important;}</style>

<div><div><div><div><div><div><h1 class="title"><a id="ch01lvl1sec10"/>总结</h1></div></div></div><p>到目前为止，您已经刷新了与深度学习相关的各种概念，并且还学习了深度网络如何从图像分类、识别声音、文本等监督任务的领域发展到通过生成模型的创造力。在下一章中，我们将看到深度学习如何在无人监管的领域中使用<strong>生成对抗网络</strong> ( <strong> GANs </strong>)来执行精彩的创造性任务。</p></div></div></div></body></html>