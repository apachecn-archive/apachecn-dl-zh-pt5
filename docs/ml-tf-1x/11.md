

# 更进一步- 21 个问题

在本章中，我们将介绍 21 个现实生活中的问题，您可以使用深度学习和 TensorFlow 来解决这些问题。先说一些公开的大规模数据集和比赛。然后，我们会在 Github 上展示一些牛逼的 TensorFlow 项目。我们还将介绍一些在其他深度学习框架中完成的有趣项目，以便您获得灵感并实现自己的 TensorFlow 解决方案。最后，我们将通过一个简单的技术将 Caffe 模型转换为 TensorFlow 模型，并使用一个高级 TensorFlow 库 TensorFlow-Slim 进行介绍。

在本章中，我们将探讨以下主题:

*   大规模公共数据集和竞赛
*   令人敬畏的 TensorFlow 项目
*   一些从其他框架中获得了深度学习项目的灵感
*   将 Caffe 模型转换为张量流
*   介绍 TensorFlow-Slim



# 数据集和挑战

在本节中，我们将向您展示一些流行的数据集和竞赛。



# 问题 1 - ImageNet 数据集

项目链接:[http://image-net.org/](http://image-net.org/)

**ImageNet** 是一项大规模的视觉识别挑战，自 2010 年以来每年举办一次。数据集是根据工作网层次结构组织的。有超过 1000 万个图片的 URL 带有手写标签，以指示图片中的对象。至少有一百万张图像包含了边界框。

ImageNet 挑战赛每年举办一次，旨在评估以下三个问题的算法:

*   1000 个类别的对象本地化。
*   200 个全标记类别的对象检测。
*   30 个完全标记类别的视频对象检测。2017 年 7 月 17 日，公布了 2017 挑战赛的结果，里面有很多先进有趣的算法。



# 问题 2 - COCO 数据集

项目链接:【http://mscoco.org/ 

COCO 是由微软赞助的用于图像识别、分割和字幕的数据集。该数据集中有 80 个对象类别，包含 300，000 多幅图像和 200 万个实例。每年都有检测、字幕和关键点的挑战。



# 问题 3 -打开图像数据集

项目链接:[https://github.com/openimages/dataset](https://github.com/openimages/dataset)

Open Images 是谷歌的一个新数据集，拥有超过 6000 个类别的 900 多万个网址。每张图像都由谷歌的视觉模型处理，并由人类验证。截至 2017 年 7 月 20 日，还有超过 200 万个跨越 600 多个对象的边界框注释。

不同之处在于，开放图像比其他图像覆盖更多的真实对象，这在开发真实应用程序时非常有用。



# 问题 4 - YouTube-8M 数据集

项目链接:[https://research.google.com/youtube8m/](https://research.google.com/youtube8m/)

YouTube-8M 是来自谷歌的大规模视频数据集，拥有超过 4，716 个类的 700 万个视频 URL 和 45 万小时的视频。谷歌还提供预先计算的、最先进的视听功能，因此人们可以轻松地基于这些功能构建他们的模型。从原始视频进行训练可能需要数周时间，这在正常情况下是不合理的。该数据集的目标是实现视频理解、表示学习、噪声数据建模、迁移学习和视频的域适应。



# 问题 5 -音频数据集

项目链接:[https://research.google.com/audioset/](https://research.google.com/audioset/)

AudioSet 是一个来自 Google 的大规模音频事件数据集，包含 632 个音频事件类和超过 210 万个手动注释的声音剪辑。音频课程从人类和动物的声音到乐器和常见的日常环境声音。使用这个数据集，您可以创建一个系统来识别音频事件，用于音频理解、安全应用等。



# 问题 6 - LSUN 挑战

项目链接:[http://lsun.cs.princeton.edu/2017/](http://lsun.cs.princeton.edu/2017/)

LSUN challenge 提供大规模场景理解数据集，涵盖三个主要问题:

*   场景分类
*   街道图像的分割任务
*   显著性预测

在场景分类问题中，算法的期望输出是图像中最可能的场景类别。在写作时，有 10 个不同的类，如卧室，教室，和餐厅。在分割问题上，可以尝试解决像素级分割和实例特定分割。在显著性预测问题中，目标是预测人在场景图像中的位置。



# 问题 7 -百万面数据集

项目链接:[http://megaface.cs.washington.edu/](http://megaface.cs.washington.edu/)

MegaFace 为人脸识别提供了大规模数据集。MegaFace 数据集分为三个部分:

*   训练集
*   测试装置
*   干扰物

**训练集**包含超过 672，057 个唯一身份的 470 万张照片。**测试集**包含来自 FaceScrub 和 FGNet 数据集的图像。**干扰项**包含 690，572 个独立用户的一百万张照片。目前，MegaFace 网站面临两大挑战。在挑战 1 中，你可以使用任何数据集进行训练，并用一百万个干扰物来测试你的方法。你的方法需要区分一组已知的人，同时将干扰物归类为未知的人。在挑战 2 中，您将使用具有 672K 个唯一身份的训练集进行训练，并使用 100 万个干扰项进行测试。在撰写本文时，MegaFace 是目前最大的人脸识别数据集。



# 问题 8 -数据科学碗 2017 挑战

项目链接:[https://www.kaggle.com/c/data-science-bowl-2017](https://www.kaggle.com/c/data-science-bowl-2017)

2017 年数据科学碗是一项百万美元的挑战，重点是肺癌检测。在数据集中，您将获得一千多张高危患者的 CT 图像。这项挑战的目标是创建一个自动系统，可以确定患者是否会在一年内被诊断为肺癌。这是一个非常有趣和重要的项目，在不久的将来将拯救成千上万的人。



# 问题 9 -星际争霸游戏数据集

项目链接:[https://github.com/TorchCraft/StarData](https://github.com/TorchCraft/StarData)

在写这本书的时候，这是最大的星际争霸-育雏战争回放数据集。该数据集包含 365GB 的 60，000 多个游戏、15.35 亿帧和 4.96 亿个玩家动作。这个数据集最适合那些想研究人工智能游戏的人。



# 基于 TensorFlow 的项目

本节将向大家介绍几个在 TensorFlow 和 Github 上开源实现的问题。我们建议你看看这些项目，学习如何提高你的张量流技能。



# 问题 10 -人体姿态估计

项目链接:[https://github.com/eldar/pose-tensorflow](https://github.com/eldar/pose-tensorflow)

这个项目是人体姿态估计中 Deep Cut 和 ArtTrack 的开源实现。这个项目的目标是联合解决检测和姿态估计的任务。我们可以将这种方法用于各种应用，例如安全中的人员检测或人类行为理解。这个项目也为大量关于人体形状估计的进一步研究提供了很好的起点，应用于虚拟试穿或服装推荐。



# 问题 11 -物体检测- YOLO

项目链接:[https://github.com/thtrieu/darkflow](https://github.com/thtrieu/darkflow)

目标检测是计算机视觉中一个有趣的问题。有很多方法可以解决这个问题。约瑟夫·雷德蒙和其他人的《YOLO》是最先进的技术之一。YOLO 使用深度神经网络提供实时对象检测。第二版 YOLO 可以实时高精度地识别多达 9000 个不同的物体。最初的 YOLO 项目是在 darknet 框架中编程的。

在 TensorFlow 中，有一个很棒的 YOLO 实现，叫做 **darkflow** 。darkflow 存储库甚至有一个工具，允许您导出模型并在移动设备上提供服务。



# 问题 12 -对象检测-更快的 RCNN

项目链接:[https://github.com/smallcorgi/Faster-RCNN_TF](https://github.com/smallcorgi/Faster-RCNN_TF)

更快的 RCNN 是另一种最先进的对象检测方法。这种方法提供了高精度的结果，也启发了许多其他问题的许多方法。更快的 RCNN 的推理速度没有 YOLO 快。但是，如果你需要高精度的检测结果，你可以考虑更快的 RCNN。



# 问题 13 -人员检测-张量盒

项目链接:[https://github.com/Russell91/TensorBox](https://github.com/Russell91/TensorBox)

Tensorbox 是 Russell Stewart 和 Mykhaylo Andriluka 对该方法的 TensorFlow 实现。这种方法的目标与前面的方法有点不同。Tensorbox 专注于解决人群人物检测问题。他们使用递归 LSTM 层用于边界框的序列生成，并定义了一个新的损失函数，该函数对一组检测结果进行操作。



# 问题 14 -洋红色

项目链接:[https://github.com/tensorflow/magenta](https://github.com/tensorflow/magenta)

Magenta 是谷歌大脑团队的一个项目，专注于使用深度学习进行音乐和艺术生成。这是一个非常活跃的资源库，有许多有趣问题的实现，如图像风格化、旋律生成或生成草图。您可以访问以下链接来访问 Magenta 的模型:

[https://github . com/tensor flow/magenta/tree/master/magenta/models](https://github.com/tensorflow/magenta/tree/master/magenta/models)



# 问题 15 - Wavenet

项目链接:【https://github.com/ibab/tensorflow-wavenet 

WaveNet 是 Google Deep Mind 的一个用于音频生成的神经网络架构。WaveNet 被训练来生成原始音频波形，并且已经显示出用于文本到语音和音频生成的良好结果。根据 Deep Mind 的说法，WaveNet 在美国英语和汉语普通话的文本到语音转换问题中，将以前的方法和人类水平的性能之间的差距减少了 50%以上。



# 问题 16 -深度演讲

项目链接:【https://github.com/mozilla/DeepSpeech 

Deep Speech 是一个开源的语音转文本引擎，基于百度的一篇研究论文。语音转文本是一个非常有趣的问题，深度语音是解决这个问题的最先进的方法之一。使用 Mozilla 的 TensorFlow 实现，您甚至可以学习如何在多台机器上使用 TensorFlow。然而，仍然存在一个问题，即个人研究人员无法像大公司一样访问大规模的语音到文本数据集。因此，即使我们可以使用深度语音或自己实现它，仍然很难有一个好的生产模型。



# 有趣的项目

在本节中，我们将向您展示一些在其他深度学习框架中实现的有趣项目。这些项目在非常困难的问题上取得了显著的成果。您可能想要挑战自己，在 TensorFlow 中实现这些方法。



# 问题 17 -交互式深度着色- iDeepColor

项目链接:[https://richzhang.github.io/ideepcolor/](https://richzhang.github.io/ideepcolor/)

交互式深度彩色化是张曦轲和尊俊彦等人正在进行的研究，用于用户指导的图像彩色化。在这个系统中，用户可以为图像中的一些点提供一些颜色提示，网络将传播用户输入以及从大规模数据中学习的语义信息。可以通过一次正向传递来实时执行着色。



# 问题 18 -微小的人脸检测器

项目链接:[https://github.com/peiyunh/tiny](https://github.com/peiyunh/tiny)

这个项目是一个人脸检测器，重点是寻找由胡佩云和 Deva Ramanan 图像中的小脸。虽然大多数人脸检测器只关注图像中的大对象，但这种微小的人脸检测器方法可以处理非常小的人脸，但与更宽的人脸数据集上的现有方法相比，仍然可以将误差降低两倍。



# 问题 19 -人员搜索

项目链接:[https://github.com/ShuangLI59/person_search](https://github.com/ShuangLI59/person_search)

这个项目是肖童和其他人的论文的实施，该论文集中在人的检测和重新识别的问题上。该项目可用于视频监控。现有的人物再识别方法主要假设人物被裁剪和对齐。然而，在真实世界的场景中，人检测算法可能无法提取人的完美裁剪区域，并降低识别准确度。在这个项目中，作者在一个受更快的 RCNN 启发的新架构中联合解决了检测和识别问题。目前的项目是在 Caffe 深度学习框架中实现的。



# 问题 20 -人脸识别- MobileID

项目链接:[https://github.com/liuziwei7/mobile-id](https://github.com/liuziwei7/mobile-id)

这个项目提供了一个速度极快的人脸识别系统，可以以 250 FPS 的速度高精度运行。通过使用最先进的人脸识别 DeepID 的输出来学习该模型。但是，移动 ID 模型的执行速度非常快，可以在处理和内存有限的情况下使用。



# 问题 21 -问答- DrQA

项目链接:[https://github.com/facebookresearch/DrQA](https://github.com/facebookresearch/DrQA)

DrQA 是一个来自脸书的开放领域问题回答系统。DrQA 专注于解决*机器阅读*的任务，其中模型将尝试理解维基百科文档，并为用户的任何问题给出答案。目前的项目是在 PyTorch 实施的。您可能会发现在 TensorFlow 中实现我们自己的解决方案很有趣。



# 咖啡到张量流

在这一部分，我们将向你展示如何利用来自 Caffe 模型动物园([https://github.com/BVLC/caffe/wiki/Model-Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo))的许多预先训练好的模型。有许多 Caffe 模型用于各种架构的不同任务。将这些模型转换为 TensorFlow 后，您可以将其用作您的架构的一部分，也可以针对不同的任务对我们的模型进行微调。使用这些预训练的模型作为初始权重是一种有效的训练方法，而不是从头开始训练。我们将在[https://github.com/ethereon/caffe-tensorflow](https://github.com/ethereon/caffe-tensorflow)向你展示如何使用索米特罗·达斯古普塔的`caffe-to-tensorflow`方法。

然而，Caffe 和 TensorFlow 之间有很多不同之处。该技术仅支持 Caffe 中图层类型的子集。即使有一些 Caffe 架构是由这个项目的作者验证的，如 ResNet、VGG 和 GoogLeNet。

首先，我们需要使用`git clone`命令克隆`caffe-tensorflow`存储库:

```
ubuntu@ubuntu-PC:~/github$ git clone https://github.com/ethereon/caffe-tensorflow
Cloning into 'caffe-tensorflow'...
remote: Counting objects: 479, done.
remote: Total 479 (delta 0), reused 0 (delta 0), pack-reused 479
Receiving objects: 100% (510/510), 1.71 MiB | 380.00 KiB/s, done.
Resolving deltas: 100% (275/275), done.
Checking connectivity... done.
```

然后，我们需要将目录更改为`caffe-to-tensorflow`目录，并运行 convert python 脚本来查看一些帮助消息:

```
cd caffe-tensorflow
python convert.py -h
The resulting console will look like this:
usage: convert.py [-h] [--caffemodel CAFFEMODEL]
                  [--data-output-path DATA_OUTPUT_PATH]
                  [--code-output-path CODE_OUTPUT_PATH] [-p PHASE]
                  def_path

positional arguments:
def_path              Model definition (.prototxt) path

optional arguments:
  -h, --help            show this help message and exit
  --caffemodel CAFFEMODEL
                        Model data (.caffemodel) path
  --data-output-path DATA_OUTPUT_PATH
                        Converted data output path
  --code-output-path CODE_OUTPUT_PATH
                        Save generated source to this path
  -p PHASE, --phase PHASE
                        The phase to convert: test (default) or train
```

根据这个帮助信息，我们可以知道`convert.py`脚本的参数。总之，我们将使用此`convert.py`在 TensorFlow 中创建带有标志 code-output-path 的网络架构，并使用标志 data-output-path 转换预训练的权重。

在我们开始转换模型之前，我们需要从这个项目的贡献者那里获得一些拉请求。目前的 master 分支存在一些问题，我们无法使用最新的 TensorFlow(编写时为 1.3 版本)和 python-protobuf(编写时为 3.4.0 版本)。因此，我们将使用以下拉请求获取代码:

[https://github.com/ethereon/caffe-tensorflow/pull/105](https://github.com/ethereon/caffe-tensorflow/pull/105)

[https://github.com/ethereon/caffe-tensorflow/pull/133](https://github.com/ethereon/caffe-tensorflow/pull/133)

您需要打开前面的链接来查看拉请求是否被合并。如果仍处于`open`状态，则需要进行下一部分。否则，您可以跳过合并的`pull`请求。

首先，我们将从拉取请求`105`中获取代码:

```
ubuntu@ubuntu-PC:~/github$ git pull origin pull/105/head
remote: Counting objects: 33, done.
remote: Total 33 (delta 8), reused 8 (delta 8), pack-reused 25
Unpacking objects: 100% (33/33), done.
From https://github.com/ethereon/caffe-tensorflow
* branch            refs/pull/105/head -> FETCH_HEAD
Updating d870c51..ccd1a52
Fast-forward
.gitignore                               |  5 +++++
convert.py                               |  8 ++++++++
examples/save_model/.gitignore           | 11 ++++++++++
examples/save_model/READMD.md            | 17 ++++++++++++++++
examples/save_model/__init__.py          |  0
examples/save_model/save_model.py        | 51 ++++++++++++++++++++++++++++++++++++++++++++++
kaffe/caffe/{caffepb.py => caffe_pb2.py} |  0
kaffe/caffe/resolver.py                  |  4 ++--
kaffe/tensorflow/network.py              |  8 ++++----
9 files changed, 98 insertions(+), 6 deletions(-)
create mode 100644 examples/save_model/.gitignore
create mode 100644 examples/save_model/READMD.md
create mode 100644 examples/save_model/__init__.py
create mode 100755 examples/save_model/save_model.py
rename kaffe/caffe/{caffepb.py => caffe_pb2.py} (100%)
```

然后，从拉请求`133`:

```
- git pull origin pull/133/head
remote: Counting objects: 31, done.
remote: Total 31 (delta 20), reused 20 (delta 20), pack-reused 11
Unpacking objects: 100% (31/31), done.
From https://github.com/ethereon/caffe-tensorflow
* branch            refs/pull/133/head -> FETCH_HEAD
Auto-merging kaffe/tensorflow/network.py
CONFLICT (content): Merge conflict in kaffe/tensorflow/network.py
Auto-merging .gitignore
CONFLICT (content): Merge conflict in .gitignore
Automatic merge failed; fix conflicts and then commit the result.
```

如您所见，在`kaffe/tensorflow/network.py`文件中有一些冲突。我们将向您展示如何解决这些`conflicts`，如下所示。

首先，我们将解决第 137 行的冲突:

![](img/8cbf68bc-d3f7-4fb7-997b-3f6daa91a467.png)

我们从第 137 行到第 140 行移除头部。最终结果将如下所示:

![](img/24ec3b97-1597-4c60-87e7-ea065ad10bcc.png)

接下来，我们将解决第 185 行的冲突:

![](img/e98bcebb-7236-47f4-8628-55673a01f83a.png)

我们还删除了第 185 行到第 187 行的头部分。最终结果将如下所示:

![](img/699ebeba-5219-4f3e-851c-c7970784f55e.png)

在`caffe-to-tensorflow`目录中，有一个名为 examples 的目录，其中包含 MNIST 和 ImageNet 挑战的代码和数据。我们将向您展示如何使用 MNIST 模型。ImageNet 挑战并没有太大的不同。

首先，我们将使用以下命令将 MNIST 体系结构从 Caffe 转换为 TensorFlow:

```
    ubuntu@ubuntu-PC:~/github$ python ./convert.py examples/mnist/lenet.prototxt --code-output-path=./mynet.py
    The result will look like this:

    ------------------------------------------------------------
        WARNING: PyCaffe not found!
        Falling back to a pure protocol buffer implementation.
        * Conversions will be drastically slower.
        * This backend is UNTESTED!
    ------------------------------------------------------------

    Type                 Name                                          Param               Output
    ----------------------------------------------------------------------------------------------
    Input                data                                             --      (64, 1, 28, 28)
    Convolution          conv1                                            --     (64, 20, 24, 24)
    Pooling              pool1                                            --     (64, 20, 12, 12)
    Convolution          conv2                                            --       (64, 50, 8, 8)
    Pooling              pool2                                            --       (64, 50, 4, 4)
    InnerProduct         ip1                                              --      (64, 500, 1, 1)
    InnerProduct         ip2                                              --       (64, 10, 1, 1)
    Softmax              prob                                             --       (64, 10, 1, 1)
    Converting data...
    Saving source...
    Done.
```

然后，我们将使用以下命令在`examples/mnist/lenet_iter_10000.caffemodel`转换 MNIST 预训练的 Caffe 模型:

```
 ubuntu@ubuntu-PC:~/github$ python ./convert.py  
 examples/mnist/lenet.prototxt --caffemodel  
 examples/mnist/lenet_iter_10000.caffemodel --data-output- 
 path=./mynet.npy
```

结果将如下所示:

```
    ------------------------------------------------------------
        WARNING: PyCaffe not found!
        Falling back to a pure protocol buffer implementation.
        * Conversions will be drastically slower.
        * This backend is UNTESTED!
    ------------------------------------------------------------

    Type                 Name                                          Param               Output
    ----------------------------------------------------------------------------------------------
    Input                data                                             --      (64, 1, 28, 28)
    Convolution          conv1                                 
(20, 1, 5, 5)     (64, 20, 24, 24)
    Pooling              pool1                                            --     (64, 20, 12, 12)
    Convolution          conv2                               
 (50, 20, 5, 5)       (64, 50, 8, 8)
    Pooling              pool2                                            --       (64, 50, 4, 4)
    InnerProduct         ip1                                   
   (500, 800)      (64, 500, 1, 1)
    InnerProduct         ip2                                      
 (10, 500)       (64, 10, 1, 1)
    Softmax              prob                                             --       (64, 10, 1, 1)
    Converting data...
    Saving data...
    Done.
```

如您所见，这些命令将在当前目录中创建一个名为`mynet.py`的 python 文件和一个名为`mynet.npy`的`numpy`文件。我们还需要将当前目录添加到`PYTHONPATH`中，以允许进一步的代码导入`mynet.py`:

```
ubuntu@ubuntu-PC:~/github$ export PYTHONPATH=$PYTHONPATH:.
ubuntu@ubuntu-PC:~/github$ python examples/mnist/finetune_mnist.py
....
('Iteration: ', 900, 0.0087626642, 1.0)
('Iteration: ', 910, 0.018495116, 1.0)
('Iteration: ', 920, 0.0029206357, 1.0)
('Iteration: ', 930, 0.0010091728, 1.0)
('Iteration: ', 940, 0.071255416, 1.0)
('Iteration: ', 950, 0.045163739, 1.0)
('Iteration: ', 960, 0.005758767, 1.0)
('Iteration: ', 970, 0.012100354, 1.0)
('Iteration: ', 980, 0.12018739, 1.0)
('Iteration: ', 990, 0.079262167, 1.0)
```

每行最后两个数字是微调过程的损耗和精度。您可以看到，使用来自 Caffe 模型的预训练权重，微调过程可以轻松实现 100%的准确性。

现在，我们将查看`finetune_mnist.py`文件，了解预训练权重是如何使用的。

首先，他们用下面的代码导入了`mynet` python:

```
    from mynet import LeNet as MyNet  
```

然后，他们为`images`和`labels`创建一些占位符，并使用图层`ip2`计算`loss`，如下所示:

```
 images = tf.placeholder(tf.float32, [None, 28, 28, 1]) 
 labels = tf.placeholder(tf.float32, [None, 10]) 
 net = MyNet({'data': images}) 

 ip2 = net.layers['ip2'] 
 pred = net.layers['prob'] 

 loss =  
 tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=ip2,  
 labels=labels), 0) 
 Finally, they load the numpy file into the graph, using the load  
 method in the network class. 
 with tf.Session() as sess: 
    # Load the data 
    sess.run(tf.global_variables_initializer()) 
    net.load('mynet.npy', sess) 
```

之后，微调过程独立于 Caffe 框架。



# 张量流-超薄

TensorFlow-Slim 是一个轻量级的库，用于定义、训练和评估 TensorFlow 中的复杂模型。使用 TensorFlow-Slim 库，我们可以通过提供大量高级层、变量和正则化子来更容易地构建、训练和评估模型。我们建议您通过以下链接查看 TensorFlow-Slim 库:[https://github . com/tensor flow/tensor flow/tree/master/tensor flow/contrib/Slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim)

TensorFlow-Slim 还提供了许多预训练模型。您可以通过以下链接利用高级 TensorFlow 层和模型:

[https://github . com/tensor flow/tensor flow/tree/master/tensor flow/contrib/slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim)



# 摘要

在这一章中，我们提供了许多有趣的挑战和问题，你可以尝试解决并从中学习，以提高你的张量流技能。在本章的最后，我们还指导您将 Caffe 模型转换为 TensorFlow，并向您介绍了高级 TensorFlow 库 TensorFlow-Slim。