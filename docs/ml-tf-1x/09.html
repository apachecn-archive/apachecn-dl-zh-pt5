<html><head/><body>


    
        <title>Cruise Control - Automation</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">巡航控制-自动化</h1>
                
            
            
                
<p>在本章中，我们将创建一个生产系统，从培训到为模型服务。我们的系统将有能力区分37种不同种类的狗和猫。用户可以上传图像到我们的系统来接收结果。该系统还可以接收用户的反馈，并每天自动训练自己以改善结果。</p>
<p>本章将集中在几个方面:</p>
<ul>
<li>如何将迁移学习应用于新数据集</li>
<li>如何使用TensorFlow服务为生产模型提供服务</li>
<li>创建一个带有数据集众包标签的系统，并根据用户数据自动微调模型</li>
</ul>


            

            
        
    






    
        <title>An overview of the system</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">系统概述</h1>
                
            
            
                
<p>下图概述了我们的系统:</p>
<div><img height="186" width="300" src="img/f70d3bc2-a815-4a92-8c76-8ac66ffc649f.png"/></div>
<p>在这个系统中，我们将使用初始数据集在训练服务器上训练卷积神经网络模型。然后，该模型将通过TensorFlow服务在生产服务器中提供服务。在生产服务器上，将有一个Flask服务器，允许用户上传新的图像，并在模型出错时更正标签。在一天中定义的时间，训练服务器将所有用户标记的图像与当前数据集相结合，以自动微调模型并将其发送到生产服务器。下面是允许用户上传和接收结果的web界面的线框:</p>
<div><img height="281" width="662" class="image-border" src="img/9972d10a-5ab1-456c-849f-1490e4f346ff.png"/></div>


            

            
        
    






    
        <title>Setting up the project</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">设置项目</h1>
                
            
            
                
<p>在这一章中，我们将微调一个已经用1000个类对<kbd>ImageNet</kbd>数据进行了训练的VGG模型。我们已经提供了一个预训练的VGG模型和一些实用程序文件的初始项目。你可以从https://github.com/mlwithtf/mlwithtf/tree/master/chapter_09<a href="https://github.com/mlwithtf/mlwithtf/tree/master/chapter_09">下载代码。</a><a href="https://github.com/mlwithtf/mlwithtf/tree/master/chapter_09"/></p>
<p>在文件夹<kbd>chapter-09</kbd>中，您将拥有以下结构:</p>
<pre><strong>- data</strong>
<strong>--VGG16.npz</strong>
<strong>- samples_data</strong>
<strong>- production</strong>
<strong>- utils</strong>
<strong>--__init__.py</strong>
<strong>--debug_print.py</strong>
<strong>- README.md</strong></pre>
<p>您应该了解两个文件:</p>
<ul>
<li><kbd>VGG16.npz</kbd>是从Caffe模型导出的预训练模型。<a href="1cae2bb8-19d3-4640-aae6-d31d66afb605.xhtml">第11章</a>，<em>更进一步——21个问题</em>将向你展示如何从Caffe模型创建这个文件。在本章中，我们将使用它作为模型的初始值。你可以从<kbd>chapter_09</kbd>文件夹中的<kbd>README.md</kbd>下载这个文件。</li>
<li><kbd>production</kbd>是我们创建的Flask服务器，作为用户上传和修改模型的web界面。</li>
<li><kbd>debug_print.py</kbd>包含一些我们将在本章中用来理解网络结构的方法。</li>
<li>包含了一些猫、狗和汽车的图片，我们将在本章中用到。</li>
</ul>


            

            
        
    






    
        <title>Loading a pre-trained model to speed up the training</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">加载预训练模型以加快训练速度</h1>
                
            
            
                
<p>在本节中，我们将重点放在TensorFlow中预训练模型的加载上。我们将使用牛津大学的K. Simonyan和A. Zisserman提出的VGG-16模型。</p>
<p>VGG-16是一个非常深的神经网络，具有许多卷积层，后跟最大池和完全连接层。在<kbd>ImageNet</kbd>挑战中，在1，000个图像类别的验证集上，VGG-16模型的前5名分类误差在单尺度方法中为8.1%；</p>
<div><img height="214" width="375" class="image-border" src="img/98634c06-1c4f-4443-a69b-1a6df6d9436b.png"/></div>
<p>首先，在<kbd>project</kbd>目录中创建一个名为<kbd>nets.py</kbd>的文件。以下代码定义了VGG-16模型的图形:</p>
<pre style="padding-left: 30px">    import tensorflow as tf 
    import numpy as np 
 
 
    def inference(images): 
    with tf.name_scope("preprocess"): 
        mean = tf.constant([123.68, 116.779, 103.939],  
    dtype=tf.float32, shape=[1, 1, 1, 3], name='img_mean') 
        input_images = images - mean 
    conv1_1 = _conv2d(input_images, 3, 3, 64, 1, 1,   
    name="conv1_1") 
    conv1_2 = _conv2d(conv1_1, 3, 3, 64, 1, 1, name="conv1_2") 
    pool1 = _max_pool(conv1_2, 2, 2, 2, 2, name="pool1") 
 
    conv2_1 = _conv2d(pool1, 3, 3, 128, 1, 1, name="conv2_1") 
    conv2_2 = _conv2d(conv2_1, 3, 3, 128, 1, 1, name="conv2_2") 
    pool2 = _max_pool(conv2_2, 2, 2, 2, 2, name="pool2") 
 
    conv3_1 = _conv2d(pool2, 3, 3, 256, 1, 1, name="conv3_1") 
    conv3_2 = _conv2d(conv3_1, 3, 3, 256, 1, 1, name="conv3_2") 
    conv3_3 = _conv2d(conv3_2, 3, 3, 256, 1, 1, name="conv3_3") 
    pool3 = _max_pool(conv3_3, 2, 2, 2, 2, name="pool3") 
 
    conv4_1 = _conv2d(pool3, 3, 3, 512, 1, 1, name="conv4_1") 
    conv4_2 = _conv2d(conv4_1, 3, 3, 512, 1, 1, name="conv4_2") 
    conv4_3 = _conv2d(conv4_2, 3, 3, 512, 1, 1, name="conv4_3") 
    pool4 = _max_pool(conv4_3, 2, 2, 2, 2, name="pool4") 
 
    conv5_1 = _conv2d(pool4, 3, 3, 512, 1, 1, name="conv5_1") 
    conv5_2 = _conv2d(conv5_1, 3, 3, 512, 1, 1, name="conv5_2") 
    conv5_3 = _conv2d(conv5_2, 3, 3, 512, 1, 1, name="conv5_3") 
    pool5 = _max_pool(conv5_3, 2, 2, 2, 2, name="pool5") 
 
    fc6 = _fully_connected(pool5, 4096, name="fc6") 
    fc7 = _fully_connected(fc6, 4096, name="fc7") 
    fc8 = _fully_connected(fc7, 1000, name='fc8', relu=False) 
    outputs = _softmax(fc8, name="output") 
    return outputs </pre>
<p>在前面的代码中，您应该注意一些事情:</p>
<ul>
<li><kbd>_conv2d</kbd>、<kbd>_max_pool</kbd>、<kbd>_fully_connected</kbd>和<kbd>_softmax</kbd>是分别定义卷积、最大池、完全连接和softmax层的方法。我们将很快实现这些方法。</li>
<li>在<kbd>preprocess</kbd>命名范围中，我们定义了一个常量张量<kbd>mean</kbd>，它从输入图像中减去。这是VGG-16模型被训练的平均向量，以使图像零均值。</li>
<li>然后，我们用参数定义卷积、最大池化和完全连接的层。</li>
<li>在<kbd>fc8</kbd>层中，我们不对输出应用ReLU激活，而是将输出发送到<kbd>softmax</kbd>层来计算1000个类的概率。</li>
</ul>
<p>现在，我们将执行<kbd>nets.py</kbd>文件中的<kbd>_conv2d</kbd>、<kbd>_max_pool</kbd>、<kbd>_fully_connected</kbd>和<kbd>_softmax</kbd>。</p>
<p>以下代码是<kbd>_conv2d</kbd>和<kbd>_max_pool</kbd>方法的代码:</p>
<pre style="padding-left: 60px"> def _conv2d(input_data, k_h, k_w, c_o, s_h, s_w, name, relu=True,  <br/> padding="SAME"): 
    c_i = input_data.get_shape()[-1].value 
    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1],  <br/> padding=padding) 
    with tf.variable_scope(name) as scope: 
        weights = tf.get_variable(name="kernel", shape=[k_h, k_w,  <br/> c_i, c_o], 
                                   <br/> initializer=tf.truncated_normal_initializer(stddev=1e-1,  <br/> dtype=tf.float32)) 
        conv = convolve(input_data, weights) 
        biases = tf.get_variable(name="bias", shape=[c_o],  <br/> dtype=tf.float32, 
                                  <br/> initializer=tf.constant_initializer(value=0.0)) 
        output = tf.nn.bias_add(conv, biases) 
        if relu: 
            output = tf.nn.relu(output, name=scope.name) 
        return output 
 def _max_pool(input_data, k_h, k_w, s_h, s_w, name,  <br/> padding="SAME"): 
    return tf.nn.max_pool(input_data, ksize=[1, k_h, k_w, 1], 
                          strides=[1, s_h, s_w, 1], padding=padding,  <br/> name=name) </pre>
<p>如果你已经阅读过<a href="ff9f54f4-c5eb-4ea8-bc0c-da5021479d77.xhtml">第4章</a>、<em>猫狗</em>，前面的大部分代码都是不言自明的，但是有几行代码需要解释一下:</p>
<ul>
<li><kbd>k_h</kbd>和<kbd>k_w</kbd>是仁的高度和重量</li>
<li><kbd>c_o</kbd>表示通道输出，即卷积层的特征图数量</li>
<li><kbd>s_h</kbd>和<kbd>s_w</kbd>是<kbd>tf.nn.conv2d</kbd>和<kbd>tf.nn.max_pool</kbd>层的步幅参数</li>
<li>使用<kbd>tf.get_variable</kbd>代替<kbd>tf.Variable</kbd>,因为当我们加载预训练的重量时，我们将需要再次使用<kbd>get_variable</kbd></li>
</ul>
<p>实现<kbd>fully_connected</kbd>层和<kbd>softmax</kbd>层非常容易:</p>
<pre style="padding-left: 60px"> def _fully_connected(input_data, num_output, name, relu=True): 
    with tf.variable_scope(name) as scope: 
        input_shape = input_data.get_shape() 
        if input_shape.ndims == 4: 
            dim = 1 
            for d in input_shape[1:].as_list(): 
                dim *= d 
            feed_in = tf.reshape(input_data, [-1, dim]) 
        else: 
            feed_in, dim = (input_data, input_shape[-1].value) 
        weights = tf.get_variable(name="kernel", shape=[dim,  <br/> num_output], 
                                   <br/> initializer=tf.truncated_normal_initializer(stddev=1e-1,  <br/> dtype=tf.float32)) 
        biases = tf.get_variable(name="bias", shape=[num_output], <br/> dtype=tf.float32, 
                                  <br/> initializer=tf.constant_initializer(value=0.0)) 
        op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b 
        output = op(feed_in, weights, biases, name=scope.name) 
        return output 
 def _softmax(input_data, name): 
    return tf.nn.softmax(input_data, name=name) </pre>
<p>使用<kbd>_fully_connected</kbd>方法，我们首先检查输入数据的维数，以便将输入数据整形为正确的形状。然后，我们用<kbd>get_variable</kbd>方法创建<kbd>weights</kbd>和<kbd>biases</kbd>变量。最后，我们检查<kbd>relu</kbd>参数，以决定我们是否应该将<kbd>relu</kbd>应用于带有<kbd>tf.nn.relu_layer</kbd>或<kbd>tf.nn.xw_plus_b</kbd>的输出。<kbd>tf.nn.relu_layer</kbd>将计算<kbd>relu(matmul(x, weights) + biases)</kbd>。<kbd>tf.nn.xw_plus_b</kbd>但只会计算<kbd>matmul(x, weights) + biases</kbd>。</p>
<p>本节的最后一个方法用于将预训练的<kbd>caffe</kbd>权重加载到定义的变量中:</p>
<pre>   def load_caffe_weights(path, sess, ignore_missing=False): 
    print("Load caffe weights from ", path) 
    data_dict = np.load(path).item() 
    for op_name in data_dict: 
        with tf.variable_scope(op_name, reuse=True): 
            for param_name, data in   
    data_dict[op_name].iteritems(): 
                try: 
                    var = tf.get_variable(param_name) 
                    sess.run(var.assign(data)) 
                except ValueError as e: 
                    if not ignore_missing: 
                        print(e) 
                        raise e </pre>
<p>为了理解这种方法，我们必须知道数据是如何存储在预先训练好的模型中的，<kbd>VGG16.npz</kbd>。我们创建了一个简单的代码来打印预训练模型中的所有变量。你可以把下面的代码放在<kbd>nets.py</kbd>的末尾，用Python <kbd>nets.py</kbd>运行它:</p>
<pre>    if __name__ == "__main__": 
    path = "data/VGG16.npz" 
    data_dict = np.load(path).item() 
    for op_name in data_dict: 
        print(op_name) 
        for param_name, data in     ].iteritems(): 
            print("\t" + param_name + "\t" + str(data.shape)) </pre>
<p>以下是几行结果:</p>
<pre><strong>conv1_1</strong>
    <strong>weights (3, 3, 3, 64)</strong>
    <strong>biases  (64,)</strong>
<strong>conv1_2</strong>
   <strong> weights (3, 3, 64, 64)</strong>
   <strong> biases  (64,)</strong></pre>
<p>如你所见，<kbd>op_name</kbd>是图层的名称，我们可以用<kbd>data_dict[op_name]</kbd>访问每个图层的<kbd>weights</kbd>和<kbd>biases</kbd>。</p>
<p>我们来看看<kbd>load_caffe_weights</kbd>:</p>
<ul>
<li>我们将它与参数中的<kbd>tf.variable_scope</kbd>和<kbd>reuse=True</kbd>一起使用，这样我们可以获得图表中定义的<kbd>weights</kbd>和<kbd>biases</kbd>的精确变量。之后，我们运行assign方法为每个变量设置数据。</li>
<li>如果没有定义变量名，<kbd>get_variable</kbd>方法将给出<kbd>ValueError</kbd>。因此，我们将使用<kbd>ignore_missing</kbd>变量来决定是否应该引发错误。</li>
</ul>


            

            
        
    






    
        <title>Testing the pre-trained model</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">测试预训练模型</h1>
                
            
            
                
<p>我们已经创建了一个VGG16神经网络。在本节中，我们将尝试使用预训练的模型来执行汽车、猫和狗的分类，以检查模型是否已成功加载。</p>
<p>在<kbd>nets.py</kbd>文件中，我们需要用以下代码替换当前的<kbd>__main__</kbd>代码:</p>
<pre>    import os 
    from utils import debug_print 
    from scipy.misc import imread, imresize 
 
 
    if __name__ == "__main__": 
    SAMPLES_FOLDER = "samples_data" 
    with open('%s/imagenet-classes.txt' % SAMPLES_FOLDER, 'rb') as   
    infile: 
     class_labels = map(str.strip, infile.readlines()) 
 
    inputs = tf.placeholder(tf.float32, [None, 224, 224, 3],   
    name="inputs") 
    outputs = inference(inputs) 
 
    debug_print.print_variables(tf.global_variables()) 
    debug_print.print_variables([inputs, outputs]) 
 
    with tf.Session() as sess: 
     load_caffe_weights("data/VGG16.npz", sess,   
    ignore_missing=False) 
 
        files = os.listdir(SAMPLES_FOLDER) 
        for file_name in files: 
            if not file_name.endswith(".jpg"): 
                continue 
            print("=== Predict %s ==== " % file_name) 
            img = imread(os.path.join(SAMPLES_FOLDER, file_name),  
            mode="RGB") 
            img = imresize(img, (224, 224)) 
 
            prob = sess.run(outputs, feed_dict={inputs: [img]})[0] 
            preds = (np.argsort(prob)[::-1])[0:3] 
 
            for p in preds: 
                print class_labels[p], prob[p]</pre>
<p>在前面的代码中，有几件事您应该注意:</p>
<ul>
<li>我们使用<kbd>debug_print</kbd>。<kbd>print_variables</kbd>通过打印变量名称和形状来可视化所有变量的辅助方法。</li>
<li>我们用形状<kbd>[None, 224, 224, 3]</kbd>定义了一个名为<kbd>inputs</kbd>的占位符，这是VGG16模型所需的输入大小:</li>
</ul>
<pre>      We get the model graph with outputs = inference(inputs). </pre>
<ul>
<li>在<kbd>tf.Session()</kbd>中，我们用<kbd>ignore_missing=False</kbd>调用<kbd>load_caffe_weights</kbd>方法，保证可以加载预训练模型的所有权重和偏差。</li>
<li>使用<kbd>scipy</kbd>中的<kbd>imread</kbd>和<kbd>imresize</kbd>方法加载图像并调整大小。然后，我们使用<kbd>sess.run</kbd>方法和<kbd>feed_dict</kbd>字典并接收预测。</li>
<li>以下结果是我们在本章开始时提供的<kbd>samples_data</kbd>中对<kbd>car.jpg</kbd>、<kbd>cat.jpg</kbd>和<kbd>dog.jpg</kbd>的预测:</li>
</ul>
<pre>    <strong>== Predict car.jpg ==== </strong>
    <strong>racer, race car, racing car 0.666172</strong>
    <strong>sports car, sport car 0.315847</strong>
    <strong>car wheel 0.0117961</strong>
    <strong>=== Predict cat.jpg ==== </strong>
    <strong>Persian cat 0.762223</strong>
    <strong>tabby, tabby cat 0.0647032</strong>
    <strong>lynx, catamount 0.0371023</strong>
    <strong>=== Predict dog.jpg ==== </strong>
    <strong>Border collie 0.562288</strong>
    <strong>collie 0.239735</strong>
    <strong>Appenzeller 0.0186233</strong></pre>
<p>前面的结果就是这些图像的确切标签。这意味着我们已经在TensorFlow中成功加载了预训练的VGG16模型。在下一节中，我们将向您展示如何在我们的数据集上微调模型。</p>


            

            
        
    






    
        <title>Training the model for our dataset</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">为我们的数据集训练模型</h1>
                
            
            
                
<p>在本节中，我们将完成创建数据集、微调模型以及导出模型以用于生产的过程。</p>


            

            
        
    






    
        <title>Introduction to the Oxford-IIIT Pet dataset</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">牛津-IIIT Pet数据集简介</h1>
                
            
            
                
<p>牛津-IIIT宠物数据库包含37种狗和猫。每一类都有200张图片，在比例、姿势和光照方面有很大的差异。地面实况数据有每个图像的物种、头部位置和像素分割的注释。在我们的应用程序中，我们只使用物种名称作为模型的类名:</p>
<div><img height="100" width="431" class="image-border" src="img/682fb671-be0e-4fa6-8895-23a01be38c5b.png"/></div>


            

            
        
    






    
        <title>Dataset Statistics</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">数据集统计</h1>
                
            
            
                
<p>以下是狗和猫品种的数据集:</p>
<ol start="1">
<li>狗的品种:</li>
</ol>
<div><table style="width: 567px;height: 1137px">
<tbody>
<tr>
<td>
<p><strong>品种</strong></p>
</td>
<td><strong>总计</strong></td>
</tr>
<tr>
<td>美国斗牛犬</td>
<td>200</td>
</tr>
<tr>
<td>美国比特犬</td>
<td>200</td>
</tr>
<tr>
<td>巴吉度猎犬</td>
<td>200</td>
</tr>
<tr>
<td>短毛小猎犬</td>
<td>200</td>
</tr>
<tr>
<td>拳击运动员</td>
<td>199</td>
</tr>
<tr>
<td>奇瓦瓦州</td>
<td>200</td>
</tr>
<tr>
<td>英国可卡犬</td>
<td>196</td>
</tr>
<tr>
<td>英国二传手</td>
<td>200</td>
</tr>
<tr>
<td>德国短毛</td>
<td>200</td>
</tr>
<tr>
<td>大比利牛斯</td>
<td>200</td>
</tr>
<tr>
<td>哈瓦那人</td>
<td>200</td>
</tr>
<tr>
<td>日本下巴</td>
<td>200</td>
</tr>
<tr>
<td>荷兰卷尾狮毛狗</td>
<td>199</td>
</tr>
<tr>
<td>莱昂贝格尔</td>
<td>200</td>
</tr>
<tr>
<td>小型品酒师</td>
<td>200</td>
</tr>
<tr>
<td>纽芬兰</td>
<td>196</td>
</tr>
<tr>
<td>波美拉尼亚狗</td>
<td>200</td>
</tr>
<tr>
<td>哈巴狗</td>
<td>200</td>
</tr>
<tr>
<td>圣·伯纳德</td>
<td>200</td>
</tr>
<tr>
<td>萨莫耶德人</td>
<td>200</td>
</tr>
<tr>
<td>苏格兰梗</td>
<td>199</td>
</tr>
<tr>
<td>柴犬</td>
<td>200</td>
</tr>
<tr>
<td>斯塔福德郡斗牛梗</td>
<td>189</td>
</tr>
<tr>
<td>小麦梗</td>
<td>200</td>
</tr>
<tr>
<td>约克夏梗</td>
<td>200</td>
</tr>
<tr>
<td><strong>总计</strong></td>
<td><strong> 4978 </strong></td>
</tr>
</tbody>
</table>
</div>
<ol start="2">
<li>猫的品种:</li>
</ol>
<div><table style="width: 568px;height: 506px">
<tbody>
<tr>
<td><strong>品种</strong></td>
<td><strong>计数</strong></td>
</tr>
<tr>
<td>红阿比</td>
<td>198</td>
</tr>
<tr>
<td>孟加拉</td>
<td>200</td>
</tr>
<tr>
<td>缅甸猫</td>
<td>200</td>
</tr>
<tr>
<td>MUMBAI 的原称</td>
<td>184</td>
</tr>
<tr>
<td>英国短毛猫</td>
<td>200</td>
</tr>
<tr>
<td>埃及毛</td>
<td>190</td>
</tr>
<tr>
<td>缅因库恩猫</td>
<td>200</td>
</tr>
<tr>
<td>波斯人</td>
<td>200</td>
</tr>
<tr>
<td>布娃娃</td>
<td>200</td>
</tr>
<tr>
<td>俄罗斯蓝猫</td>
<td>200</td>
</tr>
<tr>
<td>暹罗人</td>
<td>199</td>
</tr>
<tr>
<td>无毛猫</td>
<td>200</td>
</tr>
<tr>
<td><strong>总计</strong></td>
<td><strong> 2371 </strong></td>
</tr>
</tbody>
</table>
</div>
<ol start="3">
<li>宠物总数:</li>
</ol>
<table style="width: 677px;height: 164px">
<tbody>
<tr>
<td><strong>家族</strong></td>
<td><strong>计数</strong></td>
</tr>
<tr>
<td>猫</td>
<td>2371</td>
</tr>
<tr>
<td>狗</td>
<td>4978</td>
</tr>
<tr>
<td><strong>总计</strong></td>
<td><strong> 7349 </strong></td>
</tr>
</tbody>
</table>


            

            
        
    






    
        <title>Downloading the dataset</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">下载数据集</h1>
                
            
            
                
<p>我们可以从牛津大学http://www.robots.ox.ac.uk/~vgg/data/pets/分校的网站上获得数据集。我们需要下载数据集和地面实况数据作为<kbd>images.tar.gz</kbd>和<kbd>annotations.tar.gz</kbd>。我们将TAR文件存储在<kbd>data/datasets</kbd>文件夹中，并提取所有的<kbd>.tar</kbd>文件。确保<kbd>data</kbd>文件夹具有以下结构:</p>
<pre><strong>- data</strong>
<strong>-- VGG16.npz</strong>
<strong>-- datasets</strong>
<strong>---- annotations</strong>
<strong>------ trainval.txt</strong>
<strong>---- images</strong>
<strong>------ *.jpg</strong></pre>


            

            
        
    






    
        <title>Preparing the data</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">准备数据</h1>
                
            
            
                
<p>在开始训练过程之前，我们需要将数据集预处理成更简单的格式，我们将在进一步的自动微调中使用它。</p>
<p>首先，我们在<kbd>project</kbd>文件夹中创建一个带有命名脚本的Python包。然后，我们创建一个名为<kbd>convert_oxford_data.py</kbd>的Python文件，并添加以下代码:</p>
<pre>    import os 
    import tensorflow as tf 
    from tqdm import tqdm 
    from scipy.misc import imread, imsave 
 
    FLAGS = tf.app.flags.FLAGS 
 
    tf.app.flags.DEFINE_string( 
    'dataset_dir', 'data/datasets', 
    'The location of Oxford IIIT Pet Dataset which contains    
     annotations and images folders' 
    ) 
 
    tf.app.flags.DEFINE_string( 
    'target_dir', 'data/train_data', 
    'The location where all the images will be stored' 
    ) 
 
    def ensure_folder_exists(folder_path): 
    if not os.path.exists(folder_path): 
        os.mkdir(folder_path) 
    return folder_path 
 
    def read_image(image_path): 
    try: 
        image = imread(image_path) 
        return image 
    except IOError: 
        print(image_path, "not readable") 
    return None </pre>
<p>在这段代码中，我们使用<kbd>tf.app.flags.FLAGS</kbd>来解析参数，这样我们就可以轻松地定制脚本。我们还创建了两个<kbd>helper</kbd>方法来创建目录和读取图像。</p>
<p>接下来，我们添加以下代码，将牛津数据集转换为我们首选的格式:</p>
<pre style="padding-left: 60px"> def convert_data(split_name, save_label=False): 
    if split_name not in ["trainval", "test"]: 
    raise ValueError("split_name is not recognized!") 
    target_split_path =  <br/>    ensure_folder_exists(os.path.join(FLAGS.target_dir, split_name)) 
    output_file = open(os.path.join(FLAGS.target_dir, split_name +  <br/>    ".txt"), "w") 
 
    image_folder = os.path.join(FLAGS.dataset_dir, "images") 
    anno_folder = os.path.join(FLAGS.dataset_dir, "annotations") 
 
    list_data = [line.strip() for line in open(anno_folder + "/" +  <br/>    split_name + ".txt")] 
 
    class_name_idx_map = dict() 
    for data in tqdm(list_data, desc=split_name): 
      file_name,class_index,species,breed_id = data.split(" ") 
      file_label = int(class_index) - 1 
 
      class_name = "_".join(file_name.split("_")[0:-1]) 
      class_name_idx_map[class_name] = file_label 
 
      image_path = os.path.join(image_folder, file_name + ".jpg") 
      image = read_image(image_path) 
      if image is not None: 
      target_class_dir =  <br/>       ensure_folder_exists(os.path.join(target_split_path,    <br/>       class_name)) 
      target_image_path = os.path.join(target_class_dir,  <br/>       file_name + ".jpg") 
            imsave(target_image_path, image) 
            output_file.write("%s %s\n" % (file_label,  <br/>            target_image_path)) 
 
    if save_label: 
        label_file = open(os.path.join(FLAGS.target_dir,  <br/>        "labels.txt"), "w") 
        for class_name in sorted(class_name_idx_map,  <br/>        key=class_name_idx_map.get): 
        label_file.write("%s\n" % class_name) 
 
 
 def main(_): 
    if not FLAGS.dataset_dir: 
    raise ValueError("You must supply the dataset directory with  <br/>    --dataset_dir") 
 
    ensure_folder_exists(FLAGS.target_dir) 
    convert_data("trainval", save_label=True) 
    convert_data("test") 
 
 
 if __name__ == "__main__": 
    tf.app.run() </pre>
<p>现在，我们可以用下面的代码运行<kbd>scripts</kbd>:</p>
<pre><strong>python scripts/convert_oxford_data.py --dataset_dir data/datasets/ --target_dir data/train_data.</strong></pre>
<p>该脚本读取牛津-IIIT数据集地面实况<kbd>data</kbd>，并在<kbd>data/train_data</kbd>中创建新的<kbd>dataset</kbd>，其结构如下:</p>
<pre><strong>- train_data</strong>
<strong>-- trainval.txt</strong>
<strong>-- test.txt</strong>
<strong>-- labels.txt</strong>
<strong>-- trainval</strong>
<strong>---- Abyssinian</strong>
<strong>---- ...</strong>
<strong>-- test</strong>
<strong>---- Abyssinian</strong>
<strong>---- ...</strong></pre>
<p>让我们稍微讨论一下:</p>
<ul>
<li><kbd>labels.txt</kbd>包含我们数据集中37个物种的列表。</li>
<li><kbd>trainval.txt</kbd>包含我们将在培训过程中使用的图像列表，格式为<kbd>&lt;class_id&gt; &lt;image_path&gt;</kbd>。</li>
<li><kbd>test.txt</kbd>包含我们将用来检查模型准确性的图像列表。<kbd>test.txt</kbd>的格式与<kbd>trainval.txt</kbd>相同。</li>
<li><kbd>trainval</kbd>和<kbd>test</kbd>文件夹包含37个子文件夹，是每个类别的名称，包含每个类别的所有图片。</li>
</ul>


            

            
        
    






    
        <title>Setting up input pipelines for training and testing</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">为培训和测试设置输入管道</h1>
                
            
            
                
<p>TensorFlow使我们能够创建一个可靠的输入管道，实现快速简便的培训。在本节中，我们将实现<kbd>tf.TextLineReader</kbd>来读取火车和测试文本文件。我们将使用<kbd>tf.train.batch</kbd>并行读取和预处理图像。</p>
<p>首先，我们需要在<kbd>project</kbd>目录中创建一个名为<kbd>datasets.py</kbd>的新Python文件，并添加以下代码:</p>
<pre>    import tensorflow as tf 
    import os 
 
    def load_files(filenames): 
    filename_queue = tf.train.string_input_producer(filenames) 
    line_reader = tf.TextLineReader() 
    key, line = line_reader.read(filename_queue) 
    label, image_path = tf.decode_csv(records=line, 
                                         
    record_defaults=[tf.constant([], dtype=tf.int32),   
    tf.constant([], dtype=tf.string)], 
                                      field_delim=' ') 
    file_contents = tf.read_file(image_path) 
    image = tf.image.decode_jpeg(file_contents, channels=3) 
 
    return image, label </pre>
<p>在<kbd>load_files</kbd>方法中，我们使用<kbd>tf.TextLineReader</kbd>来读取文本文件的每一行，比如<kbd>trainval.txt, test.txt</kbd>。<kbd>tf.TextLineReader</kbd>需要一个字符串队列来读取，所以我们使用<kbd>tf.train.string_input_producer</kbd>来存储文件名。之后，我们将行变量传入<kbd>tf.decode_cvs</kbd>以获得<kbd>label</kbd>和<kbd>filename</kbd>。使用<kbd>tf.image.decode_jpeg</kbd>可以轻松读取图像。</p>
<p>现在我们可以加载映像了，接下来我们可以为<kbd>training</kbd>创建<kbd>image</kbd>批次和<kbd>label</kbd>批次。</p>
<p>在<kbd>datasets.py</kbd>中，我们需要添加一个新方法:</p>
<pre style="padding-left: 60px"> def input_pipeline(dataset_dir, batch_size, num_threads=8,   
    is_training=True, shuffle=True): 
    if is_training: 
        file_names = [os.path.join(dataset_dir, "trainval.txt")] 
    else: 
        file_names = [os.path.join(dataset_dir, "test.txt")] 
    image, label = load_files(file_names) 
 
    image = preprocessing(image, is_training) 
 
    min_after_dequeue = 1000 
    capacity = min_after_dequeue + 3 * batch_size 
    if shuffle: 
     image_batch, label_batch = tf.train.shuffle_batch( 
     [image, label], batch_size, capacity,  
     min_after_dequeue, num_threads 
      ) 
    else: 
        image_batch, label_batch = tf.train.batch( 
            [image, label], batch_size, num_threads, capacity 
            ) 
    return image_batch, label_batch</pre>
<p>我们首先用<kbd>load_files</kbd>方法加载<kbd>image</kbd>和<kbd>label</kbd>。然后，我们通过一个新的预处理方法传递图像，我们将很快实现这个方法。最后，我们将<kbd>image</kbd>和<kbd>label</kbd>传入<kbd>tf.train.shuffle_batch</kbd>进行训练，传入<kbd>tf.train.batch</kbd>进行测试:</p>
<pre style="padding-left: 60px"> def preprocessing(image, is_training=True, image_size=224,  <br/> resize_side_min=256, resize_side_max=312): 
    image = tf.cast(image, tf.float32) 
 
    if is_training: 
        resize_side = tf.random_uniform([], minval=resize_side_min,  <br/>        maxval=resize_side_max+1, dtype=tf.int32) 
        resized_image = _aspect_preserving_resize(image,  <br/>        resize_side) 
 
        distorted_image = tf.random_crop(resized_image, [image_size,  <br/>        image_size, 3]) 
 
        distorted_image =  <br/>        tf.image.random_flip_left_right(distorted_image) 
  
        distorted_image =  <br/>        tf.image.random_brightness(distorted_image, max_delta=50) 
 
        distorted_image = tf.image.random_contrast(distorted_image,  <br/>        lower=0.2, upper=2.0) 
 
        return distorted_image 
    else: 
        resized_image = _aspect_preserving_resize(image, image_size) 
        return tf.image.resize_image_with_crop_or_pad(resized_image,  <br/>        image_size, image_size)</pre>
<p>在训练和测试中有两种不同的预处理方法。在训练中，我们需要扩充数据，从当前数据集创建更多的训练数据。预处理方法中使用了一些技术:</p>
<ul>
<li>数据集中的图像可以有不同的图像分辨率，但是我们只需要224x224的图像。因此，在执行<kbd>random_crop</kbd>之前，我们需要将图像调整到一个合理的大小。下图描述了裁剪的工作原理。<kbd>_aspect_preserving_resize</kbd>方法即将实施:</li>
</ul>
<div><img height="106" width="400" src="img/062d0bd1-3f15-4966-8b71-b3603ad59f01.png"/></div>
<ul>
<li>裁剪图像后，我们将图像通过<kbd>tf.image.random_flip_left_right</kbd>、<kbd>tf.image.random_brightness</kbd>和<kbd>tf.image.random_contrast</kbd>来扭曲图像并创建新的训练样本。</li>
<li>在测试程序中，我们只需要用<kbd>_aspect_preserving_resize</kbd>和<kbd>tf.image.resize_image_with_crop_or_pad</kbd>调整图像的大小。<kbd>tf.image.resize_image_with_crop_or_pad</kbd>允许我们在中心裁剪或填充图像到目标<kbd>width</kbd>和<kbd>height</kbd>。</li>
</ul>
<p>现在，我们需要将最后两个方法添加到<kbd>datasets.py</kbd>中，如下所示:</p>
<pre>    def _smallest_size_at_least(height, width, smallest_side): 
      smallest_side = tf.convert_to_tensor(smallest_side,   
      dtype=tf.int32) 
 
      height = tf.to_float(height) 
      width = tf.to_float(width) 
      smallest_side = tf.to_float(smallest_side) 
 
      scale = tf.cond(tf.greater(height, width), 
                    lambda: smallest_side / width, 
                    lambda: smallest_side / height) 
      new_height = tf.to_int32(height * scale) 
      new_width = tf.to_int32(width * scale) 
      return new_height, new_width 
 
 
    def _aspect_preserving_resize(image, smallest_side): 
      smallest_side = tf.convert_to_tensor(smallest_side,   
      dtype=tf.int32) 
      shape = tf.shape(image) 
      height = shape[0] 
      width = shape[1] 
      new_height, new_width = _smallest_size_at_least(height, width,   
      smallest_side) 
      image = tf.expand_dims(image, 0) 
      resized_image = tf.image.resize_bilinear(image, [new_height,   
      new_width], align_corners=False) 
      resized_image = tf.squeeze(resized_image) 
      resized_image.set_shape([None, None, 3]) 
      return resized_image </pre>
<p>到这一段，我们已经做了很多准备<kbd>dataset</kbd>和<kbd>input</kbd>管线的工作。在下一节中，我们将定义<kbd>dataset</kbd>、<kbd>loss</kbd>、<kbd>accuracy</kbd>和<kbd>training</kbd>操作的模型，以执行<kbd>training</kbd>程序。</p>


            

            
        
    






    
        <title>Defining the model</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">定义模型</h1>
                
            
            
                
<p>我们的应用程序需要对狗和猫的<kbd>37</kbd>类进行分类。VGG16型号支持1，000种不同的类别。在我们的应用程序中，我们将重用一直到<kbd>fc7</kbd>层的所有层，并从头开始训练最后一层。为了使模型输出<kbd>37</kbd>类，我们需要修改<kbd>nets.py</kbd>中的推理方法如下:</p>
<pre>    def inference(images, is_training=False): 
    # 
    # All the code before fc7 are not modified. 
    # 
    fc7 = _fully_connected(fc6, 4096, name="fc7") 
    if is_training: 
        fc7 = tf.nn.dropout(fc7, keep_prob=0.5) 
    fc8 = _fully_connected(fc7, 37, name='fc8-pets', relu=False) 
    return fc8</pre>
<ul>
<li>我们给这个方法添加了一个新的参数<kbd>is_training</kbd>。在<kbd>fc7</kbd>层之后，如果推断是训练，我们添加一个<kbd>tf.nn.dropout</kbd>层。这个丢弃层可以帮助模型用看不见的数据更好地正则化，并避免过度拟合。</li>
<li><kbd>fc8</kbd>层的输出数量从1000变为37。况且<kbd>fc8</kbd>层的名字必须改成另一个名字；这种情况下，我们选择<kbd>fc8-pets</kbd>。如果我们不改变<kbd>fc8</kbd>层的名称，<kbd>load_caffe_weights</kbd>仍然会找到新的层并分配原始权重，这与我们新的<kbd>fc8</kbd>层的大小不同。</li>
<li>推理方法末尾的<kbd>softmax</kbd>层也被删除，因为我们稍后将使用的<kbd>loss</kbd>函数只需要非规范化的输出。</li>
</ul>


            

            
        
    






    
        <title>Defining training operations</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">定义培训操作</h1>
                
            
            
                
<p>我们将在一个名为<kbd>models.py</kbd>的新Python文件中定义所有操作。首先，让我们创建一些操作来计算<kbd>loss</kbd>和<kbd>accuracy</kbd>:</p>
<pre style="padding-left: 60px"> def compute_loss(logits, labels): 
   labels = tf.squeeze(tf.cast(labels, tf.int32)) 
 
   cross_entropy =   
   tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,    
   labels=labels) 
   cross_entropy_mean = tf.reduce_mean(cross_entropy) 
   tf.add_to_collection('losses', cross_entropy_mean) 
 
   return tf.add_n(tf.get_collection('losses'),    
   name='total_loss') 
 
 
 def compute_accuracy(logits, labels): 
   labels = tf.squeeze(tf.cast(labels, tf.int32)) 
   batch_predictions = tf.cast(tf.argmax(logits, 1), tf.int32) 
   predicted_correctly = tf.equal(batch_predictions, labels) 
   accuracy = tf.reduce_mean(tf.cast(predicted_correctly,   
   tf.float32)) 
   return accuracy</pre>
<p>在这些方法中，<kbd>logits</kbd>是模型的输出，<kbd>labels</kbd>是来自<kbd>dataset</kbd>的地面真实数据。在<kbd>compute_loss</kbd>方法中，我们使用<kbd>tf.nn.sparse_softmax_cross_entropy_with_logits</kbd>，所以我们不需要用<kbd>softmax</kbd>方法来规范化<kbd>logits</kbd>。此外，我们不需要使<kbd>labels</kbd>成为一个热点向量。在<kbd>compute_accuracy</kbd>方法中，我们将<kbd>logits</kbd>中的最大值与<kbd>tf.argmax</kbd>进行比较，并将其与<kbd>labels</kbd>进行比较，以获得<kbd>accuracy</kbd>。</p>
<p>接下来，我们将定义<kbd>learning_rate</kbd>和<kbd>optimizer</kbd>的操作:</p>
<pre style="padding-left: 60px"> def get_learning_rate(global_step, initial_value, decay_steps,          
   decay_rate): 
   learning_rate = tf.train.exponential_decay(initial_value,   
   global_step, decay_steps, decay_rate, staircase=True) 
   return learning_rate 
 
 
 def train(total_loss, learning_rate, global_step, train_vars): 
 
   optimizer = tf.train.AdamOptimizer(learning_rate) 
 
   train_variables = train_vars.split(",") 
 
   grads = optimizer.compute_gradients( 
       total_loss, 
       [v for v in tf.trainable_variables() if v.name in   
       train_variables] 
       ) 
   train_op = optimizer.apply_gradients(grads,   
   global_step=global_step) 
   return train_op </pre>
<p>在<kbd>train</kbd>方法中，我们仅将<kbd>optimizer</kbd>配置为<kbd>compute</kbd>，并将<kbd>gradients</kbd>应用于<kbd>train_vars</kbd>字符串中定义的一些变量。这允许我们只更新最后一层<kbd>fc8</kbd>的<kbd>weights</kbd>和<kbd>biases</kbd>，并冻结其他层。<kbd>train_vars</kbd>是包含由逗号分隔的变量列表的字符串，例如<kbd>models/fc8-pets/weights:0,models/fc8-pets/biases:0</kbd>。</p>


            

            
        
    






    
        <title>Performing the training process</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">执行培训流程</h1>
                
            
            
                
<p>现在我们准备训练模型。让我们在<kbd>scripts</kbd>文件夹中创建一个名为<kbd>train.py</kbd>的Python文件。首先，我们需要为<kbd>training</kbd>例程定义一些参数:</p>
<pre style="padding-left: 60px"> import tensorflow as tf 
 import os 
 from datetime import datetime 
 from tqdm import tqdm 
 
 import nets, models, datasets 
 
 # Dataset 
 dataset_dir = "data/train_data" 
 batch_size = 64 
 image_size = 224 
 
 # Learning rate 
 initial_learning_rate = 0.001 
 decay_steps = 250 
 decay_rate = 0.9 
 
 # Validation 
 output_steps = 10  # Number of steps to print output 
 eval_steps = 20  # Number of steps to perform evaluations 
 
 # Training 
 max_steps = 3000  # Number of steps to perform training 
 save_steps = 200  # Number of steps to perform saving checkpoints 
 num_tests = 5  # Number of times to test for test accuracy 
 max_checkpoints_to_keep = 3 
 save_dir = "data/checkpoints" 
 train_vars = 'models/fc8-pets/weights:0,models/fc8-pets/biases:0' 
 
 # Export 
 export_dir = "/tmp/export/" 
 export_name = "pet-model" 
 export_version = 2 </pre>
<p>这些变量是不言自明的。接下来，我们需要为<kbd>training</kbd>定义一些操作，如下:</p>
<pre style="padding-left: 60px"> images, labels = datasets.input_pipeline(dataset_dir, batch_size,   <br/> is_training=True) 
 test_images, test_labels = datasets.input_pipeline(dataset_dir,  <br/> batch_size, is_training=False) 
 
 with tf.variable_scope("models") as scope: 
    logits = nets.inference(images, is_training=True) 
    scope.reuse_variables() 
    test_logits = nets.inference(test_images, is_training=False) 
 
 total_loss = models.compute_loss(logits, labels) 
 train_accuracy = models.compute_accuracy(logits, labels) 
 test_accuracy = models.compute_accuracy(test_logits, test_labels) 
  
 global_step = tf.Variable(0, trainable=False) 
 learning_rate = models.get_learning_rate(global_step,  <br/> initial_learning_rate, decay_steps, decay_rate) 
 train_op = models.train(total_loss, learning_rate, global_step,  <br/> train_vars) 
 
 saver = tf.train.Saver(max_to_keep=max_checkpoints_to_keep) 
 checkpoints_dir = os.path.join(save_dir,  <br/> datetime.now().strftime("%Y-%m-%d_%H-%M-%S")) 
 if not os.path.exists(save_dir): 
    os.mkdir(save_dir) 
 if not os.path.exists(checkpoints_dir): 
    os.mkdir(checkpoints_dir) </pre>
<p>这些操作是通过调用我们在<kbd>datasets.py</kbd>、<kbd>nets.py</kbd>和<kbd>models.py</kbd>中定义的方法创建的。在这段代码中，我们创建了一个用于训练的输入管道和另一个用于测试的管道。之后，我们创建一个名为<kbd>models</kbd>的新<kbd>variable_scope</kbd>，并用<kbd>nets.inference</kbd>方法创建<kbd>logits</kbd>和<kbd>test_logits</kbd>。您必须确保添加了<kbd>scope.reuse_variables</kbd>，因为我们想在测试培训中重用<kbd>weights</kbd>和<kbd>biases</kbd>。最后，我们创建一个<kbd>saver</kbd>和一些目录来保存每个<kbd>save_steps</kbd>的检查点。</p>
<p><kbd>training</kbd>程序的最后一部分是<kbd>training</kbd>循环:</p>
<pre style="padding-left: 60px"> with tf.Session() as sess: 
    sess.run(tf.global_variables_initializer()) 
    coords = tf.train.Coordinator() 
    threads = tf.train.start_queue_runners(sess=sess, coord=coords) 
 
    with tf.variable_scope("models"): 
       nets.load_caffe_weights("data/VGG16.npz", sess,  <br/>       ignore_missing=True) 
 
    last_saved_test_accuracy = 0 
    for i in tqdm(range(max_steps), desc="training"): 
                  _, loss_value, lr_value = sess.run([train_op,    <br/>                  total_loss,  learning_rate]) 
 
      if (i + 1) % output_steps == 0: 
          print("Steps {}: Loss = {:.5f} Learning Rate =  <br/>          {}".format(i + 1, loss_value, lr_value)) 
 
      if (i + 1) % eval_steps == 0: 
          test_acc, train_acc, loss_value =  <br/>          sess.run([test_accuracy, train_accuracy, total_loss]) 
          print("Test accuracy {} Train accuracy {} : Loss =  <br/>          {:.5f}".format(test_acc, train_acc, loss_value)) 
 
      if (i + 1) % save_steps == 0 or i == max_steps - 1: 
          test_acc = 0 
          for i in range(num_tests): 
              test_acc += sess.run(test_accuracy) 
          test_acc /= num_tests 
      if test_acc &gt; last_saved_test_accuracy: 
            print("Save steps: Test Accuracy {} is higher than  <br/>            {}".format(test_acc, last_saved_test_accuracy)) 
             last_saved_test_accuracy = test_acc 
             saved_file = saver.save(sess, 
                                         <br/>     os.path.join(checkpoints_dir, 'model.ckpt'), 
                  global_step=global_step) 
          print("Save steps: Save to file %s " % saved_file) 
      else: 
          print("Save steps: Test Accuracy {} is not higher  <br/>                than {}".format(test_acc, last_saved_test_accuracy)) 
 
    models.export_model(checkpoints_dir, export_dir, export_name,  <br/>    export_version) 
 
    coords.request_stop() 
    coords.join(threads) </pre>
<p><kbd>training</kbd>循环很容易理解。首先，我们加载预训练的<kbd>VGG16</kbd>模型，其中<kbd>ignore_missing</kbd>设置为<kbd>True</kbd>，因为我们之前替换了<kbd>fc8</kbd>层的名称。然后，我们循环执行<kbd>max_steps</kbd>步骤，每<kbd>output_steps</kbd>打印一次<kbd>loss</kbd>，每<kbd>eval_steps</kbd>打印一次<kbd>test_accuracy</kbd>。每次<kbd>save_steps</kbd>，如果当前测试精度高于之前，我们都会检查并保存检查点。我们仍然需要创建<kbd>models.export_model</kbd>来导出在<kbd>training</kbd>之后服务的模型。但是，您可能希望在继续之前检查<kbd>training</kbd>程序是否工作。让我们注释掉下面一行:</p>
<pre>    models.export_model(checkpoints_dir, export_dir, export_name,  <br/>    export_version) </pre>
<p>然后，使用以下命令运行<kbd>training</kbd>脚本:</p>
<pre><strong>python scripts/train.py</strong></pre>
<p>这里是控制台中的一些输出。首先，我们的脚本加载预先训练好的模型。然后，它将输出<kbd>loss</kbd>:</p>
<pre><strong>('Load caffe weights from ', 'data/VGG16.npz')</strong>
<strong>training:   0%|▏                | 9/3000 [00:05&lt;24:59,  1.99it/s]</strong>
<strong>Steps 10: Loss = 31.10747 Learning Rate = 0.0010000000475</strong>
<strong>training:   1%|▎                | 19/3000 [00:09&lt;19:19,  2.57it/s]</strong>
<strong>Steps 20: Loss = 34.43741 Learning Rate = 0.0010000000475</strong>
<strong>Test accuracy 0.296875 Train accuracy 0.0 : Loss = 31.28600</strong>
<strong>training:   1%|▍                | 29/3000 [00:14&lt;20:01,  2.47it/s]</strong>
<strong>Steps 30: Loss = 15.81103 Learning Rate = 0.0010000000475</strong>
<strong>training:   1%|▌                | 39/3000 [00:18&lt;19:42,  2.50it/s]</strong>
<strong>Steps 40: Loss = 14.07709 Learning Rate = 0.0010000000475</strong>
<strong>Test accuracy 0.53125 Train accuracy 0.03125 : Loss = 20.65380</strong>  </pre>
<p>现在，让我们停止<kbd>training</kbd>并取消对<kbd>export_model</kbd>方法的注释。我们需要<kbd>models.export_model</kbd>方法将测试精度最高的最新模型导出到<kbd>export_dir</kbd>文件夹中，名称为<kbd>export_name</kbd>，版本为<kbd>export_version</kbd>。</p>


            

            
        
    






    
        <title>Exporting the model for production</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">为生产导出模型</h1>
                
            
            
                
<pre style="padding-left: 60px"> def export_model(checkpoint_dir, export_dir, export_name,  <br/> export_version): 
    graph = tf.Graph() 
    with graph.as_default(): 
        image = tf.placeholder(tf.float32, shape=[None, None, 3]) 
        processed_image = datasets.preprocessing(image,  <br/>        is_training=False) 
        with tf.variable_scope("models"): 
         logits = nets.inference(images=processed_image,  <br/>          is_training=False) 
 
        model_checkpoint_path =  <br/>        get_model_path_from_ckpt(checkpoint_dir) 
        saver = tf.train.Saver() 
 
        config = tf.ConfigProto() 
        config.gpu_options.allow_growth = True 
        config.gpu_options.per_process_gpu_memory_fraction = 0.7 
 
        with tf.Session(graph=graph) as sess: 
            saver.restore(sess, model_checkpoint_path) 
            export_path = os.path.join(export_dir, export_name,  <br/>            str(export_version)) 
            export_saved_model(sess, export_path, image, logits) 
            print("Exported model at", export_path)</pre>
<p>在<kbd>export_model</kbd>方法中，我们需要创建一个新的图形在生产中运行。在生产中，我们不需要所有的变量，就像在<kbd>training</kbd>中一样，我们也不需要输入管道。然而，我们需要用<kbd>export_saved_model</kbd>方法导出模型，如下所示:</p>
<pre style="padding-left: 60px"> def export_saved_model(sess, export_path, input_tensor,  <br/> output_tensor): 
    from tensorflow.python.saved_model import builder as  <br/> saved_model_builder 
    from tensorflow.python.saved_model import signature_constants 
    from tensorflow.python.saved_model import signature_def_utils 
    from tensorflow.python.saved_model import tag_constants 
    from tensorflow.python.saved_model import utils 
    builder = saved_model_builder.SavedModelBuilder(export_path) 
 
    prediction_signature = signature_def_utils.build_signature_def( 
        inputs={'images': utils.build_tensor_info(input_tensor)}, 
        outputs={ 
            'scores': utils.build_tensor_info(output_tensor) 
        }, 
        method_name=signature_constants.PREDICT_METHOD_NAME) 
 
    legacy_init_op = tf.group( 
        tf.tables_initializer(), name='legacy_init_op') 
    builder.add_meta_graph_and_variables( 
        sess, [tag_constants.SERVING], 
        signature_def_map={ 
          'predict_images': 
           prediction_signature, 
        }, 
        legacy_init_op=legacy_init_op) 
 
    builder.save() </pre>
<p>使用这种方法，我们可以创建模型的元图，用于生产。我们将在后面的章节中讨论如何服务于这个模型。现在，让我们运行<kbd>scripts</kbd>在3000步后自动训练和输出:</p>
<pre><strong>python scripts/train.py</strong></pre>
<p>在我们的系统上，使用Core i7-4790 CPU和一个TITAN-X GPU，训练程序需要20分钟才能完成。以下是我们控制台中的一些最后输出:</p>
<pre><strong>Steps 3000: Loss = 0.59160 Learning Rate = 0.000313810509397</strong>
<strong>Test accuracy 0.659375 Train accuracy 0.853125: Loss = 0.25782</strong>
<strong>Save steps: Test Accuracy 0.859375 is not higher than 0.921875</strong>
<strong>training: 100%|██████████████████| 3000/3000 [23:40&lt;00:00,  1.27it/s]</strong>
    <strong>I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:01:00.0)</strong>
    <strong>('Exported model at', '/home/ubuntu/models/pet-model/1')</strong></pre>
<p>太好了！我们有一个测试准确率为92.18%的模型。我们也有导出的模型作为一个<kbd>.pb</kbd>文件。<kbd>export_dir</kbd>文件夹将具有以下结构:</p>
<pre><strong>- /home/ubuntu/models/</strong>
<strong>-- pet_model</strong>
<strong>---- 1</strong>
<strong>------ saved_model.pb</strong>
<strong>------ variables</strong></pre>


            

            
        
    






    
        <title>Serving the model in production</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">为生产中的模型服务</h1>
                
            
            
                
<p>在生产中，我们需要创建一个端点，这样我们的用户就可以发送图像并接收结果。在TensorFlow中，我们可以很容易地使用TensorFlow服务来服务我们的模型。在本节中，我们将安装TensorFlow服务并创建一个Flask应用程序，允许用户通过web界面上传他们的图像。</p>


            

            
        
    






    
        <title>Setting up TensorFlow Serving</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">设置TensorFlow服务</h1>
                
            
            
                
<p>在您的生产服务器中，您需要安装TensorFlow服务器及其先决条件。可以访问在<a href="https://tensorflow.github.io/serving/setup">https://tensorflow.github.io/serving/setup</a>任职的TensorFlow官网。接下来，我们将使用TensorFlow Serving中提供的标准TensorFlow模型服务器来为模型提供服务。首先，我们需要用下面的命令构建<kbd>tensorflow_model_server</kbd>:</p>
<pre><strong>bazel build   <br/>//tensorflow_serving/model_servers:tensorflow_model_server</strong></pre>
<p>将培训服务器中的所有文件从<kbd>/home/ubuntu/models/pet_model</kbd>复制到生产服务器中。在我们的设置中，我们选择<kbd>/home/ubuntu/productions</kbd>作为文件夹来存储所有的生产模型。<kbd>productions</kbd>文件夹将具有以下结构:</p>
<pre><strong>- /home/ubuntu/productions/</strong>
<strong>-- 1</strong>
<strong>---- saved_model.pb</strong>
<strong>---- variables</strong></pre>
<p>我们将使用<kbd>tmux</kbd>来保持模型服务器的运行。让我们用这个命令安装<kbd>tmux</kbd>:</p>
<pre><strong>sudo apt-get install tmux</strong></pre>
<p>使用以下命令运行一个<kbd>tmux</kbd>会话:</p>
<pre><strong>tmux new -s serving</strong></pre>
<p>在<kbd>tmux</kbd>会话中，让我们将目录更改为<kbd>tensorflow_serving</kbd>目录，并运行以下命令:</p>
<pre>    <strong>bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=pet-model --model_base_path=/home/ubuntu/productions</strong></pre>
<p>控制台的输出应该如下所示:</p>
<pre>    <strong>2017-05-29 13:44:32.203153: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:274] Loading SavedModel: success. Took 537318 microseconds.</strong>
    <strong>2017-05-29 13:44:32.203243: I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version {name: pet-model version: 1}</strong>
    <strong>2017-05-29 13:44:32.205543: I tensorflow_serving/model_servers/main.cc:298] Running ModelServer at 0.0.0.0:9000 ...</strong>  </pre>
<p>如您所见，该模型正在主机<kbd>0.0.0.0</kbd>和端口<kbd>9000</kbd>上运行。在下一节中，我们将创建一个简单的Python客户机，通过gRPC向这个服务器发送图像。</p>
<p>您还应该注意到，当前服务只使用生产服务器上的CPU。使用GPU构建TensorFlow服务超出了本章的范围。如果您更喜欢使用GPU服务，您可能希望阅读<a href="8022db02-d24f-4620-9da7-ae53df279306.xhtml">附录A </a> <a href="8022db02-d24f-4620-9da7-ae53df279306.xhtml"/> <em> <a href="8022db02-d24f-4620-9da7-ae53df279306.xhtml"/>，高级安装</em>，其中解释了如何在GPU支持下构建TensorFlow和TensorFlow服务。</p>


            

            
        
    






    
        <title>Running and testing the model</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">运行和测试模型</h1>
                
            
            
                
<p>在项目存储库中，我们已经提供了一个名为<kbd>production</kbd>的包。在这个包中，我们需要将<kbd>labels.txt</kbd>文件复制到我们的<kbd>dataset</kbd>中，创建一个新的Python文件<kbd>client.py</kbd>，并添加以下代码:</p>
<pre>    import tensorflow as tf 
    import numpy as np 
    from tensorflow_serving.apis import prediction_service_pb2,     
    predict_pb2 
    from grpc.beta import implementations 
    from scipy.misc import imread 
    from datetime import datetime 
 
 
    class Output: 
    def __init__(self, score, label): 
        self.score = score 
        self.label = label 
 
    def __repr__(self): 
        return "Label: %s Score: %.2f" % (self.label, self.score) 
 
 
    def softmax(x): 
    return np.exp(x) / np.sum(np.exp(x), axis=0) 
 
 
    def process_image(path, label_data, top_k=3): 
    start_time = datetime.now() 
    img = imread(path) 
 
    host, port = "0.0.0.0:9000".split(":") 
    channel = implementations.insecure_channel(host, int(port)) 
    stub =  
    prediction_service_pb2.beta_create_PredictionService_stub(channel) 
 
    request = predict_pb2.PredictRequest() 
    request.model_spec.name = "pet-model" 
    request.model_spec.signature_name = "predict_images" 
 
    request.inputs["images"].CopyFrom( 
        tf.contrib.util.make_tensor_proto( 
            img.astype(dtype=float), 
            shape=img.shape, dtype=tf.float32 
        ) 
    ) 
 
    result = stub.Predict(request, 20.) 
    scores =    
    tf.contrib.util.make_ndarray(result.outputs["scores"])[0] 
    probs = softmax(scores) 
    index = sorted(range(len(probs)), key=lambda x: probs[x],  
    reverse=True) 
 
    outputs = [] 
    for i in range(top_k): 
        outputs.append(Output(score=float(probs[index[i]]),  
        label=label_data[index[i]])) 
 
    print(outputs) 
    print("total time", (datetime.now() -   
    start_time).total_seconds()) 
    return outputs 
 
    if __name__ == "__main__": 
    label_data = [line.strip() for line in   
    open("production/labels.txt", 'r')] 
    process_image("samples_data/dog.jpg", label_data) 
    process_image("samples_data/cat.jpg", label_data) </pre>
<p>在这段代码中，我们创建了一个<kbd>process_image</kbd>方法，它将从图像路径中读取图像，并使用一些TensorFlow方法创建一个张量，然后用gRPC将其发送到模型服务器。我们还创建了一个<kbd>Output</kbd>类，这样我们就可以轻松地将它返回给<kbd>caller</kbd>方法。在方法的最后，我们打印输出和总时间，这样我们可以更容易地调试它。我们可以运行这个Python文件来看看<kbd>process_image</kbd>是否工作:</p>
<pre><strong>python production/client.py</strong></pre>
<p>输出应该如下所示:</p>
<pre>    <strong>[Label: saint_bernard Score: 0.78, Label: american_bulldog Score: 0.21, Label: staffordshire_bull_terrier Score: 0.00]</strong>
    <strong>('total time', 14.943942)</strong>
    <strong>[Label: Maine_Coon Score: 1.00, Label: Ragdoll Score: 0.00, Label: Bengal Score: 0.00]</strong>
    <strong>('total time', 14.918235)</strong></pre>
<p>我们得到正确的结果。然而，处理每幅图像的时间几乎是15秒。原因是我们使用的是CPU模式的TensorFlow服务。如前所述，你可以在<a href="8022db02-d24f-4620-9da7-ae53df279306.xhtml">附录A </a>、<a href="8022db02-d24f-4620-9da7-ae53df279306.xhtml"/>、<em>高级安装</em>中构建有GPU支持的TensorFlow服务。如果您遵循该教程，您将获得以下结果:</p>
<pre>    <strong>[Label: saint_bernard Score: 0.78, Label: american_bulldog Score: 0.21, Label: staffordshire_bull_terrier Score: 0.00]</strong>
    <strong>('total time', 0.493618)</strong>
    <strong>[Label: Maine_Coon Score: 1.00, Label: Ragdoll Score: 0.00, Label: Bengal Score: 0.00]</strong>
    <strong>('total time', 0.023753)</strong></pre>
<p>在第一次调用时间中处理的时间是493 ms。然而，后面的调用时间将只有大约23 ms，这比CPU版本快得多。</p>


            

            
        
    






    
        <title>Designing the web server</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">设计web服务器</h1>
                
            
            
                
<p>在本节中，我们将设置一个Flask服务器，允许用户上传他们的图像，并在我们的模型出错时设置正确的标签。我们已经提供了生产包中所需的代码。实现带数据库支持的Flask服务器超出了本章的范围。在这一节中，我们将描述有关Flask的所有要点，以便您能够更好地理解。</p>
<p>允许用户上传和修改标签的主要流程可以在下面的线框中描述。</p>
<p>该流程通过以下路径实现:</p>
<table class="MsoTableGrid">
<tbody>
<tr>
<td>
<p><strong>路线</strong></p>
</td>
<td>
<p><strong>方法</strong></p>
</td>
<td>
<p><strong>描述</strong></p>
</td>
</tr>
<tr>
<td>
<p><kbd>/</kbd></p>
</td>
<td>
<p>得到</p>
</td>
<td>
<p>该路径返回一个web表单，供用户上传图像。</p>
</td>
</tr>
<tr>
<td>
<p><kbd>/upload_image</kbd></p>
</td>
<td>
<p>邮政</p>
</td>
<td>
<p>这个路径从POST数据中获取图像，保存到上传目录，并调用我们的<kbd>client.py</kbd>中的<kbd>process_image</kbd>来识别图像并将结果保存到数据库。</p>
</td>
</tr>
<tr>
<td>
<p><kbd>/results&lt;result_id&gt;</kbd></p>
</td>
<td>
<p>得到</p>
</td>
<td>
<p>该路径返回数据库中相应行的结果。</p>
</td>
</tr>
<tr>
<td>
<p><kbd>/results&lt;result_id&gt;</kbd></p>
</td>
<td>
<p>邮政</p>
</td>
<td>
<p>这条路线将标签从用户保存到数据库，以便我们可以在以后对模型进行微调。</p>
</td>
</tr>
<tr>
<td>
<p><kbd>/user-labels</kbd></p>
</td>
<td>
<p>得到</p>
</td>
<td>
<p>此路由返回所有用户标记图像的列表。在微调过程中，我们将调用这个路由来获取标记图像的列表。</p>
</td>
</tr>
<tr>
<td>
<p><kbd>/model</kbd></p>
</td>
<td>
<p>邮政</p>
</td>
<td>
<p>该路线允许来自训练服务器的微调过程服务于新的训练模型。该路由接收压缩模型的链接、版本号、检查点名称和模型名称。</p>
</td>
</tr>
<tr>
<td>
<p><kbd>/model</kbd></p>
</td>
<td>
<p>得到</p>
</td>
<td>
<p>该路径返回数据库中的最新模型。微调过程会调用这个来知道哪个是最新的型号，并从中进行微调。</p>
</td>
</tr>
</tbody>
</table>
<p>我们应该用下面的命令在一个<kbd>tmux</kbd>会话中运行这个服务器:</p>
<pre><strong>tmux new -s "flask"</strong>
<strong>python production/server.py</strong></pre>


            

            
        
    






    
        <title>Testing the system</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">测试系统</h1>
                
            
            
                
<p>现在，我们可以通过<kbd>http://0.0.0.0:5000</kbd>访问服务器。</p>
<p>首先，您将看到一个选择和提交图像的表单。</p>
<p>网站将被重定向到带有相应图像及其结果的<kbd>/results</kbd>页面。用户标签字段为空。最后还有一个简短的表格，以便您可以提交模型的正确标签。</p>


            

            
        
    






    
        <title>Automatic fine-tune in production</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">生产中的自动微调</h1>
                
            
            
                
<p>在运行系统一段时间后，我们会有一些用户标记的图像。我们将创建一个每天自动运行的微调流程，并使用新数据对最新模型进行微调。</p>
<p>让我们在脚本文件夹中创建一个名为<kbd>finetune.py</kbd>的文件。</p>


            

            
        
    






    
        <title>Loading the user-labeled data</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">加载用户标记的数据</h1>
                
            
            
                
<p>首先，我们将添加代码，从生产服务器下载所有用户标记的图像:</p>
<pre>    import tensorflow as tf 
    import os 
    import json 
    import random 
    import requests 
    import shutil 
    from scipy.misc import imread, imsave 
    from datetime import datetime 
    from tqdm import tqdm 
 
    import nets, models, datasets 
 
 
    def ensure_folder_exists(folder_path): 
    if not os.path.exists(folder_path): 
        os.mkdir(folder_path) 
    return folder_path 
 
 
    def download_user_data(url, user_dir, train_ratio=0.8): 
    response = requests.get("%s/user-labels" % url) 
    data = json.loads(response.text) 
 
    if not os.path.exists(user_dir): 
        os.mkdir(user_dir) 
    user_dir = ensure_folder_exists(user_dir) 
    train_folder = ensure_folder_exists(os.path.join(user_dir,   
    "trainval")) 
    test_folder = ensure_folder_exists(os.path.join(user_dir,   
    "test")) 
 
    train_file = open(os.path.join(user_dir, 'trainval.txt'), 'w') 
    test_file = open(os.path.join(user_dir, 'test.txt'), 'w') 
 
    for image in data: 
        is_train = random.random() &lt; train_ratio 
        image_url = image["url"] 
        file_name = image_url.split("/")[-1] 
        label = image["label"] 
        name = image["name"] 
 
        if is_train: 
          target_folder =  
          ensure_folder_exists(os.path.join(train_folder, name)) 
        else: 
          target_folder =   
          ensure_folder_exists(os.path.join(test_folder, name)) 
 
        target_file = os.path.join(target_folder, file_name) +   
        ".jpg" 
 
        if not os.path.exists(target_file): 
            response = requests.get("%s%s" % (url, image_url)) 
            temp_file_path = "/tmp/%s" % file_name 
            with open(temp_file_path, 'wb') as f: 
                for chunk in response: 
                    f.write(chunk) 
 
            image = imread(temp_file_path) 
            imsave(target_file, image) 
            os.remove(temp_file_path) 
            print("Save file: %s" % target_file) 
 
        label_path = "%s %s\n" % (label, target_file) 
        if is_train: 
            train_file.write(label_path) 
        else: 
            test_file.write(label_path) </pre>
<p>在<kbd>download_user_data</kbd>中，我们调用<kbd>/user-labels</kbd>端点来获取用户标记图像的列表。JSON具有以下格式:</p>
<pre>   [ 
    { 
     "id": 1,  
     "label": 0,  
     "name": "Abyssinian",  
     "url": "/uploads/2017-05-23_14-56-45_Abyssinian-cat.jpeg" 
    },  
    { 
     "id": 2,  
      "label": 32,  
      "name": "Siamese",  
     "url": "/uploads/2017-05-23_14-57-33_fat-Siamese-cat.jpeg" 
    } 
   ] </pre>
<p>在这个JSON中，<kbd>label</kbd>是用户选择的标签，URL是下载图片的链接。对于每张图像，我们将把它下载到<kbd>tmp</kbd>文件夹中，并使用<kbd>scipy</kbd>中的<kbd>imread</kbd>和<kbd>imsave</kbd>来确保图像是JPEG格式。我们还创建了一个<kbd>trainval.txt</kbd>和<kbd>test.txt</kbd>文件，就像在训练数据集中一样。</p>


            

            
        
    






    
        <title>Performing a fine-tune on the model</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">对模型进行微调</h1>
                
            
            
                
<p>为了对模型进行微调，我们需要知道哪个是最新的模型及其对应的检查点来恢复<kbd>weights</kbd>和<kbd>biases</kbd>。因此，我们调用<kbd>/model</kbd>端点来获取检查点名称和版本号:</p>
<pre>    def get_latest_model(url): 
    response = requests.get("%s/model" % url) 
    data = json.loads(response.text) 
    print(data) 
    return data["ckpt_name"], int(data["version"]) </pre>
<p>JSON的响应应该如下所示:</p>
<pre>    { 
     "ckpt_name": "2017-05-26_02-12-49",  
     "id": 10,  
     "link": "http://1.53.110.161:8181/pet-model/8.zip",  
     "name": "pet-model",  
     "version": 8 
    } </pre>
<p>现在，我们将实现代码来微调模型。让我们从一些参数开始:</p>
<pre>    # Server info 
    URL = "http://localhost:5000" 
    dest_api = URL + "/model" 
 
    # Server Endpoints 
    source_api = "http://1.53.110.161:8181" 
 
    # Dataset 
    dataset_dir = "data/train_data" 
    user_dir = "data/user_data" 
    batch_size = 64 
    image_size = 224 
 
    # Learning rate 
    initial_learning_rate = 0.0001 
    decay_steps = 250 
    decay_rate = 0.9 
 
    # Validation 
    output_steps = 10  # Number of steps to print output 
    eval_steps = 20  # Number of steps to perform evaluations 
 
    # Training 
    max_steps = 3000  # Number of steps to perform training 
    save_steps = 200  # Number of steps to perform saving    
    checkpoints 
    num_tests = 5  # Number of times to test for test accuracy 
    max_checkpoints_to_keep = 1 
    save_dir = "data/checkpoints" 
    train_vars = 'models/fc8-pets/weights:0,models/fc8- 
    pets/biases:0' 
 
    # Get the latest model 
    last_checkpoint_name, last_version = get_latest_model(URL) 
    last_checkpoint_dir = os.path.join(save_dir,   
    last_checkpoint_name) 
 
    # Export 
    export_dir = "/home/ubuntu/models/" 
    export_name = "pet-model" 
    export_version = last_version + 1 </pre>
<p>然后，我们将实现微调循环。在下面的代码中，我们调用<kbd>download_user_data</kbd>来下载所有用户标记的图像，并将<kbd>user_dir</kbd>传递给<kbd>input_pipeline</kbd>，这样它将加载新的图像:</p>
<pre>    # Download user-labels data 
    download_user_data(URL, user_dir) 
 
    images, labels = datasets.input_pipeline(dataset_dir,     
    batch_size, is_training=True, user_dir=user_dir) 
    test_images, test_labels =    
    datasets.input_pipeline(dataset_dir, batch_size,    
    is_training=False, user_dir=user_dir) 
 
     with tf.variable_scope("models") as scope: 
     logits = nets.inference(images, is_training=True) 
     scope.reuse_variables() 
     test_logits = nets.inference(test_images, is_training=False) 
 
    total_loss = models.compute_loss(logits, labels) 
    train_accuracy = models.compute_accuracy(logits, labels) 
    test_accuracy = models.compute_accuracy(test_logits,  
    test_labels) 
 
    global_step = tf.Variable(0, trainable=False) 
    learning_rate = models.get_learning_rate(global_step,      
    initial_learning_rate, decay_steps, decay_rate) 
    train_op = models.train(total_loss, learning_rate,  
    global_step, train_vars) 
 
    saver = tf.train.Saver(max_to_keep=max_checkpoints_to_keep) 
    checkpoint_name = datetime.now().strftime("%Y-%m-%d_%H-%M-%S") 
    checkpoints_dir = os.path.join(save_dir, checkpoint_name) 
    if not os.path.exists(save_dir): 
      os.mkdir(save_dir) 
    if not os.path.exists(checkpoints_dir): 
      os.mkdir(checkpoints_dir) 
 
    with tf.Session() as sess: 
      sess.run(tf.global_variables_initializer()) 
      coords = tf.train.Coordinator() 
      threads = tf.train.start_queue_runners(sess=sess,   
      coord=coords) 
 
    saver.restore(sess,  
    models.get_model_path_from_ckpt(last_checkpoint_dir)) 
    sess.run(global_step.assign(0)) 
 
    last_saved_test_accuracy = 0 
    for i in range(num_tests): 
        last_saved_test_accuracy += sess.run(test_accuracy) 
    last_saved_test_accuracy /= num_tests 
    should_export = False 
    print("Last model test accuracy    
    {}".format(last_saved_test_accuracy)) 
    for i in tqdm(range(max_steps), desc="training"): 
        _, loss_value, lr_value = sess.run([train_op, total_loss,   
        learning_rate]) 
 
     if (i + 1) % output_steps == 0: 
       print("Steps {}: Loss = {:.5f} Learning Rate =   
       {}".format(i + 1, loss_value, lr_value)) 
 
        if (i + 1) % eval_steps == 0: 
          test_acc, train_acc, loss_value =  
          sess.run([test_accuracy, train_accuracy, total_loss]) 
            print("Test accuracy {} Train accuracy {} : Loss =  
            {:.5f}".format(test_acc, train_acc, loss_value)) 
 
        if (i + 1) % save_steps == 0 or i == max_steps - 1: 
          test_acc = 0 
          for i in range(num_tests): 
            test_acc += sess.run(test_accuracy) 
            test_acc /= num_tests 
 
        if test_acc &gt; last_saved_test_accuracy: 
          print("Save steps: Test Accuracy {} is higher than  
          {}".format(test_acc, last_saved_test_accuracy)) 
          last_saved_test_accuracy = test_acc 
          saved_file = saver.save(sess, 
                                      
        os.path.join(checkpoints_dir, 'model.ckpt'), 
                                        global_step=global_step) 
                should_export = True 
                print("Save steps: Save to file %s " % saved_file) 
            else: 
                print("Save steps: Test Accuracy {} is not higher  
       than {}".format(test_acc, last_saved_test_accuracy)) 
 
    if should_export: 
        print("Export model with accuracy ",  
        last_saved_test_accuracy) 
        models.export_model(checkpoints_dir, export_dir,   
        export_name, export_version) 
        archive_and_send_file(source_api, dest_api,  
        checkpoint_name, export_dir, export_name, export_version) 
      coords.request_stop() 
      coords.join(threads)</pre>
<p>其他部分与训练循环非常相似。然而，我们没有从<kbd>caffe</kbd>模型中加载权重，而是使用最新模型的检查点，并运行几次测试来获得其测试精度。</p>
<p>在微调循环的最后，我们需要一个名为<kbd>archive_and_send_file</kbd>的新方法来从<kbd>exported</kbd>模型创建一个档案，并将链接发送到生产服务器:</p>
<pre>    def make_archive(dir_path): 
    return shutil.make_archive(dir_path, 'zip', dir_path) 
 
 
    def archive_and_send_file(source_api, dest_api, ckpt_name,    
    export_dir, export_name, export_version): 
    model_dir = os.path.join(export_dir, export_name,    
    str(export_version)) 
    file_path = make_archive(model_dir) 
    print("Zip model: ", file_path) 
 
    data = { 
        "link": "{}/{}/{}".format(source_api, export_name,  
     str(export_version) + ".zip"), 
        "ckpt_name": ckpt_name, 
        "version": export_version, 
        "name": export_name, 
    } 
     r = requests.post(dest_api, data=data) 
    print("send_file", r.text) </pre>
<p>您应该注意到，我们创建了一个带有<kbd>source_api</kbd>参数的链接，它是到培训服务器<kbd>http://1.53.110.161:8181</kbd>的链接。我们将建立一个简单的Apache服务器来支持这个功能。然而，在现实中，我们建议您将存档的模型上传到云存储，如亚马逊S3。现在，我们将向您展示使用Apache的最简单方法。</p>
<p>我们需要使用以下命令安装Apache:</p>
<pre><strong>sudo apt-get install apache2</strong></pre>
<p>现在，在<kbd>/etc/apache2/ports.conf</kbd>的第6行，我们需要添加这段代码，让<kbd>apache2</kbd>监听端口<kbd>8181</kbd>:</p>
<pre>    Listen 8181 </pre>
<p>然后，在<kbd>/etc/apache2/sites-available/000-default.conf</kbd>的开头添加以下代码，以支持从<kbd>/home/ubuntu/models</kbd>目录下载:</p>
<pre>    &lt;VirtualHost *:8181&gt; 
      DocumentRoot "/home/ubuntu/models" 
      &lt;Directory /&gt; 
        Require all granted 
      &lt;/Directory&gt; 
    &lt;/VirtualHost&gt; </pre>
<p>最后，我们需要重启<kbd>apache2</kbd>服务器:</p>
<pre><strong>sudo service apache2 restart</strong></pre>
<p>到目前为止，我们已经设置了所有的代码来执行微调。在第一次运行微调之前，我们需要向<kbd>POST</kbd>端点发送一个带有第一个模型信息的<kbd>/model</kbd>请求，因为我们已经将模型复制到生产服务器。</p>
<p>在<kbd>project</kbd>存储库中，让我们运行<kbd>finetune</kbd>脚本:</p>
<pre><strong>python scripts/finetune.py</strong></pre>
<p>控制台中的最后几行如下所示:</p>
<pre>    <strong>Save steps: Test Accuracy 0.84 is higher than 0.916875</strong>
    <strong>Save steps: Save to file data/checkpoints/2017-05-29_18-46-43/model.ckpt-2000</strong>
    <strong>('Export model with accuracy ', 0.916875000000004)</strong>
    <strong>2017-05-29 18:47:31.642729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:01:00.0)</strong>
    <strong>('Exported model at', '/home/ubuntu/models/pet-model/2')</strong>
    <strong>('Zip model: ', '/home/ubuntu/models/pet-model/2.zip')</strong>
    <strong>('send_file', u'{\n  "ckpt_name": "2017-05-29_18-46-43", \n  "id": 2, \n  "link": "http://1.53.110.161:8181/pet-model/2.zip", \n  "name": "pet-model", \n  "version": 2\n}\n')</strong></pre>
<p>可以看到，新模型的测试准确率达到了91%。模型也被导出并存档到<kbd>/home/ubuntu/models/pet-model/2.zip</kbd>。该代码还调用<kbd>/model</kbd>端点来将链接发布到生产服务器。在生产服务器中的Flask应用程序的日志中，我们将获得以下结果:</p>
<pre><strong>('Start downloading', u'http://1.53.110.161:8181/pet-model/2.zip')</strong>
<strong>('Downloaded file at', u'/tmp/2.zip')</strong>
<strong>('Extracted at', u'/home/ubuntu/productions/2')</strong>
<strong>127.0.0.1 - - [29/May/2017 18:49:05] "POST /model HTTP/1.1" 200 -</strong></pre>
<p>这意味着我们的Flask app已经从培训服务器下载了<kbd>2.zip</kbd>文件，并将内容提取到了<kbd>/home/ubuntu/productions/2</kbd>。在针对TensorFlow服务的<kbd>tmux</kbd>会话中，您还将获得以下结果:</p>
<pre>    <strong>2017-05-29 18:49:06.234808: I tensorflow_serving/core/loader_harness.cc:86] Successfully loaded servable version {name: pet-model version: 2}</strong>
    <strong>2017-05-29 18:49:06.234840: I tensorflow_serving/core/loader_harness.cc:137] Quiescing servable version {name: pet-model version: 1}</strong>
    <strong>2017-05-29 18:49:06.234848: I tensorflow_serving/core/loader_harness.cc:144] Done quiescing servable version {name: pet-model version: 1}</strong>
    <strong>2017-05-29 18:49:06.234853: I tensorflow_serving/core/loader_harness.cc:119] Unloading servable version {name: pet-model version: 1}</strong>
    <strong>2017-05-29 18:49:06.240118: I ./tensorflow_serving/core/simple_loader.h:226] Calling MallocExtension_ReleaseToSystem() with 645327546</strong>
    <strong>2017-05-29 18:49:06.240155: I tensorflow_serving/core/loader_harness.cc:127] Done unloading servable version {name: pet-model version: 1}</strong></pre>
<p>该输出表明TensorFlow模型服务器已经成功加载了<kbd>pet-model</kbd>中的<kbd>version 2</kbd>并卸载了<kbd>version 1</kbd>。这也意味着我们已经服务了新的模型，它在训练服务器上被训练，并通过<kbd>/model</kbd>端点被发送到生产服务器。</p>


            

            
        
    






    
        <title>Setting up cronjob to run every day</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">设置cronjob每天运行</h1>
                
            
            
                
<p>最后，我们需要设置每天运行的微调，并自动将新模型上传到服务器。我们可以通过在培训服务器中创建一个<kbd>crontab</kbd>来轻松实现这一点。</p>
<p>首先，我们需要运行<kbd>crontab</kbd>命令:</p>
<pre><strong>crontab -e</strong></pre>
<p>然后，我们可以添加下面一行来定义我们希望<kbd>finetune.py</kbd>运行的时间:</p>
<pre><strong>0 3 * * * python /home/ubuntu/project/scripts/finetune.py</strong></pre>
<p>按照我们的定义，Python命令将在每天凌晨3点运行。</p>


            

            
        
    






    
        <title>Summary</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">摘要</h1>
                
            
            
                
<p>在这一章中，我们实现了一个完整的真实生产，从训练到服务于一个深度学习模型。我们还在Flask应用程序中创建了一个web界面，以便用户可以上传他们的图像并接收结果。我们的模型可以每天自动微调，以提高系统的质量。您可以考虑一些事情来改进整个系统:</p>
<ul>
<li>模型和检查点应该保存在云存储中。</li>
<li>Flask app和TensorFlow服务应该由另一个更好的流程管理系统来管理，比如Supervisor。</li>
<li>应该有一个web界面，以便团队可以批准用户选择的标签。我们不应该完全依赖用户来决定训练集。</li>
<li>TensorFlow服务应在GPU支持下构建，以实现最佳性能。</li>
</ul>


            

            
        
    


</body></html>