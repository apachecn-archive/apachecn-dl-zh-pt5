<html><head/><body><html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Learning More about GANs</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">了解更多关于gan的信息</h1>

                

            

            

                

<p>我们在<a href="b71eb1cb-af20-41ea-9e3d-26c7d0b956ba.xhtml">第八章</a>、<em>使用甘生成图像</em>中学习了什么是<strong>生成对抗网络</strong> ( <strong>甘</strong>)以及不同类型的甘如何用于生成图像。</p>

<p>在这一章中，我们将揭示各种有趣的不同类型的甘。我们已经知道GANs可以用来生成新的图像，但是我们无法控制它们生成的图像。例如，如果我们希望我们的GAN生成一个具有特定特征的人脸，我们如何将这一信息告诉GAN？我们不能，因为我们无法控制生成器生成的图像。</p>

<p>为了解决这个问题，我们使用了一种新的GAN，称为<strong>条件GAN </strong> ( <strong> CGAN </strong>)，我们可以通过指定想要生成的内容来调节生成器和鉴别器。我们将从理解如何使用cgan生成我们感兴趣的图像开始这一章，然后我们学习如何使用<strong> TensorFlow </strong>实现cgan。</p>

<p>然后我们了解了<strong> InfoGANs </strong>，它是CGAN的一个无监督版本。我们将了解什么是InfoGANs，它们与cgan有何不同，以及我们如何使用TensorFlow来实现它们以生成新图像。</p>

<p>然后，我们将学习<strong>周期GAN</strong>，这是一种非常有趣的GAN。他们试图学习从一个域中的图像分布到另一个域中的图像分布的映射。例如，为了将灰度图像转换为彩色图像，我们训练CycleGAN学习灰度图像和彩色图像之间的映射，这意味着它们学习从一个域映射到另一个域，最棒的是，与其他架构不同，它们甚至不需要配对的数据集。我们将详细调查他们究竟是如何学习这些映射及其架构的。我们将探讨如何实现CycleGAN将真实图片转换为绘画。</p>

<p>在本章的最后，我们将探索，<strong> StackGAN </strong>，它可以将文本描述转换为照片级的逼真图像。我们将通过深入了解StackGANs的架构细节来了解它是如何做到这一点的。</p>

<p>在本章中，我们将了解以下内容:</p>

<ul>

<li>条件甘斯</li>

<li>使用CGAN生成特定数字</li>

<li>InfoGAN</li>

<li>InfoGAN的架构</li>

<li>使用TensorFlow构建InfoGAN</li>

<li>CycleGAN</li>

<li>使用CycleGAN将图片转换为绘画</li>

<li>斯塔克根</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Conditional GANs</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">条件甘斯</h1>

                

            

            

                

<p>我们知道生成器通过学习真实的数据分布来生成新的图像，而鉴别器则考察生成器生成的图像是来自真实的数据分布还是虚假的数据分布。</p>

<p>然而，通过学习真实的数据分布，生成器具有生成新的和有趣的图像的能力。我们无法控制或影响生成器生成的图像。例如，假设我们的生成器正在生成人脸；我们如何告诉生成器生成一个具有某些特征的人脸，比如大眼睛和尖鼻子？</p>

<p>我们不能！因为我们无法控制生成器生成的图像。</p>

<p>为了克服这一点，我们引入了一种称为<strong> CGAN </strong>的GAN的小型变体，它对发生器和鉴别器都施加了一个条件。这个条件告诉GAN我们希望我们的生成器生成什么样的图像。因此，我们的两个组件——鉴别器和发生器——在这种情况下起作用。</p>

<p>让我们考虑一个简单的例子。假设我们正在使用CGAN和MNIST数据集生成手写数字。让我们假设我们更专注于生成数字7而不是其他数字。现在，我们需要将这个条件应用于我们的生成器和鉴别器。我们如何做到这一点？</p>

<p>生成器将噪声<img class="fm-editor-equation" src="img/c164d061-dcfa-4c77-abff-441ad9cd92c5.png" style="width:0.75em;height:0.92em;"/>作为输入，并生成图像。但是除了<img class="fm-editor-equation" src="img/c164d061-dcfa-4c77-abff-441ad9cd92c5.png" style="width:0.75em;height:0.92em;"/>，我们还传递了一个额外的输入<img class="fm-editor-equation" src="img/92bb425b-a16a-4c8a-a295-243ecfdb386b.png" style="width:0.67em;height:0.92em;"/>。这个<img class="fm-editor-equation" src="img/9f1aaca1-ad1d-4079-9a27-8f12401d51fe.png" style="width:0.67em;height:0.92em;"/>是一个一键编码的类标签。由于我们对生成数字7感兴趣，所以我们将第七个索引设置为1，并将所有其他索引设置为0，即[0，0，0，0，0，0，1，0，0]。</p>

<p>我们将潜在向量<img class="fm-editor-equation" src="img/35a24ed1-1817-4456-ae54-3ab000857bcc.png" style="width:0.75em;height:0.92em;"/>和独热编码条件变量<img class="fm-editor-equation" src="img/3e98a2ce-923e-448d-80f7-76f21f8c6df8.png" style="width:0.67em;height:0.92em;"/>连接起来，并将其作为输入传递给生成器。然后，生成器开始生成数字7。</p>

<p>鉴别器呢？我们知道鉴别器将图像<img class="fm-editor-equation" src="img/b867ddbc-f08c-4126-b54a-2141fa745659.png" style="width:0.92em;height:0.92em;"/>作为输入，并告诉我们该图像是真图像还是假图像。在CGAN中，我们希望鉴别器根据条件进行鉴别，这意味着它必须识别生成的图像是真数字7还是假数字7。因此，除了传递输入<img class="fm-editor-equation" src="img/e7df7672-8219-4515-8446-49fa00b78885.png" style="width:0.92em;height:0.92em;"/>，我们还通过串联<img class="fm-editor-equation" src="img/cb3b4dc9-80cf-4374-8cdb-a5e075850686.png" style="width:0.92em;height:0.92em;"/>和<img class="fm-editor-equation" src="img/3e98a2ce-923e-448d-80f7-76f21f8c6df8.png" style="width:0.67em;height:0.92em;"/>将条件变量<img class="fm-editor-equation" src="img/3e98a2ce-923e-448d-80f7-76f21f8c6df8.png" style="width:0.67em;height:0.92em;"/>传递给鉴别器。</p>

<p>如下图所示，我们将<img class="fm-editor-equation" src="img/c164d061-dcfa-4c77-abff-441ad9cd92c5.png" style="width:0.75em;height:0.92em;"/>和<img class="fm-editor-equation" src="img/0dbfa7ae-18cf-4ba0-ae28-ef771eadbecd.png" style="width:0.67em;height:0.92em;"/>传递给生成器:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-878 image-border" src="img/d46bd418-6cb7-416f-acb2-42e463616a17.png" style="width:32.50em;height:36.08em;"/></p>

<p class="CDPAlignLeft CDPAlign">发电机以<strong> <img class="fm-editor-equation" src="img/cd509d39-205f-4d4d-ad26-bc085d848f0b.png" style="width:0.67em;height:0.92em;"/> </strong>上的信息为条件。类似地，除了将真实和伪造的图像传递给鉴别器，我们还将<img class="fm-editor-equation" src="img/4fcaa738-2b08-4797-864f-5b47e6446731.png" style="width:0.67em;height:0.92em;"/>传递给鉴别器。因此，发生器产生数字7，鉴别器学会区分真7和假7。</p>

<p>我们刚刚学习了如何使用CGAN生成一个特定的数字，但是CGAN的应用并没有到此为止。假设我们需要生成一个具有特定宽度和高度的数字。我们也可以在<img class="fm-editor-equation" src="img/0dbfa7ae-18cf-4ba0-ae28-ef771eadbecd.png" style="width:0.67em;height:0.92em;"/>上施加这个条件，让GAN产生任何想要的图像。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Loss function of CGAN</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">CGAN的损失函数</h1>

                

            

            

                

<p>您可能已经注意到，我们的普通GAN和CGAN之间没有太大的区别，只是在CGAN中，我们连接了额外的输入，即调理变量<img class="fm-editor-equation" src="img/083cafd3-8748-4a75-9744-7cdf44eee8c4.png" style="width:0.67em;height:0.92em;"/>与发生器和鉴频器的输入。因此，发生器和鉴频器的损耗函数与普通GAN相同，只是它以<img class="fm-editor-equation" src="img/083cafd3-8748-4a75-9744-7cdf44eee8c4.png" style="width:0.67em;height:0.92em;"/>为条件。</p>

<p>因此，鉴频器的损耗函数如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/e6a23fb2-a1aa-4d68-a8de-abf2f794ee16.png" style="width:25.17em;height:2.00em;"/></p>

<p>发电机的损耗函数由下式给出:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/3daefbdb-8cb3-4431-924b-2856bf8d53ad.png" style="width:13.50em;height:2.00em;"/></p>

<p>CGAN通过使用梯度下降最小化损失函数来学习。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Generating specific handwritten digits using CGAN</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">使用CGAN生成特定的手写数字</h1>

                

            

            

                

<p>我们刚刚了解了CGAN的工作原理和架构。为了加强我们的理解，现在我们将学习如何在TensorFlow中实现CGAN来生成特定手写数字(比如数字7)的图像。</p>

<p>首先，加载所需的库:</p>

<pre>import warnings<br/>warnings.filterwarnings('ignore')<br/><br/>import numpy as np<br/>import tensorflow as tf<br/>from tensorflow.examples.tutorials.mnist import input_data<br/>tf.logging.set_verbosity(tf.logging.ERROR)<br/>tf.reset_default_graph()<br/><br/>import matplotlib.pyplot as plt<br/>%matplotlib inline<br/><br/>from IPython import display</pre>

<p>加载MNIST数据集:</p>

<pre>data = input_data.read_data_sets("data/mnist",one_hot=True)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Defining the generator</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">定义生成器</h1>

                

            

            

                

<p>生成器<em>G</em>将噪声<img class="fm-editor-equation" src="img/3fba73ea-bd4f-4352-8535-f23286d101b8.png" style="width:0.75em;height:0.92em;"/>和条件变量<img class="fm-editor-equation" src="img/2076de9c-04e1-47b2-93f1-8d9cd520e9a0.png" style="width:0.67em;height:0.92em;"/>作为输入并返回图像。我们将发电机定义为一个简单的双层前馈网络:</p>

<pre>def generator(z, c,reuse=False):<br/>    with tf.variable_scope('generator', reuse=reuse):</pre>

<p>初始化权重:</p>

<pre>            w_init = tf.contrib.layers.xavier_initializer()</pre>

<p>连接噪声<img class="fm-editor-equation" src="img/c017b2d2-3c5d-4fe5-a6de-29cf18af21b0.png" style="width:0.75em;height:0.92em;"/>和条件变量<img class="fm-editor-equation" src="img/c5a5b62a-728c-4a2b-a938-24c2b58fbb0c.png" style="width:0.67em;height:0.92em;"/>:</p>

<pre>            inputs = tf.concat([z, c], 1)</pre>

<p>定义第一层:</p>

<pre>            dense1 = tf.layers.dense(inputs, 128, kernel_initializer=w_init)<br/>            relu1 = tf.nn.relu(dense1)</pre>

<p>定义第二层并用<kbd>tanh</kbd>激活函数计算输出:</p>

<pre>            logits = tf.layers.dense(relu1, 784, kernel_initializer=w_init)<br/>            output = tf.nn.tanh(logits)<br/><br/>            return output</pre>

<p class="mce-root"/>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Defining discriminator</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">定义鉴别器</h1>

                

            

            

                

<p class="mce-root">我们知道鉴别器，<img class="fm-editor-equation" src="img/92dd0d61-61e9-4979-bef8-5fa25b08d846.png" style="width:0.67em;height:0.75em;"/>，返回概率；也就是说，它会告诉我们给定图像是真实的概率。除了输入图像<img class="fm-editor-equation" src="img/21e9ebf0-fbab-4938-9890-29594707d2ba.png" style="width:0.83em;height:0.83em;"/>，它还将条件变量<img class="fm-editor-equation" src="img/c9b15d4e-d63d-4776-bbce-9bf5d1544b81.png" style="width:0.67em;height:0.92em;"/>作为输入。我们还将鉴别器定义为一个简单的双层前馈网络:</p>

<pre>def discriminator(x, c, reuse=False):<br/>    with tf.variable_scope('discriminator', reuse=reuse):</pre>

<p>初始化权重:</p>

<pre>            w_init = tf.contrib.layers.xavier_initializer()</pre>

<p>连接输入，<img class="fm-editor-equation" src="img/6b91c2b8-d0ad-4fdd-93c7-2027143d3a78.png" style="width:0.92em;height:0.92em;"/>和条件变量，<img class="fm-editor-equation" src="img/f16638c8-eebc-417a-8500-983bb5984248.png" style="width:0.67em;height:0.92em;"/>:</p>

<pre>            inputs = tf.concat([x, c], 1)</pre>

<p>定义第一层:</p>

<pre>            dense1 = tf.layers.dense(inputs, 128, kernel_initializer=w_init)<br/>            relu1 = tf.nn.relu(dense1)</pre>

<p>定义第二层并用<kbd>sigmoid</kbd>激活函数计算输出:</p>

<pre>             logits = tf.layers.dense(relu1, 1, kernel_initializer=w_init)<br/>             output = tf.nn.sigmoid(logits)<br/><br/>             return output</pre>

<p>定义输入的占位符<img class="fm-editor-equation" src="img/6b8eef0e-1ec8-4195-8e3b-acb7878fc080.png" style="width:0.92em;height:0.92em;"/>、条件变量<img class="fm-editor-equation" src="img/03fe94eb-54c9-4a6c-ac36-6613626a2b9d.png" style="width:0.67em;height:0.92em;"/>和噪声<img class="fm-editor-equation" src="img/aa946952-416d-46e4-8f61-b4525a754412.png" style="width:0.75em;height:0.92em;"/>:</p>

<pre>x = tf.placeholder(tf.float32, shape=(None, 784))<br/>c = tf.placeholder(tf.float32, shape=(None, 10))<br/>z = tf.placeholder(tf.float32, shape=(None, 100))</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Start the GAN!</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">启动甘！</h1>

                

            

            

                

<p>首先，我们将噪声<img class="fm-editor-equation" src="img/7a9ce465-36be-4928-a62e-93fad76038e5.png" style="width:0.75em;height:0.92em;"/>和条件变量<img class="fm-editor-equation" src="img/92212dc2-38b2-47bf-b2a7-214b4dd230db.png" style="width:0.67em;height:0.92em;"/>提供给生成器，它将输出假图像，即<img class="fm-editor-equation" src="img/718a88c0-6582-4fe1-bd16-212f9204db72.png" style="width:7.75em;height:1.25em;"/>:</p>

<pre class="mce-root">fake_x = generator(z, c)</pre>

<p class="mce-root">现在，我们将真实图像<img class="fm-editor-equation" src="img/f8310e0e-b680-4cf7-862f-050b010071da.png" style="width:0.75em;height:0.75em;"/>和条件变量<img class="fm-editor-equation" src="img/92212dc2-38b2-47bf-b2a7-214b4dd230db.png" style="width:0.42em;height:0.58em;"/>一起提供给鉴别器<img class="fm-editor-equation" src="img/ce7b8ed9-614f-4ddc-b414-da102cdc0e64.png" style="width:2.08em;height:0.83em;"/>，并获得它们为真实的概率:</p>

<pre class="mce-root">D_logits_real = discriminator(x,c)</pre>

<p class="mce-root">类似地，我们将假图像<kbd>fake_x</kbd>和条件变量<img class="fm-editor-equation" src="img/6adb17cf-a37e-4c68-9ecf-c9da309fa5fb.png" style="width:0.58em;height:0.83em;"/>提供给鉴别器<img class="fm-editor-equation" src="img/c4d9de79-ac6a-45f8-afa6-c46ffd2933ab.png" style="width:2.17em;height:0.92em;"/>，并获得它们为真的概率:</p>

<pre class="mce-root">D_logits_fake = discriminator(fake_x, c, reuse=True)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Computing the loss function</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">计算损失函数</h1>

                

            

            

                

<p class="mce-root">现在我们来看看如何计算损失函数。除了我们添加了一个条件变量之外，它与传统的GAN基本相同。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Discriminator loss</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">鉴频器损耗</h1>

                

            

            

                

<p class="mce-root">鉴频器损耗计算如下:</p>

<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/6c621f81-f100-4980-9d7a-7d9012be17e1.png" style="width:25.25em;height:1.50em;"/></p>

<p class="mce-root">首先，我们将实现第一个术语，即<img class="fm-editor-equation" src="img/c5c53cc8-1af4-4ec4-b1df-779b67a80b69.png" style="width:6.92em;height:1.08em;"/>:</p>

<pre class="mce-root">D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_real,<br/>               labels=tf.ones_like(D_logits_real)))</pre>

<p class="mce-root">现在我们将实现第二个术语，<img class="fm-editor-equation" src="img/4c06f526-38fe-4aeb-9332-e3ace5521540.png" style="width:11.92em;height:1.33em;"/>:</p>

<pre class="mce-root">D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_fake,  <br/>               labels=tf.zeros_like(D_logits_fake)))</pre>

<p class="mce-root">最终损失可以写成:</p>

<pre class="mce-root">D_loss = D_loss_real + D_loss_fake</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Generator loss</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">发电机损耗</h1>

                

            

            

                

<p class="mce-root">发电机损耗如下所示:</p>

<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/b294fdb0-97f2-463a-82aa-cf250794a4bf.png" style="width:14.83em;height:1.58em;"/></p>

<p>发电机损耗可表示为:</p>

<pre class="mce-root">G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_fake,<br/>               labels=tf.ones_like(D_logits_fake)))</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Optimizing the loss</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">优化损失</h1>

                

            

            

                

<p class="mce-root">我们需要优化我们的生成器和鉴别器。因此，我们将鉴频器和发生器的参数分别记为<kbd>theta_D</kbd>和<kbd>theta_G</kbd>:</p>

<pre class="mce-root">training_vars = tf.trainable_variables()<br/>theta_D = [var for var in training_vars if var.name.startswith('discriminator')]<br/>theta_G = [var for var in training_vars if var.name.startswith('generator')]</pre>

<p class="mce-root">使用Adam优化器优化损失:</p>

<pre class="mce-root">learning_rate = 0.001<br/><br/>D_optimizer = tf.train.AdamOptimizer(learning_rate, beta1=0.5).minimize(D_loss,         <br/>                 var_list=theta_D)<br/>G_optimizer = tf.train.AdamOptimizer(learning_rate, beta1=0.5).minimize(G_loss, <br/>                       var_list=theta_G)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Start training the CGAN</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">开始训练CGAN</h1>

                

            

            

                

<p class="mce-root">启动TensorFlow会话并初始化变量:</p>

<pre class="mce-root">session = tf.InteractiveSession()<br/>tf.global_variables_initializer().run()</pre>

<p>定义<kbd>batch_size:</kbd></p>

<pre>batch_size = 128</pre>

<p>定义时期数和类别数:</p>

<pre>num_epochs = 500<br/>num_classes = 10</pre>

<p>定义图像和标签:</p>

<pre style="font-size: 16px">images = (data.train.images)<br/>labels = data.train.labels</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Generate the handwritten digit, 7</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">生成手写数字，7</h1>

                

            

            

                

<p>我们设置数字(<kbd>label</kbd>)生成为<kbd>7</kbd>:</p>

<pre class="mce-root">label_to_generate = 7<br/>onehot = np.eye(10)</pre>

<p>设置迭代次数:</p>

<pre>for epoch in range(num_epochs):<br/><br/>    for i in range(len(images) // batch_size):</pre>

<p>基于批量的样本图像:</p>

<pre>        batch_image = images[i * batch_size:(i + 1) * batch_size]</pre>

<p>采样条件，即我们要生成的数字:</p>

<pre>        batch_c = labels[i * batch_size:(i + 1) * batch_size]</pre>

<p>样本噪声:</p>

<pre>        batch_noise = np.random.normal(0, 1, (batch_size, 100))</pre>

<p>训练发电机并计算发电机损耗:</p>

<pre>        generator_loss, _ = session.run([D_loss, D_optimizer], {x: batch_image, c: batch_c, z: batch_noise})    </pre>

<p>训练鉴频器并计算鉴频器损耗:</p>

<pre>        discriminator_loss, _ = session.run([G_loss, G_optimizer], {x: batch_image, c: batch_c, z: batch_noise})</pre>

<p>随机采样噪声:</p>

<pre>    noise = np.random.rand(1,100)</pre>

<p>选择我们要生成的数字:</p>

<pre>    gen_label = np.array([[label_to_generate]]).reshape(-1)</pre>

<p>将所选数字转换为独热编码向量:</p>

<pre>    one_hot_targets = np.eye(num_classes)[gen_label]</pre>

<p>将噪声和一个热编码条件馈送到生成器，并生成伪图像:</p>

<pre>    _fake_x = session.run(fake_x, {z: noise, c: one_hot_targets})<br/>    _fake_x = _fake_x.reshape(28,28)</pre>

<p>打印发生器和鉴别器的损耗，并绘制发生器图像:</p>

<pre>    print("Epoch: {},Discriminator Loss:{}, Generator Loss: {}".format(epoch,discriminator_loss,generator_loss))<br/>    <br/>    #plot the generated image<br/>    display.clear_output(wait=True)<br/>    plt.imshow(_fake_x) <br/>    plt.show()</pre>

<p>如下图所示，生成器现在已经学会生成数字7，而不是随机生成其他数字:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/4816e841-0f8b-4f5c-829a-c9c066a3bca1.png" style="width:14.33em;height:14.17em;"/></p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Understanding InfoGAN</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">了解InfoGAN</h1>

                

            

            

                

<p>InfoGAN是CGAN的无人监管版本。在CGAN中，我们学习了如何调节发生器和鉴别器，以生成我们想要的图像。但是，当数据集中没有标签时，我们该如何做呢？假设我们有一个没有标签的MNIST数据集；我们如何告诉生成器生成我们感兴趣的特定图像？由于数据集是未标记的，我们甚至不知道数据集中存在的类。</p>

<p>我们知道生成器使用噪声<em> z </em>作为输入并生成图像。生成器将关于图像的所有必要信息封装在<em> z </em>中，它被称为<strong>纠缠表示</strong>。它基本上是学习图像在<em> z </em>中的语义表示。如果我们能解开这个向量，那么我们就能发现我们图像的有趣特征。</p>

<p class="mce-root">所以，我们将把这个<em> z </em>一分为二:</p>

<ul>

<li>普通噪音</li>

<li>代码<em> c </em></li>

</ul>

<p>代码是什么？代码<em> c </em>基本上是可解释的不清楚的信息。假设我们有MNIST数据，那么，代码<em> c1 </em>表示数字标签，代码<em> c2 </em>表示宽度，<em> c3 </em>表示数字的笔画，等等。我们统称他们为<em> c </em>。</p>

<p>既然有了<em> z </em>和<em> c </em>，如何学习有意义的代码<em> c </em>？我们能用生成器生成的图像学习有意义的代码吗？假设一个生成器生成了7的图像。现在我们可以说代码<em> c1是7 </em>，因为我们知道c1意味着数字标签。</p>

<p>但是既然代码可以表示任何东西，比如标签、手指的宽度、笔画、旋转角度等等——我们怎么才能知道我们想要什么呢？代码<em> c </em>将基于先验的选择而被学习。例如，如果我们为<em> c </em>选择一个多项式先验，那么我们的InfoGAN可能会为<em> c </em>分配一个数字标签。比方说，我们分配一个高斯先验，然后它可能分配一个旋转角度，等等。我们也可以有一个以上的先验。</p>

<p>先前<em> c </em>的分布可以是任何东西。InfoGAN根据分布分配不同的属性。在InfoGAN中，代码<em> c </em>是根据生成器输出自动推断出来的，这与CGAN不同，在CGAN中，我们显式指定了<em> c </em>。</p>

<p>简而言之，我们是根据发电机输出<img class="fm-editor-equation" src="img/90798245-af2f-48c9-97b5-4f0e5a14b3e3.png" style="width:3.00em;height:1.17em;"/>来推断<img class="fm-editor-equation" src="img/0c7149c6-3be8-4775-b309-45e3be1b8545.png" style="width:0.67em;height:0.92em;"/>。但是我们到底是如何推断的呢？我们使用信息论中的一个概念，叫做<strong>互信息</strong>。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Mutual information</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">交互信息</h1>

                

            

            

                

<p>两个随机变量之间的互信息告诉我们可以从一个随机变量通过另一个随机变量获得的信息量。两个随机变量<em> x </em>和<em> y </em>之间的互信息可以给出如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/cd64a09b-fa5f-407f-b4e1-a0b07db0e49a.png" style="width:10.92em;height:1.17em;"/></p>

<p>基本上就是<em> y </em>的熵和给定<em> x </em>的<em> y </em>的条件熵之差。</p>

<p>代码<img class="fm-editor-equation" src="img/ff8204f0-ea05-46a2-a28b-d7f13f38195e.png" style="width:0.67em;height:0.92em;"/>和发生器输出<img class="fm-editor-equation" src="img/43fe9912-04e5-4bc0-aac5-ce5262e9fc20.png" style="width:2.58em;height:1.08em;"/>之间的交互信息告诉我们通过<img class="fm-editor-equation" src="img/43fe9912-04e5-4bc0-aac5-ce5262e9fc20.png" style="width:2.83em;height:1.17em;"/>可以获得多少关于<img class="fm-editor-equation" src="img/ff8204f0-ea05-46a2-a28b-d7f13f38195e.png" style="width:0.67em;height:0.92em;"/>的信息。如果互信息<em> c </em>和<img class="fm-editor-equation" src="img/43fe9912-04e5-4bc0-aac5-ce5262e9fc20.png" style="width:2.83em;height:1.17em;"/>为高，那么我们可以说知道发电机输出有助于我们推断<em> c </em>。但是如果互信息很低，那么我们不能从发电机输出中推断出<em> c </em>。我们的目标是最大化相互信息。</p>

<p>代码<img class="fm-editor-equation" src="img/ff8204f0-ea05-46a2-a28b-d7f13f38195e.png" style="width:0.67em;height:0.92em;"/>和发生器输出<img class="fm-editor-equation" src="img/43fe9912-04e5-4bc0-aac5-ce5262e9fc20.png" style="width:2.67em;height:1.08em;"/>之间的相互信息如下所示:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/b2a3dbb0-00cd-41d2-b072-2577c999e0b1.png" style="width:14.42em;height:1.08em;"/></p>

<p>让我们看看公式的元素:</p>

<ul>

<li><img class="fm-editor-equation" src="img/77b4d2e1-3669-4218-9056-fcdd47af1e82.png" style="width:2.00em;height:1.08em;"/>是代码的熵</li>

<li><img class="fm-editor-equation" src="img/1375ab50-62de-4d2f-bffe-3dea4a5678ad.png" style="width:5.42em;height:1.17em;"/>是给定发生器输出的代码c的条件熵<img class="fm-editor-equation" src="img/43fe9912-04e5-4bc0-aac5-ce5262e9fc20.png" style="width:2.67em;height:1.08em;"/></li>

</ul>

<p>但问题是，我们如何计算<img class="fm-editor-equation" src="img/1375ab50-62de-4d2f-bffe-3dea4a5678ad.png" style="width:4.67em;height:1.00em;"/>？因为要计算这个值，我们需要知道后验概率，<img class="fm-editor-equation" src="img/ea74a871-385f-4fd1-a422-29c2dbe4076b.png" style="width:4.75em;height:1.08em;"/>，这个我们还不知道。所以，我们用辅助分布来估计后验概率，<img class="fm-editor-equation" src="img/8197d00c-71c7-43b0-bb9f-bde673eeb1d2.png" style="width:3.33em;height:1.33em;"/>:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/b2a3dbb0-00cd-41d2-b072-2577c999e0b1.png" style="width:15.50em;height:1.17em;"/></p>

<p>比方说<img class="fm-editor-equation" src="img/7cf8508c-5680-44f2-9436-4809e8b458dd.png" style="width:5.00em;height:1.17em;"/>，那么我们可以推导出如下互信息:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/77307ccf-295e-499c-8c4f-3413deffc80f.png" style="width:28.67em;height:12.83em;"/></p>

<p>因此，我们可以说:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/504b15ff-8dbe-4e7b-8f33-f85da19dc791.png" style="width:21.08em;height:1.33em;"/></p>

<p>最大化互信息，<img class="fm-editor-equation" src="img/04461b06-9679-4dfd-8a03-3a8c0dbce1b7.png" style="width:6.00em;height:1.33em;"/>基本上意味着在给定生成的输出的情况下，我们最大化关于<em> c </em>的知识，也就是说，通过一个变量了解另一个变量。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Architecture of the InfoGAN</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">信息根的体系结构</h1>

                

            

            

                

<p>好吧。这到底是怎么回事？我们为什么要这么做？简单来说，我们将发电机的输入分成两部分:<em> z </em>和<em> c </em>。由于<em> z </em>和<em> c </em>都用于生成图像，它们捕捉图像的语义。代码<em> c </em>给了我们关于图像的可解释的清晰信息。因此，给定发电机输出，我们试图找到<em> c </em>。但是，由于我们不知道后验概率<img class="fm-editor-equation" src="img/1a09fb91-ad1e-4640-9ee1-7858444eeb75.png" style="width:5.42em;height:1.25em;"/>，所以我们不能轻易做到这一点，所以我们使用一个辅助分布<img class="fm-editor-equation" src="img/59e766d6-4103-4d50-a928-6a24384de828.png" style="width:2.75em;height:1.08em;"/>来学习<em> c </em>。</p>

<p>这个辅助分布基本上是另一个神经网络；我们姑且称这个网络为<em> Q </em>网络。<em> Q </em>网络的作用是在给定一个发生器图像<em> x </em>并由<img class="fm-editor-equation" src="img/8bdc985a-0401-4abe-88ab-4a6af6ac2097.png" style="width:2.92em;height:1.17em;"/>给出的情况下，预测<em> c </em>的可能性。</p>

<p>首先，我们从一个先验样本<em> c </em>，<em> p(c) </em>。然后，我们将<em> c </em>和<em> z </em>连接起来，并将它们馈送给生成器。接下来，我们将<img class="fm-editor-equation" src="img/36423d4e-7ade-4f6e-87b3-b71551f5b61c.png" style="width:2.83em;height:1.08em;"/>给出的生成器结果馈送给鉴别器。我们知道鉴别器的作用是输出给定图像真实的概率。因此，它获取生成器生成的图像并返回概率。此外，<em> Q </em>网络获取生成的图像，并返回给定生成的图像的<em> c </em>的估计值。</p>

<p>鉴别器<em> D </em>和<em> Q </em>网络都接收发生器图像并返回输出，因此它们共享一些层。由于它们共享一些层，我们将<em> Q </em>网络连接到鉴别器，如下图所示:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-880 image-border" src="img/cbc47881-40df-4e43-a508-96ffd57dfa4f.png" style="width:26.75em;height:21.17em;"/></p>

<p>因此，鉴别器返回两个输出:</p>

<ul>

<li>图像真实的概率</li>

<li><em> c、</em>的估计值，即给定发生器图像时<em> c </em>的概率</li>

</ul>

<p>我们在损失函数中加入了互信息项。</p>

<p>因此，鉴频器的损耗函数为:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/2a5568d6-8ba3-495a-a04d-3adf366f9206.png" style="width:29.50em;height:1.92em;"/></p>

<p>发电机的损耗函数由下式给出:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/0c69ce3b-afea-432e-a4b8-e52ac1ee4a26.png" style="width:19.25em;height:2.00em;"/></p>

<p>前面的两个等式意味着我们在最大化互信息的同时最小化GAN的损耗。还在困惑InfoGANs？放心吧！我们将通过在TensorFlow中实现InfoGANs来逐步更好地了解它们。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Constructing an InfoGAN in TensorFlow</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">在TensorFlow中构建InfoGAN</h1>

                

            

            

                

<p>通过在TensorFlow中一步步实现InfoGANs，我们会更好地理解它们。我们将使用MNIST数据集，并了解InfoGAN如何基于生成器输出自动推断代码<img class="fm-editor-equation" src="img/285c7e36-2c3b-451b-9d4c-ec3e14821693.png" style="width:0.67em;height:0.92em;"/>。我们建立一个信息DCGAN也就是说，我们在生成器和鉴别器中使用卷积层，而不是普通的神经网络。</p>

<p>首先，我们将导入所有必需的库:</p>

<pre>import warnings<br/>warnings.filterwarnings('ignore')<br/><br/>import numpy as np<br/>import tensorflow as tf<br/><br/>from tensorflow.examples.tutorials.mnist import input_data<br/>tf.logging.set_verbosity(tf.logging.ERROR)<br/><br/>import matplotlib.pyplot as plt<br/>%matplotlib inline</pre>

<p class="mceNonEditable"/>

<p>加载MNIST数据集:</p>

<pre>data = input_data.read_data_sets("data/mnist",one_hot=True)</pre>

<p>定义泄漏ReLU激活函数:</p>

<pre>def lrelu(X, leak=0.2):<br/>    f1 = 0.5 * (1 + leak)<br/>    f2 = 0.5 * (1 - leak)<br/>    return f1 * X + f2 * tf.abs(X)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Defining generator</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">定义生成器</h1>

                

            

            

                

<p class="mce-root">生成器<img class="fm-editor-equation" src="img/be85bd9d-7482-49d4-a48e-ec8024aeea1c.png" style="width:0.42em;height:0.50em;"/>，它将噪声<img class="fm-editor-equation" src="img/315bac8e-4528-42d4-b2db-971178e21db7.png" style="width:0.50em;height:0.58em;"/>和变量<img class="fm-editor-equation" src="img/8562e754-dcfe-4432-b70f-d9825a801f78.png" style="width:0.50em;height:0.75em;"/>作为输入，并返回图像。我们没有在生成器中使用完全连接的层，而是使用解卷积网络，就像我们研究DCGANs时一样:</p>

<pre>def generator(c, z,reuse=None):</pre>

<p>首先，连接噪声、<em> z、</em>和变量、<img class="fm-editor-equation" src="img/e6c9289c-bc98-4d2e-9085-3d0dad48a5b8.png" style="width:0.67em;height:0.92em;"/>:</p>

<pre>    input_combined = tf.concat([c, z], axis=1)</pre>

<p>定义第一层，这是一个具有批量标准化和ReLU激活的完全连接的层:</p>

<pre>    fuly_connected1 = tf.layers.dense(input_combined, 1024)<br/>    batch_norm1 = tf.layers.batch_normalization(fuly_connected1, training=is_train)<br/>    relu1 = tf.nn.relu(batch_norm1)</pre>

<p>定义第二层，它也完全与批量标准化和ReLU激活相关:</p>

<pre>    fully_connected2 = tf.layers.dense(relu1, 7 * 7 * 128)<br/>    batch_norm2 = tf.layers.batch_normalization(fully_connected2, training=is_train)<br/>    relu2 = tf.nn.relu(batch_norm2)</pre>

<p>展平第二层的结果:</p>

<pre>    relu_flat = tf.reshape(relu2, [batch_size, 7, 7, 128])</pre>

<p>第三层由<strong>反褶积</strong>组成；即转置卷积运算，随后是批量归一化和ReLU激活:</p>

<pre>    deconv1 = tf.layers.conv2d_transpose(relu_flat, <br/>                                          filters=64,<br/>                                          kernel_size=4,<br/>                                          strides=2,<br/>                                          padding='same',<br/>                                          activation=None)<br/>    batch_norm3 = tf.layers.batch_normalization(deconv1, training=is_train)<br/>    relu3 = tf.nn.relu(batch_norm3)</pre>

<p>第四层是另一个转置卷积运算:</p>

<pre>    deconv2 = tf.layers.conv2d_transpose(relu3, <br/>                                          filters=1,<br/>                                          kernel_size=4,<br/>                                          strides=2,<br/>                                          padding='same',<br/>                                          activation=None)</pre>

<p>将sigmoid函数应用于第四层的结果，并获得输出:</p>

<pre>    output = tf.nn.sigmoid(deconv2) <br/><br/>    return output</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Defining the discriminator</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">定义鉴别器</h1>

                

            

            

                

<p>我们了解到鉴别器<img class="fm-editor-equation" src="img/ef5d0704-9421-4960-99c5-7a189b57d943.png" style="width:0.92em;height:1.00em;"/>和<em> Q </em>网络都接收发生器镜像并返回输出，因此它们共享一些层。由于它们共享一些层，我们将<em> Q </em>网络连接到鉴别器，正如我们在InfoGAN架构中所学的。正如我们在DCGAN的鉴频器中了解到的那样，我们使用卷积网络，而不是在鉴频器中使用全连接层:</p>

<pre>def discriminator(x,reuse=None):</pre>

<p>定义第一层，该层执行卷积运算，随后是泄漏ReLU激活:</p>

<pre>    conv1 = tf.layers.conv2d(x, <br/>                             filters=64, <br/>                             kernel_size=4,<br/>                             strides=2,<br/>                             padding='same',<br/>                             kernel_initializer=tf.contrib.layers.xavier_initializer(),<br/>                             activation=None)<br/>    lrelu1 = lrelu(conv1, 0.2)</pre>

<p>我们还在第二层中执行卷积运算，随后是批量归一化和泄漏ReLU激活:</p>

<pre>    conv2 = tf.layers.conv2d(lrelu1, <br/>                             filters=128,<br/>                             kernel_size=4,<br/>                             strides=2,<br/>                             padding='same',<br/>                             kernel_initializer=tf.contrib.layers.xavier_initializer(),<br/>                             activation=None)<br/>    batch_norm2 = tf.layers.batch_normalization(conv2, training=is_train)<br/>    lrelu2 = lrelu(batch_norm2, 0.2)</pre>

<p>展平第二层的结果:</p>

<pre>   lrelu2_flat = tf.reshape(lrelu2, [batch_size, -1])</pre>

<p>将展平的结果提供给完全连接的层，这是第三层，随后是批量标准化和泄漏ReLU激活:</p>

<pre>    full_connected = tf.layers.dense(lrelu2_flat, <br/>                          units=1024, <br/>                          activation=None)<br/>    batch_norm_3 = tf.layers.batch_normalization(full_connected, training=is_train)<br/>    lrelu3 = lrelu(batch_norm_3, 0.2)</pre>

<p>计算鉴频器输出:</p>

<pre>    d_logits = tf.layers.dense(lrelu3, units=1, activation=None)</pre>

<p>正如我们所知，我们将<em> Q </em>网络连接到鉴频器。定义将鉴频器的最后一层作为输入的<em> Q </em>网络的第一层:</p>

<pre>    full_connected_2 = tf.layers.dense(lrelu3, <br/>                                     units=128, <br/>                                     activation=None)<br/><br/>    batch_norm_4 = tf.layers.batch_normalization(full_connected_2, training=is_train)<br/>    lrelu4 = lrelu(batch_norm_4, 0.2)</pre>

<p class="mce-root"/>

<p>定义第二层<em> Q </em>网络:</p>

<pre>    q_net_latent = tf.layers.dense(lrelu4, <br/>                                    units=74, <br/>                                    activation=None)</pre>

<p>估计值<em> c </em>:</p>

<pre>    q_latents_categoricals_raw = q_net_latent[:,0:10]<br/><br/>    c_estimates = tf.nn.softmax(q_latents_categoricals_raw, dim=1)</pre>

<p>返回鉴别器<kbd>logits</kbd>和估算的<em> c </em>值作为输出:</p>

<pre>    return d_logits, c_estimates</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Define the input placeholders</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">定义输入占位符</h1>

                

            

            

                

<p class="mce-root">现在我们定义输入的占位符<img class="fm-editor-equation" src="img/1198ce65-9257-470f-9ebe-fa1dd5af2b41.png" style="width:0.83em;height:0.83em;"/>、噪声<img class="fm-editor-equation" src="img/47af0b1c-6f7b-4b5e-8963-0f17cbdcca52.png" style="width:0.67em;height:0.83em;"/>和代码<img class="fm-editor-equation" src="img/7f206bce-181b-4732-a826-72a1001e9921.png" style="width:0.58em;height:0.83em;"/>:</p>

<pre>batch_size = 64<br/>input_shape = [batch_size, 28,28,1]<br/><br/><br/>x = tf.placeholder(tf.float32, input_shape)<br/>z = tf.placeholder(tf.float32, [batch_size, 64])<br/>c = tf.placeholder(tf.float32, [batch_size, 10])<br/><br/>is_train = tf.placeholder(tf.bool)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Start the GAN</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">启动GAN</h1>

                

            

            

                

<p>首先，我们将噪声<img class="fm-editor-equation" src="img/541c0403-7faf-4e90-904f-3fabb2287695.png" style="width:0.75em;height:0.92em;"/>和代码<img class="fm-editor-equation" src="img/19dc097f-0ef5-4373-9c71-2c13948ea07a.png" style="width:0.67em;height:0.92em;"/>馈送给生成器，它将根据等式<img class="fm-editor-equation" src="img/d4bb1f15-c827-442a-b4a3-2e2706b728a9.png" style="width:8.08em;height:1.25em;"/>输出假图像:</p>

<pre class="mce-root">fake_x = generator(c, z)</pre>

<p class="mce-root">现在，我们将真实图像<img class="fm-editor-equation" src="img/c3d7298c-8e7f-4dec-a5ff-4c36a29078c8.png" style="width:0.58em;height:0.58em;"/>提供给鉴别器<img class="fm-editor-equation" src="img/19be0dee-d6ea-4c21-a901-3acd2320a789.png" style="width:1.83em;height:1.00em;"/>，并获得图像真实的概率。与此同时，我们也获得了对真实图像的<img class="fm-editor-equation" src="img/235ed536-2d0f-48d3-88b9-3013d10a46d1.png" style="width:0.67em;height:0.92em;"/>的估计:</p>

<pre class="mce-root">D_logits_real, c_posterior_real = discriminator(x)</pre>

<p class="mce-root">类似地，我们将假图像提供给鉴别器，得到图像是真实图像的概率以及假图像的估计值<img class="fm-editor-equation" src="img/5e52ecb7-3193-45c3-b47f-1c66192759cb.png" style="width:0.50em;height:0.75em;"/>:</p>

<pre class="mce-root">D_logits_fake, c_posterior_fake = discriminator(fake_x,reuse=True)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Computing loss function</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">计算损失函数</h1>

                

            

            

                

<p class="mce-root">现在我们来看看如何计算损失函数。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Discriminator loss</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">鉴频器损耗</h1>

                

            

            

                

<p class="mce-root">鉴频器损耗计算如下:</p>

<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/4835bff6-b8a1-4f22-b460-2011ba5ed03d.png" style="width:22.83em;height:1.50em;"/></p>

<p>由于InfoGAN的鉴频器损耗与CGAN相同，因此实现鉴频器损耗与我们在CGAN部分所学的相同:</p>

<pre class="mce-root">#real loss<br/>D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_real, <br/> labels=tf.ones(dtype=tf.float32, shape=[batch_size, 1])))<br/><br/>#fake loss<br/>D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_fake, <br/> labels=tf.zeros(dtype=tf.float32, shape=[batch_size, 1])))<br/><br/>#final discriminator loss<br/>D_loss = D_loss_real + D_loss_fake</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Generator loss</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">发电机损耗</h1>

                

            

            

                

<p class="mce-root">发电机的损耗函数如下所示:</p>

<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/82e62838-ebe0-4eab-9f5b-823ec4f35519.png" style="width:12.83em;height:1.50em;"/></p>

<p>发电机损耗实现为:</p>

<pre class="mce-root">G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logits_fake, <br/> labels=tf.ones(dtype=tf.float32, shape=[batch_size, 1])))</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Mutual information</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">交互信息</h1>

                

            

            

                

<p class="mce-root">我们从鉴别器和发电机损耗中减去<strong>互信息</strong>。因此，鉴频器和发生器的最终损耗函数如下所示:</p>

<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/60d35e00-184e-445d-9314-985adea697e2.png" style="width:10.67em;height:1.25em;"/></p>

<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/6969ec81-922a-4d37-a3c4-d395a2bee81a.png" style="width:10.50em;height:1.25em;"/></p>

<p class="mce-root">交互信息可以计算如下:</p>

<p class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/288708fe-7ab4-4eb1-84b2-a7b46b2eb6eb.png" style="width:21.42em;height:1.33em;"/></p>

<p class="mce-root CDPAlignLeft CDPAlign">首先，我们为<img class="fm-editor-equation" src="img/3db44084-161b-4594-95d0-a12b9a741445.png" style="width:0.75em;height:0.92em;"/>定义一个先验:</p>

<pre class="mce-root">c_prior = 0.10 * tf.ones(dtype=tf.float32, shape=[batch_size, 10])</pre>

<p class="mce-root"><img class="fm-editor-equation" src="img/db8e2ca2-24ae-4c99-aeee-2fd273971ec8.png" style="width:0.58em;height:0.75em;"/>的熵表示为<img class="fm-editor-equation" src="img/2bbf0f0f-c47b-4f20-aaa0-c2dfcb91e0ce.png" style="width:2.08em;height:1.08em;"/>。我们知道熵的计算方法是<img class="fm-editor-equation" src="img/b02529c2-01a4-4ae3-ad88-d9ac0311d711.png" style="width:11.58em;height:2.42em;"/>:</p>

<pre class="mce-root">entropy_of_c = tf.reduce_mean(-tf.reduce_sum(c * tf.log(tf.clip_by_value(c_prior, 1e-12, 1.0)),axis=-1))</pre>

<p class="mce-root">给定<img class="fm-editor-equation" src="img/84c1b4e1-f67d-4298-8f91-860d6ec8ac2f.png" style="width:0.83em;height:0.83em;"/>时<img class="fm-editor-equation" src="img/00a39cdd-ada4-44a6-a583-2dcf3de42643.png" style="width:0.67em;height:0.92em;"/>的条件熵为<img class="fm-editor-equation" src="img/68c0e69b-b302-47f4-bb8d-ba72a7fefaad.png" style="width:3.17em;height:0.75em;"/>。条件熵的代码如下:</p>

<pre class="mce-root">log_q_c_given_x = tf.reduce_mean(tf.reduce_sum(c * tf.log(tf.clip_by_value(c_posterior_fake, 1e-12, 1.0)), axis=-1))</pre>

<p class="mce-root">互信息给定为<img class="fm-editor-equation" src="img/fd79fef3-96a8-4c96-94f5-3d0b50ce42e7.png" style="width:13.75em;height:1.08em;"/>:</p>

<pre class="mce-root">mutual_information = entropy_of_c + log_q_c_given_x</pre>

<p class="mce-root">鉴频器和发生器的最终损耗由下式给出:</p>

<pre class="mce-root">D_loss = D_loss - mutual_information<br/>G_loss = G_loss - mutual_information</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Optimizing the loss</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">优化损失</h1>

                

            

            

                

<p class="mce-root">现在我们需要优化我们的生成器和鉴别器。因此，我们将鉴频器和发生器的参数分别收集为<img class="fm-editor-equation" src="img/ae3bf55a-b765-41d3-8a7f-2040f62b651d.png" style="width:1.17em;height:1.00em;"/>和<img class="fm-editor-equation" src="img/00357b65-480a-4f02-8551-88c1d95a4c81.png" style="width:1.17em;height:1.08em;"/>:</p>

<pre class="mce-root">training_vars = tf.trainable_variables()<br/><br/>theta_D = [var for var in training_vars if 'discriminator' in var.name]<br/>theta_G = [var for var in training_vars if 'generator' in var.name]</pre>

<p class="mce-root">使用Adam优化器优化损失:</p>

<pre class="mce-root">learning_rate = 0.001<br/><br/>D_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(D_loss,var_list = theta_D)<br/>G_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list = theta_G)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Beginning training</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">开始训练</h1>

                

            

            

                

<p class="mce-root">定义批次大小和历元数，并初始化所有张量流变量:</p>

<pre class="mce-root">num_epochs = 100<br/>session = tf.InteractiveSession()<br/>session.run(tf.global_variables_initializer())</pre>

<p class="mce-root">定义可视化结果的辅助函数:</p>

<pre>def plot(c, x):<br/>    <br/>    c_ = np.argmax(c, 1)<br/><br/>    sort_indices = np.argsort(c_, 0)<br/>    <br/>    x_reshape = np.reshape(x[sort_indices], [batch_size, 28, 28])<br/>    <br/>    x_reshape = np.reshape( np.expand_dims(x_reshape, axis=0), [4, (batch_size // 4), 28, 28])<br/><br/>    values = []<br/>    <br/>    for i in range(0,4):<br/>        row = np.concatenate( [x_reshape[i,j,:,:] for j in range(0,(batch_size // 4))], axis=1)<br/>        values.append(row)<br/>        <br/>    return np.concatenate(values, axis=0)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Generating handwritten digits</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">生成手写数字</h1>

                

            

            

                

<p>开始训练并生成图像。对于每一次<kbd>100</kbd>迭代，我们打印由生成器生成的图像:</p>

<pre>onehot = np.eye(10)<br/><br/>for epoch in range(num_epochs):<br/><br/>    for i in range(0, data.train.num_examples // batch_size):</pre>

<p>对图像进行采样:</p>

<pre>        x_batch, _ = data.train.next_batch(batch_size)<br/>        x_batch = np.reshape(x_batch, (batch_size, 28, 28, 1))</pre>

<p>采样<em> c </em>的值:</p>

<pre>        c_ = np.random.randint(low=0, high=10, size=(batch_size,))<br/>        c_one_hot = onehot[c_]</pre>

<p>样本噪声<em> z </em>:</p>

<pre>        z_batch = np.random.uniform(low=-1.0, high=1.0, size=(batch_size,64))</pre>

<p>优化发生器和鉴频器的损耗:</p>

<pre>        feed_dict={x: x_batch, c: c_one_hot, z: z_batch, is_train: True}<br/><br/>        _ = session.run(D_optimizer, feed_dict=feed_dict)<br/>        _ = session.run(G_optimizer, feed_dict=feed_dict)</pre>

<p>每100次<sup xmlns:epub="http://www.idpf.org/2007/ops">迭代打印一次发生器图像:</sup></p>

<pre><br/>        if i % 100 == 0:<br/>            <br/>            discriminator_loss = D_loss.eval(feed_dict)<br/>            generator_loss = G_loss.eval(feed_dict)<br/>            <br/>            _fake_x = fake_x.eval(feed_dict)<br/>            <br/><br/>            print("Epoch: {}, iteration: {}, Discriminator Loss:{}, Generator Loss: {}".format(epoch,i,discriminator_loss,generator_loss))<br/>            plt.imshow(plot(c_one_hot, _fake_x))<br/>            plt.show() </pre>

<p>我们可以看到生成器是如何在每次迭代中进化并生成更好的数字的:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/302b0cac-d211-4e5c-b999-7fc25215d834.png" style="width:48.00em;height:35.08em;"/></p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Translating images using a CycleGAN</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">使用CycleGAN翻译图像</h1>

                

            

            

                

<p>我们已经学习了几种类型的gan，它们的应用是无穷无尽的。我们已经看到生成器如何学习真实数据的分布并生成新的真实样本。我们现在将看到一种真正不同且非常创新的GAN类型，称为<strong> CycleGAN </strong>。</p>

<p>与其他GAN不同，CycleGAN将数据从一个域映射到另一个域，这意味着我们在这里试图了解从一个域的图像分布到另一个域的图像分布的映射。简单来说，我们把图像从一个领域翻译到另一个领域。</p>

<p>这是什么意思？假设我们想要将灰度图像转换成彩色图像。灰度图像是一个域，彩色图像是另一个域。CycleGAN学习这两个域之间的映射，并在它们之间进行翻译。这意味着给定灰度图像，CycleGAN将图像转换成彩色图像。</p>

<p>CycleGANs的应用有很多，例如将真实照片转换为艺术图片、季节转换、照片增强等等。如下图所示，您可以看到CycleGAN如何在不同的域之间转换图像:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/24bfb704-2d29-46b4-ad20-2bfbb147825c.png"/></p>

<p>但是CycleGANs有什么特别之处呢？这是他们在没有任何配对例子的情况下将图像从一个领域转换到另一个领域的能力。假设我们正在将照片(源)转换为绘画(目标)。在一个普通的图像到图像的翻译中，我们如何做到这一点？我们通过成对收集一些照片及其对应的绘画来准备训练数据，如下图所示:</p>

<p class="mce-root CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-863 image-border" src="img/f0f516ad-affa-420a-9e51-175f6100a9b8.png" style="width:16.00em;height:27.33em;"/></p>

<p>为每个用例收集这些配对的数据点是一项昂贵的任务，我们可能没有很多记录或配对。这就是CycleGAN的最大优势所在。它不要求数据成对对齐。从照片转换成画，我们只需要一堆照片和一堆画。它们不必相互映射或对齐。</p>

<p>如下图，我们一栏有些照片，另一栏有些画；如你所见，它们没有配对。它们是完全不同的图像:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-864 image-border" src="img/caffee85-96ab-46a7-aef3-6779d717a2cf.png" style="width:19.08em;height:32.83em;"/></p>

<p>因此，要将图像从任何源域转换到目标域，我们只需要两个域中的一组图像，而不必配对。现在让我们看看它们是如何工作的，以及它们是如何学习源域和目标域之间的映射的。</p>

<p>与其他GAN不同，CycleGAN由两个发生器和两个鉴别器组成。让我们用<img class="fm-editor-equation" src="img/e6cbd39c-20ee-4b2e-96c5-b068afd8734d.png" style="width:0.75em;height:0.75em;"/>表示源域中的图像，用<img class="fm-editor-equation" src="img/d61d0722-fdd6-4331-a4c1-2becae65b971.png" style="width:0.50em;height:0.75em;"/>表示目标域中的图像。我们需要学习<img class="fm-editor-equation" src="img/519f9f4e-65c0-4e32-a83c-9bf20af36f52.png" style="width:0.58em;height:0.58em;"/>和<img class="fm-editor-equation" src="img/d61d0722-fdd6-4331-a4c1-2becae65b971.png" style="width:0.50em;height:0.83em;"/>之间的映射。</p>

<p>假设我们正在学习将一幅真实的图片<img class="fm-editor-equation" src="img/60960d1b-d4e6-4b9c-87e1-8ee02750cd75.png" style="width:0.75em;height:0.75em;"/>转换成一幅画<img class="fm-editor-equation" src="img/d61d0722-fdd6-4331-a4c1-2becae65b971.png" style="width:0.58em;height:1.00em;"/>，如下图所示:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1284 image-border" src="img/57884722-f016-4486-adea-5228202949a5.png" style="width:30.00em;height:10.33em;"/></p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Role of generators</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">发电机的作用</h1>

                

            

            

                

<p>我们有两个发电机，<img class="fm-editor-equation" src="img/f2387305-924d-40a4-9d6a-3a575d4c4a91.png" style="width:0.75em;height:0.75em;"/>和<img class="fm-editor-equation" src="img/f26d3b48-e48a-47e2-9b52-3b893a2ca07e.png" style="width:0.67em;height:0.75em;"/>。<img class="fm-editor-equation" src="img/4ae0c2af-662a-4c7c-8d91-3049e76f238e.png" style="width:0.67em;height:0.75em;"/>的作用是学习从<img class="fm-editor-equation" src="img/c74866d7-29b8-4604-b4cc-282c077598f3.png" style="width:0.75em;height:0.75em;"/>到<img class="fm-editor-equation" src="img/ef3db299-58f4-4208-ae0b-8c07c12d508f.png" style="width:0.58em;height:1.00em;"/>的映射。如上所述，<img class="fm-editor-equation" src="img/884f31f8-643c-4b27-845f-0b4d6996a1b5.png" style="width:0.75em;height:0.83em;"/>的作用是学习将照片翻译成画作，如下图所示:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-870 image-border" src="img/591401f1-c8e0-4d69-ba80-a805d400bbd5.png" style="width:30.42em;height:8.17em;"/></p>

<p>它试图生成一个假的目标图像，这意味着它将源图像<img class="fm-editor-equation" src="img/39408d7b-f87b-4bd0-b3ed-d9f192d9d5cd.png" style="width:0.42em;height:0.42em;"/>作为输入，并生成一个假的目标图像<img class="fm-editor-equation" src="img/ef3db299-58f4-4208-ae0b-8c07c12d508f.png" style="width:0.50em;height:0.67em;"/>:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/1a62a24b-575c-4bf3-8cb5-5aaecba7e7e3.png" style="font-size: 1em;width:3.83em;height:1.08em;"/></p>

<p>生成器<img class="fm-editor-equation" src="img/1b2e1c2d-6249-4a04-b264-4ff7d01d97ff.png" style="width:0.75em;height:0.83em;"/>的作用是学习从<img class="fm-editor-equation" src="img/ef3db299-58f4-4208-ae0b-8c07c12d508f.png" style="width:0.50em;height:0.83em;"/>到<img class="fm-editor-equation" src="img/a4872b2a-894e-4f82-9517-fbf12be37e3a.png" style="width:0.75em;height:0.75em;"/>的映射，学习从绘画翻译成真实的图片，如下图所示:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-871 image-border" src="img/f2572f4c-4e50-405a-aff3-7f8b4eeb3799.png" style="width:30.00em;height:8.17em;"/></p>

<p>它试图生成一个假的源图像，这意味着它将目标图像<img class="fm-editor-equation" src="img/ef3db299-58f4-4208-ae0b-8c07c12d508f.png" style="width:0.42em;height:0.67em;"/>作为输入，并生成一个假的源图像<img class="fm-editor-equation" src="img/a92caa9a-5f73-4ac8-b8cc-b1d5fa0df87c.png" style="width:0.67em;height:0.67em;"/>:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/545b880a-c12b-48db-95a9-66280805e4ef.png" style="width:3.50em;height:1.00em;"/></p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Role of discriminators</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">歧视者的角色</h1>

                

            

            

                

<p>类似于生成器，我们有两个鉴别器，<img class="fm-editor-equation" src="img/80d3f113-745d-4b0f-b80f-be4a1819cd4f.png" style="width:1.25em;height:1.00em;"/>和<img class="fm-editor-equation" src="img/96eaeabb-208c-4166-b365-7573fc3e077f.png" style="width:1.17em;height:1.00em;"/>。鉴别器<img class="fm-editor-equation" src="img/ff3805fa-fe28-45ba-91b5-e4a966d8e749.png" style="width:1.33em;height:1.00em;"/>的作用是鉴别真正的源图像<img class="fm-editor-equation" src="img/155da74d-cd57-4190-b1f6-a24d9214df6a.png" style="width:0.75em;height:0.75em;"/>和假的源图像<img class="fm-editor-equation" src="img/24043c10-de75-4b46-bba4-dec621e86dc9.png" style="width:2.00em;height:1.08em;"/>。我们知道假的源图像是由生成器<img class="fm-editor-equation" src="img/d7a67cf6-df09-41fb-8099-9b079109065d.png" style="width:0.75em;height:0.83em;"/>生成的。</p>

<p>给定一幅图像给鉴别器<img class="fm-editor-equation" src="img/8b0e71c7-60a7-4086-8990-112cdb195c92.png" style="width:1.42em;height:1.08em;"/>，它返回该图像是真实源图像的概率:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/e2370055-f57b-4877-9ee3-222b56144bda.png" style="width:14.08em;height:1.17em;"/></p>

<p>下图显示了鉴别器<img class="fm-editor-equation" src="img/8b0e71c7-60a7-4086-8990-112cdb195c92.png" style="width:1.17em;height:0.92em;"/>，如您所见，它将生成器F生成的真实源图像x和伪源图像作为输入，并返回图像是真实源图像的概率:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-868 image-border" src="img/61193748-e404-42e8-bc74-7a5fe90a4e30.png" style="width:26.08em;height:24.42em;"/></p>

<p>鉴别器<img class="fm-editor-equation" src="img/37759a1d-ab99-4bfd-a06e-f47a84bbc54e.png" style="width:1.17em;height:1.00em;"/>的作用是鉴别真实目标图像<img class="fm-editor-equation" src="img/0305c069-b0b7-4c4d-9d5a-6af14c84f7a6.png" style="width:0.50em;height:0.83em;"/>和虚假目标图像<img class="fm-editor-equation" src="img/e9cf6ebe-aea1-4a4f-a472-11f5fd14d49f.png" style="width:1.42em;height:0.75em;"/>。我们知道假目标图像是由生成器生成的，<img class="fm-editor-equation" src="img/e6b06a64-0b28-4950-8d3f-4fd5a151b5ca.png" style="width:0.67em;height:0.75em;"/>。给鉴别器<img class="fm-editor-equation" src="img/88040175-da0f-4cfa-ba2e-3f20aaa8e923.png" style="width:1.33em;height:1.17em;"/>一个图像，它返回图像是真实目标图像的概率:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/927703eb-3676-40a3-afd4-5c1640434ff7.png" style="width:12.75em;height:1.17em;"/></p>

<p class="CDPAlignLeft CDPAlign">下图显示了鉴别器<img class="fm-editor-equation" src="img/37759a1d-ab99-4bfd-a06e-f47a84bbc54e.png" style="width:1.17em;height:1.00em;"/>，如您所见，它将真实目标图像<img class="fm-editor-equation" src="img/0305c069-b0b7-4c4d-9d5a-6af14c84f7a6.png" style="width:0.75em;height:1.25em;"/>和生成器生成的虚假目标图像<img class="fm-editor-equation" src="img/e6b06a64-0b28-4950-8d3f-4fd5a151b5ca.png" style="width:0.75em;height:0.83em;"/>作为输入，并返回图像为真实目标图像的概率:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-872 image-border" src="img/6c26c935-7df9-4449-9337-db63fb930635.png" style="width:27.58em;height:25.92em;"/></p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Loss function</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">损失函数</h1>

                

            

            

                

<p>在CycleGANs中，我们有两个生成器和两个鉴别器。生成器学习将图像从一个域翻译到另一个域，鉴别器尝试在翻译的图像之间进行鉴别。</p>

<p>因此，我们可以说鉴频器<img class="fm-editor-equation" src="img/df0890f7-556a-4a6b-acde-ba0debf5b68d.png" style="width:1.50em;height:1.17em;"/>的损耗函数可以表示如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/447e0f80-e9ca-4e2a-b5df-31ee82a9250e.png" style="width:24.42em;height:1.50em;"/></p>

<p>类似地，鉴频器<img class="fm-editor-equation" src="img/dbc8900b-9e03-420c-b703-d61ecdabd2cb.png" style="width:1.33em;height:1.17em;"/>的损耗函数可以表示如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/9d48690d-01f6-42fc-a996-5c8e1f47103e.png" style="width:24.42em;height:1.50em;"/></p>

<p>发电机<img class="fm-editor-equation" src="img/171a85e6-72fc-44ca-813e-50e907dd78aa.png" style="width:0.83em;height:0.92em;"/>的损失函数可表示如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/e50dae88-b189-429d-9e31-ef711f415e4a.png" style="width:13.08em;height:1.50em;"/></p>

<p>发电机<img class="fm-editor-equation" src="img/5666a423-e13a-481e-9f41-42277b0ee5b4.png" style="width:0.67em;height:0.75em;"/>的损失函数可给出如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/6b7edf58-4bda-435f-b4e3-87cdfd384ec2.png" style="width:14.25em;height:1.67em;"/></p>

<p>总的来说，最终损失可以写成如下形式:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/cabb8433-6bad-4d41-95ce-c60c6ab50bff.png" style="width:14.58em;height:1.25em;"/></p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Cycle consistency loss</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">循环一致性损失</h1>

                

            

            

                

<p>对抗损失本身并不能确保图像的正确映射。例如，生成器可以将来自源域的图像映射到可以匹配目标分布的目标域中的图像的随机排列。</p>

<p>因此，为了避免这种情况，我们引入一种称为<strong xmlns:epub="http://www.idpf.org/2007/ops">周期一致lo</strong>T9】ss的额外损耗。它强制两个发生器<em xmlns:epub="http://www.idpf.org/2007/ops"> G </em>和<em xmlns:epub="http://www.idpf.org/2007/ops"> F </em>保持周期一致。</p>

<p>让我们回忆一下发电机的功能:</p>

<ul>

<li><strong xmlns:epub="http://www.idpf.org/2007/ops">发生器<em>G</em>T18】:将<em xmlns:epub="http://www.idpf.org/2007/ops"> x </em>转换为<em xmlns:epub="http://www.idpf.org/2007/ops"> y </em></strong></li>

<li><strong xmlns:epub="http://www.idpf.org/2007/ops">发生器<em>F</em>T26】:将<em xmlns:epub="http://www.idpf.org/2007/ops"> y </em>转换为<em xmlns:epub="http://www.idpf.org/2007/ops"> x </em></strong></li>

</ul>

<p>我们知道生成器<em> G </em>获取源图像<em> x </em>并将其转换为假目标图像<em> y </em>。现在，如果我们将这个生成的假目标图像<em> y </em>提供给生成器<em> F </em>，它必须返回原始源图像<em> x </em>。很困惑，对吧？</p>

<p>看下图；我们有一个源图像，<em> x </em>。首先，我们将这个图像提供给生成器<em> G </em>，它返回假的目标图像。现在我们获取这个假的目标图像，<em> y </em>，并将其馈送给生成器<em> F </em>，它必须返回原始的源图像:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/2acdf8f9-b887-4af7-a557-2ecf88bb42fe.png" style="width:10.25em;height:1.00em;"/></p>

<p>上述等式可以表示如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-874 image-border" src="img/16f10554-ff0c-45c7-bb4e-726914dd8b4f.png" style="width:23.67em;height:16.75em;"/></p>

<p>这被称为<strong>前向一致性丢失</strong>，可以表示如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/b3cde238-f5f1-4b51-ab2e-45b3b7e229ec.png" style="width:13.33em;height:1.33em;"/></p>

<p>同样，我们可以指定向后一致损失，如下图所示。假设我们有一个原始目标图像，<em> y </em>。我们将这个<em> y </em>馈送给鉴别器<em> F </em>，它返回伪源图像<em> x </em>。现在我们将这个假的源图像<em> x </em>馈送给生成器<em> G </em>，它必须返回原始的目标图像<em> y </em>:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/28cc50f4-c98d-4edb-868b-32c46c7169d9.png" style="width:10.83em;height:1.08em;"/></p>

<p>前面的等式可以表示为:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-875 image-border" src="img/e90a057d-6622-4304-b62f-6544beced8e6.png" style="width:24.42em;height:16.92em;"/></p>

<p>向后一致性损失可以表示如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/9527c35d-b8c7-48cd-8cb1-b004a7228ca9.png" style="width:13.42em;height:1.33em;"/></p>

<p>因此，加上前向和后向一致性损失，我们可以将周期一致性损失写成:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/921caae3-cc6c-4005-8cc1-87399e37c099.png" style="width:12.25em;height:1.17em;"/></p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/3fc60b22-7713-48c1-a1a0-9ab1596b4486.png" style="width:25.17em;height:1.50em;"/></p>

<p>我们希望我们的发电机循环一致，因此，我们用循环一致损耗乘以它们的损耗。因此，最终损失函数可由下式给出:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/77f55660-3c8a-42e3-a6d8-1eea3b607e54.png" style="width:14.92em;height:1.25em;"/></p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Converting photos to paintings using a CycleGAN</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">使用CycleGAN将照片转换为绘画</h1>

                

            

            

                

<p>现在我们将学习如何在TensorFlow中实现一个CycleGAN。我们将了解如何使用CycleGAN将图片转换为绘画:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1285 image-border" src="img/c98cbbab-07be-4a1e-ada3-198683726f4a.png" style="width:30.08em;height:10.42em;"/></p>

<p>本节使用的数据集可以从<a href="https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/monet2photo.zip" target="_blank">https://people . eecs . Berkeley . edu/~ tae sung _ park/cycle gan/datasets/Monet 2 photo . zip</a>下载。下载完数据集后，解压存档文件；它将由四个文件夹组成，<kbd>trainA</kbd>、<kbd>trainB</kbd>、<kbd>testA</kbd>和<kbd>testB</kbd>，包含训练和测试图像。</p>

<p><kbd>trainA</kbd>文件夹包含油画(莫奈)，而<kbd>trainB</kbd>文件夹包含照片。由于我们将照片(<em> x </em>)映射到绘画(<em> y </em>)，包含照片的<kbd>trainB</kbd>文件夹将是我们的源图像，<img class="fm-editor-equation" src="img/1b539a3e-4e00-4e5a-9f26-6f8824318419.png" style="width:0.42em;height:0.42em;"/>，包含绘画的<kbd>trainA</kbd>文件夹将是我们的目标图像，<img class="fm-editor-equation" src="img/413d8fcb-4439-4bc7-952e-21ec209ba5b7.png" style="width:0.42em;height:0.75em;"/>。</p>

<p>CycleGAN的完整代码以及一步一步的解释可以在Jupyter笔记本上找到，网址是<a href="https://github.com/PacktPublishing/Hands-On-Deep-Learning-Algorithms-with-Python">https://github . com/packt publishing/Hands-On-Deep-Learning-Algorithms-with-Python</a>。</p>

<p>我们将只看如何在TensorFlow中实现CycleGAN并将源图像映射到目标域，而不是看整个代码。你也可以在<a href="https://github.com/PacktPublishing/Hands-On-Deep-Learning-Algorithms-with-Python">https://github . com/packt publishing/Hands-On-Deep-Learning-Algorithms-with-Python</a>查看完整代码。</p>

<p>定义<kbd>CycleGAN</kbd>类:</p>

<pre>class CycleGAN:<br/>        def __init__(self):</pre>

<p>定义输入的占位符<kbd>X</kbd>和输出的占位符<kbd>Y</kbd>:</p>

<pre>        self.X = tf.placeholder("float", shape=[batchsize, image_height, image_width, 3])<br/>        self.Y = tf.placeholder("float", shape=[batchsize, image_height, image_width, 3])</pre>

<p>定义将<img class="fm-editor-equation" src="img/56fe4f4b-9eda-4272-8872-10529152edae.png" style="width:0.50em;height:0.50em;"/>映射到<img class="fm-editor-equation" src="img/9c32ba4d-98d2-44d7-aeb6-d768786c4630.png" style="width:0.58em;height:1.00em;"/>的生成器<img class="fm-editor-equation" src="img/182c4d15-8ba5-40f8-b249-97c18125d781.png" style="width:0.50em;height:0.50em;"/>:</p>

<pre>        G = generator("G")</pre>

<p>定义将<img class="fm-editor-equation" src="img/5f3eaf60-fe74-4775-a7d9-3cc407a97c35.png" style="width:0.42em;height:0.67em;"/>映射到<img class="fm-editor-equation" src="img/d45bf48f-aada-4436-ac4f-b125d352e8b1.png" style="width:0.58em;height:0.67em;"/>的生成器<img class="fm-editor-equation" src="img/36bef03d-9e31-47c0-82c4-5fca2416aad6.png" style="width:0.75em;height:0.83em;"/>:</p>

<pre>        F = generator("F")</pre>

<p>定义鉴别器<img class="fm-editor-equation" src="img/3a6cab69-81bb-4464-ab61-c35a59115f15.png" style="width:1.08em;height:0.83em;"/>，用于鉴别真实源图像和伪造源图像:</p>

<pre>         self.Dx = discriminator("Dx")       </pre>

<p>定义鉴别器<img class="fm-editor-equation" src="img/356ef7c9-c99f-4961-b689-ac89e4523e90.png" style="width:1.42em;height:1.17em;"/>，用于鉴别真实目标图像和虚假目标图像:</p>

<pre>        self.Dy = discriminator("Dy")</pre>

<p>生成伪源图像:</p>

<pre>        self.fake_X = F(self.Y)</pre>

<p>生成假目标图像:</p>

<pre>        self.fake_Y = G(self.X)        </pre>

<p class="mce-root"/>

<p>得到<kbd>logits</kbd>:</p>

<pre>        #real source image logits<br/>        self.Dx_logits_real = self.Dx(self.X) <br/>        <br/><br/>        #fake source image logits<br/>        self.Dx_logits_fake = self.Dx(self.fake_X, True)<br/><br/>        <br/>        #real target image logits<br/>        self.Dy_logits_fake = self.Dy(self.fake_Y, True)<br/><br/>        <br/>        #fake target image logits<br/>        self.Dy_logits_real = self.Dy(self.Y)</pre>

<p>我们知道循环一致性损失给出如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/1b2a7610-0aa3-445a-a9a5-47650edd03e9.png" style="width:20.92em;height:1.17em;"/></p>

<p>我们可以如下实现周期一致性丢失:</p>

<pre>        self.cycle_loss = tf.reduce_mean(tf.abs(F(self.fake_Y, True) - self.X)) + \<br/>                        tf.reduce_mean(tf.abs(G(self.fake_X, True) - self.Y))</pre>

<p>定义我们两个鉴别器<img class="fm-editor-equation" src="img/3e052ee5-2ec7-44d5-a708-309775749f01.png" style="width:1.08em;height:0.83em;"/>和<img class="fm-editor-equation" src="img/cc26f199-c253-4dde-8238-3cbe052233ed.png" style="width:1.17em;height:1.00em;"/>的损失。</p>

<p>我们可以用Wasserstein距离重写鉴别器的损失函数:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/dfe69197-13a3-4fd4-8cc2-6b43783a27f5.png" style="width:14.92em;height:1.33em;"/></p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/112ce76a-1cec-4244-b827-b6779ad589d3.png" style="width:14.83em;height:1.33em;"/></p>

<p>因此，鉴频器的损耗实现如下:</p>

<pre>        self.Dx_loss = -tf.reduce_mean(self.Dx_logits_real) + tf.reduce_mean(self.Dx_logits_fake) <br/>                 <br/>        self.Dy_loss = -tf.reduce_mean(self.Dy_logits_real) + tf.reduce_mean(self.Dy_logits_fake)</pre>

<p>定义两个发电机的损耗，<img class="fm-editor-equation" src="img/5a278307-2f9e-4d77-997b-5ca957c0ddeb.png" style="width:0.75em;height:0.83em;"/>和<img class="fm-editor-equation" src="img/89c696f8-ad04-4042-a889-c93eb7505a7d.png" style="width:0.67em;height:0.75em;"/>。我们可以用Wasserstein距离将发电机的损失函数改写为:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/433704ef-29de-4c76-b26c-de00e1561b24.png" style="width:9.92em;height:1.33em;"/></p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/4a705c83-3217-4ded-8f50-660f415c4073.png" style="width:10.42em;height:1.42em;"/></p>

<p>因此，两个发电机的损耗乘以循环一致性损耗，<kbd>cycle_loss</kbd>实现为:</p>

<pre>        self.G_loss = -tf.reduce_mean(self.Dy_logits_fake) + 10. * self.cycle_loss<br/><br/>        self.F_loss = -tf.reduce_mean(self.Dx_logits_fake) + 10. * self.cycle_loss</pre>

<p>使用Adam优化器优化鉴别器和生成器:</p>

<pre>       #optimize the discriminator<br/>        self.Dx_optimizer = tf.train.AdamOptimizer(2e-4, beta1=0., beta2=0.9).minimize(self.Dx_loss, var_list=[self.Dx.var])<br/><br/><br/>        self.Dy_optimizer = tf.train.AdamOptimizer(2e-4, beta1=0., beta2=0.9).minimize(self.Dy_loss, var_list=[self.Dy.var])<br/>      <br/><br/>        #optimize the generator<br/>        self.G_optimizer = tf.train.AdamOptimizer(2e-4, beta1=0., beta2=0.9).minimize(self.G_loss, var_list=[G.var])<br/><br/><br/>        self.F_optimizer = tf.train.AdamOptimizer(2e-4, beta1=0., beta2=0.9).minimize(self.F_loss, var_list=[F.var])</pre>

<p class="mce-root">一旦我们开始训练模型，我们可以看到鉴别器和生成器的损失如何随着迭代而减少:</p>

<pre>Epoch: 0, iteration: 0, Dx Loss: -0.6229429245, Dy Loss: -2.42867970467, G Loss: 1385.33557129, F Loss: 1383.81530762, Cycle Loss: 138.448059082





Epoch: 0, iteration: 50, Dx Loss: -6.46077537537, Dy Loss: -7.29514217377, G Loss: 629.768066406, F Loss: 615.080932617, Cycle Loss: 62.6807098389





Epoch: 1, iteration: 100, Dx Loss: -16.5891685486, Dy Loss: -16.0576553345, G Loss: 645.53137207, F Loss: 649.854919434, Cycle Loss: 63.9096908569</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>StackGAN</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">斯塔克根</h1>

                

            

            

                

<p>现在我们将看到一种最有趣、最迷人的GAN，它被称为<strong>堆叠GAN </strong>。如果我说StackGANs仅仅基于文本描述就能生成照片般逼真的图像，你能相信吗？嗯，是的。他们能做到。给定文本描述，它们可以生成逼真的图像。</p>

<p class="mce-root">我们先来了解一下艺术家是如何画出一个形象的。在第一阶段，艺术家绘制原始形状，并创建一个基本的轮廓，形成图像的初始版本。在下一阶段，他们通过使图像更加真实和吸引人来增强图像。</p>

<p class="mce-root">StackGANs以类似的方式工作。他们将生成图像的过程分为两个阶段。就像艺术家绘画一样，在第一阶段，他们生成一个基本的轮廓，原始的形状，并创建一个低分辨率版本的图像，在第二阶段，他们通过使其更加逼真来增强第一阶段生成的图片，然后将它们转换为高分辨率的图像。</p>

<p class="mce-root">但是StackGANs是怎么做到的呢？</p>

<p class="mce-root">他们使用两个GANs，每个阶段一个。第一级中的GAN生成基本图像并将其发送到下一级中的GAN，下一级将基本低分辨率图像转换成适当的高分辨率图像。下图显示了StackGANs如何根据文本描述在每个阶段生成图像:</p>

<p class="mce-root CDPAlignCenter CDPAlign"><img src="img/d14ffa08-2b92-42b6-9faf-41852ea42806.png" style="font-size: 1em;text-align: center;width:42.00em;height:14.83em;"/></p>

<p>资料来源:https://arxiv.org/pdf/1612.03242.pdf</p>

<div><p class="mce-root">正如你所看到的，在第一阶段，我们有一个低分辨率版本的图像，但在第二阶段，我们有良好的清晰度高分辨率图像。但是，StackGAN是怎么做到的呢？还记得吗，当我们学习有条件的GAN时，我们可以通过调节它们来使GAN生成我们想要的图像。</p>

</div>

<p>我们只是在两个阶段都用到它们。在第一阶段，我们的网络是基于文本描述的。有了这个文本描述，他们就生成了一个图像的基本版本。在第二阶段，我们的网络基于第一阶段生成的图像以及文本描述进行调节。</p>

<p>但是为什么我们在第二阶段又要以文字描述为条件呢？因为在第一阶段，我们错过了文本描述中指定的一些细节来创建图像的基本版本。因此，在第二阶段，我们再次以文本描述为条件来修复缺失的信息，并使我们的图像更加真实。</p>

<p>凭借这种仅基于文本生成图片的能力，它被用于许多应用。它在娱乐业中被大量使用，例如，仅仅基于描述创建框架，它也可以用于生成漫画等等。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>The architecture of StackGANs</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">堆栈根的架构</h1>

                

            

            

                

<p>现在我们已经对StackGANs的工作原理有了一个基本的了解，我们将更仔细地研究它们的架构，看看它们是如何从文本中生成图片的。</p>

<p>下图显示了堆栈根的完整体系结构:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/75cf1c71-6b88-4b7f-a1e4-f37f5487a4c6.png"/></p>

<p>资料来源:https://arxiv.org/pdf/1612.03242.pdf</p>

<p>我们将逐一查看每个组件。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Conditioning augmentation</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">条件增强</h1>

                

            

            

                

<p>我们有一个文本描述作为GAN的输入。基于这些描述，它必须生成图像。但是他们是如何理解文字的含义来生成图片的呢？</p>

<p>首先，我们使用编码器将文本转换成嵌入文本。我们用<img class="fm-editor-equation" src="img/a67e3253-5674-4278-921d-8eefb3a31d98.png" style="font-size: 1em;width:0.83em;height:0.67em;"/>来表示这个文本嵌入。我们能创造出<img class="fm-editor-equation" src="img/a67e3253-5674-4278-921d-8eefb3a31d98.png" style="font-size: 1em;width:1.17em;height:0.92em;"/>的变体吗？通过创建文本嵌入的变体，<img class="fm-editor-equation" src="img/a67e3253-5674-4278-921d-8eefb3a31d98.png" style="font-size: 1em;width:0.92em;height:0.75em;"/>，我们可以有额外的训练对，并且我们还可以增加对小扰动的鲁棒性。</p>

<p>设<img class="fm-editor-equation" src="img/3ecca366-0d12-43d0-8ba6-d70d5af45f18.png" style="width:2.50em;height:1.08em;"/>为均值，<img class="fm-editor-equation" src="img/00891861-b74f-4d4b-849d-aadc3615125b.png" style="width:2.58em;height:1.08em;"/>为我们文本嵌入的对角协方差矩阵，<img class="fm-editor-equation" src="img/a67e3253-5674-4278-921d-8eefb3a31d98.png" style="width:1.00em;height:0.83em;"/>。现在我们从独立的高斯分布<img class="fm-editor-equation" src="img/0cde2c39-1d06-4b38-9ee5-95e83080118f.png" style="width:6.00em;height:0.92em;"/>中随机抽取一个额外的条件变量<img class="fm-editor-equation" src="img/ae68020a-8f9d-4252-9ae7-b7647563f4cb.png" style="width:0.42em;height:0.67em;"/>。它帮助我们创造不同的文本描述和它们的含义。我们知道相同的文本可以用不同的方式书写，所以使用条件变量<img class="fm-editor-equation" src="img/ae68020a-8f9d-4252-9ae7-b7647563f4cb.png" style="width:0.50em;height:0.75em;"/>，我们可以将不同版本的文本映射到图像。</p>

<p>因此，一旦我们有了文本描述，我们将使用编码器提取它们的嵌入，然后我们计算它们的均值和协方差。然后，我们从文本嵌入的高斯分布中采样<img class="fm-editor-equation" src="img/ae68020a-8f9d-4252-9ae7-b7647563f4cb.png" style="width:0.83em;height:1.33em;"/>，<img class="fm-editor-equation" src="img/a67e3253-5674-4278-921d-8eefb3a31d98.png" style="font-size: 1em;width:1.08em;height:0.83em;"/>。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Stage I</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">第一阶段</h1>

                

            

            

                

<p>好了，现在我们有一个文本嵌入，<img class="fm-editor-equation" src="img/b98b457b-5113-4138-87a1-5ecc312f9ee4.png" style="width:1.17em;height:0.92em;"/>，还有一个条件变量，<img class="fm-editor-equation" src="img/2d0a756c-3fa1-4604-8921-217706c768a7.png" style="width:0.58em;height:0.92em;"/>。我们将看到它是如何被用来生成图像的基本版本的。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Generator</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">发电机</h1>

                

            

            

                

<p>我们知道生成器的目标是通过学习真实的数据分布来生成一个假图像。首先，我们从高斯分布中采样噪声，并创建<em> z </em>。然后，我们将<em> z </em>与我们的条件变量<img class="fm-editor-equation" src="img/2049be92-cbff-4589-9f92-654889e904da.png" style="width:0.67em;height:1.08em;"/>连接起来，并将其作为输入提供给生成器，该生成器输出图像的基本版本。</p>

<p>发电机的损耗函数如下所示:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/3563799a-e439-4332-81d9-9870c6fb465f.png" style="width:21.58em;height:1.42em;"/></p>

<p>让我们来看看这个公式:</p>

<ul>

<li><img class="fm-editor-equation" src="img/8fefbb15-57bb-408f-a6f4-18edae972eec.png" style="width:3.00em;height:0.83em;"/>表示我们从伪数据分布中抽取z样本，即噪声先验。</li>

<li><img class="fm-editor-equation" src="img/aa262917-373b-423e-b8ff-5295ea45fa41.png" style="width:3.17em;height:1.17em;"/>暗示我们从真实数据分布中抽取文本描述<img class="fm-editor-equation" src="img/045cf8e4-5c8b-4dcc-a914-8e2e7bcc15ef.png" style="width:0.50em;height:1.08em;"/>。</li>

<li><img class="fm-editor-equation" src="img/8a6a0eeb-b335-4e97-b511-4fe7c92f8d02.png" style="font-size: 1em;color: #333333;width:4.33em;height:1.25em;"/>暗示发生器获取噪声，调节变量返回图像。我们将生成的图像提供给鉴别器。</li>

<li><img class="fm-editor-equation" src="img/89856ddf-2b18-4581-a8e3-4d502f407bf8.png" style="font-size: 1em;color: #333333;width:10.67em;height:1.25em;"/>暗示生成的图像是假的对数概率。</li>

</ul>

<p>除了这种损失，我们还将正则项<img class="fm-editor-equation" src="img/fa97f5c1-7daa-4454-b679-108d3f13d2c5.png" style="width:17.08em;height:1.25em;"/>添加到我们的损失函数中，这意味着标准高斯分布和条件高斯分布之间的KL散度。这有助于我们避免过度拟合。</p>

<p>因此，发电机的最终损失函数变为:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/f75101c3-d7b2-4b82-b0fb-027f1e3cf0f2.png" style="width:37.75em;height:1.83em;"/></p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Discriminator</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">鉴别器</h1>

                

            

            

                

<p>现在，我们将生成的图像提供给鉴别器，鉴别器返回图像真实的概率。鉴频器损耗计算如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/ff6aed90-dd55-40f7-9541-dfd28d64318d.png" style="width:32.00em;height:1.83em;"/></p>

<p>这里:</p>

<ul>

<li><img class="fm-editor-equation" src="img/cf8d3d28-dce2-4c91-9fb5-d57329b166e1.png" style="width:5.08em;height:1.25em;"/>暗示真实的图像，<img class="fm-editor-equation" src="img/79417429-af4b-4492-86f7-dbe46ae3762a.png" style="width:1.00em;height:1.17em;"/>，以文字描述为条件，<img class="fm-editor-equation" src="img/788b3eff-5b35-41c9-b2d4-03cecadd3ba2.png" style="width:1.17em;height:0.92em;"/></li>

<li><img class="fm-editor-equation" src="img/59e7da3c-1310-432d-8855-869dc1caa9bd.png" style="width:4.33em;height:1.25em;"/>暗示生成的假图像</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Stage II</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">第二阶段</h1>

                

            

            

                

<p>我们已经了解了第一阶段如何生成图像的基本版本。现在，在第二阶段，我们修复了第一阶段生成的图像的缺陷，并生成了更真实的图像版本。我们用前一阶段生成的图像以及文本嵌入来调节我们的网络。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Generator</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">发电机</h1>

                

            

            

                

<p>阶段II中的生成器不是将噪声作为输入，而是将前一阶段生成的图像作为输入，并且它以文本描述为条件。</p>

<p>这里，<img class="fm-editor-equation" src="img/dfdca6f9-f1c9-4754-bb16-1dd14a2485c4.png" style="width:4.67em;height:1.08em;"/>意味着我们从<img class="fm-editor-equation" src="img/385a1be2-69ec-4ebd-bdd7-eade9473467c.png" style="width:1.75em;height:1.00em;"/>中抽取<img class="fm-editor-equation" src="img/4412e70a-76f9-42cf-a621-441ef7c58ff1.png" style="width:1.17em;height:0.92em;"/>。这基本上意味着我们正在对第一阶段生成的图像进行采样。</p>

<p><img class="fm-editor-equation" src="img/532013c8-a184-4d77-b833-45398433ea46.png" style="width:2.50em;height:0.92em;"/>暗示我们正在从给定的真实数据分布中抽取文本，<img class="fm-editor-equation" src="img/5ebebb89-77fd-4d4b-b3e3-7dfcde29d765.png" style="width:1.17em;height:0.92em;"/>。</p>

<p>那么发电机损耗可由下式给出:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/5a59d6ec-a0dc-4b5b-a7cc-0b37e179e788.png" style="width:18.92em;height:1.42em;"/></p>

<p>随着正则化，我们的发电机的损失函数变成:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/ecc0d204-c26a-429a-802d-bca587641079.png" style="width:32.08em;height:1.83em;"/></p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Discriminator</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">鉴别器</h1>

                

            

            

                

<p>鉴别器的目标是告诉我们图像是来自真实分布还是生成器分布。因此，鉴频器的损耗函数如下所示:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/f51864d9-cdd0-4a47-a689-6c2f3823d189.png" style="width:26.67em;height:1.83em;"/></p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Summary</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">摘要</h1>

                

            

            

                

<p>本章一开始，我们学习了条件句，以及如何用它们来生成我们感兴趣的图像。</p>

<p>后来，我们学习了InfoGANs，在info gans中，代码<em> c </em>是根据生成的输出自动推断出来的，不像CGAN，在CGAN中我们显式地指定了<em> c </em>。为了推断出<em> c </em>，我们需要找到后验概率<img class="fm-editor-equation" src="img/6681a392-47b2-4fde-b928-ea3e9dd3f0e7.png" style="width:4.17em;height:0.92em;"/>，而我们没有这个后验概率。所以，我们使用辅助分布。我们使用互信息来最大化互信息<img class="fm-editor-equation" src="img/30eec497-b316-4712-8e24-0cc194eb757e.png" style="width:4.50em;height:1.00em;"/>，在给定发电机输出的情况下，最大化我们关于<em> c </em>的知识。</p>

<p>然后，我们学习了CycleGANs，它将数据从一个域映射到另一个域。我们试图学习从照片领域的图像分布到绘画领域的图像分布的映射。最后，我们理解了StackGANs是如何从文本描述生成照片级真实感图像的。</p>

<p>在下一章，我们将学习自动编码器<strong xmlns:epub="http://www.idpf.org/2007/ops">和它们的类型。</strong></p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Questions</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">问题</h1>

                

            

            

                

<p>回答以下问题，衡量你从本章中学到了多少:</p>

<ol>

<li>条件甘和香草甘有什么不同？</li>

<li>InfoGAN中的代码叫什么？</li>

<li>什么是互信息？</li>

<li>为什么我们在InfoGANs中需要辅助分发？</li>

<li>什么是周期一致性损失？</li>

<li>解释发电机在循环发电中的作用。</li>

<li>StackGANs如何把文字描述转换成图片？</li>

</ol>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Further reading</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">进一步阅读</h1>

                

            

            

                

<p>有关更多信息，请参考以下链接:</p>

<ul>

<li><em>迈赫迪·米尔扎和西蒙·奥森德罗的条件生成对抗网络</em>，<a href="https://arxiv.org/pdf/1411.1784.pdf">https://arxiv.org/pdf/1411.1784.pdf</a></li>

<li><em> InfoGAN:通过信息最大化生成对抗网的可解释表示学习</em>陈曦等人，<a href="https://arxiv.org/pdf/1606.03657.pdf">https://arxiv.org/pdf/1606.03657.pdf</a></li>

<li><em>使用循环一致对抗网络的不成对图像到图像翻译</em>朱俊彦等人，<a href="https://arxiv.org/pdf/1703.10593.pdf">https://arxiv.org/pdf/1703.10593.pdf</a></li>

</ul>





            



            

        

    </body>



</html></body></html>