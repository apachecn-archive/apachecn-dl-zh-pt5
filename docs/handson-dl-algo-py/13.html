<html><head/><body><html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Reconstructing Inputs Using Autoencoders</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">使用自动编码器重构输入</h1>

                

            

            

                

<p class="mce-root"><strong>自动编码器</strong>是无监督学习算法。与其他算法不同，自动编码器学习重建输入，也就是说，自动编码器接受输入，并学习将输入作为输出再现。我们从理解什么是自动编码器以及它们如何准确地重建输入开始这一章。然后，我们将学习自动编码器如何重建MNIST图像。</p>

<p class="mce-root">接下来，我们将了解自动编码器的不同变体；首先，我们将了解使用卷积层的<strong>卷积自动编码器</strong>(<strong>CAEs</strong>)；然后，我们将了解<strong>如何对自动编码器</strong>(<strong>DAE</strong>)进行去噪，这些编码器学习去除输入中的噪声。在此之后，我们将了解稀疏自动编码器以及它们如何从稀疏输入中学习。在本章的最后，我们将学习一种有趣的生成型自动编码器，叫做<strong>变型自动编码器</strong>。我们将理解变分自动编码器如何学习生成新的输入，以及它们与其他自动编码器有何不同。</p>

<p>在本章中，我们将讨论以下主题:</p>

<ul>

<li>自动编码器及其体系结构</li>

<li>使用自动编码器重建MNIST图像</li>

<li>卷积自动编码器</li>

<li>构建卷积自动编码器</li>

<li>降噪自动编码器</li>

<li>使用去噪自动编码器去除图像中的噪声</li>

<li>稀疏自动编码器</li>

<li>收缩自动编码器</li>

<li>可变自动编码器</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>What is an autoencoder?</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">什么是自动编码器？</h1>

                

            

            

                

<p>自动编码器是一种有趣的无监督学习算法。与其他神经网络不同，自动编码器的目标是重构给定的输入；也就是说，自动编码器的输出与输入相同。它由两个重要部件组成，称为<strong>编码器</strong>和<strong>解码器</strong>。</p>

<p>编码器的作用是通过学习输入的潜在表示对输入进行编码，解码器的作用是从编码器产生的潜在表示中重建输入。这种潜在的表现也被称为<strong>瓶颈</strong>或<strong>代码</strong>。如下图所示，图像作为输入传递给自动编码器。编码器获取图像并学习图像的潜在表示。解码器获取潜在表示，并尝试重建图像:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1720 image-border" src="img/e8c5f6fa-9522-4fc2-b1a8-f10d4e451148.png" style="width:31.92em;height:14.92em;"/></p>

<p>下图显示了一个简单的两层自动编码器；您可能已经注意到，它由输入层、隐藏层和输出层组成。首先，我们将输入馈送到输入层，然后编码器学习输入的表示并将其映射到瓶颈。从瓶颈开始，解码器重建输入:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1696 image-border" src="img/08400dbf-eb6e-4d1d-b6b2-8189fc9b2542.png" style="width:29.25em;height:22.92em;"/></p>

<p>我们可能想知道这有什么用。为什么我们需要对输入进行编码和解码？为什么我们只需要重建输入？嗯，有各种各样的应用，比如降维、数据压缩、图像去噪等等。</p>

<p>由于自动编码器会重构输入，因此输入层和输出层中的节点数总是相同的。假设我们有一个包含100个输入要素的数据集，并且我们有一个输入层为100个单元、隐藏层为50个单元、输出层为100个单元的神经网络。当我们将数据集提供给自动编码器时，编码器试图学习数据集中的重要特征，并将特征的数量减少到50个，从而形成瓶颈。瓶颈包含数据的表示，即数据的嵌入，并且只包含必要的信息。然后，瓶颈被馈送到解码器以重构原始输入。如果解码器成功地重建了原始输入，则意味着编码器已经成功地学习了给定输入的编码或表示。也就是说，编码器通过捕获必要的信息，成功地将包含100个要素的数据集编码或压缩为仅包含50个要素的表示。</p>

<p>因此，本质上，编码器试图学习在不丢失有用信息的情况下减少数据的维数。我们可以认为自动编码器类似于降维技术，如<strong>主成分分析</strong> ( <strong> PCA </strong>)。在PCA中，我们使用线性变换将数据投影到低维中，并移除不需要的特征。PCA和自动编码器的区别在于，PCA使用线性变换进行降维，而自动编码器使用非线性变换。</p>

<p>除了降维，自动编码器还广泛用于图像、音频等的去噪。我们知道，自动编码器中的编码器通过只学习必要的信息来降低数据集的维数，并形成瓶颈或代码。因此，当有噪声的图像作为输入被馈送到自动编码器时，编码器仅学习图像的必要信息，并形成瓶颈。由于编码器只学习表示图像的重要和必要的信息，因此它知道噪声是不想要的信息，并从瓶颈中去除噪声的表示。</p>

<p>因此，现在我们将有一个瓶颈，即没有任何噪声信息的图像表示。当编码器的这种学习表示(即瓶颈)被提供给解码器时，解码器从编码器产生的编码中重建输入图像。由于编码没有噪声，重建的图像将不包含任何噪声。</p>

<p class="mce-root">简而言之，自动编码器将我们的高维数据映射到低级别表示。数据的这种低级数据表示被称为<strong>潜在表示</strong>或<strong>瓶颈</strong>，它们仅具有表示输入的有意义且重要的特征。</p>

<p class="mce-root">由于我们的自动编码器的作用是重建其输入，我们使用重建误差作为我们的损失函数，这意味着我们试图了解有多少输入被解码器正确地重建。因此，我们可以使用均方误差损失作为损失函数来量化自动编码器的性能。</p>

<p>现在我们已经了解了什么是自动编码器，我们将在下一节中探索自动编码器的架构。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Understanding the architecture of autoencoders</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">了解自动编码器的架构</h1>

                

            

            

                

<p>正如我们刚刚了解到的，自动编码器由两个重要组件组成:一个编码器<img class="fm-editor-equation" src="img/c65fad3f-6838-4bf8-b679-003d28baa3a7.png" style="width:2.08em;height:1.08em;"/>和一个解码器<img class="fm-editor-equation" src="img/cf3ce104-f87f-4ab7-835c-c995932034e4.png" style="width:2.42em;height:1.25em;"/>。让我们仔细看看其中的每一个:</p>

<ul>

<li><strong>编码器</strong>:编码器<img class="fm-editor-equation" src="img/9a47e5e0-17ff-4efe-b17e-b17526fa5cb4.png" style="width:1.58em;height:1.00em;"/>学习输入并返回输入的潜在表示。假设我们有一个输入，<img class="fm-editor-equation" src="img/4470ee88-2391-41ec-9171-68702209ff03.png" style="width:0.83em;height:0.83em;"/>。当我们将输入馈送给编码器时，它返回一个低维的输入潜在表示，称为代码或瓶颈，<img class="fm-editor-equation" src="img/91e148bc-9386-4668-9944-9e6df178308c.png" style="width:0.75em;height:0.92em;"/>。我们用<img class="fm-editor-equation" src="img/321cd6ec-64b6-4d9f-b925-56f95d03b72d.png" style="width:0.58em;height:1.00em;"/>表示编码器的参数:</li>

</ul>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/a82daa05-5fb1-43df-84c2-c2a4b7f2c50e.png" style="width:4.83em;height:1.33em;"/></p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/4bfa12c0-9d86-429e-b58f-a354d5f6a92b.png" style="width:6.50em;height:1.25em;"/></p>

<ul>

<li><strong>解码器</strong>:解码器<img class="fm-editor-equation" src="img/d1fb2440-9b44-452c-878f-3b0e32ac279b.png" style="width:1.50em;height:1.00em;"/>试图使用编码为<img class="fm-editor-equation" src="img/ff91f3f9-49f1-4b43-abc4-176737c14fc1.png" style="width:0.75em;height:1.00em;"/>的编码器的输出作为输入来重建原始输入<img class="fm-editor-equation" src="img/cff89e6e-fe17-4a4c-a132-24984ddd4d06.png" style="width:0.92em;height:0.92em;"/>。重建图像由<img class="fm-editor-equation" src="img/8166f7f5-d832-4f16-a73d-ccf5e48e894f.png" style="width:0.83em;height:0.92em;"/>表示。我们用<img class="fm-editor-equation" src="img/3d8f2b54-3177-4537-98d4-c0a90116f100.png" style="width:0.75em;height:1.42em;"/>表示解码器的参数:</li>

</ul>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/f30df43a-7e30-4226-8a47-1d1ca038d699.png" style="width:5.42em;height:1.50em;"/></p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/8a27d14b-69f3-46fb-8045-597e058b1932.png" style="width:8.00em;height:1.50em;"/></p>

<p>我们需要分别学习我们的编码器和解码器的最佳参数<img class="fm-editor-equation" src="img/bfdff208-233d-410f-9bf8-a9d9b8ba6aaa.png" style="width:0.75em;height:1.33em;"/>和<img class="fm-editor-equation" src="img/3ab8fb2d-f6e3-404b-85e5-1410304272ef.png" style="width:0.92em;height:1.67em;"/>，以便我们可以最小化重建损失。我们可以将损失函数定义为实际输入和重构输入之间的均方误差:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/7fda0da7-1495-4aed-a959-687fcf7eb9fb.png" style="width:16.92em;height:3.33em;"/></p>

<p>这里，<img class="fm-editor-equation" src="img/aa817e65-f1ca-498f-9e6f-147c514a640c.png" style="width:0.83em;height:0.83em;"/>是训练样本数。</p>

<p>当潜在表示的维数小于输入时，它被称为<strong>欠完整自动编码器。</strong>由于维数较少，欠完整自动编码器试图学习并保留输入中唯一有用的区分和重要特征，并删除其余特征。当潜在表示的维数大于或等于输入时，自动编码器将只是复制输入，而不学习任何有用的特征，这种类型的自动编码器被称为<strong>过完全自动编码器</strong>。</p>

<p class="mce-root"/>

<p>下图显示了欠完整和过完整自动编码器。欠完整自动编码器在隐藏层(代码)中的神经元比输入层中的神经元数量少；而在过完备自动编码器中，隐藏层(代码)中的神经元数量大于输入层中的单元数量:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-183 image-border" src="img/1fceabe6-527b-4d7b-853b-680a094ec75d.png" style="width:28.58em;height:23.08em;"/></p>

<p>因此，通过限制隐藏层(代码)中的神经元，我们可以学习输入的有用表示。自动编码器也可以有任意数量的隐藏层。具有多个隐藏层的自动编码器被称为<strong>多层自动编码器</strong>或<strong>深度自动编码器</strong>。到目前为止，我们所知道的只是<strong>普通的</strong>或<strong>浅层自动编码器</strong>。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Reconstructing the MNIST images using an autoencoder</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">使用自动编码器重建MNIST图像</h1>

                

            

            

                

<p>现在我们将学习自动编码器如何使用MNIST数据集重建手写数字。首先，让我们导入必要的库:</p>

<pre class="mce-root">import warnings<br/>warnings.filterwarnings('ignore')<br/><br/>import numpy as np<br/>import tensorflow as tf<br/><br/>from tensorflow.keras.models import Model<br/>from tensorflow.keras.layers import Input, Dense<br/>tf.logging.set_verbosity(tf.logging.ERROR)<br/><br/>#plotting<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline<br/><br/>#dataset<br/>from tensorflow.keras.datasets import mnist</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Preparing the dataset</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">准备数据集</h1>

                

            

            

                

<p class="mce-root">让我们加载MNIST数据集。因为我们正在重构给定的输入，所以我们不需要标签。因此，我们只加载<kbd>x_train</kbd>用于训练，加载<kbd>x_test</kbd>用于测试:</p>

<pre class="mce-root">(x_train, _), (x_test, _) = mnist.load_data()</pre>

<p>通过除以最大像素值来归一化数据，最大像素值是<kbd>255</kbd>:</p>

<pre class="mce-root">x_train = x_train.astype('float32') / 255<br/>x_test = x_test.astype('float32') / 255</pre>

<p>打印我们数据集的<kbd>shape</kbd>:</p>

<pre class="mce-root">print(x_train.shape, x_test.shape)<br/><br/>((60000, 28, 28), (10000, 28, 28))</pre>

<p class="mce-root">将图像重塑为2D阵列:</p>

<pre class="mce-root">x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))<br/>x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))</pre>

<p>现在，数据的形状将变成如下所示:</p>

<pre class="mce-root">print(x_train.shape, x_test.shape)<br/><br/>((60000, 784), (10000, 784))</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Defining the encoder</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">定义编码器</h1>

                

            

            

                

<p>现在我们定义编码器层，它将图像作为输入并返回编码。</p>

<p>定义编码的大小:</p>

<pre class="mce-root">encoding_dim = 32</pre>

<p class="mce-root">定义输入的占位符:</p>

<pre class="mce-root">input_image = Input(shape=(784,))</pre>

<p>定义采用<kbd>input_image</kbd>并返回编码的编码器:</p>

<pre class="mce-root">encoder  = Dense(encoding_dim, activation='relu')(input_image)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Defining the decoder</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">定义解码器</h1>

                

            

            

                

<p class="mce-root">让我们定义从编码器获取编码值并返回重建图像的解码器:</p>

<pre class="mce-root">decoder = Dense(784, activation='sigmoid')(encoder)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Building the model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">构建模型</h1>

                

            

            

                

<p class="mce-root">既然我们已经定义了编码器和解码器，那么我们定义一个模型，该模型将图像作为输入，并返回解码器的输出，即重建的图像:</p>

<pre class="mce-root">model = Model(inputs=input_image, outputs=decoder)</pre>

<p class="mce-root">让我们来看一下该模型的总结:</p>

<pre class="mce-root">model.summary()<br/><br/>________________________________________________________________

Layer (type)                Output Shape              Param #   

=================================================================

input_1 (InputLayer)         (None, 784)               0         

_________________________________________________________________

dense (Dense)                (None, 32)                25120     

_________________________________________________________________

dense_1 (Dense)              (None, 784)               25872     

=================================================================

Total params: 50,992

Trainable params: 50,992

Non-trainable params: 0

_________________________________________________________________</pre>

<p class="mce-root"/>

<p class="mce-root">使用<kbd>loss</kbd>作为二进制交叉熵编译模型，并使用<kbd>adadelta</kbd>优化器最小化损失:</p>

<pre class="mce-root">model.compile(optimizer='adadelta', loss='binary_crossentropy')</pre>

<p class="mce-root">现在我们来训练模型。</p>

<p>通常，我们将模型训练为<kbd>model.fit(x,y)</kbd>，其中<kbd>x</kbd>是输入，<kbd>y</kbd>是标签。但是由于自动编码器重建了它们的输入，模型的输入和输出应该是相同的。因此，在这里，我们将模型训练为<kbd>model.fit(x_train, x_train)</kbd>:</p>

<pre class="mce-root">model.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test))</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Reconstructing images</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">重建图像</h1>

                

            

            

                

<p class="mce-root">现在我们已经训练了模型，我们看到模型是如何重建测试集的图像的。将测试图像提供给模型，并获得重建图像:</p>

<pre class="mce-root">reconstructed_images = model.predict(x_test)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Plotting reconstructed images</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">绘制重建图像</h1>

                

            

            

                

<p>首先，让我们绘制实际图像，即输入图像:</p>

<pre>n = 7<br/>plt.figure(figsize=(20, 4))<br/>for i in range(n):<br/> <br/>    ax = plt.subplot(1, n, i+1)<br/>    plt.imshow(x_test[i].reshape(28, 28))<br/>    plt.gray()<br/>    ax.get_xaxis().set_visible(False)<br/>    ax.get_yaxis().set_visible(False)<br/>plt.show() </pre>

<p>实际图像的情节如下:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/37773424-afde-4562-bd8c-7320360ad538.png" style="width:16.50em;height:2.25em;"/></p>

<p>绘制重建图像，如下所示:</p>

<pre>n = 7<br/>plt.figure(figsize=(20, 4))<br/>for i in range(n):<br/>    ax = plt.subplot(2, n, i + n + 1)<br/>    plt.imshow(reconstructed_images[i].reshape(28, 28))<br/>    plt.gray()<br/>    ax.get_xaxis().set_visible(False)<br/>    ax.get_yaxis().set_visible(False)<br/><br/>plt.show() </pre>

<p>下图显示了重建的图像:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/1f12fa78-b120-43e2-b4a0-8fb789bf913a.png" style="width:22.83em;height:2.50em;"/></p>

<p>如您所见，autoencoder已经学习了输入图像的更好表示，并对它们进行了重构。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Autoencoders with convolutions</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">带卷积的自动编码器</h1>

                

            

            

                

<p>在前一节中，我们刚刚了解了什么是自动编码器。我们学习了一个普通的自动编码器，它基本上是一个带有一个隐藏层的前馈浅网络。不把它们作为前馈网络，我们可以把它们作为卷积网络吗？由于我们知道卷积网络擅长分类和识别图像(假设我们在自动编码器中使用卷积层而不是前馈层)，当输入是图像时，它将学习更好地重建输入。</p>

<p>因此，我们引入了一种新型的自动编码器，称为CAEs，它使用卷积网络而不是普通的神经网络。在普通的自动编码器中，编码器和解码器基本上是一个前馈网络。但是在CAEs中，它们基本上是卷积网络。这意味着编码器由卷积层组成，解码器由转置卷积层组成，而不是前馈网络。CAE如下图所示:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-184 image-border" src="img/b5250f8e-2b95-4554-9fb5-7f84ac083f25.png" style="width:34.50em;height:18.67em;"/></p>

<p>如图所示，我们将输入图像输入由卷积层组成的编码器，卷积层执行卷积运算，并从图像中提取重要特征。然后，我们执行最大池，只保留图像的重要特征。以类似的方式，我们执行几个卷积和最大池操作，并获得图像的潜在表示，称为<strong>瓶颈</strong>。</p>

<p>接下来，我们将瓶颈提供给由去卷积层组成的解码器，去卷积层执行去卷积操作，并尝试从瓶颈重建图像。它由几个去卷积和上采样操作组成，以重建原始图像。</p>

<p>因此，这就是CAE如何在编码器中使用卷积层，在解码器中转置卷积层来重建图像。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Building a convolutional autoencoder</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">构建卷积自动编码器</h1>

                

            

            

                

<p>正如我们在上一节中学习如何实现自动编码器一样，实现CAE也是一样的，但唯一的区别是我们在编码器和解码器中使用卷积层，而不是前馈网络。我们将使用相同的MNIST数据集通过CAE重建图像。</p>

<p class="mce-root"/>

<p class="mce-root"/>

<p>导入库:</p>

<pre>import warnings<br/>warnings.filterwarnings('ignore')<br/><br/>#modelling<br/>from tensorflow.keras.models import Model<br/>from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D<br/>from tensorflow.keras import backend as K<br/><br/>#plotting<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline<br/><br/>#dataset<br/>from keras.datasets import mnist<br/>import numpy as np</pre>

<p>读取并重塑数据集:</p>

<pre>(x_train, _), (x_test, _) = mnist.load_data()<br/><br/># Normalize the dataset<br/><br/>x_train = x_train.astype('float32') / 255.<br/>x_test = x_test.astype('float32') / 255.<br/><br/># reshape<br/><br/>x_train = np.reshape(x_train, (len(x_train), 28, 28, 1)) <br/>x_test = np.reshape(x_test, (len(x_test), 28, 28, 1)) </pre>

<p>让我们定义输入图像的形状:</p>

<pre>input_image = Input(shape=(28, 28, 1))  </pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Defining the encoder</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">定义编码器</h1>

                

            

            

                

<p>现在，让我们定义我们的编码器。不像普通的自动编码器，我们使用前馈网络，这里我们使用卷积网络。因此，我们的编码器包括三个卷积层，后面是一个带有<kbd>relu</kbd>激活的最大池层。</p>

<p>定义第一个卷积层，然后是最大池操作:</p>

<pre>x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_image)<br/>x = MaxPooling2D((2, 2), padding='same')(x)</pre>

<p class="mce-root"/>

<p class="mce-root"/>

<p class="mce-root"/>

<p class="mceNonEditable"/>

<p>定义第二个卷积和最大池层:</p>

<pre>x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)<br/>x = MaxPooling2D((2, 2), padding='same')(x)</pre>

<p>定义最终卷积和最大池层:</p>

<pre>x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)<br/>encoder = MaxPooling2D((2, 2), padding='same')(x)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Defining the decoder</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">定义解码器</h1>

                

            

            

                

<p>现在，我们定义我们的解码器；在解码器中，我们对三个层执行去卷积操作，也就是说，我们对编码器创建的编码进行上采样，并重建原始图像。</p>

<p>定义第一个卷积层，然后进行上采样:</p>

<pre>x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoder)<br/>x = UpSampling2D((2, 2))(x)</pre>

<p>用上采样定义第二卷积层:</p>

<pre>x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)<br/>x = UpSampling2D((2, 2))(x)</pre>

<p>使用上采样定义最终卷积层:</p>

<pre>x = Conv2D(16, (3, 3), activation='relu')(x)<br/>x = UpSampling2D((2, 2))(x)<br/>decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Building the model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">构建模型</h1>

                

            

            

                

<p>定义获取输入图像并返回解码器生成的图像(即重建图像)的模型:</p>

<pre>model = Model(input_image, decoder)</pre>

<p>让我们将损失模型编译为二进制交叉熵，并使用<kbd>adadelta</kbd>作为优化器:</p>

<pre>model.compile(optimizer='adadelta', loss='binary_crossentropy')</pre>

<p class="mce-root"/>

<p class="mce-root"/>

<p>然后，按如下方式训练模型:</p>

<pre>model.fit(x_train, x_train, epochs=50,batch_size=128, shuffle=True, validation_data=(x_test, x_test))</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Reconstructing the images</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">重建图像</h1>

                

            

            

                

<p>使用我们训练过的模型重建图像:</p>

<pre>reconstructed_images = model.predict(x_test)</pre>

<p>首先，让我们绘制输入图像:</p>

<pre>n = 7<br/>plt.figure(figsize=(20, 4))<br/>for i in range(n):<br/> <br/>    ax = plt.subplot(1, n, i+1)<br/>    plt.imshow(x_test[i].reshape(28, 28))<br/>    plt.gray()<br/>    ax.get_xaxis().set_visible(False)<br/>    ax.get_yaxis().set_visible(False)<br/>plt.show() </pre>

<p>输入图像的绘图如下:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/c91fae3e-e957-48a5-bbef-ed6872786eea.png" style="width:15.50em;height:2.17em;"/></p>

<p>现在，我们绘制重建的图像:</p>

<pre>n = 7<br/>plt.figure(figsize=(20, 4))<br/>for i in range(n):<br/>    ax = plt.subplot(2, n, i + n + 1)<br/>    plt.imshow(reconstructed_images[i].reshape(28, 28))<br/>    plt.gray()<br/>    ax.get_xaxis().set_visible(False)<br/>    ax.get_yaxis().set_visible(False)<br/><br/>plt.show() </pre>

<p>重建图像的绘图如下:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/7f684ba9-6b34-4595-b0e8-fa916886d968.png" style="width:15.67em;height:1.67em;"/></p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Exploring denoising autoencoders</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">探索降噪自动编码器</h1>

                

            

            

                

<p>DAE是自动编码器的另一个小型变体。它们主要用于消除图像、音频和其他输入中的噪声。因此，当我们将损坏的输入提供给DAE时，它会学习重建原始的未损坏输入。现在，我们来看看DAE是如何消除噪音的。</p>

<p>对于DAE，我们不是将原始输入馈送给自动编码器，而是通过添加一些随机噪声来破坏输入，并馈送被破坏的输入。我们知道，编码器通过只保留重要信息来学习输入的表示，并将压缩的表示映射到瓶颈。当被破坏的输入被发送到编码器时，在学习输入的表示时，编码器将学习噪声是不想要的信息，并移除其表示。因此，编码器通过仅保留必要的信息来学习没有噪声的输入的紧凑表示，并将所学习的表示映射到瓶颈。</p>

<p>现在解码器尝试使用编码器学习到的表示来重建图像，也就是瓶颈。由于该表示不包含任何噪声，解码器重建没有噪声的输入。这就是DAE从输入中消除噪声的方式。</p>

<p>下图显示了一个典型的DAE。首先，我们通过添加一些噪声来破坏输入，并将破坏的输入馈送到编码器，编码器学习没有噪声的输入表示，而解码器使用编码器学习的表示来重建未破坏的输入:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1787 image-border" src="img/1d4a068f-ddc8-4eb9-9611-0c7777d485fd.png" style="width:27.00em;height:21.25em;"/></p>

<p class="mce-root">数学上，这可以表示如下。</p>

<p>假设我们有一个图像，<img class="fm-editor-equation" src="img/ee167338-3666-4b9c-b1ad-53533b983029.png" style="width:0.75em;height:0.75em;"/>，我们添加噪声到图像，得到<img class="fm-editor-equation" src="img/b8bb320e-3dc9-4bdf-8661-0143a805cfad.png" style="width:0.75em;height:1.17em;"/>，这是损坏的图像:</p>

<p><img class="fm-editor-equation" src="img/3b85c1b7-2605-410e-a823-69da021bace2.png" style="width:7.75em;height:1.17em;"/></p>

<p class="CDPAlignCenter CDPAlign">现在将这个损坏的图像输入编码器:</p>

<p><img class="fm-editor-equation" src="img/5845ebff-5585-46e3-baf0-9408d64afc78.png" style="width:4.50em;height:1.25em;"/></p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/3387b54b-01f1-446a-bac0-e700b2bb7eba.png" style="width:6.08em;height:1.17em;"/></p>

<p class="CDPAlignCenter CDPAlign">解码器试图重建实际图像:</p>

<p><img class="fm-editor-equation" src="img/872eb111-1108-4874-a983-4b2b9f925f69.png" style="width:4.75em;height:1.33em;"/></p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/bcee23a0-4d4e-4313-96e0-969c734eedf3.png" style="width:6.67em;height:1.25em;"/></p>

<p class="CDPAlignCenter CDPAlign">使用DAE去噪图像</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Denoising images using DAE</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">在本节中，我们将学习如何使用DAE对图像进行降噪处理。我们使用CAE对图像去噪。DAE的代码与CAE一样，只是这里我们在输入中使用噪声图像。我们将只看到各自的变化，而不是查看整个代码。完整的代码可以在GitHub的https://GitHub . com/packt publishing/Hands-On-Deep-Learning-Algorithms-with-Python获得。</h1>

                

            

            

                

<p>设置噪声系数:</p>

<p class="mce-root">向训练和测试图像添加噪声:</p>

<pre class="mce-root">noise_factor = 1</pre>

<p>通过0和1剪辑训练和测试集:</p>

<pre>x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) <br/>x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)</pre>

<p>Clip the train and test set by 0 and 1:</p>

<pre class="mce-root">x_train_noisy = np.clip(x_train_noisy, 0., 1.)<br/>x_test_noisy = np.clip(x_test_noisy, 0., 1.)</pre>

<p class="mce-root"/>

<p class="mce-root"/>

<p class="mce-root"/>

<p class="mceNonEditable">让我们训练模型。因为，我们希望模型学习去除图像中的噪声，所以模型的输入是噪声图像，即<kbd>x_train_noisy</kbd>，输出是去噪图像，即<kbd>x_train</kbd>:</p>

<p>使用我们训练过的模型重建图像:</p>

<pre>model.fit(x_train_noisy, x_train, epochs=50,batch_size=128, shuffle=True, validation_data=(x_test_noisy, x_test))</pre>

<p>首先，让我们绘制输入图像，即被破坏的图像:</p>

<pre>reconstructed_images = model.predict(x_test_noisy)</pre>

<p>输入噪声图像的曲线图如下所示:</p>

<pre style="padding-left: 60px">n = 7<br/>plt.figure(figsize=(20, 4))<br/>for i in range(n):<br/> <br/>    ax = plt.subplot(1, n, i+1)<br/>    plt.imshow(x_test_noisy[i].reshape(28, 28))<br/>    plt.gray()<br/>    ax.get_xaxis().set_visible(False)<br/>    ax.get_yaxis().set_visible(False)<br/>plt.show() </pre>

<p><img class="alignnone size-full wp-image-194 image-border" src="img/7086c1f1-cf80-4f56-a3c6-a3dec5336f7f.png" style="width:26.92em;height:3.75em;"/></p>

<p class="CDPAlignCenter CDPAlign">现在，让我们根据模型绘制重建图像:</p>

<p>如你所见，我们的模型已经学会了从图像中去除噪声:</p>

<pre>n = 7<br/>plt.figure(figsize=(20, 4))<br/>for i in range(n):<br/>    ax = plt.subplot(2, n, i + n + 1)<br/>    plt.imshow(reconstructed_images[i].reshape(28, 28))<br/>    plt.gray()<br/>    ax.get_xaxis().set_visible(False)<br/>    ax.get_yaxis().set_visible(False)<br/><br/>plt.show()</pre>

<p><img src="img/214f7f30-9858-445e-9a5e-875142681057.png" style="width:21.67em;height:2.33em;"/></p>

<p class="CDPAlignCenter CDPAlign">了解稀疏自动编码器</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Understanding sparse autoencoders</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">我们知道自动编码器学习重建输入。但是，当我们将隐藏层中的节点数设置为大于输入层中的节点数时，它将学习一个不利的恒等函数，因为它只是完全复制输入。</h1>

                

            

            

                

<p>在隐藏层中有更多的节点有助于我们学习健壮的潜在表示。但是当隐藏层中有更多节点时，自动编码器会尝试完全模仿输入，因此会过度拟合训练数据。为了解决过度拟合的问题，我们为损失函数引入了一个新的约束，称为<strong>稀疏约束</strong>或<strong>稀疏惩罚</strong>。具有稀疏惩罚的损失函数可以表示如下:</p>

<p><img class="fm-editor-equation" src="img/bbda4978-3f00-4edc-a739-8dbd1de211ba.png" style="width:17.92em;height:1.58em;"/></p>

<p class="CDPAlignCenter CDPAlign">第一项<img class="fm-editor-equation" src="img/d270d179-f57f-45e5-906f-28816e7158ad.png" style="width:4.08em;height:1.17em;"/>表示原始输入<img class="fm-editor-equation" src="img/8535044c-1614-4749-980f-9e7cd0cd3632.png" style="width:0.83em;height:0.83em;"/>和重构输入<img class="fm-editor-equation" src="img/5d8aa7a5-a8ce-483d-94f9-824d79491ba8.png" style="width:0.75em;height:0.67em;"/>之间的重构误差。第二项意味着稀疏约束。现在我们将探索这种稀疏约束如何减轻过度拟合的问题。</p>

<p>使用稀疏约束，我们只激活隐藏层上的特定神经元，而不是激活所有的神经元。基于输入，我们激活和去激活特定的神经元，因此当神经元被激活时，它们将学习从输入中提取重要的特征。通过稀疏惩罚，自动编码器不会将输入精确地复制到输出，并且它还可以学习健壮的潜在表示。</p>

<p>如下图所示，稀疏自动编码器在隐藏层中比在输入层中有更多的单元；然而，只有隐藏层中的少数神经元被激活。无阴影的神经元代表当前被激活的神经元:</p>

<p><img class="alignnone size-full wp-image-1849 image-border" src="img/ae4a2689-b6dc-4aae-8167-e662895f00bd.png" style="width:22.42em;height:30.67em;"/></p>

<p class="CDPAlignCenter CDPAlign">如果神经元处于活动状态，则返回1，如果处于非活动状态，则返回0。在稀疏自动编码器中，我们将隐藏层中的大多数神经元设置为非活动状态。我们知道，sigmoid激活函数将值压缩到0到1之间。所以，当我们使用sigmoid激活函数时，我们试图保持神经元的值接近0。</p>

<p>我们一般会尽量让隐层中每个神经元的平均激活值接近于零，比如说0.05，但不等于零，这个值叫做<img class="fm-editor-equation" src="img/060f2b67-744d-48dd-b158-29257cebee90.png" style="width:0.42em;height:0.67em;"/>，也就是我们的稀疏度参数。我们通常将<img class="fm-editor-equation" src="img/060f2b67-744d-48dd-b158-29257cebee90.png" style="width:0.67em;height:1.00em;"/>的值设置为0.05。</p>

<p>首先，我们计算神经元的平均激活。</p>

<p>隐藏层<img class="fm-editor-equation" src="img/3728baba-3198-4a8c-9617-946925898ac3.png" style="width:0.67em;height:1.00em;"/>中的<img class="fm-editor-equation" src="img/27815132-2e2f-4c4f-b541-72464797a683.png" style="width:1.00em;height:1.08em;"/>神经元在整个训练集中的平均激活可以计算如下:</p>

<p><img class="fm-editor-equation" src="img/ccb87428-1fc2-40b3-9251-fec0b5d2027f.png" style="width:11.92em;height:3.75em;"/></p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/ccb87428-1fc2-40b3-9251-fec0b5d2027f.png" style="width:11.92em;height:3.75em;"/></p>

<p class="mce-root">在这里，以下情况成立:</p>

<p><img class="fm-editor-equation" src="img/96632d24-2330-47b2-b2b5-39bb98b48348.png" style="width:1.08em;height:1.33em;"/>表示隐藏层<img class="fm-editor-equation" src="img/3728baba-3198-4a8c-9617-946925898ac3.png" style="width:0.58em;height:0.83em;"/>中<img class="fm-editor-equation" src="img/bc7e31cd-af8d-4470-a98d-473a048fd780.png" style="width:1.33em;height:1.42em;"/>神经元的平均激活</p>

<ul>

<li><img class="fm-editor-equation" src="img/1b6dd202-1bed-4a64-9785-18c50e18d543.png" style="width:0.92em;height:0.92em;"/>是训练样本的数量</li>

<li><img class="fm-editor-equation" src="img/39738fc2-1272-4ce6-b312-2812dfa82d5f.png" style="width:1.17em;height:1.08em;"/>是隐藏层<img class="fm-editor-equation" src="img/3728baba-3198-4a8c-9617-946925898ac3.png" style="width:0.75em;height:1.08em;"/>中<img class="fm-editor-equation" src="img/c3aaa92e-1573-4bd5-b679-e6a435ae45e2.png" style="width:1.33em;height:1.42em;"/>神经元的激活</li>

<li><img class="fm-editor-equation" src="img/a940740f-e484-41e7-8a9c-31b9340ade49.png" style="width:1.75em;height:1.33em;"/>是<img class="fm-editor-equation" src="img/9c486b3d-9c82-4b8a-8449-70628da1cf67.png" style="width:1.25em;height:1.17em;"/>训练样本</li>

<li><img class="fm-editor-equation" src="img/ea1e30a9-b545-4416-a16f-5f11103b55ba.png" style="width:2.42em;height:1.42em;"/>表示激活了隐含层<sub> <img class="fm-editor-equation" src="img/912fa4b2-4be0-49ef-9f00-82abba816b56.png" style="width:1.33em;height:1.42em;"/> </sub>中的神经元<img src="img/3728baba-3198-4a8c-9617-946925898ac3.png" style="width:0.75em;height:1.08em;"/>为第<sub> <img class="fm-editor-equation" src="img/b6259e8c-84dd-44e7-917c-dcd8fd58809c.png" style="width:0.33em;height:0.92em;"/> </sub> <sup>个</sup>训练样本</li>

<li>我们试图保持神经元的平均激活值<img class="fm-editor-equation" src="img/4d1aed0a-39d6-449f-8c66-627df7c0e9bb.png" style="width:0.75em;height:1.33em;"/>接近<img class="fm-editor-equation" src="img/060f2b67-744d-48dd-b158-29257cebee90.png" style="width:0.75em;height:1.17em;"/>。也就是说，我们试图将神经元的平均激活值保持在0.05:</li>

</ul>

<p><img class="fm-editor-equation" src="img/c875dca7-014c-4e2a-b19c-e71cf3b7097d.png" style="width:3.17em;height:1.42em;"/></p>

<p class="CDPAlignCenter CDPAlign">因此，我们惩罚<img class="fm-editor-equation" src="img/adb924e9-98c0-4ec0-a7ba-ec078ccbda66.png" style="width:1.17em;height:1.42em;"/>的值，它与<img class="fm-editor-equation" src="img/060f2b67-744d-48dd-b158-29257cebee90.png" style="width:0.67em;height:1.00em;"/>不同。我们知道<strong>kull back–lei bler</strong>(<strong>KL</strong>)散度被广泛用于度量两个概率分布之间的差异。因此，在这里，我们使用KL散度来衡量两个<strong>伯努利分布</strong>之间的差异，即均值<img class="fm-editor-equation" src="img/060f2b67-744d-48dd-b158-29257cebee90.png" style="width:0.67em;height:1.00em;"/>和均值<img class="fm-editor-equation" src="img/adb924e9-98c0-4ec0-a7ba-ec078ccbda66.png" style="width:1.25em;height:1.58em;"/>之间的差异，可以给出如下:</p>

<p><img class="fm-editor-equation" src="img/1d68f8f6-497d-4141-bef3-39ffca40111d.png" style="width:45.67em;height:3.83em;"/></p>

<p class="CDPAlignCenter CDPAlign">在前面的等式中，<img class="fm-editor-equation" src="img/e9acda55-c52f-4a33-80e8-fd74159dd204.png" style="width:1.50em;height:1.25em;"/>表示隐藏层<img class="fm-editor-equation" src="img/3f117009-6b17-42df-9aae-35da95019646.png" style="width:0.75em;height:1.08em;"/>，而<img class="fm-editor-equation" src="img/702ac143-726d-44a4-8b2e-83cbfdb643a8.png" style="width:0.42em;height:1.00em;"/>表示隐藏层<img class="fm-editor-equation" src="img/e9acda55-c52f-4a33-80e8-fd74159dd204.png" style="width:1.33em;height:1.17em;"/>中的<img class="fm-editor-equation" src="img/02d427ef-0ba3-48a1-9c60-eeeb796a9216.png" style="width:1.33em;height:1.42em;"/>神经元。早期的方程基本上是稀疏惩罚或稀疏约束。因此，在稀疏性约束下，所有神经元不会同时活跃，平均而言，它们被设置为0.05。</p>

<p>现在，我们可以用稀疏惩罚重写损失函数，如下所示:</p>

<p><img class="fm-editor-equation" src="img/acc8da4c-6096-4595-85e8-996472f633b0.png" style="width:20.42em;height:3.25em;"/></p>

<p class="CDPAlignCenter CDPAlign">因此，稀疏自动编码器允许我们在隐藏层中具有比输入层更多的节点，同时借助损失函数中的稀疏性约束来减少过拟合的问题。</p>

<p>Thus, sparse autoencoders allow us to have a greater number of nodes in the hidden layer than the input layer, yet reduce the problem of overfitting with the help of the sparsity constraint in the loss function.</p>

<p class="mce-root">构建稀疏自动编码器</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Building the sparse autoencoder</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">构建稀疏自动编码器与构建常规自动编码器是一样的，只是我们在编码器和解码器中使用了稀疏正则化器，因此在下面的部分中，我们将只查看与实现稀疏正则化器相关的部分，而不是查看整个代码；GitHub上有完整的代码和解释。</h1>

                

            

            

                

<p>定义稀疏正则化子</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Defining the sparse regularizer</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">以下是定义稀疏正则化的代码:</h1>

                

            

            

                

<p>将我们的<img class="fm-editor-equation" src="img/beb50c08-7bf9-487b-8165-fa933f5e34c2.png" style="width:0.58em;height:0.92em;"/>值设置为<kbd>0.05</kbd>:</p>

<pre>def sparse_regularizer(activation_matrix):</pre>

<p>计算平均激活值<img class="fm-editor-equation" src="img/8f0b0be9-23e1-4923-8f93-931292555dc5.png" style="width:1.08em;height:1.33em;"/>:</p>

<pre style="padding-left: 60px">rho = 0.05</pre>

<p>根据等式<em> (1) </em>计算平均值<img class="fm-editor-equation" src="img/beb50c08-7bf9-487b-8165-fa933f5e34c2.png" style="width:0.67em;height:1.00em;"/>和平均值<img class="fm-editor-equation" src="img/8f0b0be9-23e1-4923-8f93-931292555dc5.png" style="width:1.08em;height:1.33em;"/>之间的KL散度:</p>

<pre style="padding-left: 60px">rho_hat = K.mean(activation_matrix) </pre>

<p>对KL散度值求和:</p>

<pre style="padding-left: 60px">KL_divergence = K.sum(rho*(K.log(rho/rho_hat)) + (1-rho)*(K.log(1-rho/1-rho_hat)))</pre>

<p>将<kbd>sum</kbd>乘以<kbd>beta</kbd>并返回结果:</p>

<pre>    sum = K.sum(KL_divergence) </pre>

<p>稀疏正则化器的整个函数如下所示:</p>

<pre>    return beta * sum</pre>

<p>The whole function for the sparse regularizer is given as follows:</p>

<pre>def sparse_regularizer(activation_matrix):<br/>    p = 0.01<br/>    beta = 3<br/>    p_hat = K.mean(activation_matrix)  <br/>    KL_divergence = p*(K.log(p/p_hat)) + (1-p)*(K.log(1-p/1-p_hat))<br/>    sum = K.sum(KL_divergence) <br/>   <br/>    return beta * sum</pre>

<p class="mce-root">学习使用收缩式自动编码器</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Learning to use contractive autoencoders</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">像稀疏自动编码器一样，<strong>收缩自动编码器</strong>给自动编码器的损失函数增加了一个新的正则项。他们试图让我们的编码对训练数据中的微小变化不那么敏感。因此，使用收缩型自动编码器，我们的编码对于小扰动变得更加鲁棒，例如训练数据集中存在的噪声。我们现在引入一个新的术语叫做<strong>正则项</strong>或<strong>罚项</strong>到我们的损失函数中。它有助于惩罚对输入过于敏感的表示。</h1>

                

            

            

                

<p class="mce-root">我们的损失函数可以用数学方法表示如下:</p>

<p><img class="fm-editor-equation" src="img/555d6657-2908-4e34-afc0-ef9483f96144.png" style="width:13.58em;height:1.58em;"/></p>

<p class="CDPAlignCenter CDPAlign">第一项代表重构误差，第二项代表惩罚项或正则项，它基本上是<strong>雅可比矩阵</strong>的<strong> Frobenius </strong> <strong>范数</strong>。等等！那是什么意思？</p>

<p>矩阵的Frobenius范数，也称为<strong>希尔伯特-施密特范数</strong>，被定义为其元素的绝对平方之和的平方根。包含向量值函数偏导数的矩阵称为<strong>雅可比矩阵</strong>。</p>

<p class="mce-root">因此，计算雅可比矩阵的Frobenius范数意味着我们的罚项是隐藏层相对于输入的所有偏导数的平方和。其给出如下:</p>

<p><img class="fm-editor-equation" src="img/89f50a8e-25a1-4d00-8bae-3ed4c134e2ee.png" style="width:12.75em;height:3.25em;"/></p>

<p class="CDPAlignCenter CDPAlign">计算隐藏层相对于输入的偏导数类似于计算损失梯度。假设我们使用sigmoid激活函数，则隐藏层相对于输入的偏导数如下所示:</p>

<p><img class="fm-editor-equation" src="img/32880779-7c18-4c95-b720-3753579a110a.png" style="width:20.50em;height:3.00em;"/></p>

<p class="CDPAlignCenter CDPAlign">将惩罚项添加到我们的损失函数有助于降低模型对输入变化的敏感性，并使我们的模型对异常值更加稳健。因此，收缩型自动编码器降低了模型对训练数据中微小变化的敏感性。</p>

<p>实现收缩自动编码器</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Implementing the contractive autoencoder</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">构建收缩自动编码器与构建自动编码器是一样的，除了我们在模型中使用收缩损失正则化器，因此我们将只查看与实现收缩损失相关的部分，而不是查看整个代码。</h1>

                

            

            

                

<p>定义收缩损失</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Defining the contractive loss</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">现在让我们看看如何在Python中定义损失函数。</h1>

                

            

            

                

<p>定义均方损耗如下:</p>

<p>从我们的编码器层获得权重并转置权重:</p>

<pre style="padding-left: 60px">MSE = K.mean(K.square(actual - predicted), axis=1)</pre>

<p>获取我们编码器层的输出:</p>

<pre style="padding-left: 60px">weights = K.variable(value=model.get_layer('encoder_layer').get_weights()[0]) <br/>weights = K.transpose(weights) </pre>

<p>定义处罚条款:</p>

<pre style="padding-left: 60px">h = model.get_layer('encoder_layer').output</pre>

<p>最终损失是均方误差和惩罚项之和乘以<kbd>lambda</kbd>:</p>

<pre style="padding-left: 60px">penalty_term =  K.sum(((h * (1 - h))**2) * K.sum(weights**2, axis=1), axis=1)</pre>

<p>收缩损失的完整代码如下所示:</p>

<pre style="padding-left: 60px">Loss = MSE + (lambda * penalty_term)</pre>

<p>剖析变分自动编码器</p>

<pre>def contractive_loss(y_pred, y_true):<br/><br/>    lamda = 1e-4<br/><br/>    MSE = K.mean(K.square(y_true - y_pred), axis=1)<br/><br/>    weights = K.variable(value=model.get_layer('encoder_layer').get_weights()[0]) <br/>    weights = K.transpose(weights) <br/><br/>    h = model.get_layer('encoder_layer').output<br/><br/>    penalty_term = K.sum(((h * (1 - h))**2) * K.sum(weights**2, axis=1), axis=1)<br/><br/>    Loss = MSE + (lambda * penalty_term)<br/><br/><br/>    return Loss</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Dissecting variational autoencoders</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">现在我们将看到另一种非常有趣的自动编码器，叫做<strong>变型自动编码器</strong> ( <strong> VAE </strong>)。与其他自动编码器不同，vae是生成模型，这意味着它们像gan一样学习生成新数据。</h1>

                

            

            

                

<p>假设我们有一个包含许多个人面部图像的数据集。当我们用这个数据集训练我们的变分自动编码器时，它会学习生成在数据集中看不到的新的真实人脸。由于它们的生成性质，VAEs具有各种应用，其中一些应用包括生成图像、歌曲等等。但是是什么使得VAE具有可生成性，它与其他自动编码器有什么不同？让我们在下一节中了解这一点。</p>

<p>正如我们在讨论GANs时了解到的那样，一个模型要生成，它必须了解输入的分布。例如，假设我们有一个由手写数字组成的数据集，比如MNIST数据集。现在，为了生成新的手写数字，我们的模型必须学习数字在给定数据集中的分布。了解数据集中出现的数字的分布有助于VAE了解有用的属性，如数字宽度、笔画、高度等。一旦模型在其分布中编码了该属性，那么它可以通过从学习的分布中采样来生成新的手写数字。</p>

<p>假设我们有一个人脸数据集，那么学习数据集中人脸的分布有助于我们学习各种属性，如性别、面部表情、头发颜色等。一旦模型在其分布中学习并编码这些属性，那么它就可以通过从学习的分布中采样来生成新的面部。</p>

<p>因此，在VAE，我们不是将编码器的编码直接映射到潜在向量(瓶颈)，而是将编码映射到一个分布；通常，它是高斯分布。我们从这个分布中抽取一个潜在向量，并将其馈送给解码器，然后解码器学习重建图像。如下图所示，编码器将其编码映射到一个分布，我们从该分布中采样一个潜在向量，并将其提供给解码器以重建图像:</p>

<p class="mce-root"><img class="alignnone size-full wp-image-1719 image-border" src="img/9861a0f1-589e-4d93-a158-46310c4d5b77.png" style="width:106.17em;height:33.00em;"/></p>

<p>高斯分布可以通过其均值和协方差矩阵来参数化。因此，我们可以让编码器生成其编码，并将其映射到近似遵循高斯分布的均值向量和标准差向量。现在，从这个分布中，我们对一个潜在向量进行采样，并将其馈送到我们的解码器，然后解码器重建图像:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1848 image-border" src="img/60c96b04-e98b-449e-854f-db846d3c2577.png" style="width:103.67em;height:31.83em;"/></p>

<p>简而言之，编码器学习给定输入的期望属性，并将它们编码成分布。我们从该分布中采样一个潜在向量，并将该潜在向量作为输入馈送到解码器，解码器然后生成从编码器的分布中学习的图像。</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1848 image-border" src="img/60c96b04-e98b-449e-854f-db846d3c2577.png" style="width:103.67em;height:31.83em;"/></p>

<p>In a nutshell, the encoder learns the desirable properties of the given input and encodes them into distribution. We sample a latent vector from this distribution and feed the latent vector as input to the decoder which then generates images learned from the encoder's distribution.</p>

<p class="mce-root">在VAE，编码器也被称为<strong>识别</strong> <strong>型</strong>，解码器也被称为<strong> g </strong> <strong>生成</strong> <strong>型</strong>。现在我们已经对VAE有了直观的了解，在下一节，我们将详细了解VAE是如何工作的。</p>

<p class="mce-root">变分推理</p>

<p>在继续之前，让我们熟悉一下符号:</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Variational inference</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">让我们用<img class="fm-editor-equation" src="img/7cb7aa48-8ffc-405f-b340-25d5b2790817.png" style="width:2.58em;height:1.25em;"/>来表示输入数据集的分布，其中<img class="fm-editor-equation" src="img/a613c746-aa3a-42f2-ac6d-5bcd8fd5bc24.png" style="width:0.50em;height:0.92em;"/>表示将在训练期间学习的网络参数</h1>

                

            

            

                

<p>我们用<img class="fm-editor-equation" src="img/c3aa8cce-dabb-403f-9fc1-d3feb2485ce6.png" style="width:0.75em;height:0.92em;"/>表示潜在变量，它通过从分布中取样来编码输入的所有属性</p>

<ul>

<li><img class="fm-editor-equation" src="img/91dc9cc1-f422-456f-8d57-25ca9b52708a.png" style="width:3.33em;height:1.33em;"/>表示输入<img class="fm-editor-equation" src="img/e05c5e69-f4c0-443f-b911-07041c10049c.png" style="width:0.83em;height:0.83em;"/>与其属性<img class="fm-editor-equation" src="img/c3aa8cce-dabb-403f-9fc1-d3feb2485ce6.png" style="width:0.75em;height:0.92em;"/>的联合分布</li>

<li><img class="fm-editor-equation" src="img/bec5dd91-4523-4f5a-8567-6bbb50b974ad.png" style="width:2.00em;height:1.25em;"/>代表潜在变量的分布</li>

<li>使用贝叶斯定理，我们可以写出以下内容:</li>

<li><img class="fm-editor-equation" src="img/6d7bcfc0-e7c4-472c-95be-a0ae6b641a77.png" style="width:11.25em;height:2.50em;"/></li>

</ul>

<p>前面的等式有助于我们计算输入数据集的概率分布。但问题在于计算<img class="fm-editor-equation" src="img/275d0bd5-e949-4dff-84a3-5e478ad671b5.png" style="width:3.42em;height:1.25em;"/>，因为计算它是棘手的。因此，我们需要找到一种容易处理的方法来估计<img class="fm-editor-equation" src="img/4b09580c-ca0a-4926-bd62-e25d1e3f1528.png" style="width:3.58em;height:1.33em;"/>。在这里，我们引入一个叫做<strong>变分推理</strong>的概念。</p>

<p class="mce-root CDPAlignCenter CDPAlign">我们不是直接推断<img class="fm-editor-equation" src="img/eef7c7d5-7470-4ea3-8696-06ea4042bc47.png" style="width:3.67em;height:1.33em;"/>的分布，而是使用另一种分布来近似它们，比如高斯分布<img class="fm-editor-equation" src="img/65d7617b-e92b-45a5-8e95-55e84dd2ff70.png" style="width:3.25em;height:1.25em;"/>。也就是说，我们使用基本上是由<img class="fm-editor-equation" src="img/61a4f823-3ae8-46c4-ae6e-665e03617e23.png" style="width:0.67em;height:1.25em;"/>参数参数化的神经网络的<img class="fm-editor-equation" src="img/7d233498-9a18-43cb-be9e-30f5fb70e7a0.png" style="width:3.67em;height:1.42em;"/>来估计<img class="fm-editor-equation" src="img/3d86662e-e642-453a-a9d6-1badf3fbb723.png" style="width:3.42em;height:1.25em;"/>的值:</p>

<p><img class="fm-editor-equation" src="img/ab54b77c-6849-40bc-bc5d-def8243a2b8a.png" style="width:2.83em;height:1.25em;"/>基本上就是我们的概率编码器；也就是说，他们要创建一个潜在向量<em> z </em>给定<img src="img/3566f116-c99f-4b80-9ea3-74fc64ae306d.png" style="width:0.92em;height:0.92em;"/></p>

<p><img class="fm-editor-equation" src="img/b44be5c0-1e45-4c12-8449-91435f295a2e.png" style="width:2.92em;height:1.25em;"/>是概率解码器；也就是说，它试图在给定潜在向量<img class="fm-editor-equation" src="img/8e8f5f3a-17ab-454a-8de9-661720e62c10.png" style="width:0.75em;height:0.92em;"/>的情况下构建输入<img class="fm-editor-equation" src="img/ccacf299-a48d-48e5-92cb-6c8ebb552af7.png" style="width:0.92em;height:0.92em;"/></p>

<ul>

<li>下图有助于您清楚地理解符号以及我们目前所看到的内容:</li>

<li><img class="alignnone size-full wp-image-1711 image-border" src="img/1d58c046-7c2f-43e3-b1ec-7eb361ed0ccd.png" style="width:40.50em;height:13.08em;"/></li>

</ul>

<p class="mce-root">损失函数</p>

<p class="CDPAlignCenter CDPAlign">我们刚刚了解到，我们用<img class="fm-editor-equation" src="img/f1438493-9995-40ff-90e1-29490b93ccc9.png" style="width:3.42em;height:1.33em;"/>来近似<img class="fm-editor-equation" src="img/79338d90-75e3-4362-87be-cb9b0b9e5528.png" style="width:3.42em;height:1.25em;"/>。因此，<img class="fm-editor-equation" src="img/f1438493-9995-40ff-90e1-29490b93ccc9.png" style="width:2.83em;height:1.08em;"/>的估计值应该接近<img class="fm-editor-equation" src="img/79338d90-75e3-4362-87be-cb9b0b9e5528.png" style="width:2.92em;height:1.08em;"/>。由于这两个都是分布，我们使用KL散度来衡量<img class="fm-editor-equation" src="img/f1438493-9995-40ff-90e1-29490b93ccc9.png" style="width:2.83em;height:1.08em;"/>如何偏离<img class="fm-editor-equation" src="img/79338d90-75e3-4362-87be-cb9b0b9e5528.png" style="width:3.00em;height:1.08em;"/>，我们需要最小化散度。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>The loss function</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title"><img class="fm-editor-equation" src="img/f1438493-9995-40ff-90e1-29490b93ccc9.png" style="width:2.33em;height:0.92em;"/>和<img class="fm-editor-equation" src="img/79338d90-75e3-4362-87be-cb9b0b9e5528.png" style="width:3.17em;height:1.17em;"/>之间的KL偏差如下所示:</h1>

                

            

            

                

<p><img class="fm-editor-equation" src="img/373898a4-30a7-43b9-8ede-c0374190d5c9.png" style="width:25.25em;height:1.25em;"/></p>

<p>因为我们知道<img class="fm-editor-equation" src="img/d96ce8de-ee39-40be-8f5c-34bc988755c9.png" style="width:9.33em;height:2.42em;"/>，将它代入前面的等式，我们可以写出如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/f04d2335-6171-43bd-8e54-934550d990f6.png" style="width:30.08em;height:2.75em;"/></p>

<p class="CDPAlignLeft CDPAlign">由于我们知道<em> log (a/b) = log(a) - log(b) </em>，我们可以将前面的等式改写如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/13b728b6-3bce-4261-ab1c-3e89e509324d.png" style="width:30.08em;height:2.42em;"/></p>

<p class="CDPAlignLeft CDPAlign">我们可以将<img class="fm-editor-equation" src="img/01774ce0-9e3e-4b97-9c58-74b450efc2af.png" style="width:2.25em;height:1.08em;"/>置于期望值之外，因为它不依赖于<img class="fm-editor-equation" src="img/60780d92-f46d-413e-9da5-038b51feefe8.png" style="width:2.25em;height:0.75em;"/>:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/174ab8f7-b314-4740-9eac-013a1d1f5a5e.png" style="width:35.83em;height:1.33em;"/></p>

<p class="CDPAlignLeft CDPAlign">We can take the <img class="fm-editor-equation" src="img/01774ce0-9e3e-4b97-9c58-74b450efc2af.png" style="width:2.25em;height:1.08em;"/> outside the expectations since it has no dependency on <img class="fm-editor-equation" src="img/60780d92-f46d-413e-9da5-038b51feefe8.png" style="width:2.25em;height:0.75em;"/>:</p>

<p class="CDPAlignCenter CDPAlign">由于我们知道<em> log(ab) = log (a) + log(b) </em>，我们可以将前面的等式改写如下:</p>

<p class="mce-root"><img class="fm-editor-equation" src="img/65e3f3ee-ab4a-46c7-bb7f-453f73f467ce.png" style="width:35.17em;height:1.25em;"/></p>

<p class="CDPAlignLeft CDPAlign"><img class="fm-editor-equation" src="img/71755a3b-640a-466d-8dbf-2b70dc4f95de.png" style="width:44.08em;height:1.33em;"/></p>

<p class="CDPAlignCenter CDPAlign">我们知道<img class="fm-editor-equation" src="img/3c1b3c68-c1dd-4e27-bee9-393c60797ebb.png" style="width:3.42em;height:1.33em;"/>和<img class="fm-editor-equation" src="img/24a816e7-23a9-43b2-8dff-fcd64ef66295.png" style="width:2.58em;height:1.33em;"/>之间的KL散度可由下式给出:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/946b6261-6e49-4f14-8bef-99671173b5f2.png" style="width:44.08em;height:1.33em;"/></p>

<p class="CDPAlignLeft CDPAlign">将方程式<em> (2) </em>代入方程式<em> (1) </em>中，我们可以写出:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/588f307e-c39f-4807-94c5-c4110aa99bdf.png" style="width:37.17em;height:1.33em;"/></p>

<p class="CDPAlignLeft CDPAlign">重新排列等式的左侧和右侧，我们可以写出以下内容:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/bfda9f6f-60f9-45fe-ba31-cc1aa663e194.png" style="width:39.58em;height:1.42em;"/></p>

<p>重新排列这些项，我们的最终等式可以给出如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/def29c99-e58f-465e-88d3-89540f1dbd80.png" style="width:36.25em;height:1.92em;"/></p>

<p class="CDPAlignLeft CDPAlign">上面的等式暗示了什么？</p>

<p class="CDPAlignCenter CDPAlign">等式的左侧也被称为<strong>变分下界</strong>或<strong>证据下界</strong> ( <strong> ELBO </strong>)。左手边的第一项<img class="fm-editor-equation" src="img/c3658f8d-cd12-47e9-88cc-f29bcebdc976.png" style="width:2.42em;height:1.17em;"/>表示输入<em> x </em>的分布，我们希望使其最大化，而<img class="fm-editor-equation" src="img/8c095851-14f2-45ba-a43f-f3d53ad08caf.png" style="width:10.25em;height:1.17em;"/>表示估计分布和实际分布之间的KL偏差。</p>

<p>损失函数可以写成如下形式:</p>

<p><img class="fm-editor-equation" src="img/7b36c24f-e352-4352-a777-13ddb87c51ba.png" style="width:18.17em;height:1.25em;"/></p>

<p>在这个等式中，您会注意到以下内容:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/3147eae6-43f5-4dd8-bbc6-83242ab53e3c.png" style="width:4.17em;height:1.08em;"/>暗示我们正在最大化输入的分布；我们可以通过简单地添加一个负号，将最大化问题转化为最小化问题；因此，我们可以写<img class="fm-editor-equation" src="img/352d5d33-1842-4d4a-8aad-1ac9f7a45865.png" style="width:5.67em;height:1.25em;"/></p>

<p><img class="fm-editor-equation" src="img/b477c3d6-8c06-4433-9a64-a63a0ba04d3f.png" style="width:11.67em;height:1.33em;"/>暗示我们正在最大化估计和真实分布之间的KL散度，但是我们想要最小化它们，所以我们可以写<img class="fm-editor-equation" src="img/673c19ad-c94e-4e0b-b2a0-169a3dc59ab1.png" style="width:11.00em;height:1.25em;"/>来最小化KL散度</p>

<ul>

<li><img class="fm-editor-equation" src="img/3147eae6-43f5-4dd8-bbc6-83242ab53e3c.png" style="width:4.17em;height:1.08em;"/>implies we are maximizing the distribution of the input; we can convert the maximization problem into minimization by simply adding a negative sign; thus, we can write <img class="fm-editor-equation" src="img/352d5d33-1842-4d4a-8aad-1ac9f7a45865.png" style="width:5.67em;height:1.25em;"/></li>

<li>因此，我们的损失函数变成如下:</li>

</ul>

<p class="mce-root"><sup> <img class="fm-editor-equation" src="img/83fbb709-c90b-402c-b991-9c89c2a46405.png" style="width:18.92em;height:1.25em;"/> </sup></p>

<p><img class="fm-editor-equation" src="img/9b784e93-0e8c-455a-b8f3-9f1ba156ea73.png" style="width:23.67em;height:1.33em;"/></p>

<p class="CDPAlignCenter CDPAlign">如果你看这个等式，<img class="fm-editor-equation" src="img/cb826f28-0f1c-4619-9919-f426752f7735.png" style="font-size: 1em;width:8.33em;height:1.33em;"/>基本上暗示了输入的重构，也就是取潜向量<img class="fm-editor-equation" src="img/bafe6f36-ba5c-4d77-bd79-62ea348576e3.png" style="width:0.75em;height:0.92em;"/>并重构输入<img class="fm-editor-equation" src="img/0408a610-5dd5-4478-bac9-7b1da33170a8.png" style="font-size: 1em;width:0.92em;height:0.92em;"/>的解码器。</p>

<p class="CDPAlignCenter CDPAlign">因此，我们的最终损失函数是重建损失和KL散度之和:</p>

<p><img class="fm-editor-equation" src="img/34903840-530c-4af8-bdd8-5cc37922025a.png" style="width:23.25em;height:1.92em;"/></p>

<p>KL散度的值简化如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/ddfcb727-e6b5-4ca0-82eb-8875888153b4.png" style="width:24.33em;height:3.17em;"/></p>

<p>因此，最小化前面的损失函数意味着我们最小化重建损失，并且最小化估计和实际分布之间的KL偏差。</p>

<p class="CDPAlignCenter CDPAlign">重新参数化技巧</p>

<p>我们在通过梯度下降训练VAE a时面临一个问题。记住，我们正在执行一个采样操作来生成一个潜在向量。由于采样操作是不可微的，我们不能计算梯度。也就是说，在反向传播网络以最小化误差时，我们无法计算采样操作的梯度，如下图所示:</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Reparameterization trick</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title"><img class="alignnone size-full wp-image-1710 image-border" src="img/7e16aa56-b27b-4198-9b08-678a5039bfed.png" style="width:103.67em;height:33.42em;"/></h1>

                

            

            

                

<p>We face a problem while training VAE a through gradient descent. Remember, we are performing a sampling operation to generate a latent vector. Since a sampling operation is not differentiable, we cannot calculate gradients. That is, while backpropagating the network to minimize the error, we cannot calculate the gradients of the sampling operation as shown in the following diagram:</p>

<p class="CDPAlignCenter CDPAlign">因此，为了解决这个问题，我们引入了一个叫做<strong>重新参数化技巧</strong>的新技巧。我们引入一个称为<strong>ε</strong>的新参数，我们从一个单位高斯中随机采样，给出如下:</p>

<p class="mce-root"><img class="fm-editor-equation" src="img/edc09dff-7c1c-4b9f-8c06-d8a4647da372.png" style="width:5.25em;height:1.25em;"/></p>

<p>现在我们可以将我们的潜在向量<img class="fm-editor-equation" src="img/2782f2b6-cb1f-4318-a3b5-b40add7dd37a.png" style="width:0.75em;height:0.92em;"/>改写为:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/c1a1d374-301f-4928-a2d9-e652e98c7e4d.png" style="width:6.50em;height:1.08em;"/></p>

<p>重新参数化的技巧如下图所示:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1709 image-border" src="img/a7932bf5-a710-4e8a-a152-696d466210ca.png" style="width:41.83em;height:17.33em;"/></p>

<p>因此，通过重新参数化技巧，我们可以用梯度下降算法来训练VAE。</p>

<p class="CDPAlignCenter CDPAlign">使用VAE生成图像</p>

<p>现在我们已经了解了VAE模型的工作原理，在这一部分，我们将学习如何使用VAE来生成图像。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Generating images using VAE</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">导入所需的库:</h1>

                

            

            

                

<p>准备数据集</p>

<p>加载MNIST数据集:</p>

<pre>import warnings<br/>warnings.filterwarnings('ignore')<br/><br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from scipy.stats import norm<br/><br/>from tensorflow.keras.layers import Input, Dense, Lambda<br/>from tensorflow.keras.models import Model<br/>from tensorflow.keras import backend as K<br/>from tensorflow.keras import metrics<br/>from tensorflow.keras.datasets import mnist<br/><br/>import tensorflow as tf<br/>tf.logging.set_verbosity(tf.logging.ERROR)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Preparing the dataset</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">规范化数据集:</h1>

                

            

            

                

<p>重塑数据集:</p>

<pre>(x_train, _), (x_test, _) = mnist.load_data()</pre>

<p class="mce-root">现在让我们定义一些重要的参数:</p>

<pre class="mce-root">x_train = x_train.astype('float32') / 255.<br/>x_test = x_test.astype('float32') / 255.</pre>

<p class="mce-root">定义编码器</p>

<pre class="mce-root">x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))<br/>x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))</pre>

<p>定义输入:</p>

<pre>batch_size = 100<br/>original_dim = 784<br/>latent_dim = 2<br/>intermediate_dim = 256<br/>epochs = 50<br/>epsilon_std = 1.0</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Defining the encoder</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">编码器隐藏层:</h1>

                

            

            

                

<p>Define the input:</p>

<pre class="mce-root">x = Input(shape=(original_dim,))</pre>

<p>Encoder hidden layer:</p>

<pre class="mce-root">h = Dense(intermediate_dim, activation='relu')(x)</pre>

<p class="mce-root">计算平均值和方差:</p>

<p class="mce-root">定义采样操作</p>

<p class="mce-root">使用重新参数化技巧定义采样操作，从编码器的分布中对潜在向量进行采样:</p>

<pre class="mce-root">z_mean = Dense(latent_dim)(h)<br/>z_log_var = Dense(latent_dim)(h)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Defining the sampling operation</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">从平均值和方差中采样潜在向量<em> z </em>:</h1>

                

            

            

                

<p>定义解码器</p>

<pre>def sampling(args):<br/>    z_mean, z_log_var = args<br/>    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=epsilon_std)<br/>    return z_mean + K.exp(z_log_var / 2) * epsilon</pre>

<p>用两层定义解码器:</p>

<pre>z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Defining the decoder</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">使用解码器重建图像，解码器将潜在向量<img class="fm-editor-equation" src="img/7b049780-80c1-4a44-8bef-98d45421b9a3.png" style="width:0.75em;height:0.92em;"/>作为输入，并返回重建图像:</h1>

                

            

            

                

<p>构建模型</p>

<pre>decoder_hidden = Dense(intermediate_dim, activation='relu')<br/>decoder_reconstruct = Dense(original_dim, activation='sigmoid')</pre>

<p class="mce-root">我们建立的模型如下:</p>

<pre class="mce-root">decoded = decoder_hidden(z)<br/>reconstructed = decoder_reconstruct(decoded)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Building the model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">定义重建损失:</h1>

                

            

            

                

<p>We build the model as follows:</p>

<pre>vae = Model(x, reconstructed)</pre>

<p>Define the reconstruction loss:</p>

<pre class="mce-root">Reconstruction_loss = original_dim * metrics.binary_crossentropy(x, reconstructed)</pre>

<p class="mce-root"/>

<p class="mce-root"/>

<p class="mce-root"/>

<p class="mce-root"/>

<p class="mceNonEditable">定义KL散度:</p>

<p class="mceNonEditable">因此，总损失可定义为:</p>

<p>添加损失并编译模型:</p>

<pre class="mce-root">kl_divergence_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)</pre>

<p class="mce-root">训练模型:</p>

<pre class="mce-root">total_loss = K.mean(Reconstruction_loss + kl_divergence_loss)</pre>

<p>定义生成器</p>

<pre class="mce-root">vae.add_loss(total_loss)<br/>vae.compile(optimizer='rmsprop')<br/>vae.summary()</pre>

<p>根据学习的分布定义发生器样本，并生成图像:</p>

<pre class="mce-root">vae.fit(x_train,<br/>        shuffle=True,<br/>        epochs=epochs,<br/>        batch_size=batch_size,<br/>        verbose=2,<br/>        validation_data=(x_test, None))</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Defining the generator</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">绘制生成的图像</h1>

                

            

            

                

<p>现在我们绘制生成器生成的图像:</p>

<pre class="mce-root">decoder_input = Input(shape=(latent_dim,))<br/>_decoded = decoder_hidden(decoder_input)<br/><br/>_reconstructed = decoder_reconstruct(_decoded)<br/>generator = Model(decoder_input, _reconstructed)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Plotting generated images</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">以下是由生成器生成的图像的绘图:</h1>

                

            

            

                

<p><img src="img/0a7a7d2e-177b-4966-af88-d8baf6897a0a.png" style="width:20.92em;height:20.25em;"/></p>

<pre>n = 7 <br/>digit_size = 28<br/>figure = np.zeros((digit_size * n, digit_size * n))<br/><br/>grid_x = norm.ppf(np.linspace(0.05, 0.95, n))<br/>grid_y = norm.ppf(np.linspace(0.05, 0.95, n))<br/><br/>for i, yi in enumerate(grid_x):<br/>    for j, xi in enumerate(grid_y):<br/>        z_sample = np.array([[xi, yi]])<br/>        x_decoded = generator.predict(z_sample)<br/>        digit = x_decoded[0].reshape(digit_size, digit_size)<br/>        figure[i * digit_size: (i + 1) * digit_size,<br/>               j * digit_size: (j + 1) * digit_size] = digit<br/><br/>plt.figure(figsize=(4, 4), dpi=100)<br/>plt.imshow(figure, cmap='Greys_r')<br/>plt.show()</pre>

<p>摘要</p>

<p class="CDPAlignCenter CDPAlign">本章一开始，我们学习了什么是自动编码器，以及如何使用自动编码器来重建自己的输入。我们研究了卷积自动编码器，其中我们没有使用前馈网络，而是分别使用卷积层和去卷积层进行编码和解码。接下来，我们学习了稀疏，它只激活特定的神经元。然后，我们了解了另一种类型的正则化自动编码器，称为压缩自动编码器，在本章的最后，我们了解了VAE，这是一个生成式自动编码器模型。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Summary</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">在下一章中，我们将学习如何使用少量的学习算法从较少的数据点中学习。</h1>

                

            

            

                

<p>We started this chapter by learning what autoencoders are and how autoencoders are used to reconstruct their own input. We explored convolutional autoencoders, where instead of using feedforward networks, we used convolutional and deconvolutional layers for encoding and decoding, respectively. Following this, we learned about sparse which activate only certain neurons. Then, we learned about another type of regularizing autoencoder, called a contractive autoencoder, and at the end of the chapter, we learned about VAE which is a generative autoencoder model.</p>

<p>In the next chapter, we will learn about how to learn from a less data points using few-shot learning algorithms.</p>

<p class="mce-root">问题</p>

<p class="mce-root">让我们通过回答以下问题来检验我们对自动编码器的了解:</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Questions</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">什么是自动编码器？</h1>

                

            

            

                

<p>自动编码器的目标功能是什么？</p>

<ol>

<li>卷积自动编码器与普通自动编码器有何不同？</li>

<li>什么是去噪自动编码器？</li>

<li>神经元的平均激活是如何计算的？</li>

<li>定义收缩自动编码器的损失函数。</li>

<li>什么是弗罗贝纽斯范数和雅可比矩阵？</li>

<li>进一步阅读</li>

<li>您也可以查看以下链接了解更多信息:</li>

</ol>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Further reading</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:398be676-029b-4423-ae83-eae14f2a5a79" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title"><em>稀疏自动编码器</em>吴恩达笔记，<a href="https://web.stanford.edu/class/cs294a/sparseAutoencoder_2011new.pdf">https://web . Stanford . edu/class/cs 294 a/sparsea auto encoder _ 2011 new . pdf</a></h1>

                

            

            

                

<p class="mce-root">萨拉赫·里法伊等人的<em>收缩型自动编码器:特征提取期间的显式不变性</em>，http://www.icml-2011.org/papers/455_icmlpaper.pdf<a href="http://www.icml-2011.org/papers/455_icmlpaper.pdf"/></p>

<ul>

<li class="mce-root"><em>yun Chen Pu等人的用于图像、标签和字幕深度学习的variable auto encoder</em>，<a href="https://papers.nips.cc/paper/6528-variational-autoencoder-for-deep-learning-of-images-labels-and-captions.pdf">https://papers . nips . cc/paper/6528-variable-auto encoder-for-Deep-Learning-of-Images-Labels-and-Captions . pdf</a></li>

<li class="mce-root"><em>Contractive Auto-Encoders: Explicit Invariance During Feature Extraction</em> by Salah Rifai, et al., <a href="http://www.icml-2011.org/papers/455_icmlpaper.pdf">http://www.icml-2011.org/papers/455_icmlpaper.pdf</a></li>

<li class="mce-root"><em>Variational Autoencoder for Deep Learning of Images, Labels and Captions</em> by Yunchen Pu, et al., <a href="https://papers.nips.cc/paper/6528-variational-autoencoder-for-deep-learning-of-images-labels-and-captions.pdf">https://papers.nips.cc/paper/6528-variational-autoencoder-for-deep-learning-of-images-labels-and-captions.pdf</a></li>

</ul>





            



            

        

    </body>



</html></body></html>