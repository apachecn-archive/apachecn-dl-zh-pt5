<html><head/><body>




<style type="text/css">body{margin:1em;background-color:transparent!important;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}#sbo-rt-content *{word-wrap:break-word!important;word-break:break-word!important;}#sbo-rt-content table,#sbo-rt-content pre{overflow-x:unset!important;overflow:unset!important;overflow-y:unset!important;white-space:pre-wrap!important;}</style>
<div><div><h1 id="_idParaDest-51"><em class="italic"> <a id="_idTextAnchor050"/>第四章</em>:跟踪代码和数据版本化</h1>
			<p>DL模型不仅仅是模型——它们与训练和测试模型的代码以及用于训练和测试的数据密切相关。如果我们不跟踪用于模型的代码和数据，就不可能重现或改进模型。此外，最近整个行业都出现了觉醒和范式转变，转向以数据为中心的人工智能(<a href="https://www.forbes.com/sites/gilpress/2021/06/16/andrew-ng-launches-a-campaign-for-data-centric-ai/?sh=5cbacdc574f5">https://www . Forbes . com/sites/Gil press/2021/06/16/Andrew-ng-launches-a-campaign-for-data-centric-AI/？sh=5cbacdc574f5 </a>)，其中数据的重要性被提升到构建ML，尤其是DL模型的一流工件。因此，在本章中，我们将学习如何使用MLflow跟踪代码和数据版本。我们将了解跟踪代码和管道版本的不同方法，以及如何使用Delta Lake进行数据版本控制。在本章结束时，你将能够理解并使用MLflow实现代码和数据的跟踪技术。</p>
			<p>在本章中，我们将讨论以下主要话题:</p>
			<ul>
				<li>跟踪笔记本和管道版本</li>
				<li>跟踪本地私有的Python库</li>
				<li>跟踪三角洲湖中的数据版本</li>
			</ul>
			<h1 id="_idParaDest-52"><a id="_idTextAnchor051"/>技术要求</h1>
			<p>本章的技术要求如下:</p>
			<ul>
				<li>使用Jupyter笔记本扩展的VS代码:<a href="https://github.com/microsoft/vscode-jupyter/wiki/Setting-Up-Run-by-Line-and-Debugging-for-Notebooks">https://github . com/Microsoft/VS Code-Jupyter/wiki/Setting-Up-Run-by-Line-and-Debugging-for-Notebooks</a>。</li>
				<li>本章的代码，可以在本书的GitHub知识库中找到:<a href="https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/tree/main/chapter04">https://GitHub . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/tree/main/chapter 04</a>。</li>
				<li>访问Databricks实例，以便您可以了解如何使用Delta Lake来启用版本化数据访问。</li>
			</ul>
			<h1 id="_idParaDest-53"><a id="_idTextAnchor052"/>跟踪笔记本和管道版本</h1>
			<p>数据科学家通常从离线试用Python笔记本开始，在这种情况下，交互式执行是一个关键优势。自<code>.ipynb</code>时代以来，Python笔记本已经走过了漫长的道路。您可能也无法使用Jupyter笔记本在MLflow跟踪服务器中看到每次运行的确切Git散列。关于是否或何时应该使用Jupyter笔记本，尤其是在生产环境中，有很多有趣的争论(参见这里的讨论:<a href="https://medium.com/mlops-community/jupyter-notebooks-in-production-4e0d38803251">https://medium . com/mlops-community/Jupyter-notebooks-in-production-4e0d 38803251</a>)。我们不应该在生产环境中使用Jupyter笔记本电脑的原因有很多，特别是当我们需要端到端流水线方式的可再现性时，在这种情况下，大量笔记本电脑可能很难进行单元测试、正确的代码版本控制和依赖性管理。使用网飞(<a href="https://papermill.readthedocs.io/en/latest/index.html">https://papermill.readthedocs.io/en/latest/index.html</a>)的开源工具<strong class="bold"> papermill </strong>，在工作流方式中围绕调度、参数化和执行Jupyter笔记本有一些早期的创新。然而，Databricks和VS Code最近的一项创新使笔记本更容易进行版本控制并与MLflow集成。让我们来看看这两种工具带来的笔记本电脑特征:</p>
			<ul>
				<li><strong class="bold">交互式执行</strong>:data bricks的笔记本和VS Code的笔记本都可以像传统的Jupyter笔记本一样，以逐个单元格的执行模式运行。通过这样做，您可以立即看到结果的输出。</li>
				<li><code>.py</code>文件扩展名。这允许所有常规的Python代码林挺(代码格式和样式检查)应用于一个笔记本。</li>
				<li><strong class="bold">用于呈现代码单元格和标记单元格的特殊符号</strong>:data bricks和VS代码都利用一些特殊符号将Python文件呈现为交互式笔记本。在数据块中，将代码划分为不同的可执行单元的特殊符号如下:<pre># COMMAND ----------  import mlflow import torch from flash.core.data.utils import download_data from flash.text import TextClassificationData, TextClassifier import torchmetrics</pre></li>
			</ul>
			<p>特殊<code>COMMAND</code>行下面的代码将在Databricks web UI门户中呈现为可执行单元，如下所示:</p>
			<div><div><img src="img/B18120_Figure_4.1.jpg" alt="Figure 4.1 – Databricks executable cell&#13;&#10;" width="1245" height="360"/>
				</div>
			</div>
			<p class="figure-caption">图4.1-数据块可执行单元</p>
			<p>要执行该单元格中的代码，只需通过右上角的下拉菜单点击<strong class="bold">运行单元格</strong>。</p>
			<p>要添加一大块文本来描述和注释数据块(也称为标记单元格)中的代码，可以在行首使用<code># MAGIC</code>符号，如下所示:</p>
			<pre># MAGIC %md
# MAGIC #### Notebooks for fine-tuning a pretrained language model to do text-based sentiment classification</pre>
			<p>然后，这将在Databricks记事本中呈现为降价注释单元格，如下所示:</p>
			<div><div><img src="img/B18120_Figure_4.2.jpg" alt="Figure 4.2 – Databricks Markdown text cell&#13;&#10;" width="1217" height="246"/>
				</div>
			</div>
			<p class="figure-caption">图4.2-数据块降价文本单元格</p>
			<p>在VS代码中，这两种类型的单元格使用的符号略有不同。对于代码单元，在单元块的开头使用<code># %%</code>符号:</p>
			<pre># %%
download_data("https://pl-flash-data.s3.amazonaws.com/imdb.zip", "./data/")
datamodule = TextClassificationData.from_csv(
    input_fields="review",
    target_fields="sentiment",
    train_file="data/imdb/train.csv",
    val_file="data/imdb/valid.csv",
    test_file="data/imdb/test.csv"
)</pre>
			<p>然后在VS代码编辑器中呈现，如下所示:</p>
			<div><div><img src="img/B18120_Figure_4.3.jpg" alt="Figure 4.3 – VSCode code cell&#13;&#10;" width="1179" height="388"/>
				</div>
			</div>
			<p class="figure-caption">图4.3–VS代码代码单元</p>
			<p>正如你所看到的，在代码块之前有一个<strong class="bold">运行单元</strong>按钮，你可以点击它来交互式地运行代码块。如果点击<strong class="bold">运行单元格</strong>按钮，代码块将在编辑器窗口的侧面板开始执行，如下图所示:</p>
			<div><div><img src="img/B18120_Figure_4.4.jpg" alt=" Figure 4.4 – Running code interactively in VSCode&#13;&#10;" width="1190" height="711"/>
				</div>
			</div>
			<p class="figure-caption">图4.4–在VS代码中交互运行代码</p>
			<p>要添加包含注释的Markdown单元格，请在行首添加以下内容以及必要的符号:</p>
			<pre># %% Notebook for fine-tuning a pretrained language model and sentiment classification</pre>
			<p>这将确保文本不是VS代码中的可执行代码块。</p>
			<p>鉴于Databricks和VS Code notebooks的优势，我们建议使用其中任何一种进行版本跟踪。我们可以使用GitHub来跟踪这两种笔记本的版本，因为它们使用常规的Python文件格式。</p>
			<p class="callout-heading">使用Databricks笔记本版本控制的两种方法</p>
			<p class="callout">对于托管Databricks实例，可以通过两种方式跟踪笔记本版本:在Databricks web UI上查看笔记本侧面板上的修订历史，或者链接到远程GitHub存储库。详细描述见Databricks笔记本文档:<a href="https://docs.databricks.com/notebooks/notebooks-use.html#version-control">https://docs . data bricks . com/notebooks/notebooks-use . html # version-control</a>。</p>
			<p>虽然Databricks web门户为笔记本版本控制和与MLflow实验跟踪的集成提供了出色的支持(请参见本章的标注框中的<em class="italic">使用Databricks笔记本版本控制的两种方法</em>和<em class="italic">Databricks笔记本中的两种MLflow实验</em>)，但是在data bricks笔记本web UI中编写代码有一个主要缺点。这是因为与VS代码相比，web UI不是典型的<strong class="bold">集成开发环境</strong> ( <strong class="bold"> IDE </strong>)，在VS代码中，代码风格和格式工具如<strong class="bold">flake 8</strong>(<a href="https://flake8.pycqa.org/en/latest/">https://flake8.pycqa.org/en/latest/</a>)和autopep 8(<a href="https://pypi.org/project/autopep8/">https://pypi.org/project/autopep8/</a>)可以很容易地实施。这可能会对代码质量和可维护性产生重大影响。因此，强烈建议您使用VS代码来创作笔记本代码(Databricks笔记本或VS代码笔记本)。</p>
			<p class="callout-heading">Databricks笔记本中的两种MLflow实验</p>
			<p class="callout">对于托管Databricks web门户实例，您可以执行两种类型的MLflow实验:工作区和笔记本实验。工作区实验主要是针对不与单个笔记本相关联的共享实验文件夹。如果需要，远程代码执行可以写入工作区实验文件夹。另一方面，笔记本电脑范围的实验与特定的笔记本电脑相关联，可以直接在Databricks门户网站的笔记本电脑页面的右上角菜单项<strong class="bold">实验</strong>中找到。更多详情请看Databricks文档网站:<a href="https://docs.databricks.com/applications/mlflow/tracking.html#experiments">https://docs . data bricks . com/applications/ml flow/tracking . html # experiments</a>。</p>
			<p>使用本章的VS代码笔记本<code>fine_tuning.py</code>，它可以在本章的GitHub资源库(<a href="https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/blob/main/chapter04/notebooks/fine_tuning.py">https://GitHub . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/blob/main/Chapter 04/notebooks/fine _ tuning . py</a>)中找到，您将能够在VS代码编辑器中交互式地运行它，并在我们在<a href="B18120_03_ePub.xhtml#_idTextAnchor040"> <em class="italic">第3章</em> </a> <em class="italic">中设置的MLflow Docker服务器中记录实验提醒一下，要想在VS代码中成功运行这个笔记本，你需要设置你的虚拟环境<code>dl_model</code>，如本章GitHub库的<code>README.md</code>文件所述。它包括以下三个步骤:</em></p>
			<pre class="source-code">conda create -n dl_model python==3.8.10</pre>
			<pre class="source-code">conda activate dl_model</pre>
			<pre class="source-code">pip install -r requirements.txt</pre>
			<p>如果您从头到尾一个单元一个单元地运行这个笔记本，您的实验页面将如下所示:</p>
			<div><div><img src="img/B18120_Figure_4.5.jpg" alt="Figure 4.5 – Logged experiment page after running a VSCode notebook interactively &#13;&#10;" width="973" height="318"/>
				</div>
			</div>
			<p class="figure-caption">图4.5–交互运行VS代码笔记本后记录的实验页面</p>
			<p>您可能会立即注意到前面截图中的一个问题—<code>fine_tuning.py</code>文件。这是因为VS代码笔记本并没有本地集成到MLflow跟踪服务器中进行源文件跟踪；它只能显示VS代码用来执行一个VS代码笔记本的<strong class="bold">ipykernel</strong>(<a href="https://pypi.org/project/ipykernel/">https://pypi.org/project/ipykernel/</a>)(<a href="https://github.com/microsoft/vscode-jupyter">https://github.com/microsoft/vscode-jupyter</a>)。不幸的是，在撰写本文时，这是一个无法通过交互式运行VS代码笔记本<em class="italic">进行实验代码跟踪来解决的限制。在托管的Databricks web UI中运行的data brick笔记本没有这样的问题，因为它们与捆绑在data brick web门户中的MLflow跟踪服务器进行了本机集成。</em></p>
			<p>然而，由于VS代码笔记本只是Python代码，我们可以在命令行<em class="italic">中非交互地运行笔记本</em>，如下所示:</p>
			<pre>python fine_tuning.py</pre>
			<p>这将在MLflow实验页面中记录实际的源代码文件名和Git提交散列，不会出现任何问题，如下所示:</p>
			<div><div><img src="img/B18120_Figure_4.6.jpg" alt="Figure 4.6 – Logged experiment page after running a VSCode notebook in the command line &#13;&#10;" width="1031" height="336"/>
				</div>
			</div>
			<p class="figure-caption">图4.6–在命令行中运行VS代码笔记本后记录的实验页面</p>
			<p>前面的截图显示了正确的源文件名(<code>fine_tuning.py</code>)和正确的git提交散列(<strong class="bold">661 ffeda 5a e 53 CFF 3623 F2 FCC 8227d 822 e 877 e 2d</strong>)。这种变通方法不需要我们更改笔记本的代码，如果我们的初始交互式笔记本调试已经完成，并且我们希望获得笔记本的完整运行，以及MLflow跟踪服务器中的正确代码版本跟踪，这种变通方法将非常有用。请注意，所有其他参数、指标和模型都被正确地跟踪，不管我们是否以交互方式运行笔记本。</p>
			<h2 id="_idParaDest-54"><a id="_idTextAnchor053"/>管道跟踪</h2>
			<p>讨论了笔记本代码跟踪(版本和文件名)之后，让我们转向管道跟踪的主题。然而，在我们讨论管道跟踪之前，我们将讨论ML/DL生命周期中管道的定义。从概念上讲，管道是一个多步骤的数据处理和任务工作流。然而，这种数据/任务工作流的实现可能非常不同。在一些ML包中，可以将管道定义为一级Python API。两个最著名的管道API如下:</p>
			<ul>
				<li><code>sklearn.pipeline.Pipeline</code>(<a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html">https://sci kit-learn . org/stable/modules/generated/sk learn . pipeline . html</a>):这广泛用于构建紧密集成的多步管道，用于经典机器学习或数据<strong class="bold">提取、转换和加载</strong> ( <strong class="bold"> ETL </strong>)管道，使用<strong class="bold">pandas data frames</strong>(https://pandas.pydata.org/docs/reference/api/pandas。DataFrame.html)。</li>
				<li><code>pyspark.ml.Pipeline</code>(<a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.Pipeline.html">https://Spark . Apache . org/docs/latest/API/python/reference/API/pyspark . ml . pipeline . html</a>):这是一个py Spark版本，用于使用<strong class="bold"> Spark DataFrames </strong>为机器学习或数据ETL管道构建简单且紧密集成的多步管道(https://Spark . Apache . org/docs/latest/API/python/reference/API/py Spark . SQL . data frame . html)。</li>
			</ul>
			<p>然而，当我们构建DL模型管道时，我们需要在管道的不同步骤使用多个不同的Python包，因此使用单一管道API的一刀切方法通常是行不通的。此外，上述两个管道API都没有对当前流行的DL包的原生支持，如<strong class="bold"> Huggingface </strong>或<strong class="bold"> PyTorch-Lightning </strong>，这些都需要额外的集成工作。虽然存在一些开源的DL管道API，如<strong class="bold">neur axle</strong>(<a href="https://github.com/Neuraxio/Neuraxle">https://github.com/Neuraxio/Neuraxle</a>)，试图提供一个类似sklearn的管道接口和框架，但并没有被广泛使用。此外，使用这些基于API的管道意味着当您需要向管道添加更多步骤时，您将被锁定，这可能会降低您在新需求出现时扩展或发展DL管道的灵活性。</p>
			<p>在本书中，我们将采用不同的方法来定义和构建一个基于MLflow的<code>fine_tuning.py</code>的DL管道，成为一个多步管道。该管道可以被视为一个三步流程图，如下所示:</p>
			<div><div><img src="img/B18120_Figure_4.7.jpg" alt="Figure 4.7 – A three-step DL pipeline &#13;&#10;" width="1337" height="111"/>
				</div>
			</div>
			<p class="figure-caption">图4.7-三步DL管道</p>
			<p>这个三步流程如下:</p>
			<ol>
				<li>将数据下载到本地执行环境</li>
				<li>微调模型</li>
				<li>注册模型</li>
			</ol>
			<p>对于我们当前的例子来说，这些模块化步骤<a id="_idIndexMarker174"/>可能看起来有些多余，但是当涉及到更复杂的情况时，或者当每个步骤都需要改变时，拥有独特的功能步骤的力量是显而易见的。如果我们定义了需要在它们之间传递的参数，每个步骤都可以被修改，而不会影响其他步骤。每个步骤都是一个独立的Python文件，可以使用一组输入参数独立执行。将有一个主管道Python文件，可以运行整个管道或管道步骤的一个子部分。在没有文件扩展名的标准YAML文件<code>MLproject</code>中，我们可以定义四个入口点(<code>main</code>、<code>download_data</code>、<code>fine_tuning_model</code>和<code>register_model</code>)、它们所需的输入参数、它们的类型和默认值，以及执行每个入口点的命令行。在我们的示例中，这些入口点将在Python命令行执行命令中提供。但是，如果任何特定步骤需要，您可以调用任何类型的执行，比如批处理shell脚本。例如，本章的<code>MLproject</code>文件中的以下行(<a href="https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/blob/main/chapter04/MLproject">https://github . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/blob/main/chapter 04/ml project</a>)描述了项目的名称、<code>conda</code>环境定义文件名和主入口点:</p>
			<pre class="source-code">name: dl_model_chapter04</pre>
			<pre class="source-code">conda_env: conda.yaml</pre>
			<pre class="source-code">entry_points:</pre>
			<pre class="source-code">  main:</pre>
			<pre class="source-code">    parameters:</pre>
			<pre class="source-code">      pipeline_steps:</pre>
			<pre class="source-code">        description: Comma-separated list of dl pipeline steps to execute </pre>
			<pre class="source-code">        type: str</pre>
			<pre class="source-code">        default: all</pre>
			<pre class="source-code">    command: "python main.py --steps {pipeline_steps}"</pre>
			<p>在这里，项目的名称是<code>dl_model_chapter04</code>。<code>conda_env</code>是指本地conda <a id="_idIndexMarker175"/>环境的YAML定义文件<code>conda.yaml</code>，与<code>MLproject</code>文件位于同一个目录下。<code>entry_points</code>部分列出了第一个入口点，称为<code>main</code>。在<code>parameters</code>部分，有一个名为<code>pipeline_steps</code>的参数，它允许用户定义要执行的DL管道步骤的逗号分隔列表。该参数属于<code>str</code>类型，其默认值为<code>all</code>，这意味着所有管道步骤都将运行。最后，<code>command</code>部分列出了如何在命令行中执行这个步骤。</p>
			<p>文件的其余部分通过遵循与主入口点相同的语法约定来定义其他三个管道步骤入口点。例如，同一<code>MLproject</code>文件中的下列行定义了<code>download_data</code>的入口点:</p>
			<pre class="source-code">  download_data:</pre>
			<pre class="source-code">    parameters:</pre>
			<pre class="source-code">      download_url:</pre>
			<pre class="source-code">        description: a url to download the data for fine tuning a text sentiment classifier</pre>
			<pre class="source-code">        type: str</pre>
			<pre class="source-code">        default: https://pl-flash-data.s3.amazonaws.com/imdb.zip</pre>
			<pre class="source-code">      local_folder:</pre>
			<pre class="source-code">        description: a local folder to store the downloaded data</pre>
			<pre class="source-code">        type: str</pre>
			<pre class="source-code">        default: ./data</pre>
			<pre class="source-code">      pipeline_run_name:</pre>
			<pre class="source-code">        description: an mlflow run name</pre>
			<pre class="source-code">        type: str</pre>
			<pre class="source-code">        default: chapter04</pre>
			<pre class="source-code">    command:</pre>
			<pre class="source-code">      "python pipeline/download_data.py --download_url {download_url} --local_folder {local_folder} \</pre>
			<pre class="source-code">      --pipeline_run_name {pipeline_run_name}"</pre>
			<p>与主入口点类似，<code>download_data</code>部分也定义了参数、类型和默认<a id="_idIndexMarker176"/>值的列表，以及执行该步骤的命令行。我们可以像在刚从这本书的GitHub资源库中签出的<code>MLproject</code>文件中一样定义其余的步骤。要了解更多细节，请看一下那个<code>MLproject</code>文件的完整内容。</p>
			<p>在定义了<code>MLproject</code>文件之后，很明显我们已经以声明的方式定义了一个多步管道。这就像是管道的规范，说明了每个步骤的名称、它期望的输入参数以及如何执行它们。现在，下一步是实现Python函数来执行管道的每一步。那么，我们来看看主入口点的Python函数的核心实现，这个函数叫做<code>main.py</code>。下面几行代码(不是<code>main.py</code>中的全部Python代码)说明了仅用管道中的一个步骤实现整个管道的核心组件(<code>download_data</code>):</p>
			<pre class="source-code">@click.command()</pre>
			<pre class="source-code">@click.option("--steps", default="all", type=str)</pre>
			<pre class="source-code">def run_pipeline(steps):</pre>
			<pre class="source-code">    with mlflow.start_run(run_name='pipeline', nested=True) as active_run:</pre>
			<pre class="source-code">        download_run = mlflow.run(".", "download_data", parameters={})</pre>
			<pre class="source-code">if __name__ == "__main__":</pre>
			<pre class="source-code">    run_pipeline()</pre>
			<p>这个主函数片段包含一个<code>run_pipeline</code>函数，当在命令行中执行<code>main.py</code>文件时将运行这个函数。有一个名为<code>steps</code>的参数，当它被提供时将被传递给这个函数。在这个例子中，我们使用<a id="_idIndexMarker177"/><code>click</code>Python包(<a href="https://click.palletsprojects.com/en/8.0.x/">https://click.palletsprojects.com/en/8.0.x/</a>)来解析命令行参数。<code>run_pipeline</code>函数通过调用<code>mlflow.start_run</code>并传递两个参数(<code>run_name</code>和<code>nested</code>)来启动MLflow实验运行。我们以前用过<code>run_name</code>——它是这次跑步的描述性短语。然而，<code>nested</code>参数<a id="_idIndexMarker178"/>是新的，这意味着这是一个父实验运行。此父实验运行包含一些将在MLflow中分层跟踪的子实验运行。每个父运行可以包含一个或多个子运行。在示例代码中，这包含管道运行的一个步骤，称为<code>download_data</code>，通过调用<code>mlflow.run</code>来调用它。这是以编程方式调用MLproject入口点的关键MLflow函数。一旦<code>download_data</code>被调用并且运行结束，父运行也将结束，从而结束流水线的运行。</p>
			<p class="callout-heading">执行MLproject入口点的两种方法</p>
			<p class="callout">有两种方法可以执行MLproject的入口点。首先可以使用MLflow的Python <a id="_idIndexMarker180"/> API，称为<code>mlflow.run</code>(<a href="https://www.mlflow.org/docs/latest/python_api/mlflow.projects.html#mlflow.projects.run">https://www . ml flow . org/docs/latest/Python _ API/ml flow . projects . html # ml flow . projects . run</a>)。或者，您可以使用MLflow的命令行接口工具，称为<code>mlflow run</code>，可以在命令行shell环境中调用它来直接执行任何入口点(<a href="https://www.mlflow.org/docs/latest/cli.html#mlflow-run">https://www.mlflow.org/docs/latest/cli.html#mlflow-run</a>)。</p>
			<p>现在，让我们学习如何一般地实现管道中的每个步骤。对于每个管道步骤，我们将Python文件放在一个<code>pipeline</code>文件夹中。在这个例子中，我们有三个文件:<code>download_data.py</code>、<code>fine_tuning_model.py</code>和<code>register_model.py</code>。因此，成功构建MLflow支持的管道项目的相关文件如下:</p>
			<pre class="source-code">MLproject</pre>
			<pre class="source-code">conda.yaml</pre>
			<pre class="source-code">main.py</pre>
			<pre class="source-code">pipeline/download_data.py</pre>
			<pre class="source-code">pipeline/fine_tuning_model.py</pre>
			<pre class="source-code">pipeline/register_model.py</pre>
			<p>对于每个管道步骤的实现，我们可以使用以下Python函数模板。预留占位符部分<a id="_idIndexMarker181"/>用于实现实际的流水线步骤逻辑:</p>
			<pre class="source-code">import click</pre>
			<pre class="source-code">import mlflow</pre>
			<pre class="source-code">@click.command()</pre>
			<pre class="source-code">@click.option("input")</pre>
			<pre class="source-code">def task(input):</pre>
			<pre class="source-code">    with mlflow.start_run() as mlrun:</pre>
			<pre class="source-code">        # Implement pipeline step logic here </pre>
			<pre class="source-code">        mlflow.log_parameter('parameter', parameter)</pre>
			<pre class="source-code">        mlflow.set_tag('pipeline_step', __file__)</pre>
			<pre class="source-code">        mlflow.log_artifacts(artifacts, artifact_path="data")</pre>
			<pre class="source-code">if __name__ == '__main__':</pre>
			<pre class="source-code">    task()</pre>
			<p>该模板允许我们标准化实现管道步骤任务的方式。这里的主要思想是，对于每个管道步骤任务，它需要从<code>mlflow.start_run</code>开始启动MLflow实验运行。一旦我们在函数中实现了特定的执行逻辑，我们需要使用<code>mlflow.log_parameter</code>记录一些参数，或者使用<code>mlflow.log_artifacts</code>记录工件存储中的一些工件，它们可以被传递给管道的下一步使用。这叫<code>mlflow.set_tag</code>。</p>
			<p>例如，在<code>download_data.py</code>步骤中，核心实现如下:</p>
			<pre class="source-code">import click</pre>
			<pre class="source-code">import mlflow</pre>
			<pre class="source-code">from flash.core.data.utils import download_data</pre>
			<pre class="source-code">@click.command()</pre>
			<pre class="source-code">@click.option("--download_url")</pre>
			<pre class="source-code">@click.option("--local_folder")</pre>
			<pre class="source-code">@click.option("--pipeline_run_name")</pre>
			<pre class="source-code">def task(download_url, local_folder, pipeline_run_name):</pre>
			<pre class="source-code">    with mlflow.start_run(run_name=pipeline_run_name) as mlrun:</pre>
			<pre class="source-code">        <strong class="bold">download_data(download_url, local_folder)</strong></pre>
			<pre class="source-code">        mlflow.log_param("download_url", download_url)</pre>
			<pre class="source-code">        mlflow.log_param("local_folder", local_folder)</pre>
			<pre class="source-code">        mlflow.set_tag('pipeline_step', __file__)</pre>
			<pre class="source-code">        mlflow.log_artifacts(local_folder, artifact_path="data")</pre>
			<pre class="source-code">if __name__ == '__main__':</pre>
			<pre class="source-code">    task()</pre>
			<p>在这个<code>download_data.py</code>实现中，任务是从远程URL下载建模数据到本地文件夹(<code>download_data(download_url, local_folder)</code>)。一旦我们完成了这些，我们将记录一些<a id="_idIndexMarker183"/>参数，比如<code>download_url</code>和<code>local_folder</code>。我们还可以使用<code>mlflow.log_artifacts</code>将新下载的数据记录到MLflow工件存储中。对于本例，这似乎没有必要，因为我们只想在本地开发环境中执行下一步。然而，对于分布式执行环境中更现实的场景，其中每个步骤可以在不同的执行环境中运行，这是非常理想的，因为我们只需要将工件URL路径传递给管道的下一个步骤来使用；我们不需要知道上一步是如何执行的，在哪里执行的。在这个例子中，当调用<code>mlflow.log_artifacts(local_folder, artifact_path="data")</code>语句时，下载的数据文件夹被上传到MLflow工件存储。然而，我们不会在本章的下游管道步骤<a id="_idIndexMarker184"/>中使用这个工件路径。在本书的后面，我们将探索如何使用这种工件存储将工件传递到管道中的下一步。这里，我们将使用日志参数将下载的数据路径传递到管道的下一步(<code>mlflow.log_param("local_folder", local_folder)</code>)。因此，让我们看看如何通过扩展<code>main.py</code>来实现这一点，使其包含下一步，即<code>fine_tuning_model</code>入口点，如下所示:</p>
			<pre class="source-code">        with mlflow.start_run(run_name='pipeline', nested=True) as active_run:</pre>
			<pre class="source-code">            download_run = mlflow.run(".", "download_data", parameters={})</pre>
			<pre class="source-code">            download_run = <strong class="bold">mlflow.tracking.MlflowClient().get_run</strong>(download_run.run_id)</pre>
			<pre class="source-code">            <strong class="bold">file_path_uri</strong> = <strong class="bold">download_run.data.params['local_folder']</strong></pre>
			<pre class="source-code">            fine_tuning_run = mlflow.run(".", "fine_tuning_model", <strong class="bold">parameters={"data_path": file_path_uri}</strong>)</pre>
			<p>我们使用<code>mlflow.tracking.MlflowClient().get_run</code>来获取<code>download_run</code> MLflow run对象，然后使用<code>download_run.data.params</code>来获取<code>file_path_uri</code>(在本例中，它只是一个本地文件夹路径)。这然后被传递到下一个<code>mlflow.run</code>，也就是<code>fine_tuning_run</code>，作为键值参数(<code>parameters={"data_path": file_path_uri</code>)。这样,<code>fine_tuning_run</code>管道步骤可以使用这个参数作为其数据源路径的前缀。这是一个非常简单的场景，用来说明我们如何将数据从一个步骤传递到下一个步骤。使用ml flow(<a href="https://www.mlflow.org/docs/latest/python_api/mlflow.tracking.html">https://www . ml flow . org/docs/latest/python _ API/ml flow . tracking . html</a>)提供的<code>mlflow.tracking.MlflowClient()</code> API，可以直接访问运行的信息(参数、指标和工件)。</p>
			<p>我们还可以通过添加<code>register_model</code>步骤，用管道的第三步来扩展<code>main.py</code>文件。这一次，我们需要已登录的模型URI来注册一个已训练的模型，这取决于<code>fine_tuning_model</code>步骤的<code>run_id</code>。因此，在<code>fine_tuning_model</code>步骤中，我们需要<a id="_idIndexMarker186"/>获取<code>fine_tuning_model</code>运行的<code>run_id</code>属性，然后通过<code>register_model</code>运行的输入参数传递它，如下所示:</p>
			<pre class="source-code">fine_tuning_run_id = fine_tuning_run.run_id</pre>
			<pre class="source-code">register_model_run = mlflow.run(".", "register_model", parameters={"mlflow_run_id": fine_tuning_run_id})</pre>
			<p>现在，<code>register_model</code>步骤可以使用<code>fine_tuning_run_id</code>来定位记录的模型。<code>register_model</code>步骤的核心实现如下:</p>
			<pre class="source-code">    with mlflow.start_run() as mlrun:</pre>
			<pre class="source-code">        logged_model = f'runs:/{mlflow_run_id}/model'</pre>
			<pre class="source-code">        mlflow.register_model(logged_model, registered_model_name)</pre>
			<p>这将在由变量<code>logged_model</code>定义的URI处注册一个微调模型到MLflow模型注册表。</p>
			<p>如果您遵循了这些步骤，那么您应该有一个可以被MLflow从头到尾跟踪的工作管道。提醒一下，一个先决条件是已经设置了本地成熟的MLflow服务器，如<a href="B18120_03_ePub.xhtml#_idTextAnchor040"> <em class="italic">第3章</em> </a> <em class="italic">所示，跟踪模型、参数和指标</em>。您应该已经在上一节中设置了虚拟环境<code>dl_model</code>。要测试此管道，请查看位于<a href="https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/tree/main/chapter04">https://GitHub . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/tree/main/chapter 04</a>的本章GitHub存储库，并运行以下命令:</p>
			<pre>python main.py</pre>
			<p>这将运行整个三步管道，并在MLflow跟踪服务器中记录管道的<code>run_id</code>(即父运行)以及子运行时每一步的运行。当它完成运行时，控制台屏幕输出的最后几行将显示如下内容(当您运行管道时，您将在屏幕上看到许多输出):</p>
			<div><div><img src="img/B18120_Figure_4.8.jpg" alt="Figure 4.8 – Console output of running the pipeline with MLflow run_ids&#13;&#10;" width="1086" height="122"/>
				</div>
			</div>
			<p class="figure-caption">图4.8–使用MLflow run_ids运行管道的控制台输出</p>
			<p>这显示了管道的<code>run_id</code>，也就是<code>f8f21fdf8fff4fd6a400eeb403b776c8</code>；最后一步是<code>fine_tuning_model</code>的<code>run_id</code>房产，也就是<code>5ba38e059695485396e709b809e9bb8d</code>。如果我们通过点击<code>http://localhost</code>转到MLflow tracking服务器的UI网页，我们应该能够看到<code>dl_model_chapter04</code>实验文件夹中运行的<a id="_idIndexMarker187"/>以下嵌套实验，如下所示:</p>
			<div><div><img src="img/B18120_Figure_4.9.jpg" alt="Figure 4.9 – A pipeline being run with nested three-step child runs in the MLflow tracking server&#13;&#10;" width="1253" height="219"/>
				</div>
			</div>
			<p class="figure-caption">图4.9–在MLflow跟踪服务器中运行嵌套三步子管道的管道</p>
			<p>前面的屏幕截图显示了管道运行，以及源文件<code>main.py</code>和管道三个步骤的嵌套运行。每一步都有一个对应的入口点名称，在<code>MLproject</code>中定义有GitHub提交哈希代码版本的<code>register_model</code>运行页面，你会看到以下信息:</p>
			<div><div><img src="img/B18120_Figure_4.10.jpg" alt="Figure 4.10 – Entry point register_model's run page on the MLflow tracking server&#13;&#10;" width="1232" height="572"/>
				</div>
			</div>
			<p class="figure-caption">图4.10–ml flow跟踪服务器上的入口点register_model运行页面</p>
			<p>前面的截图<a id="_idIndexMarker188"/>不仅显示了一些我们已经看到的熟悉信息，还显示了一些新信息，如<code>file:///</code>、GitHub哈希代码版本、入口点<code>(-e register_model</code>、执行环境(这是一个本地开发环境(<code>-b local</code>)以及<code>register_model</code>函数的预期参数(<code>-P</code>)。我们将在本书的后面学习如何使用MLflow的<code>MLproject</code>运行命令来远程执行任务。这里，我们只需要理解源代码是通过入口点(<code>register_model</code>)引用的，而不是文件名本身，因为引用是在<code>MLproject</code>文件中声明为入口点的。</p>
			<p>如果您在MLflow跟踪服务器中看到了图4.9 和图4.10 所示的输出，那么是时候庆祝了——您已经使用MLflow成功地执行了多步DL管道！</p>
			<p>总之，要在MLflow中跟踪多步骤DL管道，我们可以使用<code>MLproject</code>来定义每个管道步骤的入口点和一个主管道入口点。在主管道函数中，我们实现了一些方法，以便数据可以在管道步骤之间传递。然后，每个管道步骤使用共享的数据以及其他输入参数来执行特定的任务。使用MLflow跟踪服务器来跟踪主要管道级函数和管道的每个步骤，MLflow跟踪服务器生成一个父级<code>run_id</code>来跟踪主要管道运行，并生成多个ml flow嵌套运行来跟踪每个管道的步骤。我们为每个管道步骤引入了一个模板，以标准的方式实现这个任务。我们还探索了通过MLflow的<code>run</code>参数和工件<a id="_idIndexMarker189"/>存储完成的强大管道链接，以了解如何在管道步骤之间传递数据。</p>
			<p>现在您已经知道了如何跟踪笔记本和管道，让我们学习如何跟踪Python库。</p>
			<h1 id="_idParaDest-55"><a id="_idTextAnchor054"/>跟踪本地私有的Python库</h1>
			<p>现在，让我们把注意力转移到跟踪本地私有的Python库上。对于公开发布的Python库，我们可以在一个需求文件或者一个<code>conda.yaml</code>文件中明确指定它们的发布版本，这个版本是在PyPI中发布的。例如，本章的<code>conda.yaml</code>文件(<a href="https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/blob/main/chapter04/conda.yaml">https://github . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/blob/main/chapter 04/conda . YAML</a>)定义了Python版本并提供了对需求文件的引用，如下所示:</p>
			<pre class="source-code">name: dl_model </pre>
			<pre class="source-code">channels:</pre>
			<pre class="source-code">  - conda-forge</pre>
			<pre class="source-code">dependencies:</pre>
			<pre class="source-code">  - python=3.8.10</pre>
			<pre class="source-code">  - pip</pre>
			<pre class="source-code">  - pip:</pre>
			<pre class="source-code">    - -r requirements.txt</pre>
			<p>Python版本定义为<code>3.8.10</code>，正在强制执行。这个<code>conda.yaml</code>文件还引用了一个<code>requirements.txt</code>文件，该文件包含以下版本化的Python包作为一个<code>requirements.txt</code>文件，该文件与<code>conda.yaml</code>文件位于同一目录中:</p>
			<pre class="source-code">ipykernel==6.4.1</pre>
			<pre class="source-code">lightning-flash[all]==0.5.0</pre>
			<pre class="source-code">mlflow==1.20.2</pre>
			<pre class="source-code">transformers==4.9.2</pre>
			<pre class="source-code">boto3==1.19.7</pre>
			<pre class="source-code">pytorch-lightning==1.4.9</pre>
			<pre class="source-code">datasets==1.9.0</pre>
			<pre class="source-code">click==8.0.3</pre>
			<p>正如我们所看到的，所有这些包<a id="_idIndexMarker191"/>都使用它们发布的PyPI(<a href="https://pypi.org/">https://pypi.org/</a>)版本号被明确跟踪<a id="_idIndexMarker192"/>。当您运行MLflow <code>MLproject</code>时，MLflow将使用<code>conda.yaml</code>文件和引用的<code>requirements.txt</code>文件动态创建一个conda虚拟环境。这确保了执行环境是可再现的，并且所有DL模型管道都可以成功运行。您可能已经注意到，在您第一次运行上一节的MLflow管道项目时，已经为您创建了这样一个虚拟环境。您可以通过运行以下命令再次执行此操作:</p>
			<pre>conda env list</pre>
			<p>这将在您当前的机器中产生一个conda虚拟环境的列表。您应该能够找到一个以<code>mlflow-</code>开头的虚拟环境，后面是一长串字母数字字符，如下所示:</p>
			<pre>mlflow-95353930ddb7b60101df80a5d64ef8bf6204a808</pre>
			<p>这是由MLflow动态创建的虚拟环境，它遵循在<code>conda.yaml</code>和<code>requirements.txt</code>中指定的依赖关系。随后，当您记录微调后的模型时，<code>conda.yaml</code>和<code>requirements.txt</code>将自动记录在MLflow工件存储中，如下所示:</p>
			<div><div><img src="img/B18120_Figure_4.11.jpg" alt="Figure 4.11 – Python packages are being logged and tracked in the MLflow artifact store&#13;&#10;" width="1222" height="625"/>
				</div>
			</div>
			<p class="figure-caption">图4.11–在MLflow工件存储中记录和跟踪Python包</p>
			<p>正如我们所见，<code>conda.yaml</code>文件被自动<a id="_idIndexMarker193"/>扩展以包含<code>requirements.txt</code>的内容，以及conda决定包含的其他依赖项。</p>
			<p>对于私有构建的Python包，这意味着Python包没有发布到PyPI供公众使用和参考，推荐的方法是使用<code>git+ssh</code>来包含这样的Python包。让我们假设你有一个名为<code>cool-dl-utils</code>的私人构建项目，你工作的组织名为<code>cool_org</code>，你的项目的资源库已经建立在GitHub中。如果您想在需求文件中包含这个项目的Python包，您需要确保将您的公钥添加到您的GitHub设置中。如果你想了解如何生成一个公钥并将其加载到GitHub中，可以看看GitHub的指南，网址是<a href="https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account">https://docs . GitHub . com/en/authentic ation/connecting-to-GitHub-with-ssh/adding-a-new-ssh-key-to-your-GitHub-account</a>。在<code>requirements.txt</code>文件中，您可以添加下面一行，它将引用一个特定的GitHub hash ( <code>81218891bbf5a447103884a368a75ffe65b17a44</code>)和从这个私有存储库构建的Python <code>.egg</code>包(如果您愿意，也可以引用一个<code>.whl</code>包):</p>
			<pre class="source-code">cool-dl-utils @ git+ssh://git@github.com/cool_org/cool-dl-utils.git@81218891bbf5a447103884a368a75ffe65b17a44#egg=cool-dl-utils</pre>
			<p>如果您在自己构建的包中有一个数字发布的<a id="_idIndexMarker194"/>版本，您也可以直接引用<code>requirements.txt</code>文件中的发布号，如下所示:</p>
			<pre class="source-code">git+ssh://git@github.com/cool_org/cool-dl-utils.git@2.11.4</pre>
			<p>这里<code>cool-dl-utils</code>的发布号是<code>2.11.4</code>。这允许MLflow将这个私有构建的包拉入虚拟环境来执行<code>MLproject</code>。在本章中，我们不需要引用任何私人构建的Python包，但是值得注意的是MLflow可以利用<code>git+ssh</code>方法来做到这一点。</p>
			<p>现在，让我们学习如何跟踪数据版本。</p>
			<h1 id="_idParaDest-56"><a id="_idTextAnchor055"/>跟踪三角洲湖泊中的数据版本</h1>
			<p>在本节中，我们将了解如何在MLflow中跟踪数据。历史上，数据管理<a id="_idIndexMarker196"/>和版本控制通常被认为不同于机器学习和数据科学。然而，以数据为中心的人工智能的出现正在发挥越来越重要的作用，特别是在DL中。因此，了解使用什么数据以及如何使用数据来改进DL模型至关重要。在2021年夏天由吴恩达组织的首届以数据为中心的人工智能竞赛中，成为获胜者的要求不是改变<a id="_idIndexMarker197"/>和调整模型，而是改善固定模型的数据集(<a href="https://https-deeplearning-ai.github.io/data-centric-comp/">https://https-deeplearning-ai.github.io/data-centric-comp/</a>)。下面是来自<a id="_idIndexMarker198"/>比赛网页的一段话:</p>
			<p class="author-quote">“以数据为中心的人工智能竞赛颠覆了传统的形式，要求你在给定一个固定模型的情况下，改进一个数据集。我们将为您提供一个数据集，通过应用以数据为中心的技术进行改进，如修复不正确的标签、添加代表边缘案例的示例、应用数据扩充等。”</p>
			<p>这种范式转变凸显了数据在深度学习中的重要性，尤其是有监督的深度学习，其中标记的数据很重要。一个隐含的潜在假设是，不同的数据将产生不同的模型度量，即使使用相同的模型架构和参数。这要求我们努力地跟踪数据版本化过程，以便我们知道哪个版本的数据正被用于产生获胜的模型。</p>
			<p>在ML/DL生命周期中，有几个<a id="_idIndexMarker199"/>用于跟踪数据版本<a id="_idIndexMarker200"/>的新兴框架。这个领域的早期<a id="_idIndexMarker201"/>先驱之一是<strong class="bold">http://dvc.org</strong>(<a href="http://dvc.org">DVC</a>)。它使用一组类似GitHub的命令来拉/推数据，就像它们是代码一样。它允许数据被远程存储在S3或谷歌驱动器，以及许多其他受欢迎的商店。然而，存储在远程存储中的数据变得杂乱无章，不可读。由于访问数据的唯一方式是通过DVC工具和配置，这就变成了一个固有的问题。此外，很难跟踪数据及其模式是如何改变的。虽然可以将MLflow与DVC集成，但它的可用性和灵活性并不像我们希望的那样理想。因此，我们不会在本书中深入探讨这种方法。如果你对此感兴趣，我们建议你利用本章末尾的<em class="italic">使用DVC的ML项目中的版本控制数据和模型和AWS </em>参考来找到更多关于使用DVC的细节。</p>
			<p>最近开放的<a id="_idIndexMarker202"/> sourced和基于开放格式的<strong class="bold">Delta Lake</strong>(<a href="https://delta.io/">https://delta.io/</a>)是DL/ML项目中集成数据管理和版本控制的实用解决方案，特别是因为MLflow可以直接支持这种集成。这也是基础的<a id="_idIndexMarker203"/>数据管理层，称为<strong class="bold">lake house</strong>(<a href="https://databricks.com/blog/2020/01/30/what-is-a-data-lakehouse.html">https://databricks . com/blog/2020/01/30/what-is-a-data-lake house . html</a>)，它将数据<a id="_idIndexMarker204"/>仓库和流数据统一到一个数据基础层中。它支持模式变更跟踪和数据版本控制，这是DL/ML数据使用场景的理想选择。Delta <a id="_idIndexMarker205"/>表基于开放的标准文件格式，称为<strong class="bold">Parquet</strong>(<a href="https://parquet.apache.org/">https://parquet.apache.org/</a>)，广泛支持大规模数据存储。</p>
			<p class="callout-heading">数据块中的增量表</p>
			<p class="callout">注意，本节假设<a id="_idIndexMarker207"/>您可以访问数据块<a id="_idIndexMarker208"/>服务，这允许您<a id="_idIndexMarker209"/>在<strong class="bold">数据块文件系统</strong> ( <strong class="bold"> DBFS </strong>)中试验Delta Lake格式。你可以去Databricks门户网站<a href="https://community.cloud.databricks.com/login.html">https://community.cloud.databricks.com/login.html</a>获得社区版的试用账号<a id="_idIndexMarker210"/>。</p>
			<p>请注意，本节<a id="_idIndexMarker211"/>要求您使用<strong class="bold"> PySpark </strong>通过从/向存储器(如S3)读取/写入数据来操作数据。Delta Lake有一个叫做<strong class="bold">时间旅行</strong>的功能，可以自动<a id="_idIndexMarker212"/>版本化数据。通过传递一个参数，比如时间戳或版本号，可以读取该特定版本或时间戳的任何历史数据。这使得复制和跟踪实验更加容易，因为关于数据的唯一的时间元数据是数据的版本号或时间戳。有两种方法可以查询增量表:</p>
			<ul>
				<li><code>timestampAsOf</code>:这允许你读取增量表，以及读取一个有特定时间戳的版本。以下代码显示了如何使用<code>timestampAsOf</code> : <pre>df = spark.read \   .format("delta") \   .option("<strong class="bold">timestampAsOf</strong>", "2020-11-01") \   .load("/path/to/my/table")</pre>读取数据</li>
				<li><code>versionAsOf</code>:定义增量表版本的数值。您还可以选择从版本0开始读取具有特定版本的版本。下面的PySpark代码使用定义为版本<code>52</code> : <pre>df = spark.read \   .format("delta") \   .option("<strong class="bold">versionAsOf</strong>", "52") \   .load("/path/to/my/table")</pre>的<code>versionAsOf</code>选项读取数据</li>
			</ul>
			<p>拥有这种带时间戳或版本化的访问是使用增量表跟踪任何文件版本的一个关键优势。因此，让我们来看看MLflow中的一个具体示例，这样我们就可以跟踪我们一直在使用的IMDb数据集。</p>
			<h2 id="_idParaDest-57"><a id="_idTextAnchor056"/>使用MLflow跟踪数据的示例</h2>
			<p>对于我们一直用来微调情感分类<a id="_idIndexMarker216"/>模型的IMDb数据集<a id="_idIndexMarker215"/>，我们将把这些CSV文件上传到Databricks的数据存储或您可以从Databricks门户访问的任何S3存储桶中。完成后，按照以下步骤创建一个支持版本化和时间戳数据访问的增量表:</p>
			<ol>
				<li value="1">将以下CSV文件读入一个数据帧(假设你将<code>train.csv</code>文件上传到数据块中的<code>FileStore/imdb/</code>文件夹):<pre>imdb_train_df = spark.read.option('header', True).csv('dbfs:/FileStore/imdb/train.csv')</pre></li>
				<li>将DBFS的<code>imdb_train_df</code>数据帧写成增量表，如下:<pre>imdb_train_df.write.format('delta').option("mergeSchema", "true").mode("overwrite").save('/imdb/training.delta')</pre></li>
				<li>使用以下命令将<code>training.delta</code>文件读回内存:<pre>imdb_train_delta = spark.read.format('delta').load('/imdb/training.delta')</pre></li>
				<li>现在，通过Databricks UI查看增量表的历史。将增量表从存储器读入内存后，点击<strong class="bold">历史</strong>选项卡:</li>
			</ol>
			<div><div><img src="img/B18120_Figure_4.12.jpg" alt="Figure 4.12 – The train_delta table's history with a version and a timestamp column&#13;&#10;" width="653" height="288"/>
				</div>
			</div>
			<p class="figure-caption">图4.12–带有版本和时间戳列的train_delta表的历史</p>
			<p>前面的截图显示版本为<strong class="bold"> 0 </strong>，时间戳为<strong class="bold"> 2021-11-22 </strong>。当将版本号或时间戳传递给Spark数据帧读取器时，我们可以使用这个值来访问版本化数据。</p>
			<ol>
				<li value="5">使用以下命令读取版本化的<code>imdb/train_delta</code>文件:<pre>train_data_version = spark.read.format("delta").option("versionAsOf", "0").load('/imdb/train.delta')  </pre></li>
			</ol>
			<p>这将读取<code>train.delta</code>文件的版本<code>0</code>。如果我们有这个文件的其他版本，我们可以传递一个不同的版本号。</p>
			<ol>
				<li value="6">使用以下命令读取带时间戳的<code>imdb/train_delta</code>文件:<pre>train_data_timestamped = spark.read.format("delta").option("timestampAsOf", "2021-11-22T03:39:22").load('/imdb/train.delta')  </pre></li>
			</ol>
			<p>这将读取带有时间戳的数据。在撰写本文时，这是我们仅有的时间戳，这很好。如果我们有更多的时间戳数据，我们可以传递给它一个不同的版本。</p>
			<ol>
				<li value="7">现在，如果我们需要在MLflow跟踪实验运行中记录这个数据版本，我们可以使用<code>mlflow.log_parameter()</code>记录数据的路径、版本号和/或时间戳。这会将这些记录为实验参数键值列表的一部分:<pre>mlflow.log_parameter('file_path', '/imdb/train.delta') mlflow.log_parameter('file_version', '0') mlflow.log_parameter('file_timestamp', '2021-11-22T03:39:22') </pre></li>
			</ol>
			<p>使用增量表的唯一要求是，数据需要以支持增量表的存储形式存储，如Databricks支持的Lakehouse。这对于企业ML/DL场景<a id="_idIndexMarker220"/>有很大的<a id="_idIndexMarker219"/>价值，因为我们可以跟踪数据版本以及代码和模型版本。</p>
			<p>总之，Delta Lake提供了一种简单而强大的数据版本化方法。MLflow可以轻松地记录这些版本号和时间戳，作为实验参数列表的一部分，以跟踪数据，以及所有其他参数、指标、工件、代码和模型。</p>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor057"/>总结</h1>
			<p>在本章中，我们深入探讨了如何在MLflow实验运行中跟踪代码和数据版本。我们首先回顾了不同类型的笔记本:Jupyter笔记本、Databricks笔记本和VS Code笔记本。我们对它们进行了比较，并推荐使用VS代码来创作笔记本，因为它支持IDE、Python风格、自动完成以及许多更丰富的特性。</p>
			<p>然后，在回顾了现有ML管道API框架的局限性之后，我们讨论了如何使用MLflow的<code>run_id</code>创建多步DL管道，然后为每个管道步骤使用子管道<code>run_id</code>。通过将参数或工件存储位置传递给下一步，可以使用<code>mlflow.run()</code>和<code>mlflow.tracking.MlflowClient()</code>灵活地进行管道链接和跟踪。我们使用MLflow嵌套运行跟踪功能成功运行了端到端的三步管道。这也将为我们在以后的章节中扩展MLproject的使用，以分布式方式运行不同的步骤打开大门。</p>
			<p>我们还学习了如何使用<code>git+ssh</code>方法跟踪私有构建的Python包。然后，我们使用Delta Lake方法获得对数据的版本化和时间戳访问。这允许使用版本号或时间戳以两种方式跟踪数据。MLflow然后可以在MLflow实验运行期间记录这些版本号或时间戳作为参数。由于我们正在进入以数据为中心的人工智能时代，能够跟踪数据版本对于可重复性和时间旅行至关重要。</p>
			<p>至此，我们已经学习了如何使用MLflow全面地跟踪代码、数据和模型。在下一章，我们将学习如何以分布式方式扩展我们的DL实验。</p>
			<h1 id="_idParaDest-59"><a id="_idTextAnchor058"/>延伸阅读</h1>
			<p>有关本章涵盖的主题的更多信息，请查看以下资源:</p>
			<ol>
				<li value="1">数据块中的MLflow笔记本实验跟踪:<a href="https://docs.databricks.com/applications/mlflow/tracking.html#create-notebook-experiment">https://docs . data bricks . com/applications/ml flow/tracking . html # create-notebook-experiment</a></li>
				<li><em class="italic">构建多步骤工作流</em>:<a href="https://www.mlflow.org/docs/latest/projects.html#building-multistep-workflows">https://www . ml flow . org/docs/latest/projects . html # Building-multi step-Workflows</a></li>
				<li><em class="italic">带有MLflow项目的端到端ML管道</em>:<a href="https://dzlab.github.io/ml/2020/08/09/mlflow-pipelines/">https://dzlab.github.io/ml/2020/08/09/mlflow-pipelines/</a></li>
				<li>安装私有构建的Python包:<a href="mailto:https://medium.com/@ffreitasalves/pip-installing-a-package-from-a-private-repository-b57b19436f3e">https://medium . com/@ ffreitasalves/pip-installing-a-package-from-a-private-repository-b57b 19436 f3e</a></li>
				<li><em class="italic">使用DVC和AWS对ML项目中的数据和模型进行版本控制</em>:<a href="https://medium.com/analytics-vidhya/versioning-data-and-models-in-ml-projects-using-dvc-and-aws-s3-286e664a7209">https://medium . com/analytics-vid hya/Versioning-data-and-models-in-ML-projects-using-DVC-and-AWS-S3-286 e664 a 7209</a></li>
				<li><em class="italic">引入大规模数据湖的Delta时间旅行</em>:<a href="https://databricks.com/blog/2019/02/04/introducing-delta-time-travel-for-large-scale-data-lakes.html">https://databricks . com/blog/2019/02/04/Introducing-Delta-Time-Travel-for-Large-Scale-Data-Lakes . html</a></li>
				<li><em class="italic">我们如何赢得首届以数据为中心的人工智能大赛:Synaptic-AnN</em>:<a href="https://www.deeplearning.ai/data-centric-ai-competition-synaptic-ann/">https://www . deep learning . AI/Data-Centric-AI-Competition-Synaptic-AnN/</a></li>
				<li><em class="italic">复制任何东西:机器学习遇到数据湖屋</em>:<a href="https://databricks.com/blog/2021/04/26/reproduce-anything-machine-learning-meets-data-lakehouse.html">https://databricks . com/blog/2021/04/26/reproduct-any-Machine-Learning-Meets-Data-lake house . html</a></li>
				<li><em class="italic"> DATABRICKS社区版:初学者指南</em>:<a href="https://www.topcoder.com/thrive/articles/databricks-community-edition-a-beginners-guide">https://www . top coder . com/thrive/articles/data bricks-COMMUNITY-EDITION-A-初学者指南</a></li>
			</ol>
		</div>
	</div>
</body></html>