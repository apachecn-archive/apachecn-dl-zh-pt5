# 二、深度学习 MLflow 入门

MLflow 的关键功能之一是支持**机器学习** ( **ML** )实验管理。这一点至关重要，因为数据科学需要可再现性和可追溯性，以便可以使用相同的数据、代码和执行环境轻松再现**深度学习** ( **DL** )模型。本章将帮助我们快速开始实现 DL 实验管理。我们将了解 MLflow 实验管理概念和功能，设置 MLflow 开发环境，并使用 MLflow 完成我们的第一个 DL 实验。到本章结束时，我们将有一个工作的 MLflow 跟踪服务器显示我们的第一个 DL 实验结果。

在本章中，我们将讨论以下主要话题:

*   设置 MLflow
*   实现我们的第一个支持 MLflow 日志记录的 DL 实验
*   探索 MLflow 的组件和使用模式

# 技术要求

为了完成本章的实验，我们需要在我们的计算机上安装或检出以下工具、库和 GitHub 库:

*   VS 代码:本书我们使用的版本是 2021 年 8 月(也就是 1.60 版本)。我们在本地代码开发环境中使用 VS 代码。这是当地发展的推荐方式。请参考[https://code.visualstudio.com/updates/v1_60](https://code.visualstudio.com/updates/v1_60)。
*   MLflow:版本 1.20.2。在本章的*设置 MLflow* 部分，我们将介绍如何在本地或远程设置 MLflow。请参考[https://github.com/mlflow/mlflow/releases/tag/v1.20.2](https://github.com/mlflow/mlflow/releases/tag/v1.20.2)。
*   Miniconda:版本 4.10.3。请参考[https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)。
*   PyTorch `lightning-flash` : 0.5.0。请参考[https://github . com/PyTorchLightning/lightning-flash/releases/tag/0 . 5 . 0](https://github.com/PyTorchLightning/lightning-flash/releases/tag/0.5.0)。
*   本章代码的 GitHub URL:你可以在[https://GitHub . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/tree/main/chapter 02](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLflow/tree/main/chapter02)找到这个。

# 设置 MLflow

**MLflow** 是一个开源工具，主要用 Python 编写。它的 GitHub 源代码库中有超过 10，000 颗标记的星星(【https://github.com/mlflow/mlflow】T4)。使用 MLflow 的好处有很多，但是我们可以用下面的场景来说明一个好处:假设你正在开始一个新的 ML 项目，试图评估不同的算法和模型参数。几天之内，您使用不同的 ML/DL 库运行了数百个包含大量代码更改的实验，并获得了具有不同参数和精度的不同模型。您需要比较哪个模型更好，并允许您的团队成员复制结果用于模型评审目的。你是否准备了一份电子表格，并写下模型名称、参数、精度和模型位置？其他人如何能够重新运行您的代码或使用您的经过训练的具有不同评估数据集的模型呢？当您为不同的项目进行大量迭代时，这可能会很快变得难以管理。MLflow 可以帮助您跟踪您的实验，比较您的模型运行并允许他人轻松复制您的结果，重新使用您训练的模型进行审查，甚至轻松地将您的模型部署到生产中。

听起来很刺激？好吧，让我们设置 MLflow，以便我们可以探索它的组件和模式。MLflow 允许本地设置和基于云的设置。我们将在接下来的小节中介绍这两种设置场景。

## 使用 miniconda 在本地设置 MLflow

首先，让我们在本地开发环境中设置 MLflow。这允许快速原型制作，并帮助您熟悉 MLflow 工具的基本功能。此外，它允许您在需要时与远程 MLflow 云服务器进行交互。按照以下说明设置 MLflow。

假设您已经有了一个根据 [*第 1 章*](B18120_01_ePub.xhtml#_idTextAnchor015) 、*深度学习生命周期和 MLOps 挑战*创建的虚拟 conda 环境，您就可以在同一个虚拟环境中安装 MLflow 了:

```
pip install mlflow
```

前面的命令将安装 MLflow 的最新版本。如果您想要安装特定版本的 MLflow，可以使用以下命令:

```
pip install mlflow==1.20.2
```

如你所见，我已经安装了 MLflow 版本 1.20.2。默认情况下，MLflow 将使用本地文件系统来存储所有的实验工件(例如，一个序列化的模型)和元数据(参数、指标等等)。如果需要关系数据库作为 MLflow 的后端存储，则需要额外的安装和配置。现在，让我们使用文件系统进行存储。通过在命令行中键入以下内容，可以在本地验证 MLflow 安装:

```
mlflow --version
```

然后，它将显示已安装的 MLflow 版本，如下所示:

```
mlflow, version 1.20.2
```

这证实了我们已经在本地开发环境中安装了 ml flow 1 . 20 . 2 版。此外，您可以在本地启动 MLflow UI 以查看 MLflow 跟踪服务器 UI，如下所示:

```
mlflow ui
```

接下来，您将看到 UI web 服务器正在运行:

![Figure 2.1 – Starting the MLflow UI in a local environment
](img/B18120_02_001.jpg)

图 2.1–在本地环境中启动 MLflow UI

*图 2.1* 为本地 MLflow UI 网站:`http://127.0.0.1:5000/`。如果您单击此 URL，您将会看到以下 MLflow UI 出现在您的浏览器窗口中。由于这是一个全新的 MLflow 装置，只有一个**默认**实验，还没有运行(请参考*图 2.2* ):

![Figure 2.2 – The MLflow Default Experiments UI web page
](img/B18120_02_002.jpg)

图 2.2–ml flow 默认实验用户界面网页

看到默认 MLflow UI 页面启动并运行，即表示使用本地工作 MLflow 跟踪服务器成功设置了 MLflow。

## 设置 MLflow 以与远程 MLflow 服务器交互

在企业生产环境中，MLflow 通常托管在云服务器上，该云服务器可以是自托管的，也可以是云提供商(如 AWS、Azure 或 Google Cloud)中 Databricks 的托管服务之一。在这些情况下，需要设置您的本地开发环境，以便您可以在本地运行 ML/DL 实验，但可以与 MLflow 服务器进行远程交互。接下来，我们将借助以下三个步骤，描述如何使用环境变量来实现这一点:

1.  在 bash shell 命令行环境中，如果使用 Databricks 管理的 MLflow 跟踪服务器，请定义三个新的环境变量。第一个环境变量是`MLFLOW_TRACKING_URI`，赋值是`databricks` :

    ```
    export MLFLOW_TRACKING_URI=databricks export DATABRICKS_HOST=https://******* export DATABRICKS_TOKEN=dapi******
    ```

2.  第二个环境变量是`DATABRICKS_HOST`。如果你的 Databricks 管理的网站看起来像`https://dbc-*.cloud.databricks.com/`，那么这就是`DATABRICKS_HOST`变量的值(用你实际的网站字符串替换`*`)。
3.  第三个环境变量是`DATABRICKS_TOKEN`。通过`https://dbc-*.cloud.databricks.com/#setting/account`导航至您的数据块管理网站，点击**访问令牌**，然后点击**生成新令牌**。您将看到一个弹出窗口，其中有一个**注释**字段(可用于记录为什么要使用该令牌)和到期日期，如*图 2.3* 所示:

![Figure 2.3 – Generating a Databricks access token 
](img/B18120_02_003.jpg)

图 2.3–生成数据块访问令牌

点击`DATABRICKS_TOKEN`环境变量作为值:

![Figure 2.4 – Copying the generated token that will be used for the environment variable
](img/B18120_02_004.jpg)

图 2.4–复制将用于环境变量的生成令牌

一旦设置了这三个环境变量，您将能够在将来与 Databricks 管理的 MLflow 服务器进行交互。请注意，出于安全原因，访问令牌有一个到期日期，管理员可以随时撤销该日期，因此请确保在刷新令牌时相应地更新环境变量。

总之，我们已经了解了如何在本地设置 MLflow，以便与本地 MLflow 跟踪服务器或远程 MLflow 跟踪服务器进行交互。这将允许我们在下一节中实现我们的第一个支持 MLflow 跟踪的 DL 模型，以便我们能够以实际操作的方式探索 MLflow 概念和组件。

# 使用 MLflow 自动日志记录实现我们的第一个 DL 实验

让我们使用我们在 [*第 1 章*](B18120_01_ePub.xhtml#_idTextAnchor015) 、*深度学习生命周期和 MLOps 挑战*中构建的 DL 情感分类器，并为其添加 MLflow 自动日志记录，以探索 MLflow 的跟踪功能:

1.  首先，我们需要导入 MLflow 模块:

    ```
    import mlflow
    ```

这将为日志记录和加载模型提供 MLflow **应用编程接口**(**API**)。

1.  在运行训练代码之前，我们需要使用`mlflow.set_experiment`为当前运行的代码

    ```
    EXPERIMENT_NAME = "dl_model_chapter02" mlflow.set_experiment(EXPERIMENT_NAME) experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME) print("experiment_id:", experiment.experiment_id)
    ```

    设置一个活动实验

这会将名为`dl_model_chapter02`的实验设置为当前活动实验。如果您当前的跟踪服务器中不存在此实验，它将被自动创建。

环境变量

注意，在运行第一个实验之前，您可能需要使用`MLFLOW_TRACKING_URI`环境变量来设置跟踪服务器 URI。如果您使用托管数据块服务器，请执行以下操作:

`export MLFLOW_TRACKING_URI=databricks`

如果您使用的是本地服务器，那么将这个环境变量设置为空或者端口号为`5000`的默认 localhost，如下所示(注意，这是我们当前章节的场景，假设您使用的是本地服务器):

`export MLFLOW_TRACKING_URI= http://127.0.0.1:5000`

1.  接下来，添加一行代码来启用 MLflow 中的自动日志记录:

    ```
    mlflow.pytorch.autolog()
    ```

此将允许默认参数、指标和模型自动记录到 MLflow 跟踪服务器。

MLflow 中的自动记录

MLflow 中的自动记录功能仍处于实验模式(从版本 1.20.2 开始)可能会在未来发生变化。在这里，我们使用它来探索 MLflow 组件，因为它只需要一行代码就可以自动记录所有感兴趣的内容。在接下来的章节中，我们将了解并实现在 MLflow 中执行跟踪和日志记录的其他方法。另外，请注意，目前，PyTorch 的 MLflow 中的自动登录(从版本 1.20.2 开始)仅适用于 PyTorch Lightning 框架，而不适用于任何任意的 PyTorch 代码。

1.  通过调用`mlflow.start_run` :

    ```
    with mlflow.start_run(experiment_id=experiment.experiment_id, run_name="chapter02"):     trainer.finetune(classifier_model,                       datamodule=datamodule,                       strategy="freeze")     trainer.test()
    ```

    ，使用 Python 上下文管理器`with`语句开始实验运行

注意，`with`块下面的所有代码行都是常规的 DL 模型微调和测试步骤。我们仅启用自动 MLflow 日志记录，以便我们可以观察 MLflow 跟踪服务器正在跟踪/记录的元数据。

1.  接下来，您可以使用以下命令行运行`first_dl_with_mlflow.py`的完整代码(完整代码可以在本章的 GitHub 中查看，网址为[https://GitHub . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/blob/main/chapter 02/first _ dl _ with _ ml flow . py](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/blob/main/chapter02/first_dl_with_mlflow.py)):

    ```
    python first_dl_with_mlflow.py
    ```

在非 GPU macOS 笔记本电脑上，整个运行过程不到 10 分钟。您的屏幕上应该有一个输出，如下所示:

![Figure 2.5 – DL model training/testing with MLflow autologging enabled
](img/B18120_02_005.jpg)

图 2.5–启用 MLflow 自动记录的 DL 模型训练/测试

如果你是第一次运行这个，你会看到名称为`dl_model_chapter02`的实验并不存在。相反，MLflow 会自动为您创建这个实验:

![Figure 2.6 – MLflow automatically creates a new environment if it does not exist
](img/B18120_02_006.jpg)

图 2.6–如果不存在新环境，MLflow 会自动创建一个新环境

1.  现在，我们可以在本地打开 MLflow UI，通过导航到`http://127.0.0.1:5000/`来查看本地跟踪服务器中记录了什么。在这里，您将看到一个新的实验(`dl_model_chapter02`)和一个新的运行(`chapter02`)已被记录:

![Figure 2.7 – The MLflow tracking server UI shows a new experiment with a new run
](img/B18120_02_007.jpg)

图 2.7–ml flow 跟踪服务器用户界面显示了新运行的新实验

现在，点击*图 2.7* 中**开始时间**栏的超链接。您将看到运行记录的元数据的详细信息:

![Figure 2.8 – The MLflow run UI shows the metadata details about the experiment run
](img/B18120_02_008.jpg)

图 2.8–ml flow 运行 UI 显示了关于实验运行的元数据详细信息

如果您可以在自己的本地环境中查看该屏幕，那么恭喜您！您刚刚完成了我们第一个 DL 模型的 MLflow 跟踪的实现！在下一节中，我们将使用我们的工作示例来探索 MLflow 中的核心概念和组件。

# 探索 MLflow 的组件和使用模式

让我们使用前一节中实现的工作示例来探索 MLflow 中的以下核心概念、组件和用法。这些包括实验、运行、关于实验的元数据、实验的工件、模型和代码。

## 在 MLflow 中探索实验和运行

**实验**是 MLflow APIs 中的一个一级实体。这是有意义的，因为数据科学家和 ML 工程师需要运行大量的实验，以便建立一个满足要求的工作模型。然而，实验的想法不仅仅局限于模型开发阶段，而是延伸到 ML/DL 开发和部署的整个生命周期。因此，这意味着当我们为模型的生产版本进行再培训或培训时，我们需要将它们视为生产质量实验。这种统一的实验视图在离线和在线生产环境之间架起了一座桥梁。每个实验由许多次运行组成，在这些运行中，您可以改变每次运行的模型参数、输入数据甚至模型类型。所以，实验是一个包含一系列运行的伞状实体。下图(*图 2.9* )说明了数据科学家可以在 ML/DL 模型生命周期的多个阶段进行离线实验和在线生产实验:

![Figure 2.9 – Experiments across the offline and online production life cycles of ML/DL models
](img/B18120_02_009.jpg)

图 2.9–ML/DL 模型的离线和在线生产生命周期的实验

从*图 2.9* 中可以看出，在模型开发阶段，数据科学家可以根据项目场景，多次运行同一个实验或多个实验。如果是一个小的 ML 项目，在一个单独的离线实验下运行所有的项目就足够了。如果是一个复杂的 ML 项目，设计不同的实验并且在每个实验下进行运行是合理的。设计 ML 实验的好参考可以在[https://machine learning mastery . com/controlled-experiments-in-machine-learning/](https://machinelearningmastery.com/controlled-experiments-in-machine-learning/)找到。然后，在模型生产阶段，建立生产质量实验是可取的，因为我们需要执行模型改进和模型再培训的持续部署。生产实验将提供门控准确性检查，以防止新模型的回归。通常，这是通过对拒绝测试数据集运行自动模型评估和验证来实现的，以检查新模型在准确性方面是否仍然符合发布标准。

现在，让我们以动手的方式探索 MLflow 实验。运行以下 MLflow 命令行与跟踪服务器进行交互:

```
mlflow experiments list 
```

如果您的`MLFLOW_TRACKING_URI`环境变量指向一个远程跟踪服务器，那么它将列出您拥有读取权限的所有实验。如果您想查看本地跟踪服务器中有什么，您可以将`MLFLOW_TRACKING_URI`设置为 nothing(即空的)，如下所示(注意，如果您的本地用户配置文件中从未有过这个环境变量，您不需要这样做；但是，这样做将确保您使用本地跟踪服务器):

```
export MLFLOW_TRACKING_URI=
```

在您第一次实现启用了 MLflow 自动记录的 DL 模型之前，列出您所有实验的输出应该类似于*图 2.10* (注意，这也取决于您在哪里运行命令行；以下输出假设您在本地文件夹中运行该命令，您可以在 GitHub 上检查第 2 章 的 [*代码):*](B18120_02_ePub.xhtml#_idTextAnchor027)

![Figure 2.10 – The default MLflow experiment list in a local environment
](img/B18120_02_010.jpg)

图 2.10–本地环境中的默认 MLflow 实验列表

*图 2.10* 列出了实验属性的三列:执行 MLflow 命令的目录下的`mlruns`文件夹。基于文件系统的 MLflow 跟踪服务器使用`mlruns`文件夹来存储实验运行和工件的所有元数据。

命令行界面(CLI)与 REST APIs 以及特定于编程语言的 API

MLflow 提供了三种不同类型的工具和 API 来与跟踪服务器进行交互。这里使用了 CLI，以便我们可以探索 MLflow 组件。

因此，让我们探索一个特定的 MLflow 实验，如下所示:

1.  首先，使用 MLflow CLI 创建一个新实验，如下所示:

    ```
    mlflow experiments create -n dl_model_chapter02
    ```

前面的命令创建了一个名为`dl_model_chapter02`的新实验。如果您已经在上一节中运行了第一个带 MLflow 自动记录的 DL 模型，则前面的命令将导致一条错误消息，如下所示:

```
mlflow.exceptions.MlflowException: Experiment 'dl_model_chapter02' already exists.
```

这是意料之中的，你没做错什么。现在，如果您列出本地跟踪服务器中的所有实验，它应该包括新创建的实验，如下所示:

![Figure 2.11 – The new MLflow experiments list after creating a new experiment
](img/B18120_02_011.jpg)

图 2.11–创建新实验后的新 MLflow 实验列表

1.  现在，让我们检查实验和运行之间的关系。如果您仔细查看运行页面的 URL(*图 2.8* ，您将会看到类似于以下内容的内容:

`http://127.0.0.1:5000/#/experiments/1/runs/2f2ec6e72a5042f891abe0d3a533eec7`

正如您可能已经从中了解到的，路径`experiments`之后的整数就是实验 ID。然后，在实验 ID 之后，有一个`runs`路径，后面跟着一个类似 GUID 的随机字符串，这就是运行 ID。因此，现在我们了解了如何在具有全局唯一 ID(称为运行 ID)的实验下组织运行。

知道一个跑步的全局唯一 ID 是非常有用的。这是因为我们可以使用`run_id`检索运行记录的数据。如果您使用`mlflow runs describe --run-id <run_id>`命令行，您可以获得这次运行记录的元数据列表。对于我们刚刚运行的实验，下面显示了带有运行 ID 的完整命令:

```
mlflow runs describe –-run-id 2f2ec6e72a5042f891abe0d3a533eec7
```

该命令行的输出片段如下(*图 2.12* ):

![Figure 2.12 – The MLflow command line describes the run in the JSON data format
](img/B18120_02_012.jpg)

图 2.12–ml flow 命令行描述了 JSON 数据格式的运行

注意*图 2.12* 以 JSON 格式呈现了关于这次运行的所有元数据。该元数据包括模型训练所使用的参数；用于测量模型在训练、验证和测试中的准确性的度量标准；还有更多。相同的数据也显示在图 2.8 中*的 MLflow UI 中。请注意，强大的 MLflow CLI 将允许非常方便地探索 MLflow 记录的元数据和工件，并支持基于 shell 脚本的自动化，我们将在接下来的章节中进行探索。*

## 探索 MLflow 模型及其用法

现在，让我们探索一下 DL 模型工件是如何记录在 MLflow 跟踪服务器中的。在同一个运行页面上，如*图 2.8* 所示，如果向下滚动到底部，就会看到工件部分(*图 2.13* )。这列出了关于模型和序列化模型本身的所有元数据:

![Figure 2.13 – The model artifacts logged by MLflow
](img/B18120_02_013.jpg)

图 2.13–ml flow 记录的模型工件

MLflow 跟踪服务器的后端存储和工件存储

MLflow 跟踪服务器有两种类型的存储:第一，后端存储，它存储实验和运行元数据以及运行的参数、度量和标签；第二个是工件存储，它存储更大的文件，比如序列化的模型、文本文件，甚至是为可视化模型结果而生成的图。为了简单起见，在本章中，我们对后端存储和工件存储都使用本地文件系统。然而，一些更高级的特性，比如模型注册，在基于文件系统的工件存储中是不可用的。在后面的章节中，我们将学习如何使用模型注册中心。

我们来看看神器列表，一个一个来看:

*   `model_summary.txt`:在`root`文件夹级别，如果你点击它，这个文件看起来类似于下面的输出。它描述了 DL 模型的模型度量和层次(请参见*图 2.14* ):

![Figure 2.14 – The model summary file logged by MLflow
](img/B18120_02_014.jpg)

图 2.14–ml flow 记录的模型摘要文件

*图 2.14* 从神经网络层的数量和类型、参数的数量和大小以及训练和验证中使用的指标类型等方面快速概述了 DL 模型。当 DL 模型架构需要在团队成员或涉众之间共享和交流时，这是非常有用的。

*   `model`文件夹:该文件夹包含一个名为`data`的子文件夹，以及三个名为`MLmodel`、`conda.yaml`和`requirements.txt`的文件:
    *   `MLmodel`:这个文件描述了 MLflow 支持的模型的风格。`MLmodel`文件(*图 2.15* ):

![Figure 2.15 – Content of the MLmodel file for our first DL model run with MLflow
](img/B18120_02_015.jpg)

图 2.15–我们使用 MLflow 运行的第一个 DL 模型的 MLmodel 文件的内容

*图 2.15* 说明这是我们刚刚运行的带有`run_id`的 PyTorch 风味模型。

*   `conda.yaml`:这是一个 conda 环境定义文件，模型使用它来描述我们的依赖关系。*图 2.16* 列出了我们刚刚完成的运行中 MLflow 记录的内容:

![Figure 2.16 – The content of the conda.yaml file logged by MLflow 
](img/B18120_02_016.jpg)

图 2.16–ml flow 记录的 conda.yaml 文件的内容

*   `requirements.txt`:这是一个 Python `pip`特有的依赖定义文件。就像`conda.yaml`文件中的`pip`部分，如图*图 2.16* 所示。
*   `data`:这是一个包含实际序列化模型的文件夹，名为`model.pth`，以及一个描述文件，名为`pickle_module_info.txt`，其内容如下:

    ```
    mlflow.pytorch.pickle_module
    ```

这意味着使用 MLflow 提供的 PyTorch 兼容 pickle 序列化方法来序列化模型。这允许 MLflow 在以后需要时将模型加载回内存。

模型注册与模型日志记录

MLflow 模型注册中心需要一个像 MySQL 这样的关系数据库作为工件存储，而不仅仅是一个普通的文件系统。因此，在这一章中，我们暂不探讨。请注意，模型注册与模型日志记录的不同之处在于，对于每次运行，您都希望记录模型元数据和工件。但是，只有对于满足您的生产需求的某些运行，您可能希望将它们注册到模型注册中心，以便进行生产部署和版本控制。在后面的章节中，我们将学习如何注册模型。

到目前为止，您应该对 MLflow 工件存储中记录的关于模型和序列化模型的文件和元数据列表(以及我们实验中的`.pth`文件扩展名，它指的是 PyTorch 序列化模型)有了很好的理解。在接下来的章节中，我们将学习更多关于 MLflow 模型风格如何工作，以及如何使用日志模型进行模型注册和部署。MLflow 模型风格是由 MLflow 支持的模型框架，如 PyTorch、TensorFlow 和 scikit-learn。感兴趣的读者可以从官方 MLflow 文档网站 https://www . MLflow . org/docs/latest/models . html # built-in-model-flavors 找到更多关于 ml flow 支持的当前内置模型风格的详细信息。

## 探索 MLflow 代码跟踪及其用法

当探索运行的元数据时，我们还可以发现代码是如何被跟踪的。如 MLflow UI 和 JSON 中的命令行输出所示，代码以三种方式被跟踪:文件名、Git 提交散列和源类型。您可以执行以下命令行:

```
mlflow runs describe --run-id 2f2ec6e72a5042f891abe0d3a533eec7 | grep mlflow.source
```

您应该能够在输出中找到 JSON 键-值对的以下部分:

```
"mlflow.source.git.commit": "ad6c7338a416ff4c2848d726b092057457c22408",
"mlflow.source.name": "first_dl_with_mlflow.py",
"mlflow.source.type": "LOCAL"
```

基于这个`ad6c7338a416ff4c2848d726b092057457c22408` Git 提交散列，我们可以继续寻找我们使用的 Python 代码的精确副本:[https://github . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/blob/ad6 c 7338 a 416 ff 4c 2848d 726 b 092057457 c 22408/chapter 02/first _ dl _ with _ ml flow . py](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLflow/blob/ad6c7338a416ff4c2848d726b092057457c22408/chapter02/first_dl_with_mlflow.py)。

注意，这里的源类型是`LOCAL`。这意味着我们从代码的本地副本执行支持 MLflow 的源代码。在后面的章节中，我们将学习关于其他来源类型。

本地与远程 GitHub 代码

如果源代码是代码的本地副本，那么在 MLflow 跟踪服务器上会有一个关于 Git 提交散列的警告。如果您在本地进行了代码更改，但忘记提交它们，然后立即开始 MLflow 实验跟踪运行，MLflow 将只记录最新的 Git 提交哈希。我们可以用两种方法之一来解决这个问题:

1.在运行 MLflow 实验之前提交我们的代码更改。

2.使用远程 GitHub 代码运行实验。

因为第一种方法不容易实现，所以第二种方法是优选的。使用远程 GitHub 代码运行 DL 实验是一个高级主题，我们将在后面的章节中探讨。

到目前为止，我们已经了解了 MLflow 跟踪服务器、实验和运行。此外，我们还记录了关于运行的元数据，如参数和度量，检查了代码跟踪，并探索了模型日志记录。这些跟踪和记录功能确保我们有一个可靠的 ML 实验管理系统，不仅用于模型开发，还用于未来的模型部署，因为我们需要跟踪哪些运行产生了用于生产的模型。*再现性*和*来源追踪*是 MLflow 所提供的标志。除此之外，MLflow 还提供了其他组件，例如用于标准化 ML 项目代码组织的 **MLproject** ，用于模型版本控制的模型注册中心，模型部署功能，以及模型可解释性工具。所有这些 MLflow 组件涵盖了 ML/DL 开发、部署和生产的整个生命周期，我们将在以后的章节中对其进行更深入的研究。

# 摘要

在本章中，我们学习了如何设置 MLflow 以与本地 MLflow 跟踪服务器或远程 MLflow 跟踪服务器配合使用。然后，我们实现了第一个启用了 MLflow 自动日志记录的 DL 模型。这使我们能够以实践的方式探索 MLflow，了解一些中心概念和基础组件，如实验、运行、关于实验和运行的元数据、代码跟踪、模型日志记录和模型风格。本章获得的知识和第一轮经验将帮助我们在下一章学习更深入的 MLflow 跟踪 API。

# 延伸阅读

为了加深您的知识，您可以参考以下资源和文档:

*   MLflow *命令行界面*文档:[https://www.mlflow.org/docs/latest/cli.html](https://www.mlflow.org/docs/latest/cli.html)
*   MLflow PyTorch 自动记录文档:[https://www . ml flow . org/docs/latest/tracking . html # py torch-experimental](https://www.mlflow.org/docs/latest/tracking.html#pytorch-experimental)
*   MLflow PyTorch 模型风味文档:[https://www . ml flow . org/docs/latest/python _ API/ml flow . py torch . html # module-ml flow . py torch](https://www.mlflow.org/docs/latest/python_api/mlflow.pytorch.html#module-mlflow.pytorch)
*   *MLflow 和 py torch——前沿 AI 与 MLOps 相遇的地方*:[https://medium . com/py torch/ml flow-and-py torch-Where-Edge-AI-meets-MLOps-1985 cf 8 aa 789](https://medium.com/pytorch/mlflow-and-pytorch-where-cutting-edge-ai-meets-mlops-1985cf8aa789)
*   *机器学习中的受控实验*:[https://Machine Learning mastery . com/Controlled-Experiments-in-Machine-Learning/](https://machinelearningmastery.com/controlled-experiments-in-machine-learning/)