# 第三节– running 深度学习管道规模化

在本节中，我们将学习如何在不同的执行环境中运行**深度学习** ( **DL** )管道，并大规模执行超参数调优，或**超参数优化** ( **HPO** )。我们将从概述在不同环境中执行 DL 管道的场景和需求开始。然后我们将学习如何使用 MLflow 的**命令行接口** ( **CLI** )在分布式环境中的四个不同执行场景中运行。从这里开始，我们将通过比较 **Ray Tune** 、 **Optuna** 和 **HyperOpt** 来了解如何选择最佳的 HPO 框架，以便调整 DL 管道的超参数。最后，我们将集中讨论如何使用最先进的 HPO 框架(如 Ray Tune 和 MLflow)为 DL 大规模实施和运行 HPO。

本节包括以下章节:

*   [*第五章*](B18120_05_ePub.xhtml#_idTextAnchor060) 、*不同环境下运行的 DL 管道*
*   [*第六章*](B18120_06_ePub.xhtml#_idTextAnchor069) 、*运行超参数调谐标度*