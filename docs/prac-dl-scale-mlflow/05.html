<html><head/><body>




<style type="text/css">body{margin:1em;background-color:transparent!important;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}#sbo-rt-content *{word-wrap:break-word!important;word-break:break-word!important;}#sbo-rt-content table,#sbo-rt-content pre{overflow-x:unset!important;overflow:unset!important;overflow-y:unset!important;white-space:pre-wrap!important;}</style>
<div><div><h1 id="_idParaDest-41"><em class="italic"> <a id="_idTextAnchor040"/>第3章</em>:跟踪模型、参数和度量</h1>
			<p>鉴于MLflow可以在DL模型的生命周期中支持多种场景，因此通常会增量使用MLflow的功能。通常，人们从MLflow跟踪开始，因为它易于使用，并且可以处理许多用于再现性、来源跟踪和审计目的的场景。此外，从摇篮到日落跟踪模型的历史不仅超出了数据科学实验管理领域，而且对于企业中的模型治理也很重要，因为在生产中使用模型需要管理业务和监管风险。虽然在生产中跟踪模型的精确的商业价值仍然在发展，但是跟踪模型的整个生命周期的需求是不容置疑的，并且还在增长。为了能够做到这一点，我们将在本章开始时设置一个成熟的本地MLflow跟踪服务器。</p>
			<p>然后，我们将深入探讨如何使用MLflow的跟踪和注册API来跟踪模型及其参数和指标。在本章结束时，您应该能够自如地使用MLflow的跟踪和注册API进行各种重现和审计。</p>
			<p>在本章中，我们将讨论以下主要话题:</p>
			<ul>
				<li>设置成熟的本地MLflow跟踪服务器</li>
				<li>跟踪模型来源</li>
				<li>跟踪模型指标</li>
				<li>跟踪模型参数</li>
			</ul>
			<h1 id="_idParaDest-42"><a id="_idTextAnchor041"/>技术要求</h1>
			<p>以下是遵循本章中提供的说明所需的要求:</p>
			<ul>
				<li>Docker桌面:<a href="https://docs.docker.com/get-docker/">https://docs.docker.com/get-docker/</a>。</li>
				<li>PyTorch <code>lightning-flash</code> : 0.5.0。:<a href="https://github.com/PyTorchLightning/lightning-flash/releases/tag/0.5.0">https://github . com/PyTorchLightning/lightning-flash/releases/tag/0 . 5 . 0</a>。</li>
				<li>带有Jupyter笔记本扩展的VS代码:<a href="https://github.com/microsoft/vscode-jupyter/wiki/Setting-Up-Run-by-Line-and-Debugging-for-Notebooks">https://github . com/Microsoft/VS Code-Jupyter/wiki/Setting-Up-Run-by-Line-and-Debugging-for-Notebooks</a>。</li>
				<li>本章代码如下GitHub URL:<a href="https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLflow/tree/main/chapter03">https://GitHub . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/tree/main/chapter 03</a>。</li>
				<li>WSL2:如果你是微软Windows用户，建议安装WSL2运行本书提供的Bash脚本:<a href="https://www.windowscentral.com/how-install-wsl2-windows-10">https://www.windowscentral.com/how-install-wsl2-windows-10</a>。</li>
			</ul>
			<h1 id="_idParaDest-43"><a id="_idTextAnchor042"/>建立完善的本地MLflow跟踪服务器</h1>
			<p>在<a href="B18120_02_ePub.xhtml#_idTextAnchor027"> <em class="italic">第2章</em></a><em class="italic">深度学习MLflow入门</em>中，我们获得了使用基于本地文件系统的MLflow跟踪服务器和检查MLflow实验的组件<a id="_idIndexMarker122"/>的实践经验。但是，默认的基于本地文件系统的MLflow服务器有一些限制，因为模型注册表功能不可用。拥有模型注册中心的好处是，我们可以注册模型，对模型进行版本控制，并为模型部署到产品中做准备。因此，这个模型注册表将在离线实验和在线部署生产场景之间架起一座桥梁。因此，我们需要一个完整的MLflow跟踪服务器，它具有以下商店来跟踪模型的完整生命周期:</p>
			<ul>
				<li><strong class="bold">后端存储</strong>:需要一个关系数据库后端来支持MLflow存储关于实验的元数据<a id="_idIndexMarker123"/>(指标、参数和许多其他信息)。这也允许使用实验的查询能力。我们将使用MySQL数据库作为本地后端存储。</li>
				<li><strong class="bold">工件存储</strong>:一个<a id="_idIndexMarker124"/>对象存储，可以存储任意类型的对象，比如序列化的模型、词汇文件、图形等等。在生产环境中，一个受欢迎的选择是AWS S3商店。我们将使用<strong class="bold">MinIO</strong>(<a href="https://min.io/">https://min.io/</a>)，一个多云对象<a id="_idIndexMarker125"/>商店，作为一个本地工件商店，它与AWS S3商店API完全兼容，但可以在你的笔记本电脑上运行，无需你访问云。</li>
			</ul>
			<p>为了使这个<a id="_idIndexMarker126"/>本地设置尽可能简单，我们将使用<code>docker-compose</code>(<a href="https://docs.docker.com/compose/">https://docs.docker.com/compose/</a>)工具和一行命令来启动和停止本地成熟的MLflow跟踪服务器，如下面的<a id="_idIndexMarker127"/>步骤所述。注意，在执行这些步骤之前，必须在机器上安装并运行Docker Desktop(<a href="https://docs.docker.com/get-docker/">https://docs.docker.com/get-docker/</a>)。Docker帮助构建和共享容器化应用<a id="_idIndexMarker128"/>和微服务。以下步骤将在本地Docker容器中启动本地MLflow跟踪服务器:</p>
			<ol>
				<li>查看您本地开发环境的<code>chapter03</code>代码库:<a href="https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLflow/tree/main/chapter03">https://github . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/tree/main/chapter 03</a>。</li>
				<li>将目录转到<code>mlflow_docker_setup</code>子文件夹，可以在<code>chapter03</code>文件夹下找到。</li>
				<li>运行以下命令:<pre><strong class="bold">bash start_mlflow.sh</strong></pre></li>
			</ol>
			<p>如果该命令成功，您应该会在屏幕上看到类似以下内容的输出:</p>
			<div><div><img src="img/B18120_03_001.jpg" alt="Figure 3.1 – A local full-fledged MLflow tracking server is up and running&#13;&#10;" width="361" height="108"/>
				</div>
			</div>
			<p class="figure-caption">图3.1-本地成熟的MLflow跟踪服务器启动并运行</p>
			<ol>
				<li value="4">前往<code>http://localhost/</code>查看MLflow UI网页。然后，点击UI中的<strong class="bold">型号</strong>选项卡(<em class="italic">图3.2 </em>)。请注意，如果您只有一个本地文件系统作为MLflow跟踪服务器的后端存储，则此选项卡不起作用。因此，MLflow UI的后端现在运行在您刚刚启动的Docker容器服务上，而不是本地文件系统。由于这是一台全新的服务器，因此还没有注册型号:</li>
			</ol>
			<div><div><img src="img/B18120_03_002.jpg" alt="Figure 3.2 – MLflow model registry UI&#13;&#10;" width="902" height="299"/>
				</div>
			</div>
			<p class="figure-caption">图3.2–ml flow模型注册界面</p>
			<ol>
				<li value="5">转到<code>http://localhost:9000/</code>，应出现MinIO工件商店web UI的以下屏幕(<em class="italic">图3.3 </em>)。在<code>mlflow_docker_setup</code>文件夹下输入<code>.env</code>文件的<code>minio123</code>的<code>minio</code>:</li>
			</ol>
			<div><div><img src="img/B18120_03_003.jpg" alt="Figure 3.3 – MinIO Web UI login page and browser page after logging in&#13;&#10;" width="1657" height="519"/>
				</div>
			</div>
			<p class="figure-caption">图3.3–MinIO Web UI登录页面和登录后的浏览器页面</p>
			<p>此时<a id="_idIndexMarker130"/>您应该已经成功运行了一个成熟的本地MLflow跟踪服务器！如果您想停止服务器，只需键入以下命令:</p>
			<pre>bash stop_mlflow.sh</pre>
			<p>基于Docker的MLflow跟踪服务器将停止。我们现在准备使用这个本地MLflow服务器来跟踪模型出处、参数和度量。</p>
			<h1 id="_idParaDest-44"><a id="_idTextAnchor043"/>跟踪模型出处</h1>
			<p><strong class="bold">出处</strong>文献中对数字制品的跟踪已经研究了很久。例如，当您在生物医学行业使用一条患者诊断数据时，人们通常<a id="_idIndexMarker131"/>想知道它来自哪里，对数据进行了什么样的处理和清理，谁拥有数据，以及关于数据的其他历史和血统信息。生产中工业和商业场景的ML/DL模型的兴起使得来源跟踪成为一项必需的功能。来源跟踪的不同粒度不仅对数据科学离线实验的操作和管理至关重要，而且对模型在生产中部署之前/期间/之后的操作和管理也至关重要。那么，需要追踪哪些东西的出处呢？</p>
			<h2 id="_idParaDest-45"><a id="_idTextAnchor044"/>了解开放出处跟踪框架</h2>
			<p>让我们看看一个通用的起源追踪框架，来理解为什么起源追踪是一项主要工作。下图是基于<strong class="bold">开放源模型词汇表规范</strong>(<a href="http://open-biomed.sourceforge.net/opmv/ns.html">http://open-biomed.sourceforge.net/opmv/ns.html</a>)的<a id="_idIndexMarker133"/>:</p>
			<div><div><img src="img/B18120_03_004.jpg" alt="Figure 3.4 – An open provenance tracking framework&#13;&#10;" width="1187" height="424"/>
				</div>
			</div>
			<p class="figure-caption">图3.4–一个开放的出处跟踪框架</p>
			<p>在上图中，有三个重要的项目:</p>
			<ul>
				<li><strong class="bold">神器</strong>:工艺(<strong class="bold"> A1 </strong>和<strong class="bold"> A2 </strong>)生产或使用的东西。</li>
				<li><strong class="bold">过程</strong>:使用或生产工件所执行的动作(<strong class="bold"> P1 </strong>和<strong class="bold"> P2 </strong>)。</li>
				<li><strong class="bold">因果关系</strong>:工件与工序之间的边缘或关系，如使用的<em class="italic">，<em class="italic">由</em>生成，<em class="italic">来源于上图中的</em>(<strong class="bold">R1</strong>，<strong class="bold"> R2 </strong>，<strong class="bold"> R3 </strong>)。</em></li>
			</ul>
			<p>直观地说，这个<strong class="bold">开放出处模型</strong> ( <strong class="bold"> OPM </strong>)框架<a id="_idIndexMarker135"/>允许我们提出以下5W1H(五个w和一个H)问题，具体如下:</p>
			<div><div><img src="img/B18120_03_005.jpg" alt="Figure 3.5 – Types of provenance questions&#13;&#10;" width="579" height="377"/>
				</div>
			</div>
			<p class="figure-caption">图3.5-起源问题的类型</p>
			<p>拥有一个<a id="_idIndexMarker136"/>系统的起源框架和一组问题将帮助我们学习如何跟踪模型起源，并为这些问题提供答案。这将激励我们在下一节中实现MLflow模型跟踪。</p>
			<h2 id="_idParaDest-46"><a id="_idTextAnchor045"/>实施物流模型跟踪</h2>
			<p>如果<a id="_idIndexMarker137"/>我们为我们使用的DL模型实现了MLflow日志记录和注册，我们可以使用MLflow跟踪服务器来回答这些类型的起源问题。首先，让我们回顾一下MLflow在模型起源跟踪方面提供了什么。MLflow为模型出处提供了两组API:</p>
			<ul>
				<li><strong class="bold">日志API </strong>:这个<a id="_idIndexMarker138"/>允许实验的每次运行或者模型管道将模型工件记录到工件存储中。</li>
				<li><strong class="bold">Registry API</strong>: This <a id="_idIndexMarker139"/>allows a centralized location to track the version of the model and the stages of the model's life cycle (<strong class="bold">None</strong>, <strong class="bold">Archived</strong>, <strong class="bold">Staging</strong>, or <strong class="bold">Production</strong>).<p class="callout-heading">模型日志记录和模型注册的区别</p><p class="callout">尽管实验的每一次运行都需要被记录，并且模型需要被保存在<a id="_idIndexMarker140"/>工件库中，但是并不是模型的每一个实例都需要在模型注册表中注册。这是因为，对于许多早期的探索性模型实验来说，模型可能并不好。因此，不必注册来跟踪版本。只有当一个模型具有良好的离线性能，并成为推广到生产的候选时，我们才需要在模型注册表中注册它，以走模型推广流程。</p><p class="callout">虽然MLflow的官方API文档将日志记录和注册表分成两个组件，但在本书中，我们将它们一起称为MLflow中的模型跟踪功能。</p></li>
			</ul>
			<p>我们已经<a id="_idIndexMarker142"/>看到了我们在<a href="B18120_02_ePub.xhtml#_idTextAnchor027"> <em class="italic">第二章</em></a><em class="italic">深度学习MLflow入门</em>中构建的DL模型的MLflow自动日志记录。尽管自动日志功能强大，但当前版本存在两个问题:</p>
			<ul>
				<li>它不会自动将模型注册到模型注册中心。</li>
				<li>如果您只是按照MLflow的建议使用<code>mlflow.pyfunc.load_model</code> API来加载日志模型，那么日志模型直接处理原始输入数据(在我们的例子中，是一个英语句子)并不是现成的。这是一个限制，可能是由于MLflow中当前自动日志API的实验性质。</li>
			</ul>
			<p>让我们通过一个示例来回顾MLflow的功能和自动日志记录的局限性，以及我们如何解决这些问题:</p>
			<ol>
				<li value="1">在运行MinIO和基于MySQL的Docker组件的Bash终端中设置以下环境变量:<pre><strong class="bold">export MLFLOW_S3_ENDPOINT_URL=http://localhost:9000</strong> <strong class="bold">export AWS_ACCESS_KEY_ID=minio</strong> <strong class="bold">export AWS_SECRET_ACCESS_KEY=minio123</strong></pre></li>
			</ol>
			<p>注意，<code>AWS_ACCESS_KEY_ID</code>和<code>AWS_SECRET_ACCESS_KEY</code>使用的是在<code>mlflow_docker_setup</code>文件夹下的<code>.env</code>文件中定义的相同值。这样做是为了确保我们使用的是之前设置的MLflow服务器。由于这些环境变量是基于会话的，我们还可以在笔记本的代码中设置以下环境变量，如下所示:</p>
			<pre><strong class="bold">os.environ["AWS_ACCESS_KEY_ID"] = "minio"</strong>
<strong class="bold">os.environ["AWS_SECRET_ACCESS_KEY"] = "minio123"</strong>
<strong class="bold">os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://localhost:9000"</strong></pre>
			<p>前面的三行代码可以在本章的笔记本文件中找到，就在导入所需的Python包之后。在执行笔记本之前，请确保运行以下命令来初始化虚拟环境<code>dl_model</code>，它现在在<code>requirements.txt</code>文件中定义了额外的必需包:</p>
			<pre><strong class="bold">conda create -n dl_model python==3.8.10</strong>
<strong class="bold">conda activate dl_model</strong>
<strong class="bold">pip install -r requirements.txt</strong></pre>
			<p>如果您在前面的章节中设置了<code>dl_model</code>虚拟环境，那么您可以跳过创建一个名为<code>dl_model</code>的虚拟环境的第一行。然而，您仍然需要激活<code>dl_model</code>作为当前活动的虚拟环境，然后运行<code>pip install -r requirements.txt</code>来安装所有需要的Python包。一旦<code>dl_model</code>虚拟环境设置成功，您可以继续下一步。</p>
			<ol>
				<li value="2">为了跟进这个模型跟踪实现，请通过访问本章的GitHub存储库查看VS代码中的<code>dl_model_tracking.ipynb</code>笔记本文件:<a href="https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/blob/main/chapter03/dl_model_tracking.ipynb">https://GitHub . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/blob/main/chapter 03/dl _ model _ tracking . ipynb</a>。</li>
			</ol>
			<p>请注意，在<code>dl_model_tracking.ipynb</code>笔记本的第四个单元格中，我们需要将它指向我们刚刚在Docker中设置的正确的新MLflow跟踪URI，并定义一个新实验，如下所示:</p>
			<pre>EXPERIMENT_NAME = "dl_model_chapter03"
mlflow.set_tracking_uri('http://localhost')</pre>
			<ol>
				<li value="3">我们仍将<a id="_idIndexMarker144"/>使用MLflow提供的自动记录功能，但是我们将为运行分配一个变量名<code>dl_model_tracking_run</code> : <pre>mlflow.pytorch.autolog() with mlflow.start_run(experiment_id=experiment.experiment_id, run_name="chapter03") as <strong class="bold">dl_model_tracking_run</strong>:     trainer.finetune(classifier_model, datamodule=datamodule, strategy="freeze")     trainer.test()</pre></li>
			</ol>
			<p><code>dl_model_tracking_run</code>允许我们以编程的方式获得<code>run_id</code>参数和关于这次运行的其他元数据，我们将在下一步中看到。一旦执行了该代码单元，我们将在MLflow跟踪服务器中记录一个经过训练的模型，其中包含所有必需的参数和指标。然而，该模型尚未注册。我们可以在MLflow web UI中找到记录的实验，以及所有相关的参数和指标，位于http://localhost/#/experiments/1/runs/37 a3 Fe 9 b 6 fa f 41d 89001 ECA 13 ad 6 ca 47。您可以在<code>http://localhost:9000/minio/mlflow/1/37a3fe9b6faf41d89001eca13ad6ca47/artifacts/model/</code>中找到模型工件来查看存储UI，如下图所示:</p>
			<div><div><img src="img/B18120_03_006.jpg" alt="Figure 3.6 – Model artifacts logged In the MinIO storage backend &#13;&#10;" width="782" height="526"/>
				</div>
			</div>
			<p class="figure-caption">图3.6–记录在MinIO存储后端的模型工件</p>
			<p>文件夹<a id="_idIndexMarker145"/>的结构类似于我们在<a href="B18120_02_ePub.xhtml#_idTextAnchor027"> <em class="italic">第2章</em> </a>、<em class="italic">深度学习MLflow入门</em>中看到的，当时我们使用一个普通的文件系统来存储模型工件。然而，在这里，我们使用一个<strong class="bold">迷你</strong>桶来存放这些模型文物。</p>
			<ol>
				<li value="4">从<code>dl_model_tracking_run</code>中检索<code>run_id</code>参数，以及其他元数据，如下:<pre>run_id = dl_model_tracking_run.info.run_id print("run_id: {}; lifecycle_stage: {}".format(run_id,     mlflow.get_run(run_id).info.lifecycle_stage))</pre></li>
			</ol>
			<p>这将打印出如下内容:</p>
			<pre>run_id: 37a3fe9b6faf41d89001eca13ad6ca47; lifecycle_stage: active</pre>
			<ol>
				<li value="5">通过定义记录的模型URI检索记录的模型。这将允许我们在这个特定的位置重新加载记录的模型:<pre>logged_model = f'runs:/{run_id}/model'</pre></li>
				<li>使用<code>mlflow.pytorch.load_model</code>和下面的<code>logged_model</code> URI将模型<a id="_idIndexMarker146"/>加载回内存，并对给定的输入句子进行新的预测，如下:<pre>model = mlflow.pytorch.load_model(logged_model) model.predict({'This is great news'})</pre></li>
			</ol>
			<p>这将输出一个模型预测标签，如下所示:</p>
			<pre>['positive']</pre>
			<p class="callout-heading">mlflow.pytorch.load_model与mlflow.pyfunc.load_model</p>
			<p class="callout">默认情况下，在MLflow实验跟踪页面的工件部分，如果您有一个已记录的<a id="_idIndexMarker147"/>模型，MLflow将建议使用<code>mlflow.pyfunc.load_model</code>加载一个已记录的模型用于<a id="_idIndexMarker148"/>预测。然而，这只适用于像pandas DataFrame、NumPy数组或tensor这样的输入；这不适用于NLP文本输入。因为PyTorch lightning的自动记录使用了<code>mlflow.pytorch.log_model</code>来保存模型，所以正确的方法是使用<code>mlflow.pytorch.load_model</code>，正如我们在这里所展示的。这是因为MLflow的默认设计是使用标准化的<code>mlflow.pyfunc.load_model</code>，并且有一个已知的限制，即只能接受数字形式的输入格式。对于文本和图像数据，需要将标记化步骤作为预处理步骤。然而，由于我们在这里保存的PyTorch模型已经作为序列化模型的一部分执行了标记化，我们可以使用原生的<code>mlflow.pytorch.load_model</code>来直接加载接受文本作为输入的模型。</p>
			<p>至此，我们已经成功地记录了模型并加载回模型以进行预测。如果我们认为这个模型表现得足够好，那么我们可以注册它。</p>
			<ol>
				<li value="7">让我们通过使用<code>mlflow.register_model</code> API: <pre>model_registry_version = mlflow.register_model(logged_model, 'nlp_dl_model') print(f'Model Name: {model_registry_version.name}') print(f'Model Version: {model_registry_version.version}')</pre>来注册模型</li>
			</ol>
			<p>此<a id="_idIndexMarker149"/>将产生以下输出:</p>
			<div><div><img src="img/B18120_03_007.jpg" alt="Figure 3.7 – Model registration success message &#13;&#10;" width="1071" height="217"/>
				</div>
			</div>
			<p class="figure-caption">图3.7–型号注册成功消息</p>
			<p>这表明该模型已经成功地在模型注册中心注册为版本1，名称为<code>nlp_dl_model</code>。</p>
			<p>我们也可以通过点击<code>http://localhost/#/models/nlp_dl_model/versions/1</code>在MLflow web UI中找到这个注册的模型:</p>
			<div><div><img src="img/B18120_03_008.jpg" alt="Figure 3.8 – MLflow tracking server web UI showing the newly registered model&#13;&#10;" width="1051" height="363"/>
				</div>
			</div>
			<p class="figure-caption">图3.8–显示新注册模型的MLflow tracking server web用户界面</p>
			<p>默认情况下，新注册的模型的stage是<strong class="bold"> None </strong>，如前面的截图所示。</p>
			<p>通过使用版本号和阶段标签注册模型，我们为部署到阶段(也称为预生产)和生产奠定了基础。我们将在本书的后面讨论如何基于注册的模型执行模型部署。</p>
			<p>至此，<a id="_idIndexMarker150"/>我们已经解决了本节开始时<a id="_idIndexMarker151"/>提出的关于自动日志限制的两个问题:</p>
			<ul>
				<li>如何使用<code>mlflow.pytorch.load_model</code> API而不是<code>mlflow.pyfunc.load_model</code> API加载一个记录的DL PyTorch模型</li>
				<li>How to register a logged DL PyTorch model using the <code>mlflow.register_model</code> API<p class="callout-heading">MLflow DL模型日志记录API的选择</p><p class="callout">对于DL模型，PyTorch的<a id="_idIndexMarker152"/>自动记录只对<code>mlflow.pyfunc.log_model</code>记录<a id="_idIndexMarker157"/>模型有效，特别是当我们需要多步DL模型管道的时候。我们将在本书的后面实现这种定制的MLflow模型风格。如果你不想为PyTorch使用自动日志，那么你可以直接使用<code>mlflow.pytorch.log_model</code>。PyTorch的自动日志在其实现内部使用了<code>mlflow.pytorch.log_model</code>(见官方MLflow开源实现此处:<a href="https://github.com/mlflow/mlflow/blob/290bf3d54d1e5ce61944455cb302a5d6390107f0/mlflow/pytorch/_pytorch_autolog.py#L314">https://github . com/ml flow/ml flow/blob/290 BF 3d 54d 1 e 5 ce 61944455 CB 302 a5d 6390107 f 0/ml flow/py torch/_ py torch _ autolog . py # L314</a>)。</p></li>
			</ul>
			<p>如果我们<a id="_idIndexMarker158"/>不想使用自动日志，那么我们可以直接使用MLflow的模型日志API。这也为我们提供了一种在一次调用中同时注册模型的替代方法。您可以使用下面的代码行来记录和注册训练模型:</p>
			<pre class="source-code">mlflow.pytorch.log_model(pytorch_model=trainer.model, artifact_path='dl_model', registered_model_name='nlp_dl_model')</pre>
			<p>请注意，这一行代码没有记录模型的任何参数或指标。</p>
			<p>这样，我们不仅在跟踪服务器中记录了许多实验和模型用于离线实验，而且还注册了高性能模型用于将来的产品部署，以及版本控制和来源跟踪。我们现在可以回答我们在本章开始时提出的一些出处问题了:</p>
			<div><div><img src="img/B18120_03_009.jpg" alt="Figure 3.9 – Answers to model provenance questions&#13;&#10;" width="594" height="414"/>
				</div>
			</div>
			<p class="figure-caption">图3.9-模型起源问题的答案</p>
			<p>“为什么”和“出处在哪里”的问题还没有完全回答，但将在本书的后面部分回答。这是因为生产模型的“为什么起源”问题只能在模型准备好部署时被跟踪和记录，我们需要添加注释和理由来证明模型的部署。当我们有一个多步骤的模型管道时，哪里起源的问题可以得到完全的回答。然而，在这里，我们只有一个单步流水线，这是最简单的情况。多步骤管道包含明确分离的模块化代码，以指定哪个步骤执行什么功能，以便我们可以轻松地更改任何步骤的详细实现，而无需更改管道的流程。在接下来的两个部分中，我们将研究如何在不使用自动日志记录的情况下跟踪度量和模型的参数。</p>
			<h1 id="_idParaDest-47"><a id="_idTextAnchor046"/>跟踪模型指标</h1>
			<p>PyTorch <code>lightning-flash</code>包中文本分类模型的默认度量<a id="_idIndexMarker160"/>是<strong class="bold">准确性</strong>。如果我们想要将度量标准更改为<strong class="bold"> F1得分</strong>(精确度和召回率的调和平均值)，这是一个非常常见的用于测量分类器性能的度量标准，那么我们需要在开始模型训练过程之前更改分类器模型的配置。让我们了解如何进行这一更改，然后使用MLflow的非自动日志API来记录指标:</p>
			<ol>
				<li value="1">在定义分类器变量时，我们将传递一个名为<code>torchmetrics.F1</code>的度量函数作为变量，而不是使用默认的度量，如下:<pre>classifier_model = TextClassifier(backbone="prajjwal1/bert-tiny", num_classes=datamodule.num_classes, metrics=<strong class="bold">torchmetrics.F1(datamodule.num_classes)</strong>)</pre></li>
			</ol>
			<p>这使用了<code>torchmetrics</code>、<code>F1</code>模块的内置度量函数，以及我们需要作为参数分类的数据中的类的数量。这确保了使用这个新的度量来训练和测试模型。您将看到类似如下的输出:</p>
			<pre>{'test_cross_entropy': 0.785443127155304, 'test_f1': 0.5343999862670898}</pre>
			<p>这表明模型训练和测试使用F1分数作为度量，而不是默认的准确性度量。有关如何使用<code>torchmetrics</code>定制<a id="_idIndexMarker161"/>指标的更多信息，请参考其文档网站:<a href="https://torchmetrics.readthedocs.io/en/latest/">https://torchmetrics.readthedocs.io/en/latest/</a>。</p>
			<ol>
				<li value="2">现在，如果我们想要将所有指标记录到MLflow跟踪服务器，包括培训、验证和测试指标，我们需要通过调用培训师的回调函数来获取所有当前指标，如下所示:<pre>    cur_metrics = trainer.callback_metrics</pre></li>
			</ol>
			<p>然后，我们需要将所有指标值转换为<code>float</code>，以确保它们与MLflow <code>log_metrics</code> API兼容:</p>
			<pre>    metrics = dict(map(lambda x: (x[0], float(x[1])), cur_metrics.items()))</pre>
			<ol>
				<li value="3">现在，我们可以调用MLflow的<code>log_metrics</code>来记录跟踪服务器中的所有指标:<pre>    mlflow.log_metrics(metrics)</pre></li>
			</ol>
			<p>在使用F1分数作为分类器的指标后，您将<a id="_idIndexMarker162"/>看到以下指标，这些指标将记录在MLflow的跟踪服务器中:</p>
			<pre>{'train_f1': 0.5838666558265686, 
'train_f1_step': 0.75, 
'train_cross_entropy': 0.7465656399726868, 
'train_cross_entropy_step': 0.30964696407318115, 
'val_f1': 0.5203999876976013, 
'val_cross_entropy': 0.8168156743049622, 
'train_f1_epoch': 0.5838666558265686, 
'train_cross_entropy_epoch': 0.7465656399726868, 
'test_f1': 0.5343999862670898, 
'test_cross_entropy': 0.785443127155304}</pre>
			<p>使用MLflow的<code>log_metrics</code> API可以通过额外的代码行给我们更多的控制，但是如果我们对它的自动日志功能感到满意，那么我们唯一需要改变的就是我们想要为模型训练和测试过程使用什么度量。在这种情况下，我们只需要在声明新的DL模型时定义一个新的度量标准(也就是说，使用F1分数而不是默认的准确性度量标准)。</p>
			<ol>
				<li value="4">如果您想要同时跟踪多个模型指标，比如F1分数、准确度、精确度和召回率，那么您唯一需要做的事情就是定义一个您想要计算和跟踪的指标的Python列表，如下:<pre>list_of_metrics = [torchmetrics.Accuracy(),    torchmetrics.F1(num_classes=datamodule.num_classes),    torchmetrics.Precision(num_classes=datamodule.num_classes),    torchmetrics.Recall(num_classes=datamodule.num_classes)]</pre></li>
			</ol>
			<p>然后，在模型初始化语句中，不需要将单个指标传递给<code>metrics</code>参数，您可以传递我们刚刚定义的<code>list_of_metrics</code> Python列表，在<code>metrics</code>参数之上，如下所示:</p>
			<pre>classifier_model = TextClassifier(backbone=<strong class="bold">"prajjwal1/bert-tiny"</strong>, num_classes=datamodule.num_classes, metrics=<strong class="bold">list_of_metrics</strong>)</pre>
			<p>不需要对代码的其余部分进行更多的<a id="_idIndexMarker163"/>修改。所以，在<code>dl_model-non-auto-tracking.ipynb</code>笔记本(https://github . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/blob/main/chapter 03/dl _ model-non-auto-tracking . ipynb)中，你会注意到前面一行是默认注释掉的。但是，您可以取消对它的注释，然后注释掉前一个:</p>
			<pre>classifier_model = TextClassifier(backbone=<strong class="bold">"prajjwal1/bert-tiny"</strong>, num_classes=datamodule.num_classes, metrics=torchmetrics.F1(datamodule.num_classes))</pre>
			<p>然后，当您运行笔记本的其余部分时，您将在笔记本的输出中获得模型测试报告，以及以下指标:</p>
			<pre>{'test_accuracy': 0.6424000263214111, 'test_cross_entropy': 0.6315688490867615, 'test_f1': 0.6424000263214111, 'test_precision': 0.6424000263214111, 'test_recall': 0.6424000263214111}</pre>
			<p>您可能会注意到，准确度、F1、精确度和召回率的数字是相同的。这是因为，默认情况下，<code>torchmetrics</code>使用的<code>torchmetrics</code>不支持<code>none</code>方法，该方法计算每个类的度量并返回每个类的度量，即使是二进制的<a id="_idIndexMarker166"/>分类模型。所以，这不会产生一个单一的标量数。但是，您可以调用scikit-learn的metrics API，通过传递两个值列表来计算F1分数或基于二进制平均法的其他指标。这里可以使用<code>y_true</code>和<code>y_predict</code>，其中<code>y_true</code>是地面真实标签值列表，<code>y_predict</code>是模型预测标签值列表。这对你来说是一个很好的尝试，因为这是所有ML模型的普遍做法，而不是对DL模型的特殊处理。</p>
			<h1 id="_idParaDest-48"><a id="_idTextAnchor047"/>跟踪模型参数</h1>
			<p>正如我们已经看到的，在MLflow中使用自动记录有很多好处，但是如果我们想要<a id="_idIndexMarker167"/>跟踪额外的模型参数，我们可以使用MLflow在自动记录记录的基础上记录额外的参数，或者直接使用MLflow记录我们想要的所有参数，而根本不使用自动记录。</p>
			<p>让我们在不使用MLflow自动日志记录的情况下浏览一下笔记本。如果我们想要完全控制MLflow将记录哪些参数，我们可以使用两个API。第一个日志记录了一对键值参数，而第二个日志记录了键值参数的整个字典。那么，我们有兴趣跟踪什么样的参数呢？以下回答了这个问题:</p>
			<ul>
				<li><code>log_params</code> API在实验中记录它们。</li>
				<li><strong class="bold">模型参数</strong>:这些参数是在模型训练过程中学习到的。对于DL模型，这些通常是指在训练期间学习的神经网络权重<a id="_idIndexMarker172"/>。我们不需要单独记录这些重量参数，因为它们已经在记录的DL模型中。</li>
			</ul>
			<p>让我们使用MLflow的<code>log_params</code> API记录这些超参数，如下所示:</p>
			<pre class="source-code">    params = {"epochs": trainer.max_epochs}</pre>
			<pre class="source-code">    if hasattr(trainer, "optimizers"):</pre>
			<pre class="source-code">        optimizer = trainer.optimizers[0]</pre>
			<pre class="source-code">        params["optimizer_name"] = optimizer.__class__.__name__</pre>
			<pre class="source-code">    if hasattr(optimizer, "defaults"):</pre>
			<pre class="source-code">        params.update(optimizer.defaults)</pre>
			<pre class="source-code">    params.update(classifier_model.hparams)</pre>
			<pre class="source-code">    mlflow.log_params(params)</pre>
			<p>请注意，在这里，我们记录了最大的历元数、训练器的第一个优化器的名称、优化器的默认参数以及整个分类器的超参数(<code>classifier_model.hparams</code>)。一行代码<code>mlflow.log_params(params)</code>将<code>params</code>字典中的所有键值参数记录到MLflow跟踪服务器。如果您在MLflow跟踪服务器中看到以下超参数，则表示它工作正常！</p>
			<div><div><img src="img/B18120_03_010.jpg" alt="Figure 3.10 – MLflow tracking server web UI showing the logged model hyperparameters &#13;&#10;" width="840" height="1543"/>
				</div>
			</div>
			<p class="figure-caption">图3.10–ml flow tracking server web用户界面显示记录的模型超参数</p>
			<p>注意，这个参数列表比自动记录器记录的要多，因为我们在实验中添加了额外的超参数来记录。如果您想要记录任何其他定制的参数，您可以在您的实验中遵循相同的模式。完整的<a id="_idIndexMarker173"/>笔记本，不使用自动日志，可以在本章的GitHub知识库中查看，网址为<a href="https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/blob/main/chapter03/dl_model-non-auto-tracking.ipynb">https://GitHub . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/blob/main/chapter 03/dl _ model-non-auto-tracking . ipynb</a>。</p>
			<p>如果您已经达到本章的这一点，那么您已经成功地实现了MLflow跟踪模型及其指标和参数！</p>
			<h1 id="_idParaDest-49"><a id="_idTextAnchor048"/>总结</h1>
			<p>在本章中，我们使用MySQL和MinIO对象存储建立了一个完全支持后端存储和工件存储的本地MLflow开发环境。这将对我们在本书中开发支持MLflow的DL模型非常有用。我们首先介绍了开放式起源跟踪框架，并询问了感兴趣的模型起源跟踪问题。我们致力于解决自动记录的问题，并通过使用<code>mlflow.pytorch.load_model</code> API从MLflow中的已记录模型加载一个训练模型来进行预测，从而成功注册了一个训练模型。我们还试验了如何直接使用MLflow的<code>log_metrics</code>、<code>log_params</code>和<code>log_model</code>API而不使用自动日志记录，这让我们在如何记录额外的或定制的指标和参数方面有了更多的控制和灵活性。通过执行模型起源跟踪，我们能够回答许多起源问题，以及通过提供一些需要进一步研究使用MLflow来跟踪多步模型管道及其部署的问题。</p>
			<p>我们将在下一章继续我们的学习之旅，并学习如何使用MLflow执行代码和数据跟踪，这将为我们提供额外的能力来回答数据和代码相关的起源问题。</p>
			<h1 id="_idParaDest-50"><a id="_idTextAnchor049"/>延伸阅读</h1>
			<p>要了解本章中涵盖的主题的更多信息，请查看以下资源:</p>
			<ul>
				<li>MLflow Docker设置参考:<a href="https://github.com/sachua/mlflow-docker-compose">https://github.com/sachua/mlflow-docker-compose</a></li>
				<li>MLflow PyTorch自动登录实现:<a href="https://github.com/mlflow/mlflow/blob/master/mlflow/pytorch/_pytorch_autolog.py">https://github . com/ml flow/ml flow/blob/master/ml flow/py torch/_ py torch _ autolog . py</a></li>
				<li>MLflow PyTorch模型日志记录、加载和注册表文档:<a href="https://www.mlflow.org/docs/latest/python_api/mlflow.pytorch.html">https://www . ml flow . org/docs/latest/python _ API/ml flow . py torch . html</a></li>
				<li>MLflow参数和度量记录文档:<a href="https://www.mlflow.org/docs/latest/python_api/mlflow.html">https://www.mlflow.org/docs/latest/python_api/mlflow.html</a></li>
				<li>MLflow模型注册文档:<a href="https://www.mlflow.org/docs/latest/model-registry.html">https://www.mlflow.org/docs/latest/model-registry.html</a></li>
				<li>挖大种源(用铁锹):<a href="https://queue.acm.org/detail.cfm?id=3476885">https://queue.acm.org/detail.cfm?id=3476885</a></li>
				<li>如何利用<code>torchmetrics</code>和<code>lightning-flash</code>:<a href="https://www.exxactcorp.com/blog/Deep-Learning/advanced-pytorch-lightning-using-torchmetrics-and-lightning-flash">https://www . exxactcorp . com/blog/Deep-Learning/advanced-py torch-lightning-using-torch metrics-and-lightning-flash</a></li>
				<li>为什么在多类问题中使用微平均时，精度、召回率和F1分数相等？<a href="https://simonhessner.de/why-are-precision-recall-and-f1-score-equal-when-using-micro-averaging-in-a-multi-class-problem/">https://simonhessner . de/why-are-precision-recall-and-f1-score-equal-when-using-micro-averaging-in-a-a-a-a-multi-class-problem/</a></li>
			</ul>
		</div>
	</div>
</body></html>