# 五、在不同环境下运行 DL 管道

在不同的执行环境中，如本地或远程、内部或云中，灵活地运行**深度学习** ( **DL** )管道至关重要。这是因为，在 DL 开发的不同阶段，可能存在不同的约束或偏好，以提高开发速度或确保安全合规性。例如，在本地或笔记本电脑环境中进行小规模模型实验是可取的，而对于完整的超参数调优，我们需要在云托管的 GPU 集群上运行模型，以获得快速的周转时间。考虑到硬件和软件配置中的不同执行环境，在单一框架中实现这种灵活性曾经是一个挑战。MLflow 提供了一个易于使用的框架，可以在不同的环境中大规模运行 DL 管道。我们将在本章中学习如何做到这一点。

在本章中，我们将首先了解不同的 DL 管道执行场景及其执行环境。我们还将学习如何在不同的执行环境中运行 DL 管道的不同步骤。具体来说，我们将涵盖以下主题:

*   不同执行场景和环境的概述
*   使用本地代码在本地运行
*   本地运行 GitHub 中的远程代码
*   在云中远程运行本地代码
*   使用 GitHub 中的远程代码在云中远程运行

在本章结束时，您将能够轻松地设置 DL 管道，以便在不同的执行环境下本地或远程运行。

# 技术要求

完成本章的学习需要以下技术要求:

*   本章的代码可以在以下 GitHub 网址找到:[https://GitHub . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/tree/main/chapter 05](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/tree/main/chapter05)。
*   安装 Databricks **命令行界面** ( **CLI** )工具，访问 Databricks 平台远程执行 DL 管线:[https://github.com/databricks/databricks-cli](https://github.com/databricks/databricks-cli)。
*   访问 Databricks 实例(必须是企业版，因为社区版不支持远程执行),了解如何在 Databricks 中的集群上远程运行 DL 管道。
*   在本地运行时，这是一个成熟的 MLflow 跟踪服务器。此 MLflow 跟踪服务器设置与前面章节中的设置相同。

# 不同执行场景和环境的概述

在前面的章节中，我们主要学习了如何使用 MLflow 的跟踪功能来跟踪 DL 管道。我们的大多数执行环境都是在本地环境中，比如本地笔记本电脑或台式机环境。然而，正如我们已经知道的，DL 的整个生命周期由不同的阶段组成，在这些阶段中，我们可能需要在不同的执行环境中完整地、部分地或者作为一个单独的步骤来运行 DL 管道。这里有两个典型的例子:

*   当出于模型训练目的访问数据时，要求数据驻留在符合企业安全和隐私的环境中是很常见的，在这种环境中，计算和存储都不能离开符合要求的边界。
*   在训练 DL 模型时，通常需要使用远程 GPU 集群来最大化模型训练的效率，而本地笔记本电脑通常不具备所需的硬件能力。

这两种情况都需要一个精心定义的执行环境，在 DL 生命周期的一个或多个阶段都可能需要这个环境。请注意，当从开发阶段转移到生产环境时，这不仅仅是灵活性的要求，在生产环境中，执行硬件和软件配置可以理解地不同。还需要能够在开发阶段或不同的生产环境中切换运行环境，而无需对 DL 管道进行重大更改。

这里，我们根据 DL 管道源代码的位置和目标执行环境的不同组合，将不同的场景和执行环境分为以下四种场景，如下表所示:

![Figure 5.1 – Four different scenarios of DL pipeline source codes and target execution environments
](img/B18120_05_01.jpg)

图 5.1–DL 管道源代码和目标执行环境的四种不同场景

*图 5.1* 描述了在开发或生产环境中，我们如何能够使用本地或远程代码在不同的执行环境中运行。让我们按如下方式逐一检查它们:

*   **在本地目标环境中运行的本地源代码**:这通常发生在开发阶段，在这个阶段，本地环境中适度的计算能力足以支持现有管道中的小变化的快速原型开发或测试运行。在学习如何跟踪管道时，这是我们在前面章节的 MLflow 实验中经常使用的场景。
*   **在远程目标环境中运行的本地源代码**:这通常发生在现有 DL 模型的开发阶段或重新训练阶段，其中 GPU 或其他类型的硬件加速器，如**张量处理单元** ( **TPUs** )或**现场可编程门阵列**(**FPGA**)需要在合并 GitHub 库之前执行计算和数据密集型模型训练或调试(首先使用本地代码更改)。
*   **在本地目标环境中运行的远程源代码**:这通常发生在我们没有对代码进行任何修改，但是数据已经发生了变化的时候，无论是在开发阶段还是在生产阶段。例如，在 DL 开发阶段，我们可以通过一些数据扩充技术(例如，使用 **AugLy** 来扩充现有的训练数据:[https://github.com/facebookresearch/AugLy](https://github.com/facebookresearch/AugLy))或新注释的训练数据，用新扩充的训练数据来更改数据。在生产部署步骤中，我们通常需要运行回归测试，以根据保留的回归测试数据集评估将要部署的 DL 管道，这样，如果模型性能准确性指标不符合标准，我们就不会部署降级的模型。在这种情况下，拒不接受的测试数据集通常不大，因此可以在本地部署服务器上执行，而不是在 Databricks 服务器中启动到远程集群。
*   **在远程目标环境中运行的远程源代码**:这可能发生在开发阶段或生产阶段，我们希望使用 GitHub 的 DL 管道代码的固定版本在远程 GPU 集群中运行，以进行模型训练、超参数调整或重新训练。如此大规模的执行可能是耗时的，远程 GPU 集群可能非常有用。

给定四种不同的场景，在这些条件下，希望有一个框架能够以最小的配置改变运行相同的 DL 流水线。在 MLflow 出现之前，需要相当多的工程和人工工作来支持这些场景。MLflow 提供了一个 MLproject 框架，通过以下三种可配置机制支持所有这四种场景:

1.  **入口点**:我们可以定义一个或多个入口点来执行 DL 管道的不同步骤。例如，下面是一个定义主入口点的例子:

    ```py
    entry_points:   main:     parameters:       pipeline_steps: { type: str, default: all }     command: "python main.py –pipeline_steps {pipeline_steps}"
    ```

入口点的名称是`main`，默认情况下，在没有为 MLproject 指定入口点的情况下执行 MLflow 运行时将使用该名称。在这个`main`入口点下，有一个参数列表。我们可以使用简短的语法来定义参数的类型和默认值，如下所示:

```py
parameter_name: {type: data_type, default: value}
```

我们也可以使用长语法，如下所示:

```py
parameter_name:
  type: data_type
  default: value
```

这里，我们只定义一个参数，称为`pipeline_steps`，使用短语法格式，类型为`str`，默认值为`all`。

1.  `yaml`配置文件或 Docker 映像，用于定义 MLproject 入口点可以使用的软件和库依赖关系。请注意，单个 MLproject 可以使用 conda `yaml`文件或 Docker 图像，但不能同时使用两者。根据 DL 管道的依赖性，有时使用 conda。`yaml`文件优先于 Docker 映像，因为它更轻量级，更容易进行更改，而不需要额外的 Docker 映像存储位置，也不需要在资源有限的环境中将大的 Docker 映像加载到内存中。然而，如果运行时需要任何 Java 包(`.jar`)，Docker 映像有时确实有优势。如果没有这样的 JAR 依赖，那么最好有一个 conda。`yaml`指定依赖关系的文件。此外，从 MLflow 版本 1.22.0 开始，MLflow 命令行还不支持在 Databricks 上运行基于 Docker 的项目。如果确实有任何 Java 包依赖，可以使用本书中定义执行环境依赖的`yaml`配置文件安装。
2.  **硬件依赖**:我们可以使用集群配置 JSON 文件来定义执行目标后端环境，无论是 GPU、CPU 还是其他类型的集群。只有当目标后端执行环境是非本地的，或者在 Databricks 服务器或者在 Kubernetes ( **K8s** )集群中时，才需要这样做。

之前，我们在 [*第 4 章*](B18120_04_ePub.xhtml#_idTextAnchor050) 、*跟踪代码和数据版本*中学习了如何使用 MLproject 创建一个在本地环境中运行的多步 DL 管道，用于跟踪目的。现在，我们将学习如何使用 MLproject 来支持之前概述的不同运行场景。

# 使用本地代码在本地运行

让我们从使用相同的**自然语言处理(NLP)** 文本情感分类示例作为驱动用例的第一个运行场景开始。建议您从 GitHub 位置查看以下版本的源代码，以了解相关步骤和知识:[https://GitHub . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/tree/26119 e 984 e 52 dad 04 b 99 e 6 f 7 e 95 f 8 DDA 8b 59238/chapter 05](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/tree/26119e984e52dadd04b99e6f7e95f8dda8b59238/chapter05)。注意，这需要一个特定的 Git hash 提交版本，如 URL 路径所示。这意味着我们要求您检查一个特定的提交版本，而不是主分支。

让我们从 DL 管道开始，它将评审数据下载到本地存储，作为第一个执行练习。检查完本章的代码后，您可以键入以下命令行来执行 DL 管道的第一步:

```py
mlflow run . --experiment-name='dl_model_chapter05' -P pipeline_steps='download_data'
```

如果我们不指定入口点，它默认为`main`。在这种情况下，这是我们想要的行为，因为我们想要运行`main`入口点来启动父 DL 管道。

*点*表示当前本地目录。这告诉 MLflow 使用当前目录中的代码作为执行项目的源。如果该命令行运行成功，您应该能够在控制台中看到如下所示的前两行输出，这也揭示了目标执行环境的位置:

```py
2022/01/01 19:15:37 INFO mlflow.projects.utils: === Created directory /var/folders/51/whxjy4r92dx18788yp11ycyr0000gp/T/tmp3qj2kws2 for downloading remote URIs passed to arguments of type 'path' ===
2022/01/01 19:15:37 INFO mlflow.projects.backend.local: === Running command 'source /Users/yongliu/opt/miniconda3/bin/../etc/profile.d/conda.sh && conda activate mlflow-95353930ddb7b60101df80a5d64ef8bf6204a808 1>&2 && python main.py --pipeline_steps download_data' in run with ID 'f7133b916a004c508e227f00d534e136' ===
```

注意，第二个输出行显示了`mlflow.projects.backend.local`，这意味着目标运行环境是本地的。您可能想知道我们在初始命令行的什么地方定义本地执行环境。原来，默认情况下，名为`--backend`(或`-b`)的参数值是`local`。因此，如果我们拼出默认值，`mlflow run`命令行将如下所示:

```py
mlflow run . -e main -b local --experiment-name='dl_model_chapter05' -P pipeline_steps='download_data'
```

注意我们还需要在命令行中指定`experiment-name`或者通过一个名为`MLFLOW_EXPERIMENT_NAME`的环境变量来定义这个项目将要运行的实验。或者，您可以指定一个`experiment-id`参数，或者一个名为`MLFLOW_EXPERIMENT_ID`的环境变量，来定义已经存在的实验整数 ID。您只需要定义环境的 ID 或名称，而不是两者都定义。通常定义一个人类可读的实验名称，然后在代码的其他部分查询该实验的实验 ID，这样它们就不会不同步。

运行 MLproject 的 MLflow 实验名称或 ID

要使用 CLI 或`mlflow.run` Python API 运行 MLproject，如果我们没有通过环境变量或参数赋值来指定`experiment-name`或`experiment-id`，它将默认为`Default` MLflow 实验。这是不可取的，因为我们想把我们的实验组织成明显分开的实验。此外，一旦 MLproject 开始运行，任何子运行都将无法切换到不同的实验名称或 ID。因此，最佳实践总是在启动 MLflow 项目运行之前指定一个实验名称或 ID。

完成运行后，您将看到如下输出:

```py
2022-01-01 19:15:48,249 <Run: data=<RunData: metrics={}, params={'download_url': 'https://pl-flash-data.s3.amazonaws.com/imdb.zip',
 'local_folder': './data',
 'mlflow run id': 'f9f74ebd80f246d58a5f7a3bfb3fc635',
 'pipeline_run_name': 'chapter05'}, tags={'mlflow.gitRepoURL': 'git@github.com:PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow.git',
 'mlflow.parentRunId': 'f7133b916a004c508e227f00d534e136',
```

请注意，这是一个嵌套的 MLflow 运行，因为我们首先启动一个启动整个管道的`main`入口点(这就是为什么有`mlflow.parentRunId`)，然后在这个管道下，我们运行一个或多个步骤。这里，我们运行的步骤被称为`download_data`，它是 MLproject 中定义的另一个入口点，但是使用`mlflow.run` Python API 调用，如下所示，在`main.py`文件中:

```py
download_run = mlflow.run(".", "download_data", parameters={})
```

注意，这也指定了使用哪个代码源(`local`，因为我们指定了一个*点*)，默认情况下，是一个本地执行环境。这就是为什么您应该能够在控制台输出中看到以下几行:

```py
 'mlflow.project.backend': 'local',
 'mlflow.project.entryPoint': 'download_data',
```

您还应该看到这个入口点的运行参数的一些其他细节。命令行输出的最后两行应该如下所示:

```py
2022-01-01 19:15:48,269 finished mlflow pipeline run with a run_id = f7133b916a004c508e227f00d534e136
2022/01/01 19:15:48 INFO mlflow.projects: === Run (ID 'f7133b916a004c508e227f00d534e136') succeeded ===
```

如果您看到了这一点，您应该为自己成功地运行了一个一步到位的管道而感到自豪。

虽然这是我们以前在不知道一些细节的情况下做过的事情，但下一节将允许我们在本地环境中运行远程代码，在这里您将看到 MLproject 不断增加的灵活性和功能。

# 本地运行 GitHub 中的远程代码

现在，让我们看看我们如何在本地执行环境上从 GitHub 库运行远程代码。这允许我们使用提交散列精确地运行已经登记到 GitHub 存储库中的特定版本。让我们使用与前面相同的例子，运行我们在本章中使用的 DL 管道的单个`download_data`步骤。在命令行提示符下，运行以下命令:

```py
mlflow run https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow#chapter05 -v 26119e984e52dadd04b99e6f7e95f8dda8b59238  --experiment-name='dl_model_chapter05' -P pipeline_steps='download_data'
```

请注意这个命令行和上一节中的命令行之间的区别。我们没有用*点*来引用代码的本地副本，而是指向一个远程 GitHub 存储库([https://GitHub . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow))和包含我们想要引用的 MLproject 文件的文件夹名称(`chapter05`)。根据 MLflow 的约定，`#`符号表示根文件夹的相对路径(详见本网站 MLflow 文档:[https://www . ml flow . org/docs/latest/projects . html # running-projects](https://www.mlflow.org/docs/latest/projects.html#running-projects))。然后，我们通过使用`-v`参数指定 Git 提交散列来定义版本号。在这种情况下，它是我们在 GitHub 存储库中的这个版本:

[https://github . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/tree/26119 e 984 e 52 add 04 b 99 E6 f 7 e 95 f 8d da8 b 59238/chapter 05](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/tree/26119e984e52dadd04b99e6f7e95f8dda8b59238/chapter05)

用 GitHub 主分支运行 MLflow 项目的隐藏 Bug

当我们在 MLflow 运行中省略`-v`参数时，MLflow 将假设我们想要使用 GitHub 项目的默认`main`分支。然而，MLflow 的源代码有一个对 GitHub 项目的`main`分支的硬编码引用，称为`origin.refs.master`，要求 GitHub 项目中存在一个`master`分支。这在较新的 GitHub 项目中不起作用，比如这本书的项目，因为默认的分支被称为`main`，不再是`master`，这是由于 GitHub 最近引入的变化(详见这里:[https://github.com/github/renaming](https://github.com/github/renaming))。所以，在写这本书的时候，在 ml flow 1 . 22 . 0 版本中，没有办法运行一个 GitHub 项目的默认`main`分支。在 GitHub 存储库中运行 MLflow 项目时，我们需要专门声明 Git commit hash 版本。

那么，当您在运行 MLflow 项目时使用远程 GitHub 项目存储库中的代码时会发生什么呢？当您看到以下控制台输出的第一行时，就清楚了:

```py
2021/12/30 18:57:32 INFO mlflow.projects.utils: === Fetching project from https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow#chapter05 into /var/folders/51/whxjy4r92dx18788yp11ycyr0000gp/T/tmpdyzaa1ye ===
```

这意味着 MLflow 代表用户开始将远程项目克隆到名为`/var/folders/51/whxjy4r92dx18788yp11ycyr0000gp/T/tmpdyzaa1ye`的本地临时文件夹中。

如果您导航到这个临时文件夹，您将看到来自 GitHub 的整个项目内容已经被克隆到这个文件夹中，而不仅仅是包含您想要运行的 ML 项目的文件夹。

控制台输出的其余部分与我们在使用本地代码时看到的一样。一旦您完成了运行`download_data`步骤，您应该能够在`chapter05`下的临时文件夹中找到下载的数据，因为我们在 ML 项目文件中将本地目标文件夹定义为`./data`相对路径:

```py
local_folder: { type: str, default: ./data }
```

MLflow 自动将其转换为绝对路径，并成为`chapter05`下的克隆项目文件夹的相对路径，因为这是 MLproject 文件所在的位置。

这种引用远程 GitHub 项目并在本地环境中运行它的能力非常强大，无论这个本地环境是您的笔记本电脑还是云中的虚拟机。这通过**持续集成和持续部署** ( **CI/CD** )实现了自动化，因为这可以在命令行中直接调用，然后可以编写成 CI/CD 脚本。跟踪部分也是精确的，因为我们在 MLflow 跟踪服务器中记录了 Git 提交散列，这允许我们确切地知道执行了哪个版本的代码。

注意，在我们刚刚讨论的两个场景中，执行环境都是发出 MLflow run 命令的本地机器。MLflow 项目同步运行到完成*，这意味着它是一个阻塞调用，它将运行到完成，并在控制台输出中实时显示进度。*

 *然而，我们需要支持额外的运行场景。例如，有时我们发出 MLflow 项目运行命令的机器不够强大，无法支持我们需要的计算，例如训练一个具有许多纪元的 DL 模型。另一种情况是，如果要下载或访问用于培训的数据有数千兆字节，而您不想将其下载到本地笔记本电脑上用于模型开发。这要求我们能够在远程集群中运行代码。让我们在下一节看看如何做到这一点。

# 在云中远程运行本地代码

在前面的章节中，我们在本地笔记本电脑环境中运行了所有代码，由于笔记本电脑的功率有限，我们将 DL 微调步骤限制在三个时期。这是为了让代码在本地环境中快速运行和测试，而不是为了构建一个实际的高性能 DL 模型。我们确实需要在远程 GPU 集群中运行微调步骤。理想情况下，我们应该只更改一些配置，并且仍然在本地笔记本电脑控制台中发出 MLflow run 命令行，但是实际的管道将被提交到云中的远程集群。让我们看看如何为我们的 DL 管道做到这一点。

让我们从提交在 Databricks 服务器上运行的代码开始。有三个先决条件:

*   **企业 Databricks 服务器**:您需要能够访问企业许可的 Databricks 服务器或云中的免费试用版 Databricks 服务器([https://docs . data bricks . com/getting-started/try-data bricks . html # sign-up-for-a-data bricks-free-trial](https://docs.databricks.com/getting-started/try-databricks.html#sign-up-for-a-databricks-free-trial))。Databricks 的社区版本不支持这种远程执行。
*   Databricks CLI :你需要设置 Databricks CLI，在那里你发出 MLflow 项目运行命令。要安装它，只需运行以下命令:

    ```py
    pip install databricks-cli
    ```

当你检查本章的代码时，我们也在`chapter05`的`requirements.txt`文件中包含了这个依赖。

*   `.databrickscfg`本地个人文件夹中的文件。您不需要两者都有，但是如果您有两者，当被 Databricks 命令行选中时，使用环境变量定义的那个将具有更高的优先级。使用环境变量和生成访问令牌的方法在第 1 章 、*深度学习生命周期和 MLOps 挑战*的*设置 MLflow 与远程 MLflow 服务器*部分中有所描述。注意这些环境变量可以直接在命令行中设置，或者如果你使用的是 macOS 或 Linux 机器，可以放入你的`.bash_profile`文件中。

这里，我们描述如何使用 Databricks 命令行工具来生成一个`.databrickscfg`文件:

1.  运行下面的命令来设置令牌配置:

    ```py
    databricks configure --token
    ```

2.  按照提示填写远程数据块主机 URL 和访问令牌:

    ```py
    Databricks Host (should begin with https://): https://???? Token: dapi??????????
    ```

3.  现在，如果您检查您的本地主文件夹，您应该会找到一个名为`.databrickscfg`的隐藏文件。

如果您打开这个文件，您应该能够看到如下内容:

```py
[DEFAULT]
host = https://??????
token = dapi???????
jobs-api-version = 2.0 
```

请注意，最后一行表示 Databricks 服务器正在使用的远程作业提交和执行 API 版本。

现在您已经正确设置了访问，让我们看看如何使用以下步骤在远程 Databricks 服务器中远程运行 DL 管道:

1.  由于我们要使用远程数据块服务器，我们之前设置的本地 MLflow 服务器不再工作。这意味着我们需要禁用并注释掉`main.py`文件中的以下行，这些行只对本地 MLflow 服务器设置有用(从 GitHub 查看最新版本的`chapter05`代码以遵循这些步骤，位于[https://GitHub . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow . git](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow.git)):

    ```py
    os.environ["MLFLOW_TRACKING_URI"] = http://localhost os.environ["MLFLOW_S3_ENDPOINT_URL"] = http://localhost:9000 os.environ["AWS_ACCESS_KEY_ID"] = "minio" os.environ["AWS_SECRET_ACCESS_KEY"] = "minio123"
    ```

相反，我们应该使用下面的环境变量，它可以在`.bash_profile`文件中定义或者直接在命令行中执行:

```py
export MLFLOW_TRACKING_URI="databricks"
```

这将使用 Databricks 服务器上的 MLflow 跟踪服务器。如果不指定，它将默认为 localhost，但会失败，因为远程 Databricks 服务器上没有 MLflow 的 localhost 版本。因此，请确保您已经正确设置了这一点。现在，我们已经准备好远程运行本地代码了。

1.  现在，运行下面的命令行，将本地代码提交给远程 Databricks 服务器运行。我们将从`download_data`步骤开始，如下:

    ```py
    mlflow run . -b databricks --backend-config cluster_spec.json --experiment-name='/Shared/dl_model_chapter05' -P pipeline_steps ='download_data'
    ```

这次您将看到命令行有两个新参数:`-b databricks`，它将后端指定为 Databricks 服务器，以及`--backend-config cluster_spec.json`，它详细说明了集群规范。这个`cluster_spec.json`文件的内容如下:

```py
{
    "new_cluster": {
        "spark_version": "9.1.x-gpu-ml-scala2.12",
        "num_workers": 1,
        "node_type_id": "g4dn.xlarge"
    }
}
```

这个`cluster_spec.json`文件通常位于 MLproject 文件所在的同一个文件夹中，并且需要被预定义，以便 MLflow run 命令可以拾取它。我们在此给出的示例仅定义了使用 AWS 的 GPU 虚拟机作为单个节点在 Databricks 上创建作业集群所需的最小参数集，但是如果需要，您可以创建更丰富的集群规范(有关更多详细信息，请参见下面的*data bricks 集群规范*框)。

数据块的群集规范

向 Databricks 提交作业时，需要创建一个新的作业集群，该集群不同于您已有的交互式集群，您可以通过连接笔记本来运行交互式作业。集群规范是通过最低限度地指定 Databricks 运行时版本来定义的，在我们当前的示例中是`9.1.x-gpu-ml-scala2.12`、工作节点的数量和节点类型 ID，如我们的示例所示。建议使用`g4dn.xlarge`进行学习。您可以在这个集群规范中定义许多其他配置，包括存储和访问权限，以及`init`脚本。生成有效的集群规范 JSON 文件的最简单方法是使用 Databricks 门户 UI 创建一个新的集群，在这里您可以选择 Databricks 运行时版本、集群节点类型和其他参数([https://docs.databricks.com/clusters/create.html](https://docs.databricks.com/clusters/create.html))。然后，您可以通过点击**创建集群** UI 页面右上角的 JSON 链接获得集群的 JSON 表示(参见*图 5.2* )。

![Figure 5.2 - An example of creating a cluster on Databricks 
](img/B18120_05_02.jpg)

图 5.2 -在数据块上创建集群的示例

还要注意，前面命令中的`experiment-name`参数不再只接受实验名称字符串，而是需要包含 Databricks 工作区中的绝对路径。这与本地 MLflow 跟踪服务器不同。必须遵循这个约定才能使这个远程作业提交工作。请注意，如果您希望拥有多层子文件夹结构，如下所示，则每个子文件夹必须已经存在于 Databricks 服务器中:

```py
/rootPath/subfolder1/subfolder2/my_experiment_name
```

这意味着`rootPath`、`subfolder1,`和`subfolder2`文件夹必须已经存在。否则，命令行将失败，因为它无法在 Databricks 服务器上自动创建父文件夹。如果最后一个字符串`my_experiment_name`还不存在，那么可以自动创建它，因为这是实际的实验名称，它将托管所有的实验运行。请注意，在本例中，我们使用命令行参数来指定实验名称，但是也可以使用环境变量来指定它，如下所示:

```py
export MLFLOW_EXPERIMENT_NAME=/Shared/dl_model_chapter05
```

1.  一旦这个命令被执行，您将会看到一个比之前在本地环境中运行时短得多的控制台输出消息。这是因为当以这种方式执行代码时，它运行*异步*，这意味着作业被提交到远程 Databricks 服务器，并立即返回到控制台，而无需等待。让我们看看输出的前三行:

    ```py
    INFO: '/Shared/dl_model_chapter05' does not exist. Creating a new experiment 2022/01/06 17:35:32 INFO mlflow.projects.databricks: === Uploading project to DBFS path /dbfs/mlflow-experiments/427565/projects-code/f1cbec57b21eabfca52f417f8482054bbea22be 9205b5bbde461780d809924c2.tar.gz === 2022/01/06 17:35:32 INFO mlflow.projects.databricks: === Finished uploading project to /dbfs/mlflow-experiments/427565/projects-code/f1cbec57b21eabfca52f417f8482054bbea22be 9205b5bbde461780d809924c2.tar.gz ===
    ```

第一行表示该实验在 Databricks 服务器中不存在，因此它正在被创建。如果您再次运行此程序，它将不会显示。第二行和第三行描述了 MLflow 将 MLproject 打包成一个`.tar.gz`文件并上传到 Databricks 文件服务器的过程。注意，不像 GitHub 项目需要从资源库中签出整个项目，在这里，它只需要打包`chapter05`文件夹，因为那是我们的 MLproject 所在的位置。这可以通过查看 Databricks 集群中的作业运行日志来确认，我们将在接下来的几段中解释(从哪里获取作业 URL 以及如何查找日志)。

MLproject 的同步和异步运行

官方 MLflow 运行 CLI 不支持指定以异步或同步模式运行 MLflow 项目的参数。但是，MLflow run Python API 确实有一个名为`synchronous`的参数，默认设置为`True`。当使用 MLflow 的 CLI 以 Databricks 作为后端运行 MLflow 作业时，默认行为是异步的。有时，在 CI/CD 自动化过程中，当您需要确保 MLflow 运行在进入下一步之前成功完成时，CLI run 命令的同步行为是可取的。这无法通过官方的 MLflow run CLI 来完成，但您可以编写一个包装器 CLI Python 函数，在同步模式设置为`True`的情况下调用 MLflow 的 Python API，然后使用您自己的 CLI Python 命令在同步模式下运行 MLflow 作业。另外，注意`mlflow.run()`是`mlflow.projects.run()` API 的高级 fluent(面向对象)API。为了保持一致性，我们在本书中广泛使用了`mlflow.run()` API。关于 MLflow 运行 Python API 的详细信息，请参见官方文档页面:[https://www . ml flow . org/docs/latest/Python _ API/ml flow . projects . html # ml flow . projects . run](https://www.mlflow.org/docs/latest/python_api/mlflow.projects.html#mlflow.projects.run)。

接下来的几行输出如下所示:

```py
2022/01/06 17:48:31 INFO mlflow.projects.databricks: === Running entry point main of project . on Databricks ===
2022/01/06 17:48:31 INFO mlflow.projects.databricks: === Launched MLflow run as Databricks job run with ID 279456. Getting run status page URL... ===
2022/01/06 17:48:31 INFO mlflow.projects.databricks: === Check the run's status at https://???.cloud.databricks.com#job/168339/run/1 ===
```

这些行描述了作业已经提交到 Databricks 服务器，作业运行 ID 和作业 URL 显示在最后一行(用您实际的 Databricks URL 替换`???`以便为您工作)。请注意，MLflow 运行 ID 是`279456`，它不同于您在作业 URL 中看到的 ID(`168339`)。这是因为作业 URL 由 Databricks 作业管理系统管理，并以不同的方式生成和跟踪每个实际作业。

1.  点击作业 URL 链接(`https://???.cloud.databricks.com#job/168339/run/1`)并检查该作业的状态，这将显示进度和标准输出以及错误日志(参见*图 5.3* )。通常，该页面将花费几分钟时间来开始显示运行进度，因为它需要在开始运行作业之前基于`cluster_spec.json`创建一个全新的集群。

![Figure 5.3 – MLflow run job status page with standard output
](img/B18120_05_03.jpg)

图 5.3–具有标准输出的 MLflow 运行作业状态页面

*图 5.3* 显示作业已成功完成(`chapter05`文件夹已上传并提取到数据块文件系统 ( **DBFS** )。如前所述，在 DBFS 中，只有我们想要运行的 MLproject 被打包、上传和提取，而不是整个项目存储库。

在同一个作业状态页面上，您还会发现标准错误部分，它显示了描述我们想要运行的管道步骤的日志:`download_data`。这些不是错误，只是信息性消息。所有 Python 日志都聚集在这里。详见*图 5.4* :

![Figure 5.4 – MLflow job information logged on the job status page
](img/B18120_05_04.jpg)

图 5.4–作业状态页面上记录的 MLflow 作业信息

*图 5.4* 显示的日志与我们在本地交互环境中运行时看到的日志非常相似，但现在这些运行是在我们提交作业时指定的集群中执行的。注意*图 5.4* 中的管道实验 ID 为`427565`。使用以下 URL 模式中的实验 ID `427565`，您应该能够在 Databricks 服务器上的集成 MLflow 跟踪服务器中找到成功完成的 MLflow DL 管道运行:

`https://[your databricks hostname]/#mlflow/experiments/427565`

如果您看到我们在前面章节中看到的熟悉的跟踪结果，请给自己一个大大的拥抱，因为您刚刚完成了在远程 Databricks 集群中运行本地代码的重要学习里程碑！

此外，我们可以使用这种方法运行 DL 管道的多个步骤，而无需更改单个步骤实现中的任何代码。例如，如果我们想要运行 DL 管道的`download_data`和`fine_tuning_model`步骤，我们可以发出以下命令:

```py
mlflow run . -b databricks --backend-config cluster_spec.json --experiment-name='/Shared/dl_model_chapter05' -P pipeline_steps='download_data,fine_tuning_model'
```

输出控制台将显示以下短消息:

```py
2022/01/07 15:22:39 INFO mlflow.projects.databricks: === Uploading project to DBFS path /dbfs/mlflow-experiments/427565/projects-code/743cadfec82a55b8c76e9f27754cfdd516545b155254e990c2cc62650b8af959.tar.gz ===
2022/01/07 15:22:40 INFO mlflow.projects.databricks: === Finished uploading project to /dbfs/mlflow-experiments/427565/projects-code/743cadfec82a55b8c76e9f27754cfdd516545b155254e990c2cc62650b8af959.tar.gz ===
2022/01/07 15:22:40 INFO mlflow.projects.databricks: === Running entry point main of project . on Databricks ===
2022/01/07 15:22:40 INFO mlflow.projects.databricks: === Launched MLflow run as Databricks job run with ID 279540\. Getting run status page URL... ===
2022/01/07 15:22:40 INFO mlflow.projects.databricks: === Check the run's status at https://?????.cloud.databricks.com#job/168429/run/1 ===
```

然后，您可以转到控制台输出的最后一行中显示的作业 URL 页面，等待创建一个新集群并完成这两个步骤。然后，您应该能够使用相同的实验 URL(因为我们使用相同的实验名称)在 MLflow 跟踪服务器中记录的实验文件夹中找到这两个步骤:

`https://[your databricks hostname]/#mlflow/experiments/427565`

现在我们知道了如何在远程 Databricks 集群中运行本地代码，我们将学习如何在远程 Databricks 集群中运行 GitHub 存储库中的代码。

# 使用 GitHub 中的远程代码在云中远程运行

最可靠的复制 DL 管道的方式是将指向 GitHub 中项目代码的特定版本，然后在云中运行它，而不调用任何本地资源。这样，我们知道了代码的确切版本，并且使用了项目中定义的相同运行环境。让我们看看这是如何与我们的 DL 管道一起工作的。

作为先决条件和提醒，在发出 MLflow run 命令完成本部分学习之前，需要设置以下三个环境变量:

```py
export MLFLOW_TRACKING_URI=databricks
export DATABRICKS_TOKEN=[databricks_token]
export DATABRICKS_HOST='https://[your databricks host name/'
```

从上一节我们已经知道了如何设置这些环境变量。可能还需要一个设置，即允许您的 Databricks 服务器访问您的非公共 GitHub 存储库(参见下面的 *GitHub 令牌，用于 Databricks 访问非公共或企业项目存储库*框)。

用于数据块访问非公共或企业项目存储库的 GitHub 令牌

为了允许 Databricks 访问 GitHub 中的项目存储库，还需要另一个令牌。这可以通过转到您的个人 GitHub 页面(https://github.com/settings/tokens)并遵循该页面上描述的步骤来生成([https://docs . GitHub . com/en/authentic ation/keeping-your-account-and-data-secure/creating-a-personal-access-token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token))。然后可以按照 Databricks 文档网站上的说明进行设置:[https://docs . data bricks . com/repos . html # configure-your-git-integration-with-data bricks](https://docs.databricks.com/repos.html#configure-your-git-integration-with-databricks)。

现在，让我们使用 GitHub 存储库中的特定版本在远程数据块集群上运行项目:

```py
mlflow run https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow#chapter05 -v 395c33858a53bcd8ac217a962ab81e148d9f1d9a -b databricks --backend-config cluster_spec.json --experiment-name='/Shared/dl_model_chapter05' -P pipeline_steps='all'
```

然后我们会看到只有六行的输出。让我们看看每行显示的重要信息及其工作原理:

1.  第一行显示了项目存储库的内容下载到本地的位置:

    ```py
    2022/01/07 17:36:54 INFO mlflow.projects.utils: === Fetching project from https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow#chapter05 into /var/folders/51/whxjy4r92dx18788yp11ycyr0000gp/T/tmpzcepn5h5 ===
    ```

如果我们在本地机器上执行这个命令时，转到这个消息中显示的临时目录，我们会看到整个存储库已经下载到这个文件夹:`/var/folders/51/whxjy4r92dx18788yp11ycyr0000gp/T/tmpzcepn5h5`。

1.  接下来的两行显示项目内容被压缩并上传到 Databricks 服务器上的 DBFS 文件夹:

    ```py
    2022/01/07 17:36:57 INFO mlflow.projects.databricks: === Uploading project to DBFS path /dbfs/mlflow-experiments/427565/projects-code/fba3d31e1895b78f40227b5965461faddb 61ec9df906fb09b161f74efaa90aa2.tar.gz === 2022/01/07 17:36:57 INFO mlflow.projects.databricks: === Finished uploading project to /dbfs/mlflow-experiments/427565/projects-code/fba3d31e1895b78f40227b5965461faddb61ec 9df906fb09b161f74efaa90aa2.tar.gz ===
    ```

如果我们使用 Databricks 的 local 命令行工具，我们可以列出这个`.tar.gz`文件，就好像它是一个本地文件一样(但实际上，它位于 Databricks 服务器的远程位置):

```py
databricks fs ls -l dbfs:/mlflow-experiments/427565/projects-code/fba3d31e1895b78f40227b5965461faddb61ec 9df906fb09b161f74efaa90aa2.tar.gz
```

您应该会看到类似下面的输出，它描述了文件的属性(大小、所有者/组 ID 以及它是文件还是目录):

```py
file  3070  fba3d31e1895b78f40227b5965461faddb61ec 9df906fb09b161f74efaa90aa2.tar.gz  1641605818000
```

1.  下一行显示它开始运行这个 GitHub 项目的`main`入口点:

    ```py
    2022/01/07 17:36:57 INFO mlflow.projects.databricks: === Running entry point main of project https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow#chapter05 on Databricks ===
    ```

请注意我们运行本地代码时的区别(它是项目后面的一个*点*，这意味着本地系统上的当前目录)。现在，它列出了 GitHub 存储库位置的完整路径。

1.  最后两行类似于前一部分的输出，其中列出了工作 URL:

    ```py
    2022/01/07 17:36:57 INFO mlflow.projects.databricks: === Launched MLflow run as Databricks job run with ID 279660\. Getting run status page URL... === 2022/01/07 17:36:57 INFO mlflow.projects.databricks: === Check the run's status at https://????.cloud.databricks.com#job/168527/run/1 ===
    ```

2.  如果我们单击控制台输出的最后一行中的作业 URL，我们将能够在该网站上看到以下内容(*图 5.5* ):

![Figure 5.5 – MLflow run job status page using the code from the GitHub repository
](img/B18120_05_05.jpg)

图 5.5–使用来自 GitHub 存储库的代码的 MLflow 运行作业状态页面

*图 5.5* 显示了该作业的结束状态。注意，现在页面的标题是**ml flow Run for https://github . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow # chapter 05**，而不是 **MLflow Run for。**如前一节所示当使用本地代码运行时。

作业的状态显示该作业已成功运行，您还将看到结果像以前一样记录在实验页面中，所有三个步骤都已完成。该模型还按照预期在模型注册中心注册，注册在 Databricks 服务器中的以下 URL 下:

`https://[your_databricks_hostname]/#mlflow/models/dl_finetuned_model`

总之，这种方法的工作机制如下图所示(*图 5.6* ):

![Figure 5.6 – Summary view of running remote GitHub code in a remote Databricks cluster server
](img/B18120_05_06.jpg)

图 5.6–在远程 Databricks 集群服务器中运行远程 GitHub 代码的概要视图

*图 5.6* 显示了有三个不同的位置(一个我们发出 MLflow 运行命令的机器，一个远程 Databricks 服务器，和一个远程 GitHub 项目)。当发出 MLflow run 命令时，远程 GitHub 项目源代码被克隆到发出 MLflow run 命令的机器上，然后被上传到远程 Databricks 服务器，并提交一个作业来执行 DL 管道的多个步骤。这是一个异步执行，需要根据创建的作业 URL 监控作业的状态。

在其他后端上运行 MLflow 项目

现在，Databricks 支持两种类型的远程运行后端环境:Databricks 和 K8s。不过，截至 MLflow 1 . 22 . 0 版本([https://www . ml flow . org/docs/latest/projects . html # run-an-ml flow-project-on-kubernetes-experimental](https://www.mlflow.org/docs/latest/projects.html#run-an-mlflow-project-on-kubernetes-experimental))，在 K8s 上运行 ml flow 项目仍处于实验模式，可能会有变化。如果您有兴趣了解这方面的更多信息，请参考*进一步阅读*部分中的参考资料，探究提供的示例。还有其他第三方提供的后端(也叫社区插件)比如`hadoop-yarn`([https://github.com/criteo/mlflow-yarn](https://github.com/criteo/mlflow-yarn))。由于 Databricks 在所有主要云提供商中的可用性及其在支持符合企业安全的生产场景方面的成熟性，本书目前主要关注学习如何在 Databricks 服务器中远程运行 MLflow 项目。

# 总结

在本章中，我们学习了如何使用本地源代码或 GitHub 项目存储库代码在不同的执行环境(本地或远程数据块集群)中运行 DL 管道。这不仅对执行 DL 流水线的再现性和灵活性至关重要，而且还能提供更高的生产率和未来使用 CI/CD 工具实现自动化的可能性。在资源丰富的远程环境中运行 DL 管道的一个或多个步骤的能力使我们能够快速执行大规模计算和数据密集型作业，这些作业通常在生产质量的 DL 模型培训和微调中出现。这允许我们在必要时对 DL 模型进行超参数调整或交叉验证。我们将在下一章开始学习如何运行大规模超参数调优，这是我们自然的下一步。

# 延伸阅读

*   MLflow 运行项目参数(针对命令行和 Python API):[https://www . ml flow . org/docs/latest/projects . html # running-projects](https://www.mlflow.org/docs/latest/projects.html#running-projects)
*   MLflow 运行命令行(CLI)文档:[https://www.mlflow.org/docs/latest/cli.html#mlflow-run](https://www.mlflow.org/docs/latest/cli.html#mlflow-run)
*   MLflow 在数据块上运行项目:[https://www . ml flow . org/docs/latest/projects . html # run-an-ml flow-project-on-data bricks](https://www.mlflow.org/docs/latest/projects.html#run-an-mlflow-project-on-databricks)
*   在 K8s 上运行 MLflow 项目的例子:[https://github . com/sameeragandhi/ml flow-on-K8s/tree/master/examples/LogisticRegression](https://github.com/SameeraGrandhi/mlflow-on-k8s/tree/master/examples/LogisticRegression)
*   在 Azure 上运行 MLflow 项目:[https://docs . Microsoft . com/en-us/Azure/machine-learning/how-to-train-ml flow-projects](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-mlflow-projects)*