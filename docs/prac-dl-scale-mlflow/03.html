<html><head/><body>




<style type="text/css">body{margin:1em;background-color:transparent!important;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}#sbo-rt-content *{word-wrap:break-word!important;word-break:break-word!important;}#sbo-rt-content table,#sbo-rt-content pre{overflow-x:unset!important;overflow:unset!important;overflow-y:unset!important;white-space:pre-wrap!important;}</style>
<div><div><h1 id="_idParaDest-28"><em class="italic"> <a id="_idTextAnchor027"/>第二章</em>:深度学习MLflow入门</h1>
			<p>MLflow的关键功能之一是支持<strong class="bold">机器学习</strong> ( <strong class="bold"> ML </strong>)实验管理。这一点至关重要，因为数据科学需要可再现性和可追溯性，以便可以使用相同的数据、代码和执行环境轻松再现<strong class="bold">深度学习</strong> ( <strong class="bold"> DL </strong>)模型。本章将帮助我们快速开始实施DL实验管理。我们将了解MLflow实验管理概念和功能，设置MLflow开发环境，并使用MLflow完成我们的第一个DL实验。到本章结束时，我们将有一个工作的MLflow跟踪服务器显示我们的第一个DL实验结果。</p>
			<p>在本章中，我们将讨论以下主要话题:</p>
			<ul>
				<li>设置MLflow</li>
				<li>实现我们的第一个支持MLflow日志记录的DL实验</li>
				<li>探索MLflow的组件和使用模式</li>
			</ul>
			<h1 id="_idParaDest-29"><a id="_idTextAnchor028"/>技术要求</h1>
			<p>为了完成本章的实验，我们需要在我们的计算机上安装或检出以下工具、库和GitHub库:</p>
			<ul>
				<li>VS代码:本书我们使用的版本是2021年8月(也就是1.60版本)。我们在本地代码开发环境中使用VS代码。这是当地发展的推荐方式。请参考<a href="https://code.visualstudio.com/updates/v1_60">https://code.visualstudio.com/updates/v1_60</a>。</li>
				<li>MLflow:版本1.20.2。在本章的<em class="italic">设置MLflow </em>部分，我们将介绍如何在本地或远程设置MLflow。请参考<a href="https://github.com/mlflow/mlflow/releases/tag/v1.20.2">https://github.com/mlflow/mlflow/releases/tag/v1.20.2</a>。</li>
				<li>Miniconda:版本4.10.3。请参考<a href="https://docs.conda.io/en/latest/miniconda.html">https://docs.conda.io/en/latest/miniconda.html</a>。</li>
				<li>PyTorch <code>lightning-flash</code> : 0.5.0。请参考<a href="https://github.com/PyTorchLightning/lightning-flash/releases/tag/0.5.0">https://github . com/PyTorchLightning/lightning-flash/releases/tag/0 . 5 . 0</a>。</li>
				<li>本章代码的GitHub URL:你可以在<a href="https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLflow/tree/main/chapter02">https://GitHub . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/tree/main/chapter 02</a>找到这个。</li>
			</ul>
			<h1 id="_idParaDest-30"><a id="_idTextAnchor029"/>设置MLflow</h1>
			<p><strong class="bold"> MLflow </strong>是一个<a id="_idIndexMarker073"/>开源工具，主要用Python编写。它的GitHub源代码库中有超过10，000颗<a id="_idIndexMarker074"/>标记的星星(【https://github.com/mlflow/mlflow】T4)。使用MLflow的好处有很多，但是我们可以用下面的场景来说明一个好处:假设你正在开始一个新的ML项目，试图评估不同的算法和模型参数。几天之内，您使用不同的ML/DL库运行了数百个包含大量代码更改的实验，并获得了具有不同参数和精度的不同模型。您需要比较哪个模型更好，并允许您的团队成员复制结果<a id="_idIndexMarker075"/>用于模型评审目的。你是否准备了一份电子表格，并写下模型名称、参数、精度和模型位置？其他人如何能够重新运行您的代码或使用您的经过训练的具有不同评估数据集的模型呢？当您为不同的项目进行大量迭代时，这可能会很快变得难以管理。MLflow可以帮助您跟踪您的实验，比较您的模型运行并允许他人轻松复制您的结果，重新使用您训练的模型进行审查，甚至轻松地将您的模型部署到生产中。</p>
			<p>听起来很刺激？好吧，让我们设置MLflow，以便我们可以探索它的组件和模式。MLflow允许本地设置和基于云的设置。我们将在接下来的小节中介绍这两种设置场景。</p>
			<h2 id="_idParaDest-31"><a id="_idTextAnchor030"/>使用miniconda在本地设置MLflow</h2>
			<p>首先，让我们在本地开发环境中设置<a id="_idIndexMarker076"/> MLflow。这允许快速原型制作，并帮助您熟悉MLflow工具的基本功能。此外，它允许您在需要时与远程MLflow云服务器进行交互。按照以下说明设置MLflow。</p>
			<p>假设您已经有了一个根据<a href="B18120_01_ePub.xhtml#_idTextAnchor015"> <em class="italic">第1章</em> </a>、<em class="italic">深度学习生命周期和MLOps挑战</em>创建的虚拟conda环境，您就可以在同一个虚拟环境中安装MLflow了:</p>
			<pre>pip install mlflow</pre>
			<p>前面的命令将安装MLflow的最新版本。如果您想要安装特定版本的MLflow，可以使用以下命令:</p>
			<pre>pip install mlflow==1.20.2</pre>
			<p>如你所见，我<a id="_idIndexMarker077"/>已经安装了MLflow版本1.20.2。默认情况下，MLflow将使用本地文件系统来存储所有的实验工件(例如，一个序列化的模型)和元数据(参数、指标等等)。如果需要关系数据库作为MLflow的后端存储，则需要额外的安装和配置。现在，让我们使用文件系统进行存储。通过在命令行中键入以下内容，可以在本地验证MLflow安装:</p>
			<pre>mlflow --version</pre>
			<p>然后，它将显示已安装的MLflow版本，如下所示:</p>
			<pre>mlflow, version 1.20.2</pre>
			<p>这证实了我们已经在本地开发环境中安装了ml flow 1 . 20 . 2版。此外，您可以在本地启动MLflow UI以查看MLflow跟踪服务器UI，如下所示:</p>
			<pre>mlflow ui</pre>
			<p>接下来，您将看到UI web服务器正在运行:</p>
			<div><div><img src="img/B18120_02_001.jpg" alt="Figure 2.1 – Starting the MLflow UI in a local environment&#13;&#10;" width="610" height="87"/>
				</div>
			</div>
			<p class="figure-caption">图2.1–在本地环境中启动MLflow UI</p>
			<p><em class="italic">图2.1 </em>为本地MLflow UI网站:<code>http://127.0.0.1:5000/</code>。如果您单击此URL，您将会看到以下MLflow UI出现在您的浏览器窗口中。由于这是一个全新的MLflow装置，只有一个<strong class="bold">默认</strong>实验，还没有运行(请参考<em class="italic">图2.2 </em>):</p>
			<div><div><img src="img/B18120_02_002.jpg" alt="Figure 2.2 – The MLflow Default Experiments UI web page&#13;&#10;" width="1124" height="598"/>
				</div>
			</div>
			<p class="figure-caption">图2.2–ml flow默认实验用户界面网页</p>
			<p>看到<a id="_idIndexMarker078"/>默认MLflow UI页面启动并运行，即表示使用本地工作MLflow跟踪服务器成功设置了MLflow。</p>
			<h2 id="_idParaDest-32"><a id="_idTextAnchor031"/>设置MLflow以与远程MLflow服务器交互</h2>
			<p>在企业<a id="_idIndexMarker079"/>生产环境中，MLflow通常托管在云服务器上，该云服务器可以是自托管的，也可以是云提供商(如AWS、Azure或Google Cloud)中Databricks的托管服务之一。在这些情况下，需要设置您的本地开发环境，以便您可以在本地运行ML/DL实验，但可以与MLflow服务器进行远程交互。接下来，我们将借助以下三个步骤，描述如何使用环境变量来实现这一点:</p>
			<ol>
				<li>在bash shell命令行环境中，如果使用Databricks管理的MLflow跟踪服务器，请定义三个新的环境变量。第一个环境变量是<code>MLFLOW_TRACKING_URI</code>，赋值是<code>databricks</code> : <pre>export MLFLOW_TRACKING_URI=databricks export DATABRICKS_HOST=https://******* export DATABRICKS_TOKEN=dapi******</pre></li>
				<li>第二个环境变量是<code>DATABRICKS_HOST</code>。如果你的Databricks管理的网站看起来像<code>https://dbc-*.cloud.databricks.com/</code>，那么这就是<code>DATABRICKS_HOST</code>变量的值(用你实际的网站字符串替换<code>*</code>)。</li>
				<li>第三个<a id="_idIndexMarker080"/>环境变量是<code>DATABRICKS_TOKEN</code>。通过<code>https://dbc-*.cloud.databricks.com/#setting/account</code>导航至您的数据块管理网站，点击<strong class="bold">访问令牌</strong>，然后点击<strong class="bold">生成新令牌</strong>。您将看到一个弹出窗口，其中有一个<strong class="bold">注释</strong>字段(可用于记录为什么要使用该令牌)和到期日期，如<em class="italic">图2.3 </em>所示:</li>
			</ol>
			<div><div><img src="img/B18120_02_003.jpg" alt="Figure 2.3 – Generating a Databricks access token &#13;&#10;" width="1100" height="347"/>
				</div>
			</div>
			<p class="figure-caption">图2.3–生成数据块访问令牌</p>
			<p>点击<code>DATABRICKS_TOKEN</code>环境变量作为值:</p>
			<div><div><img src="img/B18120_02_004.jpg" alt="Figure 2.4 – Copying the generated token that will be used for the environment variable&#13;&#10;" width="485" height="211"/>
				</div>
			</div>
			<p class="figure-caption">图2.4–复制将用于环境变量的生成令牌</p>
			<p>一旦设置了这三个环境变量，您将能够在将来与Databricks管理的MLflow服务器进行交互。请注意，出于安全原因，访问令牌有一个到期日期，管理员可以随时撤销该日期，因此请确保在刷新令牌时相应地更新环境变量。</p>
			<p>总之，我们已经了解了如何在本地设置MLflow，以便与本地MLflow跟踪服务器或远程MLflow跟踪服务器进行交互。这将允许我们在下一节中实现我们的第一个支持MLflow跟踪的DL模型，以便我们能够以实际操作的方式探索MLflow概念和组件。</p>
			<h1 id="_idParaDest-33"><a id="_idTextAnchor032"/>使用MLflow自动日志记录实现我们的第一个DL实验</h1>
			<p>让我们使用我们在<a href="B18120_01_ePub.xhtml#_idTextAnchor015"> <em class="italic">第1章</em> </a>、<em class="italic">深度学习生命周期和MLOps挑战</em>中构建的<a id="_idIndexMarker082"/> DL情感<a id="_idIndexMarker083"/>分类器，并为其添加MLflow自动日志记录，以探索MLflow的跟踪功能:</p>
			<ol>
				<li value="1">首先，我们需要导入MLflow模块:<pre>import mlflow</pre></li>
			</ol>
			<p>这将为日志记录和加载模型提供MLflow <strong class="bold">应用编程接口</strong>(<strong class="bold">API</strong>)。</p>
			<ol>
				<li value="2">在运行训练代码之前，我们需要使用<code>mlflow.set_experiment</code>为当前运行的代码<pre>EXPERIMENT_NAME = "dl_model_chapter02" mlflow.set_experiment(EXPERIMENT_NAME) experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME) print("experiment_id:", experiment.experiment_id)</pre>设置一个活动实验</li>
			</ol>
			<p>这会将名为<code>dl_model_chapter02</code>的实验<a id="_idIndexMarker085"/>设置为当前活动实验。如果您当前的跟踪服务器中不存在此实验，它将被自动创建。</p>
			<p class="callout-heading">环境变量</p>
			<p class="callout">注意，在运行第一个实验之前，您可能需要使用<code>MLFLOW_TRACKING_URI</code>环境变量来设置跟踪服务器URI。如果您使用托管数据块服务器，请执行以下操作:</p>
			<p class="callout"><code>export MLFLOW_TRACKING_URI=databricks </code></p>
			<p class="callout">如果您使用的是本地服务器，那么将这个环境变量设置为空或者端口号为<code>5000</code>的默认localhost，如下所示(注意，这是我们当前章节的场景，假设您使用的是本地服务器):</p>
			<p class="callout"><code>export MLFLOW_TRACKING_URI= http://127.0.0.1:5000 </code></p>
			<ol>
				<li value="3">接下来，添加一行代码来启用MLflow中的自动日志记录:<pre>mlflow.pytorch.autolog()</pre></li>
			</ol>
			<p>此<a id="_idIndexMarker086"/>将允许默认<a id="_idIndexMarker087"/>参数、指标和模型自动记录到MLflow跟踪服务器。</p>
			<p class="callout-heading">MLflow中的自动记录</p>
			<p class="callout">MLflow中的自动记录功能<a id="_idIndexMarker088"/>仍处于实验模式(从版本1.20.2开始)<a id="_idIndexMarker089"/>可能会在未来发生变化。在这里，我们使用它来探索MLflow组件，因为它只需要一行代码就可以自动记录所有感兴趣的内容。在接下来的章节中，我们将了解并实现在MLflow中执行跟踪和日志记录的其他方法。另外，请注意，目前，PyTorch的MLflow中的自动登录(从版本1.20.2开始)仅适用于PyTorch Lightning框架，而不适用于任何任意的PyTorch代码。</p>
			<ol>
				<li value="4">通过调用<code>mlflow.start_run</code> : <pre><strong class="bold">with mlflow.start_run</strong>(experiment_id=experiment.experiment_id, run_name="chapter02"):     trainer.finetune(classifier_model,                       datamodule=datamodule,                       strategy="freeze")     trainer.test()</pre>，使用Python上下文管理器<code>with</code>语句开始实验运行</li>
			</ol>
			<p>注意，<code>with</code>块下面的所有代码行都是常规的DL模型微调和测试步骤。我们仅启用自动MLflow日志记录，以便我们可以观察MLflow跟踪服务器正在跟踪/记录的元数据。</p>
			<ol>
				<li value="5">接下来，您可以使用以下命令行运行<code>first_dl_with_mlflow.py</code>的完整代码(完整代码可以在本章的GitHub中查看，网址为<a href="https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/blob/main/chapter02/first_dl_with_mlflow.py">https://GitHub . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/blob/main/chapter 02/first _ dl _ with _ ml flow . py</a>):<pre><strong class="bold">python first_dl_with_mlflow.py</strong></pre></li>
			</ol>
			<p>在非GPU macOS笔记本电脑上，整个运行过程不到10分钟。您的屏幕上应该有一个输出，如下所示:</p>
			<div><div><img src="img/B18120_02_005.jpg" alt="Figure 2.5 – DL model training/testing with MLflow autologging enabled&#13;&#10;" width="1033" height="647"/>
				</div>
			</div>
			<p class="figure-caption">图2.5–启用MLflow自动记录的DL模型训练/测试</p>
			<p>如果你是第一次运行这个，你会看到名称为<code>dl_model_chapter02</code>的实验并不存在。相反，MLflow会自动为您创建这个实验:</p>
			<div><div><img src="img/B18120_02_006.jpg" alt="Figure 2.6 – MLflow automatically creates a new environment if it does not exist&#13;&#10;" width="690" height="47"/>
				</div>
			</div>
			<p class="figure-caption">图2.6–如果不存在新环境，MLflow会自动创建一个新环境</p>
			<ol>
				<li value="6">现在，我们<a id="_idIndexMarker092"/>可以在本地打开<a id="_idIndexMarker093"/> MLflow UI，通过导航到<code>http://127.0.0.1:5000/</code>来查看本地跟踪服务器中记录了什么。在这里，您将看到一个新的实验(<code>dl_model_chapter02</code>)和一个新的运行(<code>chapter02</code>)已被记录:</li>
			</ol>
			<div><div><img src="img/B18120_02_007.jpg" alt="Figure 2.7 – The MLflow tracking server UI shows a new experiment with a new run&#13;&#10;" width="1239" height="500"/>
				</div>
			</div>
			<p class="figure-caption">图2.7–ml flow跟踪服务器用户界面显示了新运行的新实验</p>
			<p>现在，点击<em class="italic">图2.7 </em>中<strong class="bold">开始时间</strong>栏的超链接。您将看到运行记录的元数据的详细信息:</p>
			<div><div><img src="img/B18120_02_008.jpg" alt="Figure 2.8 – The MLflow run UI shows the metadata details about the experiment run&#13;&#10;" width="825" height="991"/>
				</div>
			</div>
			<p class="figure-caption">图2.8–ml flow运行UI显示了关于实验运行的元数据详细信息</p>
			<p>如果您可以在自己的<a id="_idIndexMarker095"/>本地环境中查看<a id="_idIndexMarker094"/>该屏幕，那么恭喜您！您刚刚完成了我们第一个DL模型的MLflow跟踪的实现！在下一节中，我们将使用我们的工作示例来探索MLflow中的核心概念和组件。</p>
			<h1 id="_idParaDest-34"><a id="_idTextAnchor033"/>探索MLflow的组件和使用模式</h1>
			<p>让我们使用前一节中实现的工作示例<a id="_idIndexMarker096"/>来探索MLflow中的以下<a id="_idIndexMarker097"/>核心概念、组件和用法。这些包括实验、运行、关于实验的元数据、实验的工件、模型和代码。</p>
			<h2 id="_idParaDest-35"><a id="_idTextAnchor034"/>在MLflow中探索实验和运行</h2>
			<p><strong class="bold">实验</strong>是MLflow APIs中的一个<a id="_idIndexMarker098"/>一级实体。这是有意义的，因为数据科学家和ML工程师需要运行大量的实验，以便建立一个满足要求的工作模型。然而，实验的想法不仅仅局限于模型开发阶段，而是延伸到ML/DL开发和部署的整个生命周期。因此，这意味着当我们为模型的生产版本进行再培训或培训时，我们需要将它们视为生产质量实验。这种统一的实验视图在离线和在线生产环境之间架起了一座桥梁。每个实验由许多次运行组成，在这些运行中，您可以改变每次运行的模型参数、输入数据甚至模型类型。所以，实验是一个包含一系列运行的伞状实体。下图(<em class="italic">图2.9 </em>)说明了数据科学家可以在ML/DL模型生命周期的多个阶段进行离线实验和在线生产实验:</p>
			<div><div><img src="img/B18120_02_009.jpg" alt="Figure 2.9 – Experiments across the offline and online production life cycles of ML/DL models&#13;&#10;" width="1215" height="319"/>
				</div>
			</div>
			<p class="figure-caption">图2.9–ML/DL模型的离线和在线生产生命周期的实验</p>
			<p>从<em class="italic">图2.9 </em>中可以看出，在模型开发阶段，数据科学家可以根据项目场景，多次运行同一个实验或多个实验。如果是一个小的ML项目，在一个单独的离线实验下运行所有的项目就足够了。如果是一个复杂的ML项目，设计不同的实验并且<a id="_idIndexMarker100"/>在每个实验下进行运行是合理的。设计ML实验的好参考<a id="_idIndexMarker101"/>可以在<a href="https://machinelearningmastery.com/controlled-experiments-in-machine-learning/">https://machine learning mastery . com/controlled-experiments-in-machine-learning/</a>找到。然后，在模型生产阶段，建立生产质量实验是可取的，因为我们需要执行模型改进和模型再培训的持续部署。生产实验将提供门控准确性检查，以防止新模型的回归。通常，这是通过对拒绝测试数据集运行自动模型评估和验证来实现的，以检查新模型在准确性方面是否仍然符合发布标准。</p>
			<p>现在，让我们以动手的方式探索MLflow实验。运行以下MLflow命令行与跟踪服务器进行交互:</p>
			<pre>mlflow experiments list </pre>
			<p>如果您的<code>MLFLOW_TRACKING_URI</code>环境变量指向一个远程跟踪服务器，那么它将列出您拥有读取权限的所有实验。如果您想查看本地跟踪服务器中有什么，您可以将<code>MLFLOW_TRACKING_URI</code>设置为nothing(即空的)，如下所示(注意，如果您的本地用户配置文件中从未有过这个环境变量，您不需要这样做；但是，这样做将确保您使用本地跟踪服务器):</p>
			<pre>export MLFLOW_TRACKING_URI=</pre>
			<p>在您第一次实现启用了MLflow自动记录的DL模型之前，列出您所有实验的输出应该类似于<em class="italic">图2.10 </em>(注意，这也取决于您在哪里运行命令行；以下输出假设您在本地文件夹中运行该命令，您可以在GitHub上检查第2章 的<a href="B18120_02_ePub.xhtml#_idTextAnchor027"> <em class="italic">代码):</em></a></p>
			<div><div><img src="img/B18120_02_010.jpg" alt="Figure 2.10 – The default MLflow experiment list in a local environment&#13;&#10;" width="976" height="69"/>
				</div>
			</div>
			<p class="figure-caption">图2.10–本地环境中的默认MLflow实验列表</p>
			<p><em class="italic">图2.10 </em>列出了实验属性的三列:执行MLflow命令的目录下的<code>mlruns</code>文件夹。基于文件系统的MLflow跟踪服务器使用<code>mlruns</code>文件夹来存储实验运行和工件的所有元数据。</p>
			<p class="callout-heading">命令行界面(CLI)与REST APIs以及特定于编程语言的API</p>
			<p class="callout">MLflow提供了三种不同类型的工具和API来与跟踪服务器进行交互。这里使用了CLI，以便我们可以探索MLflow组件。</p>
			<p>因此，让我们探索一个<a id="_idIndexMarker102"/>特定的MLflow实验，如下所示:</p>
			<ol>
				<li value="1">首先，使用MLflow CLI创建一个新实验，如下所示:<pre><strong class="bold">mlflow experiments create -n dl_model_chapter02</strong></pre></li>
			</ol>
			<p>前面的命令创建了一个名为<code>dl_model_chapter02</code>的新实验。如果您已经在上一节中运行了第一个带MLflow自动记录的DL模型，则前面的命令将导致一条错误消息，如下所示:</p>
			<pre><strong class="bold">mlflow.exceptions.MlflowException: Experiment 'dl_model_chapter02' already exists.</strong></pre>
			<p>这是意料之中的，你没做错什么。现在，如果您列出本地跟踪服务器中的所有实验，它应该包括新创建的实验，如下所示:</p>
			<div><div><img src="img/B18120_02_011.jpg" alt="Figure 2.11 – The new MLflow experiments list after creating a new experiment&#13;&#10;" width="976" height="91"/>
				</div>
			</div>
			<p class="figure-caption">图2.11–创建新实验后的新MLflow实验列表</p>
			<ol>
				<li value="2">现在，让我们检查实验和运行之间的关系。如果您仔细查看运行页面的URL(<em class="italic">图2.8 </em>，您将会看到类似于以下内容的内容:</li>
			</ol>
			<p><code>http://127.0.0.1:5000/#/experiments/1/runs/2f2ec6e72a5042f891abe0d3a533eec7</code></p>
			<p>正如您可能已经从<a id="_idIndexMarker103"/>中了解到的，路径<code>experiments</code>之后的整数就是实验ID。然后，在实验ID之后，有一个<code>runs</code>路径，后面跟着一个类似GUID的随机字符串，这就是运行ID。因此，现在我们了解了如何在具有全局唯一ID(称为运行ID)的实验下组织运行。</p>
			<p>知道一个跑步的全局唯一ID是非常有用的。这是因为我们可以使用<code>run_id</code>检索运行记录的数据。如果您使用<code>mlflow runs describe --run-id &lt;run_id&gt;</code>命令行，您可以获得这次运行记录的元数据列表。对于我们刚刚运行的实验，下面显示了带有运行ID的完整命令:</p>
			<pre><strong class="bold">mlflow runs describe –-run-id 2f2ec6e72a5042f891abe0d3a533eec7</strong></pre>
			<p>该命令行的输出片段如下(<em class="italic">图2.12 </em>):</p>
			<div><div><img src="img/B18120_02_012.jpg" alt="Figure 2.12 – The MLflow command line describes the run in the JSON data format&#13;&#10;" width="1397" height="698"/>
				</div>
			</div>
			<p class="figure-caption">图2.12–ml flow命令行描述了JSON数据格式的运行</p>
			<p>注意<em class="italic">图2.12 </em>以JSON格式呈现了<a id="_idIndexMarker104"/>关于这次运行的所有元数据。该元数据包括模型训练所使用的参数；用于测量模型在训练、验证和测试中的准确性的度量标准；还有更多。相同的数据也显示在图2.8 中<em class="italic">的MLflow UI中。请注意，强大的MLflow CLI将允许非常方便地探索MLflow记录的元数据和工件，并支持基于shell脚本的自动化，我们将在接下来的章节中进行探索。</em></p>
			<h2 id="_idParaDest-36"><a id="_idTextAnchor035"/>探索MLflow模型及其用法</h2>
			<p>现在，让我们探索一下<a id="_idIndexMarker105"/> DL模型工件是如何记录在MLflow跟踪服务器中的。在同一个运行页面上，如<em class="italic">图2.8 </em>所示，如果向下滚动到底部，就会看到工件部分(<em class="italic">图2.13 </em>)。这列出了关于模型和序列化模型本身的所有元数据:</p>
			<div><div><img src="img/B18120_02_013.jpg" alt="Figure 2.13 – The model artifacts logged by MLflow&#13;&#10;" width="289" height="293"/>
				</div>
			</div>
			<p class="figure-caption">图2.13–ml flow记录的模型工件</p>
			<p class="callout-heading">MLflow跟踪服务器的后端存储和工件存储</p>
			<p class="callout">MLflow跟踪服务器<a id="_idIndexMarker106"/>有两种类型的存储:第一，后端存储，它存储实验和运行元数据以及运行的参数、度量和标签；第二个是工件存储，它存储更大的文件，比如序列化的模型、文本文件，甚至是为可视化模型结果而生成的图。为了简单起见，在本章中，我们对后端存储和工件存储都使用本地文件系统。然而，一些更高级的特性，比如模型注册，在基于文件系统的工件存储中是不可用的。在后面的章节中，我们将学习如何使用模型注册中心。</p>
			<p>我们来看看<a id="_idIndexMarker107"/>神器列表，一个一个来看:</p>
			<ul>
				<li><code>model_summary.txt</code>:在<code>root</code>文件夹级别，如果你点击它，这个文件看起来类似于下面的输出。它描述了DL模型的模型度量和层次(请参见<em class="italic">图2.14 </em>):</li>
			</ul>
			<div><div><img src="img/B18120_02_014.jpg" alt="Figure 2.14 – The model summary file logged by MLflow&#13;&#10;" width="711" height="565"/>
				</div>
			</div>
			<p class="figure-caption">图2.14–ml flow记录的模型摘要文件</p>
			<p><em class="italic">图2.14 </em>从神经网络层的数量和类型、参数的数量和大小以及训练和验证中使用的指标类型等方面快速概述了DL模型。当DL模型架构需要在团队成员或涉众之间共享和交流时，这是非常有用的。</p>
			<ul>
				<li><code>model</code>文件夹:该文件夹包含一个名为<code>data</code>的子文件夹，以及三个名为<code>MLmodel</code>、<code>conda.yaml</code>和<code>requirements.txt</code>的文件:<ul><li><code>MLmodel</code>:这个文件描述了MLflow支持的模型的风格。<code>MLmodel</code>文件(<em class="italic">图2.15 </em>):</li></ul></li>
			</ul>
			<div><div><img src="img/B18120_02_015.jpg" alt="Figure 2.15 – Content of the MLmodel file for our first DL model run with MLflow&#13;&#10;" width="825" height="508"/>
				</div>
			</div>
			<p class="figure-caption">图2.15–我们使用MLflow运行的第一个DL模型的MLmodel文件的内容</p>
			<p><em class="italic">图2.15 </em>说明这是我们刚刚运行的带有<code>run_id</code>的PyTorch风味模型。</p>
			<ul>
				<li><code>conda.yaml</code>:这是一个<a id="_idIndexMarker108"/> conda环境定义文件，模型使用它来描述我们的依赖关系。<em class="italic">图2.16 </em>列出了我们刚刚完成的运行中MLflow记录的内容:</li>
			</ul>
			<div><div><img src="img/B18120_02_016.jpg" alt="Figure 2.16 – The content of the conda.yaml file logged by MLflow &#13;&#10;" width="248" height="472"/>
				</div>
			</div>
			<p class="figure-caption">图2.16–ml flow记录的conda.yaml文件的内容</p>
			<ul>
				<li><code>requirements.txt</code>:这是一个<a id="_idIndexMarker109"/> Python <code>pip</code>特有的依赖定义文件。就像<code>conda.yaml</code>文件中的<code>pip</code>部分，如图<em class="italic">图2.16 </em>所示。</li>
				<li><code>data</code>:这是一个包含实际序列化模型的文件夹，名为<code>model.pth</code>，以及一个描述文件，名为<code>pickle_module_info.txt</code>，其内容如下:<pre>mlflow.pytorch.pickle_module</pre></li>
			</ul>
			<p>这意味着使用MLflow提供的PyTorch兼容pickle序列化方法来序列化模型。这允许MLflow在以后需要时将模型加载回内存。</p>
			<p class="callout-heading">模型注册与模型日志记录</p>
			<p class="callout">MLflow <a id="_idIndexMarker110"/>模型注册中心需要一个像MySQL这样的关系数据库作为工件存储，而不仅仅是一个普通的文件系统。因此，在这一章中，我们暂不探讨。请注意，模型注册与模型日志记录的不同之处在于，对于每次运行，您都希望记录模型元数据和工件。但是，只有对于满足您的生产需求的某些运行，您可能希望将它们注册到模型注册中心，以便进行生产部署和版本控制。在后面的章节中，我们将学习如何注册模型。</p>
			<p>到目前为止，您应该<a id="_idIndexMarker111"/>对MLflow工件存储中记录的关于模型和序列化模型的文件和元数据列表(以及我们实验中的<code>.pth</code>文件扩展名，它指的是PyTorch序列化模型)有了很好的理解。在接下来的章节中，我们将学习更多关于MLflow模型风格如何工作，以及如何使用日志模型进行模型注册和部署。MLflow模型风格是由MLflow支持的模型框架，如PyTorch、TensorFlow和scikit-learn。感兴趣的读者可以从官方MLflow文档网站https://www . MLflow . org/docs/latest/models . html # built-in-model-flavors找到更多关于ml flow支持的当前内置模型风格<a id="_idIndexMarker112"/>的详细信息。</p>
			<h2 id="_idParaDest-37"><a id="_idTextAnchor036"/>探索MLflow代码跟踪及其用法</h2>
			<p>当探索运行的<a id="_idIndexMarker113"/>元数据时，我们还可以发现代码是如何被跟踪的。如MLflow UI和JSON中的命令行输出所示，代码以三种方式被跟踪:文件名、Git提交散列和源类型。您可以执行以下命令行:</p>
			<pre>mlflow runs describe --run-id 2f2ec6e72a5042f891abe0d3a533eec7 | grep mlflow.source</pre>
			<p>您应该能够在输出中找到JSON键-值对的以下部分:</p>
			<pre>"mlflow.source.git.commit": "ad6c7338a416ff4c2848d726b092057457c22408",
"mlflow.source.name": "first_dl_with_mlflow.py",
"mlflow.source.type": "LOCAL"</pre>
			<p>基于这个<code>ad6c7338a416ff4c2848d726b092057457c22408</code> Git提交散列，我们可以继续寻找我们使用的Python代码的精确副本:<a href="https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLflow/blob/ad6c7338a416ff4c2848d726b092057457c22408/chapter02/first_dl_with_mlflow.py">https://github . com/packt publishing/Practical-Deep-Learning-at-Scale-with-ml flow/blob/ad6 c 7338 a 416 ff 4c 2848d 726 b 092057457 c 22408/chapter 02/first _ dl _ with _ ml flow . py</a>。</p>
			<p>注意，这里的源类型是<code>LOCAL</code>。这意味着我们从代码的本地副本执行支持MLflow的源代码<a id="_idIndexMarker115"/>。在后面的章节中，我们将学习<a id="_idIndexMarker116"/>关于其他来源类型。</p>
			<p class="callout-heading">本地与远程GitHub代码</p>
			<p class="callout">如果源代码是代码的本地副本，那么在MLflow跟踪服务器上会有一个关于Git提交散列的警告。如果您在本地进行了代码更改，但忘记提交它们，然后立即开始MLflow实验跟踪运行，MLflow将只记录最新的Git提交哈希。我们可以用两种方法之一来解决这个问题:</p>
			<p class="callout">1.在运行MLflow实验之前提交我们的代码更改。</p>
			<p class="callout">2.使用远程GitHub代码运行实验。</p>
			<p class="callout">因为第一种方法不容易实施，所以第二种方法是优选的。使用远程GitHub代码运行DL实验是一个高级主题，我们将在后面的章节中探讨。</p>
			<p>到目前为止，我们已经<a id="_idIndexMarker119"/>了解了MLflow跟踪服务器、实验和运行。此外，我们还记录了关于运行的元数据，如参数和度量，检查了代码跟踪，并探索了模型日志记录。这些跟踪和记录<a id="_idIndexMarker120"/>功能确保我们有一个可靠的ML实验管理系统，不仅用于模型开发，还用于未来的模型部署，因为我们需要跟踪哪些运行产生了用于生产的模型。<em class="italic">再现性</em>和<em class="italic">来源追踪</em>是MLflow所提供的标志。除此之外，MLflow还提供了其他组件<a id="_idIndexMarker121"/>，例如用于标准化ML项目代码组织的<strong class="bold"> MLproject </strong>，用于模型版本控制的模型注册中心，模型部署功能，以及模型可解释性工具。所有这些MLflow组件涵盖了ML/DL开发、部署和生产的整个生命周期，我们将在以后的章节中对其进行更深入的研究。</p>
			<h1 id="_idParaDest-38"><a id="_idTextAnchor037"/>摘要</h1>
			<p>在本章中，我们学习了如何设置MLflow以与本地MLflow跟踪服务器或远程MLflow跟踪服务器配合使用。然后，我们实现了第一个启用了MLflow自动日志记录的DL模型。这使我们能够以实践的方式探索MLflow，了解一些中心概念和基础组件，如实验、运行、关于实验和运行的元数据、代码跟踪、模型日志记录和模型风格。本章获得的知识和第一轮经验将帮助我们在下一章学习更深入的MLflow跟踪API。</p>
			<h1 id="_idParaDest-39"><a id="_idTextAnchor038"/>延伸阅读</h1>
			<p>为了加深您的知识，您可以参考以下资源和文档:</p>
			<ul>
				<li>MLflow <em class="italic">命令行界面</em>文档:<a href="https://www.mlflow.org/docs/latest/cli.html">https://www.mlflow.org/docs/latest/cli.html</a></li>
				<li>MLflow PyTorch自动记录文档:<a href="https://www.mlflow.org/docs/latest/tracking.html#pytorch-experimental">https://www . ml flow . org/docs/latest/tracking . html # py torch-experimental</a></li>
				<li>MLflow PyTorch模型风味文档:<a href="https://www.mlflow.org/docs/latest/python_api/mlflow.pytorch.html#module-mlflow.pytorch">https://www . ml flow . org/docs/latest/python _ API/ml flow . py torch . html # module-ml flow . py torch</a></li>
				<li><em class="italic"> MLflow和py torch——前沿AI与MLOps相遇的地方</em>:<a href="https://medium.com/pytorch/mlflow-and-pytorch-where-cutting-edge-ai-meets-mlops-1985cf8aa789">https://medium . com/py torch/ml flow-and-py torch-Where-Edge-AI-meets-MLOps-1985 cf 8 aa 789</a></li>
				<li><em class="italic">机器学习中的受控实验</em>:<a href="https://machinelearningmastery.com/controlled-experiments-in-machine-learning/">https://Machine Learning mastery . com/Controlled-Experiments-in-Machine-Learning/</a></li>
			</ul>
		</div>
	</div>
</body></html>