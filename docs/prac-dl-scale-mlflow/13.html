<html><head/><body>




<style type="text/css">body{margin:1em;background-color:transparent!important;}#sbo-rt-content *{text-indent:0pt!important;}#sbo-rt-content .bq{margin-right:1em!important;}#sbo-rt-content *{word-wrap:break-word!important;word-break:break-word!important;}#sbo-rt-content table,#sbo-rt-content pre{overflow-x:unset!important;overflow:unset!important;overflow-y:unset!important;white-space:pre-wrap!important;}</style>
<div><div><h1 id="_idParaDest-112"><a id="_idTextAnchor111"/>第5节–深度学习模型的规模化解释能力</h1>
			<p>在本节中，我们将了解可解释性和<strong class="bold">可解释人工智能</strong> ( <strong class="bold"> XAI </strong>)的基本概念，以及如何用MLflow实现<strong class="bold">深度学习</strong> ( <strong class="bold"> DL </strong>)可解释性。我们将从可解释性的八个维度的概述开始，然后学习如何使用<strong class="bold"> SHapley附加解释</strong> ( <strong class="bold"> SHAP </strong>)和<strong class="bold">变形金刚解释</strong>来为一个<strong class="bold">自然语言处理</strong> ( <strong class="bold"> NLP </strong>)流水线执行可解释性。此外，我们将学习和分析当前与SHAP的MLflow集成，以了解利弊并避免潜在的实施问题。然后，我们将展示如何使用MLflow的日志API实现SHAP。最后，我们将学习如何将SHAP解释器实现为一个MLflow Python模型，然后将其作为批量解释的Spark UDF或在线解释即服务的web服务进行加载。</p>
			<p>本节包括以下章节:</p>
			<ul>
				<li><a href="B18120_09_ePub.xhtml#_idTextAnchor112"> <em class="italic">第九章</em> </a>、<em class="italic">深度学习的基础知识讲解</em></li>
				<li><a href="B18120_10_ePub.xhtml#_idTextAnchor127"> <em class="italic">第十章</em> </a>，<em class="italic">用MLflow实现DL可解释性</em></li>
			</ul>
		</div>
	</div>
</body></html>