<html><head/><body><html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Indoor Localization in IoT</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">物联网室内定位</h1>

                

            

            

                

<p>许多物联网应用，如零售商、智能家居、智能校园和医院的室内导航和位置感知营销，都依赖于室内定位。此类应用生成的输入数据通常来自多种来源，如红外线、超声波、Wi-Fi、RFID、超宽带、蓝牙等。</p>

<p>这些设备和技术的通信指纹(如Wi-Fi指纹数据)可以使用DL模型进行分析，以预测设备或用户在室内环境中的位置。在这一章中，我们将通过一个实际操作的例子来讨论如何在物联网应用中将DL技术用于室内定位。此外，我们将讨论物联网环境中室内定位服务的一些部署设置。本章将简要介绍以下主题:</p>

<ul>

<li>在物联网应用中引入室内定位</li>

<li><strong>深度学习</strong> ( <strong> DL </strong>)用于物联网应用中的室内定位</li>

<li>示例–Wi-Fi指纹识别中的室内定位</li>

<li>基于DL的室内定位的不同部署选项</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>An overview of indoor localization</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">室内本地化概述</h1>

                

            

            

                

<p>随着移动互联网的快速发展，<strong>基于位置的</strong> <strong> S </strong> <strong>服务</strong> ( <strong> LBS </strong>)在大型公共室内场所越来越受欢迎。在这样的室内位置，<strong>接收信号强度指标</strong> ( <strong> RSSI </strong>)通常被用作物联网设备从<strong>无线接入点</strong>(<strong>WAP</strong>)接收的功率水平的估计值。然而，当与信号源的距离增加时，信号变弱，无线数据速率变慢，导致整体数据吞吐量降低。<br/></p>

<p class="mce-root"/>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Techniques for indoor localization</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">室内定位技术</h1>

                

            

            

                

<p>迄今为止，基于诸如超声波、红外线、图像、光、磁场和无线信号的测量技术，已经提出了几种室内定位技术。例如，<strong>基于蓝牙低能耗</strong> ( <strong> BLE </strong>)的室内定位已经吸引了越来越多的兴趣，因为它是低成本、低功耗的，并且在几乎每个移动设备上都无处不在。另一方面，Wi-Fi定位系统基于Wi-Fi信号的<strong>信道状态信息</strong> ( <strong> CSI </strong>)。</p>

<p>最近，已经提出了DL方法，其中DL模型用于学习高维CSI信号的指纹模式。尽管每次Wi-Fi扫描都包含其附近可用AP的信号强度测量值，但只能观察到环境中网络总数的一个子集。</p>

<p>此外，由于这些设备是具有非常小的处理能力的低端设备，在这些方法中使用的不可预测的减弱或增强组合会影响多径信号，这将破坏RSSI和传输距离之间的关系，并因此被证明效率较低。另一方面，指纹方法不依赖于距离的恢复，而是仅使用测量的RSSIs作为空间模式。因此它不易受到多径效应的影响。<br/></p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Fingerprinting</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">指纹识别</h1>

                

            

            

                

<p>通常使用的指纹识别方法有两个阶段:离线阶段和在线阶段。</p>

<p>一个阶段使用指纹数据库来构建位置相关参数，这些参数是从测量的RSSIs的参考位置提取的，称为<strong>离线阶段</strong>。在定位阶段，也称为<strong>在线阶段</strong>，使用数据库中最相关的RSSI指纹将RSSI测量值映射到参考位置，解释如下:</p>

<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="img/b86e0d50-48d9-41ad-bcad-3f123875d7ae.png" style="width:16.58em;height:1.25em;"/></p>

<p class="mce-root">在上式中，<img class="fm-editor-equation" src="img/bab27896-3a38-49f3-8ec0-1677e6fc1bb6.png" style="width:0.83em;height:0.83em;"/>是数据库中参考位置的总数，<img class="fm-editor-equation" src="img/242d15f7-deb3-407d-b33c-ca60da767fea.png" style="width:0.92em;height:1.17em;"/>表示<img class="fm-editor-equation" src="img/b68d16c9-827a-41a5-a8cf-380580a3429b.png" style="width:1.17em;height:1.08em;"/>参考位置的指纹图案，<img class="fm-editor-equation" src="img/449d1379-8d2b-43d3-aab5-ecca314065e9.png" style="width:1.25em;height:1.08em;"/>是该参考位置的空间坐标。指纹模式<img class="fm-editor-equation" src="img/ab5fac86-a4b7-43f4-92b9-8b545d15ff87.png" style="width:0.42em;height:0.83em;"/>可以是来自多个信标站的原始RSSI值，或者是从RSSI中提取的任何其他特征向量，可以表示如下:<br/></p>

<p><img class="fm-editor-equation" src="img/d6372765-89d2-45b0-8de8-c747c53e1a14.png" style="width:9.42em;height:1.42em;"/></p>

<p class="CDPAlignCenter CDPAlign">然而，在现有的指纹识别系统中，原始RSSI值被用作空间模式。在上式中，<em> m </em>是BLE信标站或Wi-Fi接入点的总数，<img class="fm-editor-equation" src="img/44ce7c44-7826-44b9-85f5-cf7b91f88441.png" style="width:1.08em;height:1.08em;"/>代表<img class="fm-editor-equation" src="img/01e38a2a-24f4-455d-9388-1dc08b082661.png" style="width:1.50em;height:1.50em;"/>站的实测RSSI值。<br/></p>

<p>现在，我们大致知道什么是室内定位了。在下一节中，我们将看到如何使用机器学习和DL算法来开发这样一个室内定位系统。</p>

<p>基于DL的物联网室内定位</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>DL-based indoor localization for IoT</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">现在，如果我们想开发一个DL应用程序并部署低端设备，这样的物联网设备将无法处理它们。特别是，处理非常高维的数据将是一个瓶颈。因此，可以使用机器学习算法(如<strong>k-最近邻</strong> ( <strong> k-NNs </strong>)以合理的精度解决室外定位问题，因为在移动设备中包含GPS传感器意味着我们现在手头有更多的数据。</h1>

                

            

            

                

<p>然而，室内定位仍然是一个开放的研究问题，主要是由于室内环境中GPS信号的丢失，尽管有先进的室内定位技术。幸运的是，通过使用DL技术，我们可以以合理的精度解决这个问题，特别是因为使用<strong>自动编码器</strong> ( <strong> AEs </strong>)和它们的表示能力可以是一个非常好的变通方法和可行的选择。在这种情况下，我们有两种选择:</p>

<p>在AE网络前面添加一个全连接层和一个softmax层，它将充当端到端的分类器。</p>

<ol>

<li>使用任何其他分类算法，如逻辑回归、k-NN、随机森林或支持向量机进行位置估计(即分类)，如下图所示:</li>

</ol>

<ol start="2">

<li><img src="img/0c323e9d-9947-4845-b736-6e662bc90b1f.png" style="width:66.83em;height:40.50em;"/></li>

</ol>

<p class="CDPAlignCenter CDPAlign">想法是使用AEs进行表示学习，以便网络可以很好地学习特征。然后，编码器部分的输出可以用于初始化分类器部分的权重。在下一节中，我们将讨论k-NN和AEs，并了解它们如何用于解决室内定位问题。</p>

<p>k-最近邻分类器</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>K-nearest neighbor (k-NN) classifier</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">k-NN算法是一种非参数方法，可以使用来自物联网设备的指纹数据进行训练。这将尝试将从网关收集的RSSI值分类到其中一个参考点，而不是坐标。输入由k个最接近的RSSI值组成，输出为类成员。然后，输入样本通过其邻居的多次投票进行分类，将该对象分配到其k个最近邻居中最常见的类别。</h1>

                

            

            

                

<p>从技术上讲，如果指纹数据库由(<em> X，y </em>)组成，其中<em> X </em>是RSSI值，<em> y </em>是已知位置的集合，那么k-NN首先计算距离<img class="fm-editor-equation" src="img/b6016adb-5765-47b1-8f24-9983adfe5dfb.png" style="width:6.25em;height:1.33em;"/>，其中<em> x </em>是未知样本。然后，它计算一个集合<img class="fm-editor-equation" src="img/90cfbfa6-1377-48ef-af6e-d3b0bad19a33.png" style="width:0.50em;height:0.75em;"/>，该集合包含从<img class="fm-editor-equation" src="img/d6f38274-2e83-4fe5-8ee9-d2f0c4d3b6e7.png" style="width:0.67em;height:0.83em;"/>到<em> k </em>最小距离的索引。然后，返回<img class="fm-editor-equation" src="img/18562ef7-7264-488e-b212-421a0c37a3e7.png" style="width:1.00em;height:1.00em;"/>的多数标签，其中<img class="fm-editor-equation" src="img/d3ee66fb-7bd8-4e35-b3f9-2e7feaf938a4.png" style="width:2.25em;height:0.92em;"/>。换句话说，使用k-NN，通过计算观测数据和数据库中训练RSSI样本的记录之间的相似性来执行分类。最终，在第一个<em> k个</em>最相似记录中出现次数最多的格网单元就是估计位置，如下图所示:</p>

<p>使用k-NN算法定位物联网设备<br/></p>

<div><img src="img/e7c21824-f316-41f0-99ef-9b1ceca414e5.png" style="width:28.83em;height:28.00em;"/></div>

<p>在上图中，对于k=4，Wi-Fi数据包跟踪被分类为在网格c(绿色三角形)记录中，而当<em> k=6 </em>时，它被分类为在网格a(红色矩形)中。因此，k-NN可以被认为是一种懒惰的学习方法，在这种方法中，函数只是局部近似，所有计算都推迟到分类发生时进行。k-NN算法的好处是它对噪声数据具有鲁棒性。特别地，加权距离的平方反比被用作距离度量。然而，如果它已经在大量的训练数据上训练过，它会表现得很好。</p>

<p>也可能有缺点。比如我们需要确定<em> K </em>参数值，也就是最近邻的个数。基于所使用的距离度量，它的表现非常不同。使用k-NN算法的计算成本相当高，因为需要计算训练数据中每个样本的距离。这在非常高维的数据的情况下变得更加糟糕。在下一节中，我们将使用k-NN作为端到端分类器，而不是使用神经网络设置来提供基于AE的分类器和k-NN分类器之间的比较分析。</p>

<p>声发射分类器</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>AE classifier</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">正如在<a href="7626c72a-c3b8-4707-96a5-88d524d9f3f7.xhtml">第2章</a>、<em>物联网深度学习架构</em>中所述，AEs是一种特殊类型的神经网络，可以从输入数据中自动学习。AEs由两部分组成:编码器和解码器。编码器将输入压缩成潜在空间表示。然后，解码器部分尝试从该表示中重建原始输入数据:</h1>

                

            

            

                

<p><strong>编码器</strong>:使用被称为<img class="fm-editor-equation" src="img/b5bf675d-1f97-4cdd-a9c5-c5de096126fd.png" style="width:3.50em;height:1.17em;"/>的函数将输入编码或压缩成潜在空间表示</p>

<ul>

<li><strong>解码器</strong>:使用被称为<img class="fm-editor-equation" src="img/643771fa-fed6-457b-b4c6-beb20bfbcf5d.png" style="width:3.58em;height:1.17em;"/>的函数从潜在空间表示中解码或重建输入</li>

<li>因此，AE可以用<img class="fm-editor-equation" src="img/5455f554-5bcc-42bd-8b3b-ec1070db6e05.png" style="width:5.17em;height:1.25em;"/>的函数来描述，其中我们希望<em> 0 </em>尽可能接近于<em> x </em>的原始输入。AEs对于数据去噪和数据可视化的降维非常有用。AEs可以比PCA更有效地学习数据投影，称为<strong>表示</strong>。下图显示了去噪AE的架构:<br/></li>

</ul>

<p><img src="img/f40044e9-4968-443e-8ca5-1771240ccac6.png" style="width:37.58em;height:31.50em;"/></p>

<p class="CDPAlignCenter CDPAlign">因此，一旦我们手头有了指纹数据库，就可以用原始RSSI测量值来训练AEs，并且训练好的网络本身被用作特定参考位置的指纹模式。由于深度网络可以用每一层的权重来表示，因此指纹图案可以表示如下:<br/></p>

<p><img class="fm-editor-equation" src="img/468c9efa-9469-4607-a4a8-2b8f4f4defe4.png" style="width:19.17em;height:1.75em;"/></p>

<p class="CDPAlignCenter CDPAlign">上式中，<em> l </em>为一个AE的编码隐层个数，<img class="fm-editor-equation" src="img/5a91f9bf-9c2b-44bb-857a-a1e0f676c199.png" style="width:1.33em;height:0.92em;"/>和<img class="fm-editor-equation" src="img/35489ecc-25a5-4e0a-b4ae-4378f7665645.png" style="width:1.17em;height:0.92em;"/>分别代表<img class="fm-editor-equation" src="img/ef1ef057-8bed-40e9-87b9-8de470f3daae.png" style="width:1.33em;height:1.17em;"/>编码隐层及其解码镜像层的权重，如下图:<br/></p>

<p><img src="img/8b2950f2-58fb-4dff-ad2f-7fa884d78a3a.png" style="width:35.83em;height:24.42em;"/></p>

<p class="CDPAlignCenter CDPAlign">然后，我们可以使用AE的中心隐藏层的输出作为完全连接的softmax层的输入来预测位置，如上图所示。既然我们知道了室内定位在神经网络或机器学习环境中是如何工作的，我们现在可以开始使用Wi-Fi指纹识别的动手示例。<br/></p>

<p>示例–通过Wi-Fi指纹识别进行室内定位</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Example – Indoor localization with Wi-Fi fingerprinting</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">在本例中，我们将使用一个<strong>多建筑、多层室内定位</strong>数据库和堆叠AEs来定位Wi-Fi指纹识别。只需很少的努力，这个应用程序就可以部署到移动机器人上，使用Wi-Fi定位子系统。</h1>

                

            

            

                

<p>描述数据集</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Describing the dataset</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title"><kbd>UJIIndoorLoc</kbd>数据集是一个多建筑、多层室内定位数据库，旨在测试依赖Wi-Fi指纹识别的室内定位系统。自动用户定位包括估计用户的位置，例如从移动电话收集的纬度、经度和高度。<kbd>UJIIndoorLoc</kbd>数据库涵盖了2013年通过20多名不同用户和25台Android设备测量的3栋4层或更多层、近110，000平方米的大学建筑。数据库由两个CSV文件组成:</h1>

                

            

            

                

<p><kbd>trainingData.csv</kbd>:19937条培训/参考记录</p>

<ul>

<li><kbd>validationData.csv</kbd>:1111条验证/测试记录</li>

<li>529个属性包含Wi-Fi指纹和它们被拍摄的坐标。每个Wi-Fi指纹可以由检测到的WAP和相应的RSSI来表征。强度值表示为从1，04 dBm(极弱信号)到0 dBm的负整数值。正值100用于表示未检测到WAP。在数据库创建期间，检测到520个不同的WAP。因此，Wi-Fi指纹由520个强度值组成。坐标的纬度、经度、楼层和<strong>建筑物ID </strong>信息是要预测的属性。以下列表给出了数据集的快速摘要:</li>

</ul>

<p><strong>属性001到520(即WAP001到WAP520) </strong>:这些是接入点的强度测量值，其值在-104到0和+100之间。值100表示没有检测到WAP001。</p>

<ul>

<li>属性521(经度):从7，695.9，387，549，299，299，000到-7之间的负实数值。56866.88668686667</li>

<li><strong>属性522(纬度)</strong>:4，864，745.7，450，159，714到4，865，017.3，646，842，018的正实值。</li>

<li><strong>属性523(楼层)</strong>:建筑内楼层高度。从0到4的整数值。</li>

<li><strong>属性524 (BuildingID) </strong>:标识建筑物的ID，作为从0到2的分类整数值提供。</li>

<li><strong>属性525 (SpaceID) </strong>:标识空间的内部ID号，如办公室、走廊或教室。</li>

<li><strong>属性526 (RelativePosition) </strong>:相对于空间的相对位置(1—内部，2—外部，门前)。</li>

<li><strong>属性527 (UserID) </strong>:用户标识符。</li>

<li><strong>属性528 (PhoneID) </strong>:安卓设备标识符(见下文)。</li>

<li><strong>属性529(时间戳)</strong>:进行捕获的UNIX时间。</li>

<li>网络建设</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Network construction</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">我们将使用的AE分类器将有一个由编码器和解码器组成的AE部分。以下AE架构用于确定Wi-Fi所在的楼层和建筑位置。AE的输入是在扫描中检测到的信号强度。然后，每个可见网络的一个值被视为一个RSSI记录。解码器的输出是从简化的表示中重建的输入，如下图所示(来源:<em>使用深度学习的Wi-Fi指纹的低努力地点识别</em>，Michał .等人，arXiv:1611.02049v1):</h1>

                

            

            

                

<p><img src="img/104e89b7-6a30-4173-bc33-ed0cbacab1e5.png" style="width:37.92em;height:21.50em;"/></p>

<p class="mce-root CDPAlignCenter CDPAlign">用于特征空间表示的AE架构</p>

<p>分类器部分由两个隐含层组成；根据问题的复杂程度，需要选择神经元的数量。当AE的权重的无监督学习完成时，网络的解码器部分被断开。然后，通过将整个网络变成分类器，全连接的层通常被放置在编码器的输出之后。在下图中，预训练的编码器部分连接到完全连接的softmax层(来源:<em>使用深度学习的Wi-Fi指纹的低努力地点识别</em>，Michał .等人，arXiv:1611.02049v1):</p>

<p>基于Wi-Fi扫描输入对建筑物及其楼层进行分类的AE分类器的架构</p>

<div><img src="img/7efbdf3f-e1a6-4412-9f42-0003d051578a.png" style="width:40.17em;height:23.50em;"/></div>

<p>最终输出图层是softmax图层，它输出当前样本属于所分析类别的概率。现在，没有任何进一步的延迟，让我们开始实现前面的网络。</p>

<p class="CDPAlignLeft CDPAlign">履行</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Implementation</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">我们将使用Keras来总结这个概念化。首先，让我们导入必要的包和库，如下所示:</h1>

                

            

            

                

<p>一旦我们导入了所有必需的包，我们就可以开始准备训练集和测试集，它们可以分别用于训练和评估模型。</p>

<pre><strong>import</strong> pandas as pd<br/><strong>import</strong> numpy as np<br/><strong>import</strong> tensorflow as tf<br/><strong>from</strong> sklearn.preprocessing <strong>import</strong> scale<br/><strong>from</strong> keras.models <strong>import</strong> Sequential<br/><strong>from</strong> keras.layers <strong>import</strong> Input, Dense, Flatten, Dropout, Embedding, BatchNormalization<br/><strong>from</strong> keras.layers.convolutional <strong>import</strong> Conv1D,MaxPooling1D<br/><strong>from</strong> keras.layers <strong>import</strong> LSTM<br/><strong>from</strong> keras.layers.merge <strong>import</strong> concatenate<br/><strong>from</strong> keras.layers <strong>import</strong> GaussianNoise<br/><strong>from</strong> pickle <strong>import</strong> load<br/><strong>from</strong> keras <strong>import</strong> optimizers<br/><strong>from</strong> sklearn.metrics <strong>import</strong> classification_report<br/><strong>from</strong> sklearn.metrics <strong>import</strong> confusion_matrix<br/><strong>from</strong> sklearn.metrics <strong>import</strong> precision_recall_curve<br/><strong>from</strong> sklearn.metrics <strong>import</strong> precision_recall_fscore_support<br/><strong>import</strong> pandas_profiling</pre>

<p>探索性分析</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Exploratory analysis</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">毫无疑问，使用<strong> Python pandas </strong>库对数据进行探索性分析提供了许多强大的特性。然而，使用<kbd>df.describe()</kbd>、<kbd>df.dtypes</kbd>，或者使用<kbd>df.isnull().sum()</kbd>并分别绘制它们总是很耗时。有时候，你甚至无法通过复杂的方式获得所需的信息。事实上，您将不得不编写额外的代码行来将它们转换成可展示的格式。然而，为了让你的生活更容易，你现在可以开始使用<kbd>pandas_profiling</kbd>库(见<a href="https://github.com/pandas-profiling/pandas-profiling">https://github.com/pandas-profiling/pandas-profiling</a>)。一行代码就能提供您需要的信息:</h1>

                

            

            

                

<p>当然，使用<kbd>pandas_profiling</kbd>来快速了解你的数据是值得的。我们来试试吧！首先，我们通过显式传递<kbd>header=0</kbd>来读取训练数据，以便能够替换现有的名称:</p>

<pre>pandas_profiling.ProfileReport(df)</pre>

<p>要检索由于高度相关而被拒绝的变量列表，可以使用以下命令:</p>

<pre>trainDF = pd.read_csv("trainingData.csv",header = 0)</pre>

<p>这将生成显示数据集信息的报告:</p>

<div><pre>profile = pandas_profiling.ProfileReport(trainDF) </pre>

<p><img src="img/f81ce1d6-dc12-4b22-a14c-4b38ff6d3eff.png" style="width:34.75em;height:32.58em;"/></p>

<p class="CDPAlignCenter CDPAlign">让我们看看报告的前几行。正如我们所看到的，我们没有任何空值，所有的变量都是数字，这很好。然而，一些特征不太重要，与其他变量高度相关(例如，74个变量被拒绝)，并且一些变量非常偏斜，给出非常宽的分布。甚至我们的训练数据集也有637个重复行。被拒绝的变量不会帮助模型很好地学习。因此，这些可以从训练数据中删除(尽管这是可选的)。可使用<kbd>get_rejected_variables</kbd>方法收集此类被拒绝变量的列表，如下所示:</p>

<p>如果您想生成一个HTML报告文件，将配置文件保存到一个对象并使用<kbd>to_file</kbd>功能，如下所示:</p>

<pre>rejected_variables = profile.get_rejected_variables(threshold=0.9)</pre></div>

<p>这将生成一个包含必要信息的<kbd>HTML</kbd>报告。现在我们知道了数据和变量，让我们把注意力集中在特性工程步骤上，通过这些步骤，我们将准备训练和测试所需的数据。</p>

<div><pre>profile.to_file(outputfile="Report.html")</pre>

<p>准备训练集和测试集</p>

</div>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Preparing training and test sets</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">首先，我们将数据缩放到平均值的中心。然后，我们对单位方差执行组件式缩放。这将有助于我们的模型更快地融合培训:</h1>

                

            

            

                

<p>然后，我们构建真正的标签。我们将所有建筑id和建筑楼层转换为字符串:</p>

<pre>featureDF = np.asarray(trainDF.iloc[:,0:520]) # First 520 features <br/>featureDF[featureDF == 100] = -110<br/>featureDF = (featureDF - featureDF.mean()) / featureDF.var()</pre>

<p>然后，我们试着创建两个变量:<kbd>train_x</kbd>和<kbd>train_y</kbd>。这将有助于避免培训评估过程中的混乱:</p>

<pre>labelDF = np.asarray(trainDF["BUILDINGID"].map(str) + trainDF["FLOOR"].map(str)) <br/>labelDF = np.asarray(pd.get_dummies(labelDF))</pre>

<p>现在，与训练集类似，我们也准备测试集:</p>

<pre>train_x = featureDF<br/>train_y = labelDF<br/>print(train_x.shape)<br/>print(train_x.shape[1])</pre>

<p>一旦我们准备好了培训和测试集，我们现在就可以继续创建AE了。</p>

<pre>testDF = pd.read_csv("validationData.csv",header = 0)<br/>test_featureDF = np.asarray(testDF.iloc[:,0:520])<br/>test_featureDF[test_featureDF == 100] = -110<br/>test_x = (test_featureDF - test_featureDF.mean()) / test_featureDF.var()<br/>test_labelDF = np.asarray(testDF["BUILDINGID"].map(str) + testDF["FLOOR"].map(str))<br/>test_y = np.asarray(pd.get_dummies(test_labelDF))<br/>print(test_x.shape)<br/>print(test_y.shape[1])</pre>

<p>Once we have the training and the test sets ready, we can now proceed with creating an AE.</p>

<p class="mce-root">创建AE</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Creating an AE</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">让我们创建单独的编码器和解码器函数，因为稍后您将使用编码器权重进行分类。首先，我们定义一些参数，比如时期数和批量大小。此外，我们计算输入数据的形状以及构建和训练AE所需的类的数量:</h1>

                

            

            

                

<p>然后，我们创建AE的编码器部分，它有三个隐藏层:</p>

<pre>number_epochs = 100<br/>batch_size = 32<br/>input_size = train_x.shape[1] # 520<br/>num_classes = train_y.shape[1] # 13</pre>

<p>接下来，我们创建AE的解码器部分，它有三个隐藏层，后面是<kbd>compile()</kbd>方法:</p>

<pre><strong>def</strong> encoder():<br/>    model = Sequential()<br/>    model.add(Dense(256, input_dim=input_size, activation='relu', use_bias=True))<br/>    model.add(Dense(128, activation='relu', use_bias=True))<br/>    model.add(Dense(64, activation='relu', use_bias=True))    <br/>    return model</pre>

<p>然后，我们将它们堆叠在一起，构建一个AE:</p>

<pre><strong>def</strong> decoder(encoder):   <br/>    encoder.add(Dense(128, input_dim=64, activation='relu', use_bias=True))<br/>    encoder.add(Dense(256, activation='relu', use_bias=True))<br/>    encoder.add(Dense(input_size, activation='relu', use_bias=True))<br/>    encoder.compile(optimizer='adam', loss='mse')<br/>    <strong>return</strong> encoder </pre>

<p>让我们看看AE的结构和摘要:</p>

<pre>encoderModel = encoder() # Encoder<br/>auto_encoder = decoder(encoderModel) # The autoencoder <br/>auto_encoder.summary()</pre>

<p><img src="img/d99b49b5-34e4-402d-8d44-9f1def2179d7.png" style="width:34.75em;height:21.25em;"/></p>

<p class="CDPAlignCenter CDPAlign">然后，我们可以用100次迭代的训练数据来训练AE，其中10%的训练数据将用于验证:</p>

<p>由于我们在前面的代码块中设置了<kbd>verbose =1</kbd>，在训练期间，您将会看到以下日志:</p>

<pre>auto_encoder.fit(train_x, train_x, epochs = 100, batch_size = batch_size, <br/>                 validation_split=0.1, verbose = 1)</pre>

<p class="mce-root">然后，我们将训练集和测试集的编码器网络的输出作为潜在特征:</p>

<pre>Train on 17943 samples, validate on 1994 samples

Epoch 1/100

17943/17943 [==============================] - 5s 269us/step - loss: 0.0109 - val_loss: 0.0071

Epoch 2/100

17943/17943 [==============================] - 4s 204us/step - loss: 0.0085 - val_loss: 0.0066

Epoch 3/100

17943/17943 [==============================] - 3s 185us/step - loss: 0.0081 - val_loss: 0.0062

Epoch 4/100

17943/17943 [==============================] - 4s 200us/step - loss: 0.0077 - val_loss: 0.0062<br/>Epoch 98/100

17943/17943 [==============================] - 6s 360us/step - loss: 0.0067 - val_loss: 0.0055<br/>.......

Epoch 99/100

17943/17943 [==============================] - 5s 271us/step - loss: 0.0067 - val_loss: 0.0055

Epoch 100/100

17943/17943 [==============================] - 7s 375us/step - loss: 0.0067 - val_loss: 0.0055</pre>

<p>创建声发射分类器</p>

<pre>X_train_re = encoderModel.predict(train_x)<br/>X_test_re = encoderModel.predict(test_x)</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Creating an AE classifier</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">接下来，我们将重新训练<kbd>auto_encoder</kbd>模型，使前三层可训练为<kbd>True</kbd>，而不是保持为<kbd>False</kbd>:</h1>

                

            

            

                

<p>或者，我们可以弹出前三层，如下所示:</p>

<pre><strong>for</strong> layer in auto_encoder.layers[0:3]:<br/>    layer.trainable = True  </pre>

<p>然后，我们在前面添加完全连接的层，<kbd>BatchNormalization</kbd>层后面是第一个密集层。然后，我们添加另一个密集层，接着是<kbd>BatchNormalization</kbd>和<kbd>Dropout</kbd>层。然后，我们放置另一个密集层，接着是一个<kbd>GaussionNoise</kbd>层和一个<kbd>Dropout</kbd>层，最后是softmax层:</p>

<pre><strong>for</strong> i in range(number_of_layers_to_remove):<br/>    auto_encoder.pop()</pre>

<p>最后，我们得到完整的声发射分类器:</p>

<pre>auto_encoder.add(Dense(128, input_dim=64, activation='relu', use_bias=True)) <br/>auto_encoder.add(BatchNormalization())                     <br/>auto_encoder.add(Dense(64, activation='relu', kernel_initializer = 'he_normal', use_bias=True)) <br/>auto_encoder.add(BatchNormalization())<br/>auto_encoder.add(Dropout(0.2))    <br/>auto_encoder.add(Dense(32, activation='relu', kernel_initializer = 'he_normal', use_bias=True))<br/>auto_encoder.add(GaussianNoise(0.1))<br/>auto_encoder.add(Dropout(0.1))  <br/>auto_encoder.add(Dense(num_classes, activation = 'softmax', use_bias=True))</pre>

<p>完整代码如下所示:</p>

<pre>full_model = autoEncoderClassifier(auto_encoder)</pre>

<p>然后，我们在开始培训之前编译模型:</p>

<pre><strong>def</strong> autoEncoderClassifier(auto_encoder):<br/>    for layer in auto_encoder.layers[0:3]:<br/>        layer.trainable = True        <br/><br/>    auto_encoder.add(Dense(128, input_dim=64, activation='relu', use_bias=True)) <br/>    auto_encoder.add(BatchNormalization())                     <br/>    auto_encoder.add(Dense(64, activation='relu', kernel_initializer = 'he_normal', use_bias=True)) <br/>    auto_encoder.add(BatchNormalization())<br/>    auto_encoder.add(Dropout(0.2))    <br/>    auto_encoder.add(Dense(32, activation='relu', kernel_initializer = 'he_normal', use_bias=True))<br/>    auto_encoder.add(GaussianNoise(0.1))<br/>    auto_encoder.add(Dropout(0.1))  <br/>    auto_encoder.add(Dense(num_classes, activation = 'softmax', use_bias=True))<br/>    return auto_encoder<br/><br/>full_model = autoEncoderClassifier(auto_encoder)</pre>

<p>现在，我们开始以受监督的方式微调网络:</p>

<pre>full_model.compile(loss = 'categorical_crossentropy', optimizer = optimizers.adam(lr = 0.001), metrics = ['accuracy'])</pre>

<p>因为我们在前面的代码块中设置了<kbd>verbose =1</kbd>,所以在训练过程中，您将会看到以下日志:</p>

<pre>history = full_model.fit(X_train_re, train_y, epochs = 50, batch_size = 200, validation_split = 0.2, verbose = 1)</pre>

<p>现在让我们来看看培训损失与验证损失的对比，这将有助于我们了解培训的进展情况。这也将有助于我们确定我们的神经网络是否存在过拟合和欠拟合等问题:</p>

<pre>Train on 15949 samples, validate on 3988 samples

Epoch 1/50

15949/15949 [==============================] - 10s 651us/step - loss: 0.9263 - acc: 0.7086 - val_loss: 1.4313 - val_acc: 0.5747

Epoch 2/50

15949/15949 [==============================] - 5s 289us/step - loss: 0.6103 - acc: 0.7749 - val_loss: 1.2776 - val_acc: 0.5619

Epoch 3/50

15949/15949 [==============================] - 5s 292us/step - loss: 0.5499 - acc: 0.7942 - val_loss: 1.3871 - val_acc: 0.5364<br/>.......<br/>Epoch 49/50

15949/15949 [==============================] - 5s 342us/step - loss: 1.3861 - acc: 0.4662 - val_loss: 1.8799 - val_acc: 0.2706

Epoch 50/50

15949/15949 [==============================] - 5s 308us/step - loss: 1.3735 - acc: 0.4805 - val_loss: 2.1081 - val_acc: 0.2199</pre>

<p>前面的代码块将绘制训练损失和验证损失:</p>

<pre><strong>import</strong> pandas as pd<br/><strong>import</strong> numpy as np<br/><strong>import</strong> matplotlib.pyplot as plt<br/>%matplotlib inline<br/><br/>plt.plot(history.history['acc'])<br/>plt.plot(history.history['val_acc'])<br/>plt.ylabel('Accuracy')<br/>plt.xlabel('Epochs')<br/>plt.legend(['Training loss', 'Validation loss'], loc='upper left')<br/>plt.show()</pre>

<p class="CDPAlignLeft CDPAlign"><img src="img/c2372d36-7447-4aca-9c0e-86565eeefeaf.png" style="width:30.92em;height:19.67em;"/></p>

<p class="CDPAlignCenter CDPAlign">如上图所示，跨时期的训练损失高于验证损失，这是过度拟合的迹象。我们没有足够的训练样本来很好地训练神经网络。一些样本甚至在数据集中重复，这在网络中实际上被证明是琐碎和冗余的。这可能是添加<strong>辍学</strong>和<strong>高斯</strong>噪声层没有多大帮助的原因。无论如何，我们还可以保存训练好的模型以备将来重用，这将在下一节中讨论。</p>

<p>保存已训练的模型</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Saving the trained model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">现在我们已经完全训练好了AE分类器，我们可以保存它，以便以后可以从磁盘恢复它:</h1>

                

            

            

                

<p>在下一节中，我们将评估测试集上的训练模型，这将在下一小节中讨论。</p>

<pre><strong>import</strong> os<br/><strong>from</strong> pickle <strong>import</strong> load<br/><strong>from</strong> keras.models <strong>import</strong> load_model<br/>os.environ["PATH"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'<br/><strong>from</strong> keras.utils.vis_utils <strong>import</strong> plot_model<br/><br/>plot_model(full_model, show_shapes=True, to_file='Localization.png')<br/># save the model<br/>full_model.save('model.h5')<br/># load the model<br/>model = load_model('model.h5') </pre>

<p>评估模型</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Evaluating the model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">现在我们的模型已经完全训练好了，我们可以在看不见的数据上评估它的性能:</h1>

                

            

            

                

<p>前面几行代码将显示准确度分数，如下所示:</p>

<pre>results = full_model.evaluate(X_test_re, test_y)<br/>print('Test accuracy: ', results[1])</pre>

<p>然后，让我们计算性能指标:</p>

<pre>1111/1111 [==============================] - 0s 142us/step

Test accuracy: 0.8874887488748875</pre>

<p>前面的代码块将显示以下输出，给出大约88%的F1分数:</p>

<pre>predicted_classes = full_model.predict(test_x)<br/>pred_y = np.argmax(np.round(predicted_classes),axis=1)<br/>y = np.argmax(np.round(test_y),axis=1)<br/>p, r, f1, s = precision_recall_fscore_support(y, pred_y, average='weighted')<br/>print("Precision: " + str(p*100) + "%")<br/>print("Recall: " + str(r*100) + "%")<br/>print("F1-score: " + str(f1*100) + "%")</pre>

<p>此外，我们还可以打印分类报告，以了解特定于类别的本地化:</p>

<pre>Precision: 90.29611866225324%

Recall: 88.11881188118812%

F1-score: 88.17976604784566%</pre>

<p>前面的代码行将产生以下输出:</p>

<pre>print(classification_report(y, pred_y))</pre>

<p>此外，我们将绘制混淆矩阵:</p>

<div><img src="img/e2f80ecc-424d-4628-9cd6-b442280fcb78.png" style="width:28.25em;height:19.83em;"/></div>

<p>前面的代码行将产生以下混淆矩阵:</p>

<pre>print(confusion_matrix(y, pred_y))</pre>

<p><img src="img/91024568-524d-40ff-9690-1f36e7a1242b.png" style="width:21.92em;height:19.08em;"/></p>

<p class="CDPAlignCenter CDPAlign">正如在前面的混淆矩阵中所看到的，我们的AE分类器对于类别11最容易混淆，并预测多达39个样本将被分类到网格12中。然而，我们仍然设法获得非常好的精确度。可能的改进建议如下:</p>

<p>在去除被拒绝的变量之后训练网络</p>

<ul>

<li>在更多的时代训练网络</li>

<li>使用网格搜索和交叉验证执行超参数调整</li>

<li>向网络添加更多层</li>

<li>一旦您找到基于更多数据训练的优化模型，提供稳定、改进的性能，它就可以部署在支持物联网的设备上。我们将在下一节讨论一些可能的部署选项。</li>

</ul>

<p>部署技术</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Deployment techniques</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">正如我们之前所讨论的，每次Wi-Fi扫描都包含其附近可用接入点的信号强度测量，但只能观察到环境中网络总数的一个子集。许多物联网设备，如手机或树莓派，都是低端设备，处理能力很低。因此，部署这样的DL模型将是一项具有挑战性的任务。</h1>

                

            

            

                

<p>许多解决方案提供商和技术公司在商业上提供智能定位服务。使用室内和室外位置数据的Wi-Fi指纹识别，现在可以准确跟踪设备。在大多数这样的公司中，RSSI指纹定位被用作核心技术。在这样的设置中，具有不同RSSI值灵敏度级别的信号或消息(当然受邻近性的影响)可以被网关拾取。然后，如果网络中有<img class="fm-editor-equation" src="img/c189cb14-792d-4335-8822-38f5e338c167.png" style="width:0.83em;height:0.92em;"/>个网关，从特定室内或室外位置获取的RSSI值将形成在该位置具有<em> n </em>个条目的RSSI指纹，如下所示:</p>

<p><img src="img/f080db6c-cb77-425d-bedb-97be4ebdc152.png" style="width:22.50em;height:18.75em;"/></p>

<p class="CDPAlignCenter CDPAlign">上图对应于以下等式:</p>

<p><img class="fm-editor-equation" src="img/95c8924c-4289-48ba-887d-109ac1944279.png" style="width:21.75em;height:1.33em;"/></p>

<p class="CDPAlignCenter CDPAlign">但是，在有大量网关(&gt; 4个)的情况下，指纹在一定范围内可能是唯一的。一种部署技术可以是使用在后端服务的经过训练的模型，并将其作为Android或iOS移动应用程序。然后，应用程序监控来自已部署在室内位置的物联网设备的信号，将它们作为RSSI值插入SQLite数据库，并根据RSSI值准备测试集，并向预训练模型发送查询以获取位置。</p>

<p>下图显示了一个示意性架构，概述了此类部署所需的所有步骤:<br/></p>

<p><img src="img/187ba3bf-40ca-4c00-8ed9-aef4555073f5.png" style="width:68.08em;height:28.92em;"/></p>

<p class="CDPAlignCenter CDPAlign">在这种情况下，经过训练的模型将作为迁移学习。然而，经过训练的模型可以作为使用Flask或DJango Python框架的web应用程序。然后，来自物联网设备的RSSI值和信号可以存储在数据库中，以丰富历史数据。随后可以使用Android或iOS应用程序跟踪位置。</p>

<p>摘要</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Summary</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:86d202d3-ea3e-40e5-8f75-0218d47a52e1" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">在本章中，我们讨论了室内定位如何适用于支持物联网的设备。具体来说，我们已经通过一个实际操作的例子，了解了如何在物联网应用中利用这些数据将DL技术用于室内定位。此外，我们还研究了物联网环境中室内定位服务的一些部署设置。</h1>

                

            

            

                

<p>在<a href="958a0ed2-1d5f-4df1-8bfa-55d3c870d733.xhtml">第6章</a>、<em>物联网中的生理和心理状态检测</em>中，我们将讨论物联网应用中基于DL的人体生理和心理状态检测技术。考虑一个真实世界的场景，我们将看看两个基于生理和心理状态检测的物联网应用。</p>

<p>In <a href="958a0ed2-1d5f-4df1-8bfa-55d3c870d733.xhtml">Chapter 6</a>, <em>Physiological and Psychological State Detection in IoT</em>, we will discuss DL-based human physiological and psychological state detection techniques for IoT applications in general. Considering a real-world scenario, we will look at two IoT applications based on physiological and psychological state detection.</p>





            



            

        

    </body>



</html></body></html>