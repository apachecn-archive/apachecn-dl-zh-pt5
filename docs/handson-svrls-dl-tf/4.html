<html><head/><body>

    

        <title>Working with TensorFlow on AWS Lambda</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">在AWS Lambda上使用TensorFlow</h1>

                

            

            

                

<p>在本章中，我们将了解使用AWS部署TensorFlow的架构，并且我们将使用预先存在的包和无服务器框架在AWS Lambda上部署TensorFlow。我们还将研究在AWS Lambda上部署各种Python框架的各种常见问题，然后讨论这些问题的所有解决方案。</p>

<p>我们将讨论以下主题:</p>

<ul>

<li>使用AWS Lambda部署TensorFlow的架构</li>

<li>在AWS Lambda上部署Python框架的一般问题</li>

<li>使用预先存在的包在AWS Lambda上部署TensorFlow</li>

<li>使用无服务器框架部署TensorFlow</li>

</ul>





            



            

        

    






    

        <title>Technical Requirements</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">技术要求</h1>

                

            

            

                

<ul>

<li>AWS订阅</li>

<li>Python 3.6</li>

<li>AWS CLI</li>

<li>无服务器框架</li>

<li>您可以在以下位置找到所有代码:<a href="https://github.com/PacktPublishing/Hands-On-Serverless-Deep-Learning-with-TensorFlow-and-AWS-Lambda">https://github . com/packt publishing/Hands-On-server less-Deep-Learning-with-tensor flow-and-AWS-Lambda</a></li>

</ul>





            



            

        

    






    

        <title>Architecture of the deploying TensorFlow with AWS Lambda</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">使用AWS Lambda部署TensorFlow的架构</h1>

                

            

            

                

<p>在本节中，我们将了解使用AWS Lambda部署TensorFlow的架构。部署的一个关键问题是关于在哪里保存将在AWS Lambda中使用的重新训练的模型。</p>

<p>有以下三种可能的选择:</p>

<ul>

<li>将模型与代码和库一起放在部署包中</li>

<li>在执行期间，将模型保存在S3存储桶上，并将其卸载到AWS Lambda中</li>

<li>将模型保存在FTP或HTTP服务器上，并在执行期间将其卸载到AWS Lambda中</li>

</ul>





            



            

        

    






    

        <title>Model within the deployment package</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">部署包中的模型</h1>

                

            

            

                

<p>这个选项意味着模型在部署包中。代码将从本地文件系统导入它。这种选择有其利弊。</p>





            



            

        

    






    

        <title>Pros</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">赞成的意见</h1>

                

            

            

                

<p>该模型在部署包中的优势如下:</p>

<ul>

<li>我们的部署将获得非常好的启动速度，因为加载模型上没有开销</li>

<li>我们将从一个单一的包开始</li>

<li>我们不需要任何外部服务器或AWS服务作为我们部署的一部分</li>

</ul>





            



            

        

    






    

        <title>Cons</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">骗局</h1>

                

            

            

                

<p>部署包中模型的缺点如下:</p>

<ul>

<li>在包装尺寸上有相当大的限制，它限制了我们模型的可能尺寸</li>

<li>在您需要管理模型的不同版本的情况下，要么将它们都保存在一个包中，要么处理您的包的不同版本，这可能会很棘手</li>

</ul>

<p class="mce-root"/>





            



            

        

    






    

        <title>Model on the S3 bucket</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">S3铲斗模型</h1>

                

            

            

                

<p>这个选项意味着我们必须将模型保存在S3桶中，并在AWS Lambda执行期间卸载它。就封装尺寸而言，此选项非常有限。</p>





            



            

        

    






    

        <title>Pros</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">赞成的意见</h1>

                

            

            

                

<p>该模型在S3铲斗上的优势如下:</p>

<ul>

<li>乍一看，它将被限制为只有500 MB的使用量，这是AWS Lambda上TMP文件夹的最大大小，但实际上可以通过这个限制将模型直接下载到内存中</li>

<li>管理多个模型会容易得多，因为您可以使用AWS Lambda环境变量来为您想要使用的每个模型获取到S3铲斗的设备链接</li>

</ul>





            



            

        

    






    

        <title>Cons</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">骗局</h1>

                

            

            

                

<p>S3铲斗模型的缺点如下:</p>

<ul>

<li>我们将得到一个比以前更慢的开始，因为Lambda将需要首先下载模型</li>

<li>应该注意的是，虽然它只发生在冷启动期间，但是在热启动期间，该模型将已经在存储器中</li>

<li>作为部署的一部分，您需要让S3存储桶上传您的所有模型，并在代码中添加管理不同模型的逻辑</li>

</ul>





            



            

        

    






    

        <title>Model on the HTTP/FTP server</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">HTTP/FTP服务器上的模型</h1>

                

            

            

                

<p>该选项主要用于希望限制使用AWS服务、内存或与AWS之外的服务集成的情况。AWS Lambda在部署期间从HTTP或FTP服务器下载模型。</p>





            



            

        

    






    

        <title>Pros</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">赞成的意见</h1>

                

            

            

                

<p>该模型在HTTP/FTP服务器上的优势如下:</p>

<ul>

<li>您可以对模型使用许多公开可用的服务</li>

<li>你不需要在S3桶或包内更新你的模型</li>

</ul>

<p class="mce-root"/>





            



            

        

    






    

        <title>Cons</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">骗局</h1>

                

            

            

                

<p>该模型在HTTP/FTP服务器上的缺点如下:</p>

<ul>

<li>这可能比前一种情况更慢，这是这种模型的缺点</li>

<li>由于时间较慢，您需要确保服务器在您所在的位置可用</li>

</ul>





            



            

        

    






    

        <title>General issues with deploying Python frameworks on AWS Lambda</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">在AWS Lambda上部署Python框架的一般问题</h1>

                

            

            

                

<p>在本节中，我们将了解AWS Lambda主限制，也称为包的大小。Lambda部署包的当前限制是50 MB。它应该包括库和代码。我们需要安装两个主要的库:</p>

<ul>

<li>张量流</li>

<li>NumPy</li>

</ul>

<p>这些库用于矩阵计算。正如你可能知道的，库本身是相当大的，它们不能在AWS Lambda上工作。正如您在前面关于部署的部分中已经看到的，当我们通过S3部署它们时，我们没有这个限制，并且我们对解压缩后的包只有250 MB的限制。在这种情况下，为了让它工作，我们需要减小封装的大小。</p>





            



            

        

    






    

        <title>Solutions for issues with deploying Python frameworks on AWS Lambda</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">在AWS Lambda上部署Python框架的问题解决方案</h1>

                

            

            

                

<p>有多种方法可以减小封装尺寸。以下是这些问题的解决方案:</p>

<ul>

<li>我们可以压缩共享库；这通常使我们能够获得最佳的尺寸缩减。</li>

<li>我们可以删除<kbd>.pyc</kbd>文件，因为它们不会影响库的工作。</li>

<li>接下来，我们可以从库中删除测试和可视化文件夹，因为它们在生产中没有用。</li>

<li>接下来，我们可以删除AWS Lambda上已经存在的库。</li>

<li>最后，我们可以检查并删除执行过程中不使用的库，例如wheel或PIP库。</li>

</ul>

<p>现在，在下面的代码中，有一部分查找并压缩所有共享库。然后，我们找到并删除所有的<kbd>.pyc</kbd>文件。</p>

<p>以下屏幕截图显示了上述解释的命令:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/20c2e405-bef7-4cf5-a70a-bcf2add76128.png" style="width:22.75em;height:6.75em;"/></p>

<p>接下来，我们需要删除执行过程中不会用到的库，比如<kbd>.pip</kbd>和<kbd>wheel</kbd>。最后，我们还可以从TensorFlow库中删除一些文件夹。</p>

<p>以下屏幕截图显示了上述解释的不同命令:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/b707219e-0514-45d0-ba06-2ae2ab8777fa.png" style="width:21.58em;height:8.08em;"/></p>

<p>为AWS Lambda准备一个包的整个过程可以通过Docker来完成。对于我们将要创建的项目，您不需要使用它，但是最好记住如何准备这种包。</p>

<p>要安装Docker，您只需在注释行中运行三条注释:</p>

<ol>

<li>您需要获得最新的Amazon Linux映像，我们将在其上运行脚本。</li>

<li>您需要启动一个Docker容器，容器内有管理输出文件夹。</li>

</ol>

<ol start="3">

<li>您可以在容器中运行脚本，它将为您组装软件包。以下屏幕截图显示了安装Docker的所有命令:</li>

</ol>

<p class="CDPAlignCenter CDPAlign"><img src="img/5af485f9-ae76-479d-9a5a-3e4d5144bcf0.png" style="width:37.83em;height:11.17em;"/></p>





            



            

        

    






    

        <title>Deploying TensorFlow on AWS Lambda using the pre-existing pack</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">使用预先存在的包在AWS Lambda上部署TensorFlow</h1>

                

            

            

                

<p>在本节中，我们将学习使用预先存在的包在AWS Lambda上部署TensorFlow。在项目文件中，我们有模型文件，也称为模型本身，以及使我们能够通过标签转换模型响应的文件。在<kbd>Inception</kbd>文件夹和Lambda包中，也就是在<kbd>lambdapack</kbd>文件夹中的代码和库。</p>

<p>要运行代码，我们需要执行以下操作:</p>

<ul>

<li>我们将创建S3桶，我们将保持模型和上传模型本身</li>

<li>然后，我们将修改特定存储桶的代码，并添加创建的存储桶名称</li>

<li>最后，我们可以将其打包并上传以添加AWS Lambda</li>

</ul>

<p>现在，我们将使用AWS控制台创建S3桶，并在那里上传文件。我们将打开代码并添加我们刚刚创建的bucket。然后，我们来打包上传添加AWS Lambda。</p>

<p>我们必须遵循给定的步骤:</p>

<ol>

<li>我们需要转到S3服务，然后单击创建存储桶:</li>

</ol>

<p class="CDPAlignCenter CDPAlign"><img src="img/b5a2b678-1b9c-4697-adbc-1135d167ae79.png"/></p>

<ol start="2">

<li>现在，我们可以选择存储桶名称:</li>

</ol>

<p class="CDPAlignCenter CDPAlign"><img src="img/00a6f22d-931b-4cf4-b9ce-c845814d4794.png"/></p>

<ol start="3">

<li>一旦我们有了存储桶，我们就可以在那里上传文件。你只需要点击上传，然后选择文件。所以，在这里我们只是上传带有库的包，它将启动上传过程，以及包本身。我们需要上传模型文件，这些文件位于<kbd>Inception</kbd>文件夹中:</li>

</ol>

<p class="CDPAlignCenter CDPAlign"><img src="img/f34cd6e4-a3e2-4a48-9398-4199e7a14df6.png" style="width:29.92em;height:15.00em;"/></p>

<div><ol start="4">

<li>您可以看到，现在我们的S3桶中有一个包:</li>

</ol>

<p class="CDPAlignCenter CDPAlign"><img src="img/682c7e5f-5f9c-4f88-905f-b0ad32720507.png" style="width:50.25em;height:8.75em;"/></p>

<ol start="5">

<li>现在，我们必须为AWS Lambda创建角色，这可以从IAM服务中完成:</li>

</ol>

<p class="CDPAlignCenter CDPAlign"><img src="img/ae17137a-3ad4-4bef-87e2-301f05dec8dc.png"/></p>

<ol start="6">

<li>我们需要选择Lambda并点击Next: Permissions，它位于屏幕的右下角:</li>

</ol>

<p class="CDPAlignCenter CDPAlign"><img src="img/588d2e5d-3f17-47ca-9e68-57637d30be29.png"/></p>

<ol start="7">

<li>为简单起见，选择管理员访问权限并单击位于屏幕右下角的Next: Tags会更容易。这将允许我们的Lambda访问所有服务。通常在生产中，该角色仅限于访问特定的服务。我们将在使用无服务器框架时讨论这一点:</li>

</ol>

<p class="CDPAlignCenter CDPAlign"><img src="img/5c6a709f-8ec2-48a7-9bf9-212c95d8eb07.png"/></p>

<ol start="8">

<li>创建一个角色名:<kbd>lambdaAdminRole</kbd>，这将在Lambda中创建角色:</li>

</ol>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-741 image-border" src="img/193478df-a06a-41a1-93cd-c7d66ab776b9.png" style="width:82.67em;height:45.92em;"/></p>

<ol start="9">

<li>若要创建Lambda，请导航到Lambda函数并创建该函数。这里输入名称<kbd>testensorflolambda</kbd>，运行时为Python 3.6。对于角色，选择选择现有角色，在现有角色中，选择<kbd>lambdaAdminRole</kbd>，然后点击右下角的创建功能:</li>

</ol>

<p class="CDPAlignCenter CDPAlign"><img src="img/72181902-1d22-486f-9804-3251a600c875.png" style="width:51.33em;height:37.25em;"/></p>

<div><p style="padding-left: 60px">10.创建函数后，我们需要将处理程序改为<kbd>index.handler</kbd>:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/b80f11de-8c3c-43c2-ba43-afb498cc4ae6.png" style="width:45.33em;height:8.08em;"/></p>

<ol start="11">

<li>在同一屏幕上，向下滚动，在“基本设置”选项卡中，添加足够的资源，如下图所示:</li>

</ol>

<p class="CDPAlignCenter CDPAlign"><img src="img/aac2594e-7e37-4cd4-be1b-676607b34a82.png"/></p>

<ol start="12">

<li>传递带有我们的软件包(S3·布切克特)的URL的链接，并点击右上角的保存:</li>

</ol>

<p class="CDPAlignCenter CDPAlign"><img src="img/ee4da3e6-39d0-4dc0-8790-13c716385262.png" style="width:47.08em;height:15.08em;"/></p>

<ol start="13">

<li>你可以看到函数已经创建好了。要测试该功能，请单击右上角的测试:</li>

</ol>

<p class="CDPAlignCenter CDPAlign"><img src="img/53e3a850-3fe8-4ae4-b926-85058b791050.png" style="width:48.33em;height:15.08em;"/></p>

<ol start="14">

<li>测试该函数后，它将成功产生以下结果:</li>

</ol>

<p class="CDPAlignCenter CDPAlign"><img src="img/9da215f9-adda-42eb-afd4-bba15ac46475.png" style="width:46.33em;height:11.67em;"/></p>





            



            

        

    






    

        <title>Deploying TensorFlow using a serverless framework</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">使用无服务器框架部署TensorFlow</h1>

                

            

            

                

<p>首先，我们将查看项目文件。我们在<kbd>Inception</kbd>文件夹中有模型文件，在<kbd>Lambdapack</kbd>文件夹中有带有<kbd>Serverless.yml</kbd>的Lambda代码，配置文件。</p>

<p>部署流程将与上一节相同。一个主要的区别是，我们将通过无服务器CML文件提供对bucket的访问，而不是提供AWS Lambda管理角色。我们唯一需要添加的是<kbd>bucketname</kbd>，并运行access的属性，如下所示:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/410584be-c45d-4925-b33b-75144ce6eb88.png" style="width:25.92em;height:12.17em;"/></p>

<p>我们将需要创建一个S3桶，上传文件，然后部署AWS Lambda。我们将创建一个S3桶，并从命令行上传文件:<kbd>aws s3 sync.s3://&lt;bucket&gt;/</kbd>。</p>





            



            

        

    






    

        <title>Creating a bucket</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">创建存储桶</h1>

                

            

            

                

<p>我们首先需要创建一个bucket，然后将模型文件上传到bucket，运行serverless，并启动AWS Lambda。</p>





            



            

        

    






    

        <title>Index.py</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">索引. py</h1>

                

            

            

                

<p>让我们看看可用的文件。我们将查看如图所示的<kbd>index.py</kbd>文件:</p>

<pre>import boto3<br/>import numpy as np<br/>import tensorflow as tf<br/>import os.path<br/>import re<br/>from urllib.request import urlretrieve<br/>import json<br/>SESSION = None<br/>strBucket = 'serverlessdeeplearning'<br/>def handler(event, context):<br/> global strBucket<br/> if not os.path.exists('/tmp/imagenet/'):<br/> os.makedirs('/tmp/imagenet/')<br/>strFile = '/tmp/imagenet/inputimage.jpg'</pre>

<p>主要的区别是我们在<kbd>handler</kbd>函数中运行代码，我们需要从S3桶中下载模型文件和图像文件:</p>

<pre>if not os.path.exists('/tmp/imagenet/'):<br/> os.makedirs('/tmp/imagenet/')<br/>strFile = '/tmp/imagenet/inputimage.jpg'<br/>downloadFromS3(strBucket,'imagenet/inputimage.jpg',strFile)<br/>global SESSION<br/> if SESSION is None:<br/>downloadFromS3(strBucket,'imagenet/imagenet_2012_challenge_label_map_proto.pbtxt','/tmp/imagenet/imagenet_2012_challenge_label_map_proto.pbtxt')<br/>downloadFromS3(strBucket,'imagenet/imagenet_synset_to_human_label_map.txt','/tmp/imagenet/imagenet_synset_to_human_label_map.txt')<br/> image = os.path.join('/tmp/imagenet/', 'inputimage.jpg')<br/> strResult = run_inference_on_image(image)<br/>return strResult<br/>def run_inference_on_image(image):</pre>

<p>另外，我们可以利用AWS Lambda的一个优点。我们可以将模型文件保存为全局变量。基本上，我们可以将会话定义为一个全局变量。有了这些，如果我们在前一个Lambda执行之后立即启动Lambda，所有的模型文件都将在RAM内存中:</p>

<pre>global SESSION<br/> if SESSION is None:<br/> downloadFromS3(strBucket,'imagenet/imagenet_2012_challenge_label_map_proto.pbtxt','/tmp/imagenet/imagenet_2012_challenge_label_map_proto.pbtxt')<br/> downloadFromS3(strBucket,'imagenet/imagenet_synset_to_human_label_map.txt','/tmp/imagenet/imagenet_synset_to_human_label_map.txt')<br/> image = os.path.join('/tmp/imagenet/', 'inputimage.jpg')<br/> strResult = run_inference_on_image(image)<br/>return strResult<br/>def run_inference_on_image(image):<br/> image_data = tf.gfile.FastGFile(image, 'rb').read()<br/> global SESSION<br/> if SESSION is None:<br/> SESSION = tf.InteractiveSession()<br/> create_graph()</pre>





            



            

        

    






    

        <title>Serverless.yml</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">无服务器. yml</h1>

                

            

            

                

<p class="mce-root CDPAlignLeft CDPAlign">在<kbd>Serverless.yml</kbd>文件中，我们需要定义对S3桶的访问，因为我们将在那里保存我们的模型。除此之外，它将与前面提到的用于其他Lambdas的无服务器CML文件完全一样:</p>

<pre>service: deeplearninglambda<br/>frameworkVersion: "&gt;=1.2.0 &lt;2.0.0"<br/>provider:<br/>  name: aws<br/>  region: us-east-1<br/>  runtime: python3.6<br/>  memorySize: 1536<br/>  timeout: 60<br/><strong>iamRoleStatements:</strong><br/><strong> - Effect: "Allow"</strong><br/><strong> Action:</strong><br/><strong> - "s3:ListBucket"</strong><br/><strong> Resource:</strong><br/><strong> - arn:aws:s3:::serverlessdeeplearning</strong><br/><strong> - Effect: "Allow"</strong><br/><strong> Action:</strong><br/><strong> - "s3:GetObject"</strong><br/><strong> Resource:</strong><br/><strong> - arn:aws:s3:::serverlessdeeplearning/*</strong><br/>functions:<br/> main:<br/> handler: index.handler</pre>

<p class="mce-root">此外，我们需要<kbd>inputimage.jpg</kbd>的图像用于初始模型。</p>

<p class="mce-root CDPAlignLeft CDPAlign">让我们来看看需要上传到S3木桶的文件:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/9bfbd63b-4255-4328-bb0d-41f3e314ff40.png"/></p>

<p class="mce-root CDPAlignLeft CDPAlign">有两个非常方便的命令:一个允许我们创建一个桶，另一个允许我们轻松地将文件上传到桶中:</p>

<ul>

<li class="CDPAlignLeft CDPAlign"><kbd>aws s3api create-bucket --bucket serverlessdeeplearning</kbd></li>

<li><kbd>aws s3 sync . s3://serverlessdeeplearning/imagenet</kbd></li>

</ul>

<p class="mce-root CDPAlignLeft CDPAlign">因为我们在这个存储桶中已经有了模型文件，所以现在没有必要保存它，但是您可以使用这个命令上传到您的存储桶。接下来，我们可以使用我们的函数返回到该文件夹并运行<kbd>serverless deploy</kbd>命令。</p>

<p class="mce-root CDPAlignLeft CDPAlign">现在，我们将使用以下命令调用该函数:</p>

<pre class="mce-root CDPAlignLeft CDPAlign"><strong>serverless invoke --function main</strong></pre>

<p class="mce-root CDPAlignLeft CDPAlign">如你所见，它成功地识别了图像。此外，如果我们在此之后再次调用该函数，它将运行得更快:</p>

<p class="CDPAlignCenter CDPAlign"><img src="img/10ae6ce4-b240-4ed1-b05a-50de48fc9c4c.png" style="width:44.67em;height:11.92em;"/></p>





            



            

        

    






    

        <title>Summary</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:47c30fe0-708a-4ee4-a010-a72f15252cad" name="Adept.expected.resource"/>

    



    

        



                            

                    <h1 class="header-title">摘要</h1>

                

            

            

                

<p>在本章中，我们学习了使用AWS Lambda部署TensorFlow的体系结构，其中涵盖了使用AWS Lambda部署TensorFlow的可能选项及其优缺点。我们还讨论了在AWS Lambda中部署Python框架的一般问题及其解决方案。最后，我们使用预先存在的包和无服务器框架在AWS Lambda上部署TensorFlow。</p>

<p>在下一章，我们将使用AWS Lambda创建深度学习API。</p>





            



            

        

    



</div></div></body></html>