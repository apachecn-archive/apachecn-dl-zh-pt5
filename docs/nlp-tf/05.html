<html><head/><body>
<html>
  <head>
    <title>Chapter 5. Sentence Classification with Convolutional Neural Networks</title>
    <meta content="DocBook XSL Stylesheets V1.75.2" name="generator"/>
    <meta content="urn:uuid:7a74de9d-8dca-491a-886e-bcc2b2120efe" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title">第五章。基于卷积神经网络的句子分类</h1></div></div></div><p class="calibre10">在本章中，我们将讨论一种被称为<strong class="calibre11">卷积神经网络</strong>(<strong class="calibre11">CNN</strong>)的神经网络。CNN与完全连接的神经网络有很大不同，并且已经在许多任务中实现了最先进的性能。这些任务包括图像分类、对象检测、语音识别，当然还有句子分类。CNN的主要优势之一是，与全连接层相比，CNN中的卷积层具有更少的参数。这允许我们构建更深层次的模型，而不用担心内存溢出。此外，更深的模型通常会带来更好的性能。</p><p class="calibre10">我们将通过讨论CNN中的不同组成部分，向您详细介绍什么是CNN，以及是什么使CNN不同于它们完全连接的对等物。然后，我们将讨论CNN中使用的各种操作，如卷积和池操作，以及与这些操作相关的某些超参数，如滤波器大小、填充和步长。我们还将研究实际操作背后的一些数学知识。在对CNN有了很好的理解之后，我们将看看用TensorFlow实现CNN的实际方面。首先，我们将实现一个CNN来分类对象，然后使用一个CNN进行句子分类。</p><div><div><div><div><h1 class="title1"><a id="ch05lvl1sec35" class="calibre7"/>引入卷积神经网络</h1></div></div></div><p class="calibre10">在这一部分，你将了解到关于CNN的<a id="id296"/>。具体来说，您将首先了解CNN中存在的各种操作，如卷积层、池层和全连接层。接下来，我们将简要了解所有这些是如何连接起来形成端到端模型的。然后我们将深入这些操作的细节，从数学上定义它们，并了解这些操作涉及的各种超参数如何改变它们产生的输出。</p><div><div><div><div><h2 class="title3"><a id="ch05lvl2sec57" class="calibre7"/> CNN基础</h2></div></div></div><p class="calibre10">现在，让我们在不深究太多技术细节的情况下探索CNN背后的基本思想。如前一段所述，CNN是层的堆叠，例如卷积层、汇集层和全连接层。我们将逐一讨论，以了解他们在CNN中的角色。</p><p class="calibre10">最初，输入连接到一组卷积层。这些卷积层在输入上滑动一片权重(有时称为卷积窗口或滤波器),并通过卷积运算产生输出。与完全连接的神经网络不同，卷积层使用少量的权重，这些权重被组织为仅覆盖每层中的一小部分输入，并且这些权重在某些维度上共享(例如，图像的宽度和高度维度)。此外，通过沿着期望的维度滑动这一小组权重，CNN使用卷积运算来共享来自输出的权重。我们最终从这个卷积运算中得到的结果如图5.1所示。如果卷积滤波器中存在的模式存在于一个图像片中，则卷积将输出该位置的高值；否则，它将输出一个低值。此外，通过卷积完整的图像，我们得到一个矩阵，表明在给定的位置是否存在一个模式。最后，我们将得到一个矩阵作为卷积输出:</p><div><img alt="CNN fundamentals" src="img/B08681_05_01.jpg" class="calibre12"/><div><p class="calibre10">图5.1:卷积运算对图像的影响</p></div></div><p class="calibre10">此外，这些卷积层可选地与汇集/子采样层交错，这降低了输入的维度。在降低维度的同时，我们使CNN的平移不变，并迫使CNN用更少的信息进行学习，从而导致模型的更好的泛化和正则化。通过将输入分成几个小块并将每个小块转换成单个元素来降低维数。例如，这种变换包括挑选面片的最大元素或平均面片中的所有值。我们将在<em class="calibre15">图5.2 </em>中说明池如何使CNN的转换不变:</p><div><img alt="CNN fundamentals" src="img/B08681_05_02.jpg" class="calibre12"/><div><p class="calibre10">图5.2:池操作如何帮助数据转换不变</p></div></div><p class="calibre10">这里，我们有<a id="id298"/>的原始图像和在<em class="calibre15"> y </em>轴上稍微平移的图像。我们有两幅图像的卷积输出，您可以看到值<strong class="calibre11"> 10 </strong>出现在卷积输出中稍有不同的位置。但是，使用max pooling(取每个厚方块的最大值)，我们最终可以得到相同的输出。我们将在后面详细讨论这些操作。</p><p class="calibre10">最后，输出被馈送到一组完全连接的层，然后这些层将输出转发到最终的分类/回归层(例如，句子/图像分类)。完全连接的层包含CNN的总权重的很大一部分，因为卷积层具有少量的权重。然而，已经发现，具有全连接层的CNN比没有全连接层的CNN性能更好。这可能是因为卷积图层由于尺寸较小而获取了更多的局部化要素，而完全连接的图层则提供了一幅全局图，说明如何将这些局部化要素连接在一起以生成所需的最终输出。<em class="calibre15">图5.3 </em>显示了用于图像分类的典型CNN:</p><div><img alt="CNN fundamentals" src="img/B08681_05_03.jpg" class="calibre12"/><div><p class="calibre10">图5.3:典型的CNN架构</p></div></div><p class="calibre10">从图中可以明显看出<a id="id299"/>,通过设计，CNN在学习过程中保留了输入的空间结构。换句话说，对于二维输入，CNN的大部分层都是二维的，而我们只有靠近输出层的全连接层。保留空间结构允许CNN利用输入的有价值的空间信息，并利用较少的参数了解输入。空间信息的价值在<em class="calibre15">图5.4 </em>中说明:</p><div><img alt="CNN fundamentals" src="img/B08681_05_04.jpg" class="calibre12"/><div><p class="calibre10">图5.4:将图像展开成一维向量会丢失一些重要的空间信息</p></div></div><p class="calibre10">正如你所看到的，当一只猫的二维图像被展开为一维向量时，耳朵<a id="id300"/>不再靠近眼睛，鼻子也远离眼睛。这意味着我们在展开过程中破坏了一些有用的空间信息。</p></div><div><div><div><div><h2 class="title3"><a id="ch05lvl2sec58" class="calibre7"/>卷积神经网络的威力</h2></div></div></div><p class="calibre10">CNN是一个非常通用的<a id="id301"/>模型家族，并且在许多类型的任务中表现出卓越的性能。这种多功能性归功于CNN同时执行特征提取和学习的能力，从而导致更高的效率和泛化能力。让我们讨论几个CNN效用的例子。</p><p class="calibre10">在2016年的<strong class="calibre11"> ImageNet大规模视觉识别挑战赛</strong> ( <strong class="calibre11"> ILSVRC </strong>)中，涉及图像分类、检测对象以及在图像中定位对象，CNN被用于实现<a id="id302"/>难以置信的测试准确性。例如，对于图像分类任务，它对1，000个不同对象类别的测试精度约为98%，这意味着CNN能够正确识别大约980个不同的对象。</p><p class="calibre10">CNN也被用于图像分割。图像分割包括将图像分割成不同的区域。例如，在包含建筑物、道路、车辆和乘客的城市景观图像中，将道路从建筑物中分离出来是一项分割任务。此外，CNN已经取得了令人难以置信的进步，证明了它们在句子分类、文本生成和机器翻译等NLP任务中的性能。</p></div></div></div></body></html>


<html>
  <head>
    <title>Understanding Convolution Neural Networks</title>
    <meta content="DocBook XSL Stylesheets V1.75.2" name="generator"/>
    <meta content="urn:uuid:7a74de9d-8dca-491a-886e-bcc2b2120efe" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title1"><a id="ch05lvl1sec36" class="calibre7"/>了解卷积神经网络</h1></div></div></div><p class="calibre10">现在让我们浏览一下CNN的技术细节。首先，我们将讨论<a id="id304"/>卷积运算，并介绍一些术语，如滤波器大小、步幅和填充。简而言之，<strong class="calibre11">滤波器大小</strong>指的是<a id="id305"/>卷积运算的窗口大小，<strong class="calibre11">步距</strong>指的是卷积窗口两次移动之间的距离，<strong class="calibre11">填充</strong>指的是<a id="id306"/>处理输入边界的方式<a id="id307"/>。我们还将讨论一种称为反卷积或转置卷积的运算。然后我们将讨论联营业务的细节。最后，我们将讨论如何连接完全连接的层和由卷积和汇集层产生的二维输出，以及如何使用输出进行分类或回归。</p><div><div><div><div><h2 class="title3"><a id="ch05lvl2sec59" class="calibre7"/>卷积运算</h2></div></div></div><p class="calibre10">在本节中，我们将详细讨论卷积运算。首先我们将讨论没有步幅和填充的卷积运算，接下来我们将描述具有步幅的卷积运算<a id="id308"/>，然后我们将讨论具有填充的卷积运算。最后，我们将讨论一种叫做转置卷积的东西。对于本章中的所有运算，我们考虑从1开始的索引，而不是从0开始。</p><div><div><div><div><h3 class="title5"><a id="ch05lvl3sec13" class="calibre7"/>标准卷积运算</h3></div></div></div><p class="calibre10">卷积<a id="id309"/>操作是细胞神经网络的核心部分。对于尺寸为<img alt="Standard convolution operation" src="img/B08681_05_05.jpg" class="calibre27"/>的输入和<img alt="Standard convolution operation" src="img/B08681_05_06.jpg" class="calibre27"/>的权重补丁(也称为<em class="calibre15">滤波器</em>),其中<img alt="Standard convolution operation" src="img/B08681_05_07.jpg" class="calibre27"/>，卷积运算在输入上滑动权重补丁。让我们用<em class="calibre15"> X </em>表示输入，用<em class="calibre15"> W </em>表示权块，用<em class="calibre15"> H </em>表示输出。同样，在每个位置<img alt="Standard convolution operation" src="img/B08681_05_08.jpg" class="calibre27"/>；输出计算如下:</p><div><img alt="Standard convolution operation" src="img/B08681_05_09.jpg" class="calibre12"/></div><p class="calibre10">这里，<em class="calibre15"> x </em> <em class="calibre15"> <sub class="calibre17"> i，j </sub> </em>，<em class="calibre15"> w </em> <em class="calibre15"> <sub class="calibre17"> i，j </sub> </em>和<em class="calibre15"> h </em> <em class="calibre15"> i，j </em>表示<em class="calibre15"> (i，j) </em> <em class="calibre15"> <sup class="calibre26"> th </sup>位置处的值<em class="calibre15"> X </em>，<em class="calibre15"> W </em>和<em class="calibre15">H<em class="calibre15">如等式所示，虽然输入大小为<img alt="Standard convolution operation" src="img/B08681_05_10.jpg" class="calibre27"/>，但这种情况下的输出将为<img alt="Standard convolution operation" src="img/B08681_05_11.jpg" class="calibre27"/>。另外，<em class="calibre15"> m </em>也称为滤波器尺寸。让我们通过可视化来看一下(参见<em class="calibre15">图5.5 </em>):</em></em></em></p><div><div><h3 class="title4"><a id="note25" class="calibre7"/>注意</h3><p class="calibre16">卷积运算产生的输出(图5.5<em class="calibre15">顶部的矩形</em>)有时被称为<strong class="calibre11">特征图</strong>。</p></div></div><div><img alt="Standard convolution operation" src="img/B08681_05_12.jpg" class="calibre12"/><div><p class="calibre10">图5.5:滤波器大小(m) = 3跨距= 1且无填充的卷积运算</p></div></div></div><div><div><div><div><h3 class="title5"><a id="ch05lvl3sec14" class="calibre7"/>昂首阔步</h3></div></div></div><p class="calibre10">在前面的例子中，我们将<a id="id310"/>过滤器移动了一步。然而，这不是强制性的；在卷积输入时，我们可以采取大的步骤或大步。因此，一步的大小被称为步幅。让我们修改前面的等式，以包括<em class="calibre15"> s </em> <em class="calibre15"> <sub class="calibre17"> i </sub> </em>和<em class="calibre15"> s </em> <em class="calibre15"> <sub class="calibre17"> j </sub> </em>步幅:</p><div><img alt="Convolving with stride" src="img/B08681_05_13.jpg" class="calibre12"/></div><p class="calibre10">在这种情况下，随着<em class="calibre15">s</em>T55】I和<em class="calibre15">s</em>T59】j的尺寸增大，输出会变小。比较<em class="calibre15">图5.5 </em> ( <em class="calibre15"> stride = 1 </em>)和<em class="calibre15">图5.6 </em> ( <em class="calibre15"> stride = 2 </em>)说明了不同步幅的效果:</p><div><img alt="Convolving with stride" src="img/B08681_05_15.jpg" class="calibre12"/><div><p class="calibre10">图5.6:滤波器大小(m) = 2跨距= 2且无填充的卷积运算</p></div></div><div><div><h3 class="title4"><a id="note26" class="calibre7"/>注</h3><p class="calibre16">如您所见，使用stride进行<a id="id311"/>卷积有助于减少输入的维度，类似于池层。因此，有时使用具有步长的卷积来代替CNN中的汇集，因为它降低了计算复杂度。</p></div></div></div><div><div><div><div><h3 class="title5"><a id="ch05lvl3sec15" class="calibre7"/>用填料进行卷积</h3></div></div></div><p class="calibre10">每个卷积导致的不可避免的输出大小<a id="id312"/>减小(没有步长)是不希望的特性。这极大地限制了网络中的层数。此外，众所周知，较深的网络比浅的网络性能更好。这不应该与stride实现的维数减少混淆，因为这是一个设计选择，如果必要，我们可以决定将stride设为1。因此，使用填充来规避这个问题。这是通过在输入的边界填充零来实现的，以便输出大小和输入大小相等。让我们假设步幅为1:</p><div><img alt="Convolving with padding" src="img/B08681_05_16.jpg" class="calibre12"/></div><p class="calibre10">这里:</p><div><img alt="Convolving with padding" src="img/B08681_05_17.jpg" class="calibre12"/></div><p class="calibre10"><em class="calibre15">图5.7 </em>描述了填充的结果:</p><div><img alt="Convolving with padding" src="img/B08681_05_18.jpg" class="calibre12"/><div><p class="calibre10">图5.7:滤波器大小(m=3)、步距(s=1)和零填充的卷积运算</p></div></div></div><div><div><div><div><h3 class="title5"><a id="ch05lvl3sec16" class="calibre7"/>转置卷积</h3></div></div></div><p class="calibre10">虽然卷积运算在数学上看起来很复杂，但它可以简化为矩阵乘法。出于这个原因，我们可以定义卷积运算的转置或<strong class="calibre11">反卷积</strong>，因为它有时被称为<a id="id314"/>。然而，我们将使用术语<strong class="calibre11">转置卷积</strong>，因为它听起来更自然。此外，去卷积指的是不同的<a id="id315"/>数学概念。转置卷积运算在细胞神经网络中起着重要的作用，用于反向传播过程中梯度的反向累积。我们来看一个例子。</p><p class="calibre10">对于大小为<img alt="Transposed convolution" src="img/B08681_05_19.jpg" class="calibre27"/>的输入和权重补丁或滤波器<img alt="Transposed convolution" src="img/B08681_05_20.jpg" class="calibre27"/>，其中<img alt="Transposed convolution" src="img/B08681_05_21.jpg" class="calibre27"/>，卷积运算在输入上滑动权重补丁。让我们用<em class="calibre15"> X </em>表示输入，用<em class="calibre15"> W </em>表示权值，用<em class="calibre15"> H </em>表示输出。输出<em class="calibre15"> h </em>可以计算为如下矩阵乘法。</p><p class="calibre10">为了清楚起见，我们假设<img alt="Transposed convolution" src="img/B08681_05_22.jpg" class="calibre27"/>和<img alt="Transposed convolution" src="img/B08681_05_23.jpg" class="calibre27"/>，从左到右、从上到下展开输入<em class="calibre15"> X </em>，结果如下:</p><div><img alt="Transposed convolution" src="img/B08681_05_24.jpg" class="calibre12"/></div><p class="calibre10">让我们从<em class="calibre15"> W </em>定义一个<a id="id316"/>新矩阵<em class="calibre15"> A </em>:</p><div><img alt="Transposed convolution" src="img/B08681_05_84.jpg" class="calibre12"/></div><p class="calibre10">然后，如果我们执行下面的矩阵乘法，我们得到<em class="calibre15"> H </em>:</p><div><img alt="Transposed convolution" src="img/B08681_05_30.jpg" class="calibre12"/></div><p class="calibre10">现在，通过将输出<img alt="Transposed convolution" src="img/B08681_05_31.jpg" class="calibre27"/>整形为<img alt="Transposed convolution" src="img/B08681_05_32.jpg" class="calibre27"/>，我们获得卷积输出。现在让我们将这个结果投射回<em class="calibre15"> n </em>和<em class="calibre15"> m </em>:</p><p class="calibre10">通过解开<a id="id317"/>到<img alt="Transposed convolution" src="img/B08681_05_34.jpg" class="calibre27"/>的输入<img alt="Transposed convolution" src="img/B08681_05_33.jpg" class="calibre27"/>，并通过从<em class="calibre15"> w </em>创建一个矩阵<img alt="Transposed convolution" src="img/B08681_05_35.jpg" class="calibre27"/>，正如我们之前展示的，我们获得<img alt="Transposed convolution" src="img/B08681_05_36.jpg" class="calibre27"/>，然后它将被整形为<img alt="Transposed convolution" src="img/B08681_05_37.jpg" class="calibre27"/>。</p><p class="calibre10">接下来，为了获得转置卷积，我们简单地转置<em class="calibre15"> A </em>并得到如下结果:</p><div><img alt="Transposed convolution" src="img/B08681_05_38.jpg" class="calibre12"/></div><p class="calibre10">这里，<img alt="Transposed convolution" src="img/B08681_05_83.jpg" class="calibre27"/>是转置卷积的结果输出。</p><p class="calibre10">我们在这里结束关于卷积运算的讨论。我们讨论了卷积运算、步长卷积运算、填充卷积运算以及如何计算转置卷积。接下来，我们将更详细地讨论池操作。</p></div></div><div><div><div><div><h2 class="title3"><a id="ch05lvl2sec60" class="calibre7"/>汇集操作</h2></div></div></div><p class="calibre10">池操作，有时被称为子采样操作，被引入CNN主要是为了减小中间输出的大小，以及使CNN的转换不变。这优于没有填充的卷积导致的自然降维，因为我们可以决定在哪里使用池层减少输出的大小，而不是每次都强制执行。在没有填充的情况下强迫维度减少将严格限制我们在CNN模型中可以拥有的层数。</p><p class="calibre10">我们在下面几节中用数学方法定义了池化<a id="id319"/>操作。更准确地说，我们将讨论两种类型的池:最大池和平均池。然而，首先，我们将定义符号。对于大小为<img alt="Pooling operation" src="img/B08681_05_39.jpg" class="calibre27"/>的输入和大小为<img alt="Pooling operation" src="img/B08681_05_40.jpg" class="calibre27"/>的核(类似于卷积层的过滤器)，其中<img alt="Pooling operation" src="img/B08681_05_41.jpg" class="calibre27"/>，卷积操作在输入上滑动权重补丁。让我们用<em class="calibre15"> x </em>表示输入，用<em class="calibre15"> w </em>表示权值，用<em class="calibre15"> h </em>表示输出。</p><div><div><div><div><h3 class="title5"><a id="ch05lvl3sec17" class="calibre7"/>最大池</h3></div></div></div><p class="calibre10">最大池操作<a id="id320"/>在输入的定义的<a id="id321"/>内核中挑选最大元素来产生输出。最大汇集操作移位是输入上的窗口(图5.8 中<em class="calibre15">的中间方块)，每次取最大值。在数学上，我们将联营等式定义如下:</em></p><div><img alt="Max pooling" src="img/B08681_05_42.jpg" class="calibre12"/></div><p class="calibre10"><em class="calibre15">图5.8 </em>显示了该操作:</p><div><img alt="Max pooling" src="img/B08681_05_43.jpg" class="calibre12"/><div><p class="calibre10">图5.8:过滤器大小为3、步幅为1且无填充的最大池操作</p></div></div></div><div><div><div><div><h3 class="title5"><a id="ch05lvl3sec18" class="calibre7"/>最大合并步幅</h3></div></div></div><p class="calibre10">最大池与步幅的<a id="id322"/>类似于卷积与步幅。下面是等式:</p><div><img alt="Max pooling with stride" src="img/B08681_05_44.jpg" class="calibre12"/></div><div><img alt="Max pooling with stride" src="img/B08681_05_45.jpg" class="calibre12"/></div><p class="calibre10"><em class="calibre15">图5.9 </em>显示了结果:</p><div><img alt="Max pooling with stride" src="img/B08681_05_46.jpg" class="calibre12"/><div><p class="calibre10">图5.9:大小为(n=4)的输入的最大池操作，过滤器大小为(m=2)，步幅为(s=2)并且没有填充</p></div></div></div><div><div><div><div><h3 class="title5"><a id="ch05lvl3sec19" class="calibre7"/>平均分摊</h3></div></div></div><p class="calibre10">平均池的工作方式<a id="id323"/>类似于最大池，除了不是只取最大值，而是取内核中所有输入的平均值。考虑以下等式:</p><div><img alt="Average pooling" src="img/B08681_05_47.jpg" class="calibre12"/></div><p class="calibre10">平均汇集操作如图<em class="calibre15">图5.10 </em>所示:</p><div><img alt="Average pooling" src="img/B08681_05_48.jpg" class="calibre12"/><div><p class="calibre10">图5.10:大小为(n=4)的输入的平均池操作，过滤器大小为(m=2)，步长为(s=1)且没有填充</p></div></div></div></div><div><div><div><div><h2 class="title3"><a id="ch05lvl2sec61" class="calibre7"/>完全连接的层</h2></div></div></div><p class="calibre10">全连接图层是从输入到输出的一组全连接权重。这些完全连接的权重能够学习全局信息，因为它们从每个输入连接到每个输出。此外，拥有这种完全连接的层允许我们将完全连接的层之前的卷积层学习到的特征<a id="id324"/>进行全局组合，以产生有意义的输出。</p><p class="calibre10">让我们定义最后一个卷积或池层的输出大小为<img alt="Fully connected layers" src="img/B08681_05_49.jpg" class="calibre27"/>，其中<em class="calibre15"> p </em>是输入的高度，<em class="calibre15"> o </em>是输入的宽度，<em class="calibre15"> d </em>是输入的深度。例如，想象一个RGB图像，它具有固定的高度、固定的宽度和深度3(每个RGB分量一个深度通道)。</p><p class="calibre10">然后，对于紧接在最后一个卷积或池层之后找到的初始全连接层，权重矩阵将是<img alt="Fully connected layers" src="img/B08681_05_50.jpg" class="calibre27"/>，其中层输出的<em class="calibre15">高度×宽度×深度</em>是由该最后一层产生的输出单元的数量，<em class="calibre15"> m </em>是全连接层中隐藏单元的数量。然后，在推断(或预测)期间，我们将最后一个卷积/池层的输出整形为大小<img alt="Fully connected layers" src="img/B08681_05_51.jpg" class="calibre27"/>，并执行以下矩阵乘法以获得<em class="calibre15"> h </em>:</p><div><img alt="Fully connected layers" src="img/B08681_05_52.jpg" class="calibre12"/></div><p class="calibre10">生成的完全连接的层将表现为完全连接的神经网络，其中有几个完全连接的层和一个输出层。对于分类问题，输出图层可以是softmax分类图层；对于回归问题，输出图层可以是线性图层。</p></div><div><div><div><div><h2 class="title3">把所有东西放在一起</h2></div></div></div><p class="calibre10">现在我们将讨论卷积层、池层和全连接层是如何组成一个完整的CNN的。</p><p class="calibre10">如图<em class="calibre15">图5.11 </em>所示，卷积、池化和完全连接层共同形成一个端到端的学习模型，该模型采用原始数据，这些数据可以是高维的(例如，RGB图像)，并产生有意义的输出(例如，对象的类)。首先，卷积层学习图像的空间特征。较低的卷积层学习低级特征，例如图像中存在的不同方向的边缘，而较高的层学习更高级的特征，例如图像中存在的形状(例如，圆形和三角形)或对象的较大部分(例如，狗的脸、狗的尾巴和汽车的前部)。中间的池层使这些学习到的特性稍微具有平移不变性。这意味着，在新图像中，即使该特征与特征<a id="id326"/>在学习图像中出现的位置相比出现了一点偏移，CNN仍将识别该特征。最后，完全连接的层结合CNN学习的高级特征来产生全局表示，最终输出层将使用该全局表示来确定对象所属的类:</p><div><img alt="Putting everything together" src="img/B08681_05_53.jpg" class="calibre12"/><div><p class="calibre10">图5.11:将卷积层、池层和全连接层组合成一个CNN</p></div></div></div></div></body></html>


<html>
  <head>
    <title>Exercise – image classification on MNIST with CNN</title>
    <meta content="DocBook XSL Stylesheets V1.75.2" name="generator"/>
    <meta content="urn:uuid:7a74de9d-8dca-491a-886e-bcc2b2120efe" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title1"><a id="ch05lvl1sec37" class="calibre7"/>练习–CNN MNIST图片分类</h1></div></div></div><p class="calibre10">这将是我们<a id="id327"/>第一个使用CNN进行真实世界机器学习任务的例子。我们将使用CNN对图像进行分类。不从NLP任务开始的原因是，将CNN应用于NLP任务(例如，句子分类)不是很简单。使用CNN完成这样的任务有几个技巧。然而，最初，CNN被设计成处理图像数据。因此，让我们从那里开始，然后找到我们的方法，看看CNN如何应用于NLP任务。</p><div><div><div><div><h2 class="title3"><a id="ch05lvl2sec63" class="calibre7"/>关于数据</h2></div></div></div><p class="calibre10">在本练习中，我们将<a id="id328"/>使用计算机视觉社区中众所周知的数据集:MNIST数据集。MNIST数据集是从0到9的手写数字的标记图像的数据库。数据集包含三个不同的子数据集:训练集、验证集和测试集。我们<a id="id329"/>将在训练集上进行训练，并在未知的测试数据集上评估我们模型的性能。我们将使用验证数据集来提高模型的性能，并将其用作模型的监控机制。我们稍后将讨论细节。这是图像分类中最简单的任务之一，可以用一个简单的CNN很好地解决。我们将看到，我们可以达到大约98%的测试精度，而不需要任何特殊的调整或技巧。</p></div><div><div><div><div><h2 class="title3"><a id="ch05lvl2sec64" class="calibre7"/>实施CNN</h2></div></div></div><p class="calibre10">在这一小节中，我们将看看<a id="id330"/>CNN tensor flow实现中的一些重要代码片段。完整的代码可以在<code class="literal">ch5</code>文件夹的<code class="literal">image_classification_mnist.ipynb</code>中找到。首先，我们将为输入(图像)和输出(标签)定义TensorFlow占位符。然后，我们将定义一个全局步长，它将用于衰减学习率:</p><div><pre class="programlisting"># Inputs and Outputs Placeholders
tf_inputs = tf.placeholder(shape=[batch_size, image_size, image_size, n_channels],dtype=tf.float32,name='tf_mnist_images')
tf_labels = tf.placeholder(shape=[batch_size, n_classes],dtype=tf.float32,name='tf_mnist_labels')

# Global step for decaying the learning rate
global_step = tf.Variable(0,trainable=False)</pre></div><p class="calibre10">接下来，我们将定义张量流变量，它们是卷积权重和偏差以及全连接权重。我们将在一个名为<code class="literal">layer_hyperparameters</code>的Python字典中定义每个卷积层的过滤器大小、步幅和填充，每个池层的内核大小、步幅和填充，以及每个全连接层的输出单元数量:</p><div><pre class="programlisting"># Initializing the variables
layer_weights = {}
layer_biases = {}
for layer_id in cnn_layer_ids:
    if 'pool' not in layer_id:
        layer_weights[layer_id] = 
tf.Variable(initial_value=tf.random_normal(shape=layer_hyperparameters[layer_id]['weight_shape'],
stddev=0.02,dtype=tf.float32),name=layer_id+'_weights')
layer_biases[layer_id] = tf.Variable(initial_value=tf.random_normal(shape=[layer_hyperparameters[layer_id]['weight_shape'][-1]], stddev=0.01,dtype=tf.float32), name=layer_id+'_bias')</pre></div><p class="calibre10">我们还将定义logit计算。<strong class="calibre11">逻辑值</strong>是应用softmax激活前输出层的值。为了计算这个，我们将遍历每一层。</p><p class="calibre10">对于每个<a id="id331"/>卷积层，我们将使用以下公式对输入进行卷积:</p><div><pre class="programlisting">h = tf.nn.conv2d(h,layer_weights[layer_id],layer_hyperparameters[layer_id]['stride'],
layer_hyperparameters[layer_id]['padding']) + layer_biases[layer_id]</pre></div><p class="calibre10">这里，<code class="literal">tf.nn.conv2d</code>的输入<code class="literal">h</code>在第一次卷积中被替换为<code class="literal">tf_inputs</code>。记得我们在<a href="ch02.html" title="Chapter 2. Understanding TensorFlow">第二章</a>、<em class="calibre15">理解张量流</em>中详细讨论了我们反馈给<code class="literal">tf.nn.conv2d</code>的每个参数。但是，我们将简要回顾一下<code class="literal">tf.nn.conv2d</code>的论点。另外，<code class="literal">tf.nn.conv2d(input, filter, strides, padding)</code>按顺序接受以下参数值:</p><div><ul class="itemizedlist"><li class="listitem"><code class="literal">input</code>:这是卷积的输入，形状为<code class="literal">[batch size, input height, input width, input depth]</code></li><li class="listitem"><code class="literal">filter</code>:这是我们对输入进行卷积的卷积滤波器，其形状为<code class="literal">[filter height, filter width, input depth, output depth]</code></li><li class="listitem"><code class="literal">strides</code>:表示输入的每个维度上的步幅，形状为<code class="literal">[batch stride, height stride, width stride, depth stride]</code></li><li class="listitem"><code class="literal">padding</code>:表示填充的类型(可以是<code class="literal">'SAME'</code>或<code class="literal">'VALID'</code></li></ul></div><p class="calibre10">我们还应用如下的非线性激活:</p><div><pre class="programlisting">h = tf.nn.relu(h)</pre></div><p class="calibre10">然后，对于每个池层，我们使用以下内容对输入进行二次抽样:</p><div><pre class="programlisting">h = tf.nn.max_pool(h, layer_hyperparameters[layer_id]['kernel_shape'],layer_hyperparameters[layer_id]['stride'],
layer_hyperparameters[layer_id]['padding'])</pre></div><p class="calibre10"><code class="literal">tf.nn.max_pool(input, ksize, strides, padding)</code>函数按顺序接受以下参数:</p><div><ul class="itemizedlist"><li class="listitem"><code class="literal">input</code>:这是子样本的输入，形状为<code class="literal">[batch size, input height, input width, input depth]</code></li><li class="listitem"><code class="literal">ksize</code>:这是最大池操作<code class="literal">[batch kernel size, height kernel size, width kernel size, depth kernel size]</code>的每个维度上的内核大小</li><li class="listitem"><code class="literal">strides</code>:这是输入的每个维度上的步幅<code class="literal">[batch stride, height stride, width stride, depth stride]</code></li><li class="listitem"><code class="literal">padding</code>:可以是<code class="literal">'SAME'</code>或<code class="literal">'VALID'</code></li></ul></div><p class="calibre10">接下来，对于第一个完全连接的层，我们对输出进行整形:</p><div><pre class="programlisting">h = tf.reshape(h,[batch_size,-1])</pre></div><p class="calibre10">然后，我们将执行权重乘法和偏置加法，随后是非线性激活:</p><div><pre class="programlisting">h = tf.matmul(h,layer_weights[layer_id]) + layer_biases[layer_id]
h = tf.nn.relu(h)</pre></div><p class="calibre10">现在，我们可以计算逻辑:</p><div><pre class="programlisting">h = tf.matmul(h,layer_weights[layer_id]) + layer_biases[layer_id]</pre></div><p class="calibre10">我们将把<code class="literal">h</code>的最后一个值(最后一层的输出)分配给<code class="literal">tf_logits</code>,如下所示:</p><div><pre class="programlisting">tf_logits = h</pre></div><p class="calibre10">接下来，我们将定义softmax交叉熵损失，这是监督分类任务的常用损失函数:</p><div><pre class="programlisting">tf_loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=tf_logits,labels=tf_labels)</pre></div><p class="calibre10">我们还需要<a id="id332"/>定义一个学习率，每当验证精度在预定义的历元数内没有增加时，我们将学习率降低一个因子<code class="literal">0.5</code>(一个历元是对整个数据集的一次遍历)。这被称为<strong class="calibre11">学习率衰减</strong>:</p><div><pre class="programlisting">tf_learning_rate = tf.train.exponential_decay(learning_rate=0.001,global_step=global_step,decay_rate=0.5,decay_steps=1,staircase=True)</pre></div><p class="calibre10">接下来，我们将使用称为<code class="literal">RMSPropOptimizer</code>的优化器来定义损失最小化，该优化器已被发现比传统的<strong class="calibre11">随机梯度下降</strong> ( <strong class="calibre11"> SGD </strong>)性能更好，尤其是在计算视觉中:</p><div><pre class="programlisting">tf_loss_minimize = tf.train.RMSPropOptimizer(learning_rate=tf_learning_rate, momentum=0.9).minimize(tf_loss)</pre></div><p class="calibre10">最后，为了通过将预测标签与实际标签进行比较来计算预测的准确性，我们将定义以下预测计算函数:</p><div><pre class="programlisting">tf_predictions = tf.nn.softmax(tf_logits)</pre></div><p class="calibre10">您刚刚学习完我们用来创建第一个CNN的函数。您学习了使用函数来实现CNN结构以及定义损耗，最小化<a id="id333"/>损耗，并获得对未知数据的预测。我们使用了一个简单的CNN来看看它是否可以学习对手写图像进行分类。同样，我们能够用一个相当简单的CNN达到98%以上的准确率。接下来我们将分析CNN的一些结果。我们将看到为什么CNN不能正确识别一些图像。</p></div><div><div><div><div><h2 class="title3"><a id="ch05lvl2sec65" class="calibre7"/>分析CNN产生的预测</h2></div></div></div><p class="calibre10">这里我们可以随机<a id="id334"/>从测试集中挑选一些正确和错误分类的样本来评估CNN的学习能力(见<em class="calibre15">图5.12 </em>)。我们可以看到，对于正确分类的实例，CNN对输出非常有信心，这可以被视为学习算法的一个良好属性。然而，当我们评估错误分类的示例时，我们可以看到它们实际上很难，甚至一个人也可能弄错其中的一些(例如，第二行中左起第三幅图像)。对于不正确的样本，CNN通常不像对于正确的样本那样有信心，这也是一个好的特性。此外，即使最高置信度的答案对于错误分类的答案是错误的，正确的标签通常也不会被完全忽略，而是在预测值方面得到一些认可:</p><div><img alt="Analyzing the predictions produced with a CNN" src="img/B08681_05_54.jpg" class="calibre12"/><div><p class="calibre10">图5.12: MNIST正确分类和错误分类的实例</p></div></div></div></div></body></html>


<html>
  <head>
    <title>Using CNNs for sentence classification</title>
    <meta content="DocBook XSL Stylesheets V1.75.2" name="generator"/>
    <meta content="urn:uuid:7a74de9d-8dca-491a-886e-bcc2b2120efe" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title1"><a id="ch05lvl1sec38" class="calibre7"/>使用CNN进行句子分类</h1></div></div></div><p class="calibre10">尽管细胞神经网络主要用于计算机视觉任务，但没有什么能阻止它们在自然语言处理应用中的使用。CNN被有效使用的一个应用是句子分类。</p><p class="calibre10">在句子分类中，一个给定的句子应该被分类到一个类中。我们将使用一个问题数据库，其中每个问题都标有问题的内容。例如，问题“谁是亚伯拉罕·林肯？”将是一个问题，其标签将是<em class="calibre15">人</em>。为此，我们将使用http://cogcomp.org/Data/QA/QC/<a href="http://cogcomp.org/Data/QA/QC/">的句子分类数据集；在这里你会发现1000个训练句子和它们各自的标签，以及500个测试句子。</a></p><p class="calibre10">我们将使用Yoon Kim在论文中介绍的CNN网络，<em class="calibre15">用于句子分类的卷积神经网络</em>，来理解CNN对于NLP任务的价值。然而，使用CNN进行句子分类与我们讨论的MNIST的例子有些不同，因为操作(例如，卷积和合并)现在发生在一维<a id="id337"/>而不是二维<a id="id338"/>。此外，正如我们将很快看到的，汇集操作也将与正常的汇集操作有某些不同。您可以在<code class="literal">ch5</code>文件夹中的<code class="literal">cnn_sentence_classification.ipynb</code>文件中找到这个练习的代码。</p><div><div><div><div><h2 class="title3"><a id="ch05lvl2sec66" class="calibre7"/> CNN结构</h2></div></div></div><p class="calibre10">现在我们将讨论用于句子分类的CNN的技术细节。首先，我们将讨论如何将数据或句子转换成CNN可以轻松处理的首选格式。接下来，我们将讨论卷积和池运算如何适用于句子分类，最后，我们将讨论所有这些成分是如何连接的。</p><div><div><div><div><h3 class="title5"><a id="ch05lvl3sec20" class="calibre7"/>数据转换</h3></div></div></div><p class="calibre10">让我们假设一个<a id="id340"/>句的<em class="calibre15"> p </em>字。首先我们会用一些特殊的词来填充句子(如果句子长度是&lt; <em class="calibre15"> n </em>)来设置句子长度为<em class="calibre15"> n </em>个词，其中<img alt="Data transformation" src="img/B08681_05_55.jpg" class="calibre27"/>。接下来，我们将通过大小为<em class="calibre15"> k </em>的向量来表示句子中的每个单词，其中该向量可以是one-hot-encoded表示，也可以是使用skip-gram、CBOW或GloVe学习的Word2vec单词向量。那么一批大小为<em class="calibre15"> b </em>的句子可以用一个<img alt="Data transformation" src="img/B08681_05_56.jpg" class="calibre27"/>矩阵来表示。</p><p class="calibre10">让我们看一个例子。我们来考虑以下三句话:</p><div><ul class="itemizedlist"><li class="listitem">鲍勃和玛丽是朋友。</li><li class="listitem">鲍勃踢足球。</li><li class="listitem">玛丽喜欢在唱诗班唱歌。</li></ul></div><p class="calibre10">在这个例子中，第三句话的字数最多，所以我们设置<img alt="Data transformation" src="img/B08681_05_57.jpg" class="calibre27"/>，这是第三句话的字数。接下来，让我们看看每个单词的一位热编码表示。在这种情况下，有13个不同的单词。因此，我们得到这个:</p><p class="calibre10">鲍勃:1，0，0，0，0，0，0，0，0，0，0，0，0</p><p class="calibre10"><em class="calibre15">和:0，1，0，0，0，0，0，0，0，0，0，0 </em></p><p class="calibre10">玛丽:0，0，1，0，0，0，0，0，0，0，0，0，0</p><p class="calibre10">同样，<img alt="Data transformation" src="img/B08681_05_58.jpg" class="calibre27"/>出于同样的原因。有了这个表示，我们可以把三个句子表示成一个大小为<img alt="Data transformation" src="img/B08681_05_59.jpg" class="calibre27"/>的三维<a id="id341"/>矩阵，如图<em class="calibre15">图5.13 </em>所示:</p><div><img alt="Data transformation" src="img/B08681_05_60.jpg" class="calibre12"/><div><p class="calibre10">图5.13:句子矩阵</p></div></div></div><div><div><div><div><h3 class="title5"><a id="ch05lvl3sec21" class="calibre7"/>卷积运算</h3></div></div></div><p class="calibre10">如果忽略批量大小，也就是说如果我们<a id="id342"/>假设我们一次只处理一个单句，我们的数据就是一个<img alt="The convolution operation" src="img/B08681_05_61.jpg" class="calibre27"/>矩阵，其中<em class="calibre15"> n </em>是填充后每句话的字数，<em class="calibre15"> k </em>是单个单词向量的维数。在我们的例子中，这将是<img alt="The convolution operation" src="img/B08681_05_62.jpg" class="calibre27"/>。</p><p class="calibre10">现在我们将定义卷积权重矩阵的大小为<img alt="The convolution operation" src="img/B08681_05_63.jpg" class="calibre27"/>，其中<em class="calibre15"> m </em>是一维卷积运算的滤波器大小。通过将大小为<img alt="The convolution operation" src="img/B08681_05_64.jpg" class="calibre27"/>的输入<em class="calibre15"> x </em>与大小为<img alt="The convolution operation" src="img/B08681_05_65.jpg" class="calibre27"/>的权重矩阵<em class="calibre15"> W </em>进行卷积，我们将产生大小为<img alt="The convolution operation" src="img/B08681_05_66.jpg" class="calibre27"/>的输出<em class="calibre15"> h </em>，如下所示:</p><div><img alt="The convolution operation" src="img/B08681_05_67.jpg" class="calibre12"/></div><p class="calibre10">这里，<em class="calibre15"> w <sub class="calibre17"> i，j</sub>T15】是<em class="calibre15"> W </em>的第<em class="calibre15"> (i，j)<sup class="calibre26"/></em>个元素，我们将用零填充<em class="calibre15"> x </em>，这样<em class="calibre15"> h </em>的大小就是<img alt="The convolution operation" src="img/B08681_05_68.jpg" class="calibre27"/>。此外，我们将更简单地定义此操作，如下所示:</em></p><div><img alt="The convolution operation" src="img/B08681_05_69.jpg" class="calibre12"/></div><p class="calibre10">这里，<em class="calibre15"> * </em>定义了卷积运算(带填充)，我们将添加一个额外的标量偏移<em class="calibre15"> b </em>。<em class="calibre15">图5.14 </em>说明了该操作:</p><div><img alt="The convolution operation" src="img/B08681_05_70.jpg" class="calibre12"/><div><p class="calibre10">图5.14:句子分类的卷积运算</p></div></div><p class="calibre10">然后，为了学习一组丰富的特性，我们有不同卷积滤波器大小的平行层。每个卷积层输出一个大小为<img alt="The convolution operation" src="img/B08681_05_71.jpg" class="calibre27"/>的隐藏向量，我们将连接这些输出以形成下一个大小为<img alt="The convolution operation" src="img/B08681_05_72.jpg" class="calibre27"/>的层的输入，其中<em class="calibre15"> q </em>是我们将使用的并行层数。<em class="calibre15"> q </em>越大，模型性能越好。</p><p class="calibre10">卷积的价值可以通过以下方式来理解。思考电影分级学习问题(有两个类，正面或负面)，我们有以下句子:</p><div><ul class="itemizedlist"><li class="listitem">我喜欢这部电影，还不错</li><li class="listitem"><em class="calibre15">我不喜欢这部电影，不好</em></li></ul></div><p class="calibre10">现在想象<a id="id344"/>一个大小为5的卷积窗。让我们根据卷积窗的移动来对单词进行分类。</p><p class="calibre10">句子<em class="calibre15">我喜欢这部电影，不太坏</em>给出:</p><p class="calibre10"><em class="calibre15">【我，喜欢，电影，’，’】</em></p><p class="calibre10"><em class="calibre15">【喜欢，那个，电影，‘，‘，不是】</em></p><p class="calibre10"><em class="calibre15">【那个，电影，‘，’，不也是】</em></p><p class="calibre10"><em class="calibre15">【电影，‘，‘，不算太差】</em></p><p class="calibre10">句子<em class="calibre15">我不喜欢这部电影，不好的</em>给出如下:</p><p class="calibre10"><em class="calibre15">【我，做了，不，喜欢了】</em></p><p class="calibre10"><em class="calibre15">【有，没有，喜欢，电影】</em></p><p class="calibre10"><em class="calibre15">【不是，喜欢，电影，’，’】</em></p><p class="calibre10"><em class="calibre15">【喜欢，那个，电影，‘，’，坏】</em></p><p class="calibre10">对于第一句，如下所示的窗口表示评级为正面:</p><p class="calibre10"><em class="calibre15">【我，喜欢，电影，’，’】</em></p><p class="calibre10"><em class="calibre15">【电影，‘，‘，不算太差】</em></p><p class="calibre10">但是，对于第二句话，如下所示的窗口传达了评级中的负面信息:</p><p class="calibre10"><em class="calibre15">【做了，不喜欢，电影】</em></p><p class="calibre10">由于保留了空间性，我们能够看到有助于分级的模式。例如，如果您使用像<em class="calibre15">单词袋</em>这样的技术来计算丢失空间信息的句子表示，句子表示将高度相似。卷积运算在保持句子的空间信息方面起着重要的作用。</p><p class="calibre10">由于不同的层具有不同的过滤器尺寸，网络学习用不同尺寸的短语提取评级，导致性能的提高。</p></div></div><div><div><div><div><h2 class="title3"><a id="ch05lvl2sec67" class="calibre7"/>一段时间内的汇集</h2></div></div></div><p class="calibre10">汇集操作旨在对之前讨论的并行<a id="id345"/>卷积层产生的输出进行二次采样。这是通过以下方式实现的。</p><p class="calibre10">假设最后一层<em class="calibre15"> h </em>的输出大小为<img alt="Pooling over time" src="img/B08681_05_73.jpg" class="calibre27"/>。随时间的汇集层将产生大小为<img alt="Pooling over time" src="img/B08681_05_74.jpg" class="calibre27"/>输出的输出<em class="calibre15">h’</em>。精确的计算如下:</p><div><img alt="Pooling over time" src="img/B08681_05_75.jpg" class="calibre12"/></div><p class="calibre10">这里，<img alt="Pooling over time" src="img/B08681_05_76.jpg" class="calibre27"/>和<em class="calibre15"> h </em> <em class="calibre15"> (i) </em>是由<img alt="Pooling over time" src="img/B08681_05_77.jpg" class="calibre27"/>卷积层产生的输出，<img alt="Pooling over time" src="img/B08681_05_78.jpg" class="calibre27"/>是属于该层的一组权重。简而言之，随时间汇集操作通过连接每个卷积图层的最大元素来创建矢量。我们将在<em class="calibre15">图5.15 </em>中说明该操作:</p><div><img alt="Pooling over time" src="img/B08681_05_79.jpg" class="calibre12"/><div><p class="calibre10">图5.15:句子分类的随时间汇集操作</p></div></div><p class="calibre10">通过组合<a id="id346"/>这些操作，我们最终得到了<em class="calibre15">图5.16 </em>所示的架构:</p><div><img alt="Pooling over time" src="img/B08681_05_80.jpg" class="calibre12"/><div><p class="calibre10">5.16:句子分类CNN架构</p></div></div></div><div><div><div><div><h2 class="title3"><a id="ch05lvl2sec68" class="calibre7"/>实施–使用CNN进行句子分类</h2></div></div></div><p class="calibre10">首先，我们将定义<a id="id347"/>输入和输出。输入将是一批句子，其中的单词由一位热编码的单词向量表示——单词嵌入将比一位热编码的表示提供更好的性能；然而，为了简单起见，我们将使用一个热编码的表示:</p><div><pre class="programlisting">sent_inputs = tf.placeholder(shape=[batch_size,sent_length,vocabulary_size],dtype=tf.float32,name='sentence_inputs')
sent_labels = tf.placeholder(shape=[batch_size,num_classes],dtype=tf.float32,name='sentence_labels')</pre></div><p class="calibre10">这里，我们将定义三个不同的一维卷积层，它们具有三种不同的滤波器尺寸<code class="literal">3</code>、<code class="literal">5</code>和<code class="literal">7</code>(在<code class="literal">filter_sizes</code>中以列表形式提供)以及它们各自的偏差:</p><div><pre class="programlisting">w1 = tf.Variable(tf.truncated_normal([filter_sizes[0],vocabulary_size,1],stddev=0.02,dtype=tf.float32),name='weights_1')
b1 = tf.Variable(tf.random_uniform([1],0,0.01,dtype=tf.float32),name='bias_1')

w2 = tf.Variable(tf.truncated_normal([filter_sizes[1],vocabulary_size,1],stddev=0.02,dtype=tf.float32),name='weights_2')
b2 = tf.Variable(tf.random_uniform([1],0,0.01,dtype=tf.float32),name='bias_2')

w3 = tf.Variable(tf.truncated_normal([filter_sizes[2],vocabulary_size,1],stddev=0.02,dtype=tf.float32),name='weights_3')
b3 = tf.Variable(tf.random_uniform([1],0,0.01,dtype=tf.float32),name='bias_3')</pre></div><p class="calibre10">现在，我们将计算三个输出，每个输出都属于一个卷积层，正如我们刚刚定义的那样。这可以用TensorFlow中提供的<code class="literal">tf.nn.conv1d</code>函数很容易地计算出来。我们使用步长<code class="literal">1</code>和零填充来确保输出与输入具有相同的大小:</p><div><pre class="programlisting">h1_1 = tf.nn.relu(tf.nn.conv1d(sent_inputs,w1,stride=1,padding='SAME') + b1)
h1_2 = tf.nn.relu(tf.nn.conv1d(sent_inputs,w2,stride=1,padding='SAME') + b2)
h1_3 = tf.nn.relu(tf.nn.conv1d(sent_inputs,w3,stride=1,padding='SAME') + b3)</pre></div><p class="calibre10">为了随时间计算max <a id="id348"/> pooling，我们需要在TensorFlow中编写基本函数来完成这项工作，因为TensorFlow没有为我们完成这项工作的原生函数。然而，编写这些函数是相当容易的。</p><p class="calibre10">首先，我们将计算每个卷积层产生的每个隐藏输出的最大值。这导致每个层只有一个标量:</p><div><pre class="programlisting">h2_1 = tf.reduce_max(h1_1,axis=1)
h2_2 = tf.reduce_max(h1_2,axis=1)
h2_3 = tf.reduce_max(h1_3,axis=1)</pre></div><p class="calibre10">然后，我们将连接轴<code class="literal">1</code>(宽度)上产生的输出，以产生大小为<img alt="Implementation – sentence classification with CNNs" src="img/B08681_05_81.jpg" class="calibre27"/>的输出:</p><div><pre class="programlisting">h2 = tf.concat([h2_1,h2_2,h2_3],axis=1)</pre></div><p class="calibre10">接下来，我们将定义完全连接的层，这些层将完全连接到由随时间池化层产生的输出<img alt="Implementation – sentence classification with CNNs" src="img/B08681_05_82.jpg" class="calibre27"/>。在这种情况下，只有一个完全连接的层，这也将是我们的输出层:</p><div><pre class="programlisting">w_fc1 = tf.Variable(tf.truncated_normal([len(filter_sizes),num_classes],stddev=0.5,dtype=tf.float32),name='weights_fulcon_1')
b_fc1 = tf.Variable(tf.random_uniform([num_classes],0,0.01,dtype=tf.float32),name='bias_fulcon_1')</pre></div><p class="calibre10">此处定义的函数将产生用于计算网络损耗的逻辑值:</p><div><pre class="programlisting">logits = tf.matmul(h2,w_fc1) + b_fc1</pre></div><p class="calibre10">这里，通过<a id="id349"/>将softmax激活应用于逻辑，我们将获得预测:</p><div><pre class="programlisting">predictions = tf.argmax(tf.nn.softmax(logits),axis=1)</pre></div><p class="calibre10">此外，我们将定义<code class="literal">loss</code>函数，它是交叉熵损失:</p><div><pre class="programlisting">loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=sent_labels,logits=logits))</pre></div><p class="calibre10">为了优化网络，我们将使用名为<code class="literal">MomentumOptimizer</code>的TensorFlow内置优化器:</p><div><pre class="programlisting">optimizer = tf.train.MomentumOptimizer(learning_rate=0.01,momentum=0.9).minimize(loss)</pre></div><p class="calibre10">运行这些前面定义的操作来优化CNN并评估练习中给出的测试数据，在这个句子分类任务中给我们提供了接近90%的测试准确度(500个测试句子)。</p><p class="calibre10">这里我们结束关于使用CNN进行句子分类的讨论。我们首先讨论了如何将一维卷积运算与一种称为<em class="calibre15">随时间池化</em>的特殊池化运算相结合，来实现基于CNN架构的句子分类器。最后，我们讨论了如何使用TensorFlow来实现这样的CNN，并看到它实际上在句子分类中表现良好。</p><p class="calibre10">知道我们刚刚解决的问题如何在现实世界中有用是很有用的。假设你手里有一大份关于罗马历史的文件，你想在不阅读整份文件的情况下了解朱利叶斯·凯撒。在这种情况下，我们刚刚实现的句子分类器可以作为一个方便的工具，用来总结只对应于一个人的句子，所以你不必阅读整个文档。</p><p class="calibre10">句子分类也可以用于许多其他任务；这种方法的一个常见用途是将电影评论分为正面或负面，这对自动计算<a id="id350"/>电影评级很有用。句子分类的另一个重要应用可以在医学领域看到，它是从包含大量文本的大型文档中提取临床上有用的句子。</p></div></div></body></html>


<html>
  <head>
    <title>Summary</title>
    <meta content="DocBook XSL Stylesheets V1.75.2" name="generator"/>
    <meta content="urn:uuid:7a74de9d-8dca-491a-886e-bcc2b2120efe" name="Adept.expected.resource"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title1"><a id="ch05lvl1sec39" class="calibre7"/>总结</h1></div></div></div><p class="calibre10">在这一章中，我们讨论了CNN及其各种应用。首先，我们详细解释了什么是CNN，以及它们在机器学习任务中表现出色的能力。接下来，我们将CNN分解成几个部分，比如卷积层和池层，并详细讨论了这些操作符是如何工作的。此外，我们讨论了与这些操作符相关的几个超参数，如过滤器大小、步幅和填充。然后，为了说明CNN的功能，我们通过一个简单的例子将手写数字图像分类到相应的图像。我们也做了一点分析，看看为什么CNN不能正确识别一些图像。最后，我们开始讨论CNN如何应用于NLP任务。具体地说，我们讨论了一种可以用来对句子进行分类的改变的CNN结构。然后，我们实现了这个特定的CNN架构，并在一个实际的句子分类任务上对其进行了测试。</p><p class="calibre10">在下一章中，我们将继续讨论用于许多NLP任务的最流行的神经网络类型之一— <strong class="calibre11">递归神经网络</strong> ( <strong class="calibre11"> RNNs </strong>)。</p></div></body></html>
</body></html>