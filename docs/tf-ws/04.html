<html><head/><body>


	
		<title>B16341_04_ePub</title>
		
	
	
		<div><div/>
		</div>
		<div><h1 id="_idParaDest-77"><a id="_idTextAnchor077"/> 4。回归和分类模型</h1>
		</div>
		<div><p class="callout-heading">概观</p>
			<p class="callout">在本章中，您将学习如何使用TensorFlow构建回归和分类模型。您将使用TensorFlow利用Keras层构建模型，Keras层是一种简单的模型构建方法，提供了用于构建和训练模型的高级API。您将创建模型来解决回归和分类任务，包括各种分子结合属性的分类。您还将使用TensorBoard来可视化TensorFlow模型的架构并查看培训过程。</p>
			<h1 id="_idParaDest-78"><a id="_idTextAnchor078"/>简介</h1>
			<p>在前一章中，您学习了如何使用一些TensorFlow资源来帮助开发。其中包括TensorBoard(用于可视化计算图形)、TensorFlow Hub(机器学习模块的在线存储库)和Google Colab(用于在Google服务器上运行代码的在线Python开发环境)。所有这些资源都有助于机器学习实践者高效地开发模型。</p>
			<p>在本章中，您将探索如何使用TensorFlow创建人工神经网络。您将构建具有不同架构的人工神经网络来解决回归和分类任务。回归任务旨在从输入训练数据中预测连续变量，而分类任务旨在将输入数据分类为两个或更多个类别。例如，预测某一天是否会下雨的模型是一项分类任务，因为模型的结果将分为两类——下雨或不下雨。但是，预测某一天降雨量的模型就是回归任务的一个例子，因为模型的输出是一个连续变量，即降雨量。</p>
			<p>用于处理这些任务的模型代表了一大类机器学习模型，大量的机器学习问题属于这两类。本章将演示如何在TensorFlow中创建、训练和评估回归和分类模型。您将使用前面章节中的大部分知识(包括使用TensorBoard监控模型训练过程)来理解如何构建高性能模型。</p>
			<p>本章介绍了用于构建人工神经网络的各种参数(称为<strong class="bold">超参数</strong>，包括激活函数、损失函数和优化器。在模型拟合过程中选择的其他超参数包括历元数和批量大小，它们分别改变使用整个数据集来更新权重的次数和每次更新的数据点数。您还将学习如何在模型拟合过程中记录变量，以便它们可以在TensorBoard中可视化。这使您可以确定模型是欠拟合还是过拟合训练数据。最后，在构建模型后，您将学习如何在数据集上对其进行评估，以了解其表现如何。</p>
			<h1 id="_idParaDest-79"><a id="_idTextAnchor079"/>顺序模型</h1>
			<p>序列模型用于建立回归和分类模型。在顺序模型中，信息通过网络从开始的输入层传播到最后的输出层。模型中的层按顺序堆叠，每层都有一个输入和一个输出。</p>
			<p>还存在其他类型的人工神经网络模型，如递归神经网络(其中输出反馈到输入)，这将在后面的章节中介绍。顺序神经网络和递归神经网络的区别如图<em class="italic">图4.01 </em>所示。在这两个模型中，信息从输入层通过隐藏层流向输出层，如箭头方向所示。然而，在递归架构中，隐藏层的输出反馈到隐藏层的输入中:</p>
			<div><div><img src="img/B16341_04_01.jpg" alt="Figure 4.1: The architectures of sequential and recurrent ANNs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图4.1:顺序和循环人工神经网络的架构</p>
			<p>在下一节中，您将学习如何在TensorFlow中创建序列模型，这些模型构成了回归和分类模型的基础。您将利用Keras API，它现在作为TensorFlow库的一部分包含在序列模型中，因为高级API为创建这些模型提供了一个简单的接口。使用这个API，你会发现向一个模型中添加更多的层是非常容易的，并且对于学习这个领域的新手来说是非常好的。</p>
			<p>顺序模型可以初始化如下:</p>
			<pre>model = tf.keras.Sequential()</pre>
			<p>一旦模型被初始化，层可以被添加到模型中。在本节中，您还将探索如何将Keras层添加到模型中。</p>
			<h2 id="_idParaDest-80"><a id="_idTextAnchor080"/>喀拉斯层</h2>
			<p>Keras图层包含在TensorFlow包中。Keras层是常用层的集合，可以很容易地添加到顺序模型中。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">你可以在这里查看Keras图层的所有可能选项:<a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers">https://www.tensorflow.org/api_docs/python/tf/keras/layers</a>。</p>
			<p>要向<code>Sequential</code>类的模型添加层，您可以使用模型的<code>add</code>方法。可以添加到顺序模型开始的一个可选层是作为网络入口点的<strong class="bold">输入层</strong>。输入图层可以采用以下常见输入参数:</p>
			<ul>
				<li><code>input_shape</code>(必选):输入张量的形状，不包括批处理轴</li>
				<li><code>batch_size</code>:可选参数，表示输入批量</li>
				<li><code>name</code>:输入层的可选名称</li>
			</ul>
			<p>可以按如下方式将输入图层添加到模型中。以下代码片段用于添加图层，预期输入具有八个特征:</p>
			<pre>model.add(tf.keras.layers.InputLayer(input_shape=(8,), \
                                     name='Input_layer'))</pre>
			<p>通过提供一个<code>name</code>参数，您可以标记层，这在TensorBoard中可视化模型时会很有用。构建回归和分类模型时通常使用的另一种类型的层是作为参数提供的<code>input_shape</code>。以下是<code>Dense</code>类各层的常见输入参数:</p>
			<ul>
				<li><code>units</code>(必选):这是一个正整数，表示层中的单元数。</li>
				<li><code>input_shape</code>:这是输入张量的形状，但不是必需的，除非它是模型的第一层。</li>
				<li><code>activation</code>:可选参数，表示将哪个激活函数应用于层的输出。</li>
				<li><code>use_bias</code>:这是一个布尔参数，指示是否在层中使用偏置。默认设置为<code>True</code>。</li>
				<li><code>name</code>:这是指层的名称。如果不提供此参数，将会生成一个。</li>
				<li>这是内核权重的初始化器。默认使用<strong class="bold"> Glorot统一初始化器</strong>，其正态分布以零为中心，标准偏差取决于层中的单元数量。</li>
				<li><code>bias_initializer</code>:这是偏向的初始化器。该参数的默认值用于将偏置值设置为零。</li>
				<li><code>kernel_regularizer</code>:这是用于内核权重的正则化器。默认情况下没有应用。</li>
				<li><code>bias_regularizer</code>:这是用于偏差的正则化子。默认情况下没有应用。</li>
			</ul>
			<p>下面是一个例子，将一个密集层添加到一个具有<code>12</code>单元的模型，在层的输出处添加一个<code>sigmoid</code>激活函数，并将层命名为<code>Dense_layer_1</code>:</p>
			<pre>model.add(tf.keras.layers.Dense(units=12, name='Dense_layer_1', \
                                activation='sigmoid'))</pre>
			<p>现在您已经了解了如何初始化顺序模型并向其添加层，您将在第一个练习中使用TensorFlow创建一个Keras顺序模型。您将初始化模型，向模型添加层，向模型的输出添加激活函数，并通过模型传递数据来模拟创建预测。</p>
			<h2 id="_idParaDest-81"><a id="_idTextAnchor081"/>练习4.01:使用张量流创建人工神经网络</h2>
			<p>在本练习中，您将在TensorFlow中创建第一个顺序ANN。你将有一个输入层，一个有四个单元和一个ReLU激活函数的隐藏层，和一个有一个单元的输出层。然后，您将通过生成随机数并将其传递给模型来创建一些模拟数据，使用模型的<code>predict</code>方法来模拟每个数据示例的预测。</p>
			<p>执行以下步骤来完成练习:</p>
			<ol>
				<li>打开Jupyter笔记本，导入TensorFlow库:<pre>import tensorflow as tf</pre></li>
				<li>初始化顺序类的Keras模型:<pre>model = tf.keras.Sequential()</pre></li>
				<li>使用模型的<code>add</code>方法向模型添加一个输入图层，并添加大小为<code>(8,)</code>的<code>input_shape</code>参数，以八个特征表示输入数据:<pre>model.add(tf.keras.layers.InputLayer(input_shape=(8,), \                                      name='Input_layer'))</pre></li>
				<li>向模型中添加两层<code>Dense</code>类。第一个用四个单元和一个ReLU激活函数表示你的隐藏层，第二个用一个单元表示你的输出层:<pre>model.add(tf.keras.layers.Dense(4, activation='relu', \                                 name='First_hidden_layer')) model.add(tf.keras.layers.Dense(1, name='Output_layer'))</pre></li>
				<li>View the weights by calling the <code>variables</code> attribute of the model:<pre>model.variables</pre><p>您应该得到以下输出:</p><div><img src="img/B16341_04_02.jpg" alt="Figure 4.2: The variables of the ANN&#13;&#10;"/></div><p class="figure-caption">图4.2:人工神经网络的变量</p><p>此输出显示了组成模型的所有变量；它们包括每个图层中所有权重和偏差的值。</p></li>
				<li>创建一个大小为<code>32x8</code>的张量，它代表一个有32条记录和8个特征的张量:<pre>data = tf.random.normal((32,8))</pre></li>
				<li>Call the <code>predict</code> method of the model and pass in the sample data:<pre>model.predict(data)
prediction</pre><p>您应该会得到以下结果:</p><div><img src="img/B16341_04_03.jpg" alt="Figure 4.3: The output of the ANN after random inputs have been applied&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">图4.3:应用随机输入后人工神经网络的输出</p>
			<p>对样本数据调用<code>predict()</code>方法将通过网络传播数据。在每一层中，将存在数据与权重的矩阵乘法，并且将在数据作为输入数据被传递到下一层之前添加偏差。这个过程一直持续到最后的输出层。</p>
			<p>在本练习中，您创建了一个具有多个层的连续模型。您初始化了一个模型，添加了一个输入图层来接受具有八个要素的数据，添加了一个具有四个单位的隐藏图层，并添加了一个具有一个单位的输出图层。在将模型拟合到训练数据之前，必须首先使用优化器编译模型，并选择一个损失函数，通过在训练过程中更新权重来最小化它计算的值。</p>
			<p>在下一节中，您将探索如何编译模型，然后使它们适合训练数据。</p>
			<h1 id="_idParaDest-82"><a id="_idTextAnchor082"/>模型拟合</h1>
			<p>一旦模型被初始化并且层被添加到ANN中，模型必须通过编译过程配置有优化器、损耗和任何评估度量。可以使用模型的<code>compile</code>方法编译模型，如下所示:</p>
			<pre>model.compile(optimizer='adam', loss='binary_crossentropy', \
              metrics=['accuracy'])</pre>
			<p>可以通过简单地将优化器命名为参数来选择优化器。以下优化器是Keras模型的默认选项:</p>
			<ul>
				<li><strong class="bold">随机梯度下降</strong> ( <strong class="bold"> SGD </strong>):更新数据集中每个例子的权重。你可以在这里找到更多关于SGD的信息:<a href="https://keras.io/api/optimizers/sgd/">https://keras.io/api/optimizers/sgd/</a>。</li>
				<li>RMSprop :这是一个自适应优化器，它在每次更新时通过使用梯度的衰减平均值来改变训练期间的权重。你可以在这里找到更多关于RMSprop的信息:【https://keras.io/api/optimizers/rmsprop/<a href="https://keras.io/api/optimizers/rmsprop/">。</a></li>
				<li><strong class="bold"> Adam </strong>:这也是一个实现Adam算法的自适应优化器，根据一阶和二阶梯度更新学习率。你可以在这里找到更多关于亚当的信息:<a href="https://keras.io/api/optimizers/adam/">https://keras.io/api/optimizers/adam/</a>。</li>
				<li><strong class="bold"> Adagrad </strong>:这种自适应梯度优化器在每次权重更新时调整学习率。使用先验梯度和观测值来调整每个特征的学习速率。你可以在这里找到更多关于阿达格勒的信息:<a href="https://keras.io/api/optimizers/adagrad/">https://keras.io/api/optimizers/adagrad/</a>。</li>
				<li><strong class="bold"> Adadelta </strong>:这是Adagrad的一个更健壮的版本，它使用梯度更新的滑动窗口来适应学习速率。你可以在这里找到更多关于阿达德尔塔的信息:<a href="https://keras.io/api/optimizers/adadelta/">https://keras.io/api/optimizers/adadelta/</a>。</li>
				<li><strong class="bold"> Adamax </strong>:这是一个自适应优化器，是Adam优化器的变体。你可以在这里找到更多关于Adamax的信息:<a href="https://keras.io/api/optimizers/adamax/">https://keras.io/api/optimizers/adamax/</a>。</li>
				<li>Nadam :这是另一个自适应优化器，是带有内斯特罗夫动量的adam优化器的变体。你可以在这里找到更多关于那达慕的信息:<a href="https://keras.io/api/optimizers/Nadam/">https://keras.io/api/optimizers/Nadam/</a>。</li>
				<li>这是一个实现Ftrl算法的优化器。你可以在这里找到更多关于Ftrl的信息:<a href="https://keras.io/api/optimizers/ftrl/">https://keras.io/api/optimizers/ftrl/</a>。</li>
			</ul>
			<p>如果提供的优化器不相关，也可以将自定义优化器添加到Keras模型中。选择最合适的优化器通常需要尝试每一种优化器，并确定哪一种优化器产生的错误最小。这个过程被称为<strong class="bold">超参数调整</strong>，将在后面的章节中介绍。在下一节中，您将发现编译模型时的另一个选项:损失函数。训练模型的目标是最小化由损失函数计算的值。</p>
			<h2 id="_idParaDest-83"><a id="_idTextAnchor083"/>损失函数</h2>
			<p>损失函数是预测结果和真实结果之间的误差的度量。您可以在训练过程中使用损失函数来确定改变任何权重和偏差是否会通过优化过程最小化损失函数的值来创建更好的模型。</p>
			<p>有许多不同类型的损失函数可以使用，具体的损失函数将取决于问题和目标。一般来说，回归和分类任务会有不同的损失函数。由于回归模型预测连续变量，回归模型的损失函数通常旨在总结预测值与真实值的平均差距。对于分类模型，损失函数旨在确定预测类的真阳性、真阴性、假阳性和假阴性分类的数量与真实类相比如何变化。</p>
			<p><strong class="bold">真阳性</strong>被定义为被分类器标记为阳性的正确预测；类似地，<strong class="bold">真否定</strong>是标记为否定的正确预测。<strong class="bold">假阳性</strong>是在真值为负的情况下标记为阳性的预测，而<strong class="bold">假阴性</strong>是标记为阴性但实际为阳性的预测。可直接用于Keras序列回归模型的损失函数包括:</p>
			<ul>
				<li><code>(true value – predicted value)^2</code>，并返回整个数据集的平均值。该损失函数主要用于回归问题，两个值之差的平方确保损失函数的结果为正数。</li>
				<li><code>|true value – predicted value|</code>，并返回整个数据集的平均值。该方法还确保结果为正值。</li>
				<li><code>|(true value– predicted value) / true value|</code>，并以百分比形式返回整个数据集的平均值。</li>
			</ul>
			<p>对于分类，可用的损失函数包括:</p>
			<ul>
				<li><code>0</code>和<code>1</code>，越接近<code>1</code>的值代表越多的真实肯定分类。</li>
				<li><code>0</code>和<code>1</code>。</li>
			</ul>
			<p>在编译模型时，其他指标也可以作为参数传递给方法。它们将在每个历元后计算，并在训练过程中保存。可用于计算Keras模型的指标包括:</p>
			<ul>
				<li><strong class="bold">准确率</strong>:正确结果占总结果的比例。</li>
				<li><strong class="bold"> Precision </strong>:这是预测的总阳性中真正阳性的比例。</li>
				<li><strong class="bold">回忆</strong>:这是实际阳性中真阳性的比例。</li>
				<li><strong class="bold"> AUC </strong>:该指标代表ROC曲线下的面积。</li>
			</ul>
			<p>这些指标对于理解模型在训练过程中的表现非常有价值。所有指标的值都在<code>0</code>和<code>1</code>之间，值越高代表性能越好。一旦模型被编译，它就可以适合训练数据。这可以通过调用<code>fit</code>方法并传入以下参数来实现:</p>
			<ul>
				<li><code>x</code>:这是作为TensorFlow张量或NumPy数组的特征数据。</li>
				<li><code>y</code>:这是作为TensorFlow张量或NumPy数组的目标数据。</li>
				<li><code>epochs</code>:指运行模型的时期数。一个历元是对整个训练数据集的迭代。</li>
				<li><code>batch_size</code>:这是每次梯度更新使用的训练数据样本的数量。</li>
				<li><code>validation_split</code>:这是在每个时期后评估的用于验证的训练数据的比例。权重更新流程中不使用这部分数据。</li>
				<li><code>shuffle</code>:表示是否在每个历元之前混洗训练数据。</li>
			</ul>
			<p>为了使模型符合训练数据，可通过以下方式将<code>fit</code>方法应用于模型:</p>
			<pre>model.fit(x=features, y=target, epochs=10, batch_size=32, \
         validation_split=0.2, shuffle=False)</pre>
			<p>一旦调用了<code>fit</code>方法，模型将开始拟合训练数据。在每个时期之后，损失被返回用于训练。如果定义了验证分割，则损失也在验证分割中进行评估。</p>
			<h2 id="_idParaDest-84"><a id="_idTextAnchor084"/>模型评估</h2>
			<p>一旦模型被训练，就可以利用模型的<code>evaluate</code>方法对它们进行评估。<code>evaluate</code>方法根据用于训练模型的损失函数和传递给模型的任何指标来评估模型的性能。当通过传入尚未在训练过程中使用的要素和目标数据集或样本外数据集来确定模型将如何对新的、看不见的数据执行时，最好使用该方法。该方法可以按如下方式调用:</p>
			<pre>eval_metrics = model.evaluate(features, target)</pre>
			<p>该方法的结果首先是根据输入数据计算的损失，然后，如果在模型编译过程中传递了任何指标，则在执行<code>evaluate</code>方法时也会计算这些指标。模型评估是决定模型性能的重要步骤。由于存在大量的超参数(例如隐藏层的数量、每层中单元的数量以及激活函数的选择，等等)，模型评估对于确定超参数的哪个组合是最优的是必要的。有效的模型评估有助于提供一个公正的观点，即哪种模型架构整体性能最好。</p>
			<p>在下面的练习中，您将执行创建ANN、编译模型、将模型拟合到定型数据，以及最后根据定型数据评估模型的过程。您将使用ANN重新创建线性回归算法，ANN可以解释为只有一个层和一个单元的ANN。此外，您将在TensorBoard中查看模型的架构和模型培训流程。</p>
			<h2 id="_idParaDest-85"><a id="_idTextAnchor085"/>练习4.02:使用TensorFlow创建一个线性回归模型作为ANN</h2>
			<p>在本练习中，您将使用TensorFlow创建一个线性回归模型作为ANN。数据集<code>Bias_correction_ucl.csv</code>描述了韩国首尔气温预报的偏差修正。这些字段表示给定日期的温度测量值、测量指标的气象站、与天气相关的指标(如湿度)的模型预测以及第二天的温度预测。您需要根据气象站先前时间点和属性的测量值来预测下一个最高和最低温度。</p>
			<p class="callout-heading">注意</p>
			<p class="callout"><code>Bias_correction_ucl.csv</code>文件可以在这里找到:<a href="https://packt.link/khfeF">https://packt.link/khfeF</a>。</p>
			<p>执行以下步骤来完成本练习:</p>
			<ol>
				<li value="1">打开一个新的Jupyter笔记本来实现这个练习。</li>
				<li>在一个新的Jupyter笔记本单元格中，导入TensorFlow和pandas库:<pre>import tensorflow as tf import pandas as pd</pre></li>
				<li>Load in the dataset using the pandas <code>read_csv</code> function:<pre>df = pd.read_csv(<strong class="bold">'Bias_correction_ucl.csv'</strong>)</pre><p class="callout-heading">注意</p><p class="callout">确保根据CSV文件在系统上的位置更改其路径(突出显示)。如果您从存储CSV文件的同一个目录运行Jupyter笔记本，那么您可以不做任何修改就运行前面的代码。</p></li>
				<li>删除<code>date</code>列，并删除所有具有空值的行，因为您的模型只需要数值:<pre>df.drop('Date', inplace=True, axis=1) df.dropna(inplace=True)</pre></li>
				<li>创建目标和要素数据集。目标数据集将包含名为<code>Next_Tmax</code>和<code>Next_Tmin</code>的列，而特征数据集将包含除了名为<code>Next_Tmax</code>和<code>Next_Tmin</code> : <pre>target = df[['Next_Tmax', 'Next_Tmin']] features = df.drop(['Next_Tmax', 'Next_Tmin'], axis=1)</pre>的列之外的所有列</li>
				<li>重新缩放要素数据集:<pre>from sklearn.preprocessing import MinMaxScaler scaler = MinMaxScaler() feature_array = scaler.fit_transform(features) features = pd.DataFrame(feature_array, columns=features.columns)</pre></li>
				<li>初始化<code>Sequential</code>类的Keras模型:<pre>model = tf.keras.Sequential()</pre></li>
				<li>使用模型的<code>add</code>方法向模型添加输入图层，并将<code>input_shape</code>设置为要素数据集中的列数:<pre>model.add(tf.keras.layers.InputLayer\          (input_shape=(features.shape[1],), \                        name='Input_layer'))</pre></li>
				<li>将<code>Dense</code>类的输出层添加到模型中，大小为<code>2</code>，代表两个目标变量:<pre>model.add(tf.keras.layers.Dense(2, name='Output_layer'))</pre></li>
				<li>用RMSprop优化器和均方误差损失编译模型:<pre>model.compile(tf.optimizers.RMSprop(0.001), loss='mse')</pre></li>
				<li>为TensorBoard添加回调:<pre>tensorboard_callback = tf.keras.callbacks\                          .TensorBoard(log_dir="./logs")</pre></li>
				<li>Fit the model to the training data:<pre>model.fit(x=features.to_numpy(), y=target.to_numpy(),\
          epochs=50, callbacks=[tensorboard_callback])</pre><p>您应该得到以下输出:</p><div><img src="img/B16341_04_04.jpg" alt="Figure 4.4: The output of the fitting process showing the epoch, train time per sample, and loss after each epoch&#13;&#10;"/></div><p class="figure-caption">图4.4:拟合过程的输出，显示了时期、每个样本的训练时间以及每个时期后的损失</p></li>
				<li>Evaluate the model on the training data:<pre>loss = model.evaluate(features.to_numpy(), target.to_numpy())
print('loss:', loss)</pre><p>这会产生以下输出:</p><pre>loss: 3.5468221449764012</pre></li>
				<li>View the model architecture and model-fitting process on TensorBoard by calling the following on the command line:<pre>tensorboard –-logdir=logs/</pre><p>通过访问启动TensorBoard后提供的URL，您可以在web浏览器中看到它的执行。提供的默认网址是<code>http://localhost:6006/</code>:</p><div><img src="img/B16341_04_05.jpg" alt="Figure 4.5: A visual representation of the model architecture in TensorBoard&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">图4.5:tensor board中模型架构的可视化表示</p>
			<p>损失函数可以如下图所示进行可视化:</p>
			<div><div><img src="img/B16341_04_06.jpg" alt="Figure 4.6: A visual representation of the loss as a function of an epoch in TensorBoard&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图4.6:损失作为TensorBoard中一个历元的函数的直观表示</p>
			<p>您可以在<code>GRAPHS</code>选项卡中看到模型的架构。该架构显示了模型中的输入层和输出层，以及计算的损耗。在模型拟合过程中，损耗在每个时期后计算，并显示在<code>SCALARS</code>选项卡的张量板上。损失是在编译过程中定义的；因此，在这种情况下，损失是均方误差。从TensorBoard中，您可以看到，在每个历元之后，均方误差都在减少，这表明模型正在从训练数据中学习，更新权重以减少总损失。</p>
			<p>在本练习中，您学习了如何通过使用Keras层创建、训练和评估具有TensorFlow的ANN。您通过创建一个具有输入层和输出层(每个输出层有一个单元)的ANN，重新创建了线性回归算法。这里，有两个输出代表温度的最大值和最小值；因此，输出层有两个单元。</p>
			<p>在<em class="italic">练习4.01 </em>、<em class="italic">使用TensorFlow </em>创建人工神经网络中，您创建的人工神经网络只有一个包含权重和输出层的层。这是一个<strong class="bold">浅层神经网络</strong>的例子。具有许多包含权重的隐藏层的神经网络被称为<strong class="bold">深度神经网络</strong>，训练它们的过程被称为<strong class="bold">深度学习</strong>。通过增加层数和加深人工神经网络，模型变得更加灵活，能够模拟更复杂的函数。但是，为了增加灵活性，您需要更多的训练数据和更多的计算能力来训练模型。</p>
			<p>在下一个练习中，您将创建和训练具有多个隐藏层的ann。</p>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor086"/>练习4.03:使用TensorFlow创建多层人工神经网络</h2>
			<p>在本练习中，您将使用TensorFlow创建一个多层ANN。这个模型将有四个隐藏层。您将向模型添加多个层，并向层的输出添加激活函数。第一个隐藏层将有<code>16</code>个单位，第二个将有<code>8</code>个单位，第三个将有<code>4</code>个单位。输出层将有<code>2</code>个单位。您将使用与<em class="italic">练习4.02 </em>、<em class="italic">中相同的数据集，使用TensorFlow </em>创建一个线性回归模型作为ANN，该模型描述了韩国首尔气温预测的偏差校正。该练习旨在根据气象站先前时间点和属性的测量值预测下一个最高和最低温度。</p>
			<p>执行以下步骤来完成本练习:</p>
			<ol>
				<li value="1">打开一个新的Jupyter笔记本来实现这个练习。</li>
				<li>在一个新的Jupyter笔记本单元格中，导入TensorFlow和pandas库:<pre>import tensorflow as tf import pandas as pd</pre></li>
				<li>Load in the dataset using the pandas <code>read_csv</code> function:<pre>df = pd.read_csv(<strong class="bold">'Bias_correction_ucl.csv'</strong>)</pre><p class="callout-heading">注意</p><p class="callout">确保根据CSV文件在系统上的位置更改其路径(突出显示)。如果您从存储CSV文件的同一个目录运行Jupyter笔记本，那么您可以不做任何修改就运行前面的代码。</p></li>
				<li>删除<code>Date</code>列，并删除所有包含空值的行:<pre>df.drop('Date', inplace=True, axis=1) df.dropna(inplace=True)</pre></li>
				<li>创建目标和特征数据集:<pre>target = df[['Next_Tmax', 'Next_Tmin']] features = df.drop(['Next_Tmax', 'Next_Tmin'], axis=1)</pre></li>
				<li>重新缩放要素数据集:<pre>from sklearn.preprocessing import MinMaxScaler scaler = MinMaxScaler() feature_array = scaler.fit_transform(features) features = pd.DataFrame(feature_array, columns=features.columns)</pre></li>
				<li>初始化<code>Sequential</code>类的Keras模型:<pre>model = tf.keras.Sequential()</pre></li>
				<li>使用模型的<code>add</code>方法向模型添加输入图层，并将<code>input_shape</code>设置为要素数据集中的列数:<pre>model.add(tf.keras.layers.InputLayer\                          (input_shape=(features.shape[1],), \                           name='Input_layer'))</pre></li>
				<li>向模型添加三个隐藏层和一个<code>Dense</code>类的输出层。第一个隐藏层将有<code>16</code>个单位，第二个将有<code>8</code>个单位，第三个将有<code>4</code>个单位。适当地标记这些层。输出层将有两个单元来匹配有两列的目标变量:<pre>model.add(tf.keras.layers.Dense(16, name='Dense_layer_1')) model.add(tf.keras.layers.Dense(8, name='Dense_layer_2')) model.add(tf.keras.layers.Dense(4, name='Dense_layer_3')) model.add(tf.keras.layers.Dense(2, name='Output_layer'))</pre></li>
				<li>用RMSprop优化器和均方误差损失编译模型:<pre>model.compile(tf.optimizers.RMSprop(0.001), loss='mse')</pre></li>
				<li>为TensorBoard添加回调:<pre>tensorboard_callback = tf.keras.callbacks\                          .TensorBoard(log_dir="./logs")</pre></li>
				<li>Fit the model to the training data for <code>50</code> epochs and add a validation split equal to 20%:<pre>model.fit(x=features.to_numpy(), y=target.to_numpy(),\
          epochs=50, callbacks=[tensorboard_callback] , \
          validation_split=0.2)</pre><p>您应该得到以下输出:</p><div><img src="img/B16341_04_07.jpg" alt="Figure 4.7: The output of the fitting process showing the epoch, training time per sample, and loss after each epoch"/></div><p class="figure-caption">图4.7:拟合过程的输出，显示了时期、每个样本的训练时间以及每个时期后的损失</p></li>
				<li>Evaluate the model on the training data:<pre>loss = model.evaluate(features.to_numpy(), target.to_numpy())
print('loss:', loss)</pre><p>这将显示以下结果:</p><pre>loss: 1.664448248190068</pre></li>
				<li>View the model architecture and model-fitting process in TensorBoard:<pre>tensorboard --logdir=logs/</pre><p>您应该会得到如下所示的内容:</p><div><img src="img/B16341_04_08.jpg" alt="Figure 4.8: A visual representation of the model architecture in TensorBoard&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">图4.8:tensor board中模型架构的可视化表示</p>
			<p>您可以将损失函数可视化，如下图所示:</p>
			<div><div><img src="img/B16341_04_09.jpg" alt="Figure 4.9: A visual representation of the loss as a function of an epoch in TensorBoard &#13;&#10;on the training and validation split&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图4.9:作为TensorBoard中的历元函数的损失在训练和验证分割中的直观表示</p>
			<p>网络结构显示了模型的输入层和四个隐藏层，以及最后计算的损耗。在模型拟合过程中，损耗在每个时期后计算，并显示在<code>SCALARS</code>选项卡的TensorBoard中。这里，损失是均方误差。从TensorBoard中，您可以看到，在每个时期之后，训练集(橙色线)和验证集(蓝色线)上的均方误差减小，这表明模型正在有效地从训练数据中学习。</p>
			<p>在本练习中，您创建了一个具有多个隐藏层的ANN。你得到的损失低于使用线性回归得到的损失，这证明了人工神经网络的力量。通过对超参数进行一些调整(例如改变层数、每层中的单元数、添加激活函数以及改变损耗和优化器)，损耗甚至可以更低。在下一个活动中，您将在新的数据集上运用您的建模技能。</p>
			<h2 id="_idParaDest-87"><a id="_idTextAnchor087"/>活动4.01:使用TensorFlow创建多层人工神经网络</h2>
			<p>特征数据集<code>superconductivity.csv</code>包含超导体的属性，包括材料的原子质量及其密度。重要的是，数据集还包含材料的临界温度，即材料表现出超导特性的温度。在这项活动中，你的任务是找到材料的临界温度或材料获得超导性能的温度。</p>
			<p class="callout-heading">注意</p>
			<p class="callout"><code>superconductivity.csv</code>文件可以在这里找到:<a href="https://packt.link/sOCPh">https://packt.link/sOCPh</a>。</p>
			<p>执行以下步骤来完成本练习:</p>
			<ol>
				<li value="1">打开一个新的Jupyter笔记本来执行此活动。</li>
				<li>导入TensorFlow和pandas库。</li>
				<li>加载到<code>superconductivity.csv</code>数据集中。</li>
				<li>删除所有包含空值的行。</li>
				<li>将目标设置为<code>critical_temp</code>列，将特征数据集设置为其余列。</li>
				<li>使用标准缩放器重新缩放要素数据集。</li>
				<li>初始化Keras <code>Sequential</code>类的模型。</li>
				<li>向模型添加一个输入层，四个大小为<code>64</code>、<code>32</code>、<code>16</code>和<code>8</code>的隐藏层，以及一个大小为<code>1</code>的输出层。给第一个隐藏层添加一个ReLU激活函数。</li>
				<li>用RMSprop优化器编译模型，学习率等于<code>0.001</code>，损失的均方误差。</li>
				<li>添加回调以将日志写入TensorBoard。</li>
				<li>将模型拟合到<code>100</code>时期的训练数据，批量等于<code>32</code>，验证分割等于20%。</li>
				<li>根据训练数据评估模型。</li>
				<li>View the model architecture in TensorBoard.<p>您应该得到如下所示的输出:</p><div><img src="img/B16341_04_10.jpg" alt="Figure 4.10: A visual representation of the model architecture in TensorBoard&#13;&#10;"/></div><p class="figure-caption">图4.10:tensor board中模型架构的可视化表示</p></li>
				<li>在TensorBoard中可视化模型拟合过程。您应该得到以下输出:<div> <img src="img/B16341_04_11.jpg" alt="Figure 4.11: A visual representation of the loss as a function of an epoch on the training and validation split in TensorBoard&#13;&#10;"/> </div></li>
			</ol>
			<p class="figure-caption">图4.11:在TensorBoard中，作为训练和验证分割的历元函数的损失的可视化表示</p>
			<p class="callout-heading">注意</p>
			<p class="callout">此活动的解决方案可通过<a href="B16341_Solution_ePub.xhtml#_idTextAnchor262">此链接</a>找到。</p>
			<p>在下一节中，您将探索分类模型，它试图将数据分类到不同的类中。您将从二元分类模型开始，该模型将数据分为两类。这是分类模型的最简单形式。一旦掌握了二元分类器，就可以处理更复杂的模型，例如多标签和多类分类。</p>
			<h1 id="_idParaDest-88"><a id="_idTextAnchor088"/>分类模型</h1>
			<p>分类模型的目标是将数据分为不同的类别。例如，垃圾邮件过滤器是一种分类模型，旨在将电子邮件分类为“垃圾邮件”(指未经请求和不受欢迎的电子邮件)或“垃圾邮件”(合法电子邮件)。垃圾邮件过滤器是二元分类器的一个例子，因为有两个类别。过滤器的输入可以包括电子邮件的内容、发件人的电子邮件地址和主题行，以及其他特征，输出将是预测的类、<code>spam</code>或<code>ham</code>。分类模型可以将数据分为两个以上不同的类别(称为<strong class="bold">多类别分类</strong>)或者对具有多个正标签的数据进行分类(称为<strong class="bold">多标签分类</strong>)。</p>
			<p>有几种不同的算法可用于分类任务。一些流行的方法包括逻辑回归、决策树和人工神经网络。人工神经网络是分类模型的一个很好的选择，因为它们可以学习特征和目标之间的复杂关系，并且可以在人工神经网络的输出层上使用适当的激活函数来获得结果。</p>
			<p>用于分类模型的常见激活函数是sigmoid函数，它与逻辑回归中使用的函数相同。事实上，逻辑回归模型可以通过建立具有一个单元和sigmoid激活函数的单层ANN来创建。sigmoid函数是一种变换，其中输入是任何实数值，输出是严格介于<code>0</code>和<code>1</code>之间的数字。下图显示了一个直观的表示。</p>
			<p>sigmoid变换的输出可以被解释为值在正类中的概率；与<code>1</code>的值越接近的值表示在正类中的概率越高:</p>
			<div><div><img src="img/B16341_04_12.jpg" alt="Figure 4.12: A visual representation of the sigmoid function&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图4.12:sigmoid函数的可视化表示</p>
			<p>在应用sigmoid函数之后，应用阈值，高于该阈值的数据被分类为正类，低于该阈值的数据被分类为负类。sigmoid函数的默认阈值是<code>0.5</code>，这意味着任何等于或大于<code>0.5</code>的值都被归类为正值。</p>
			<p>在下一个练习中，您将使用TensorFlow创建一个逻辑回归模型。您将通过创建单层ANN来实现这一点，其过程类似于<em class="italic">练习4.02 </em>、<em class="italic">使用TensorFlow </em>创建线性回归模型作为ANN中的线性回归模型。不同之处在于，您将向人工神经网络的输出添加一个sigmoid激活函数。区分这两个练习的另一个区别是您将用来计算损失的损失函数。</p>
			<h2 id="_idParaDest-89"><a id="_idTextAnchor089"/>练习4.04:使用TensorFlow创建逻辑回归模型作为人工神经网络</h2>
			<p>在本练习中，您将使用TensorFlow创建一个逻辑回归模型作为ANN。数据集<code>qsar_androgen_receptor.csv</code>用于开发分类模型，用于在给定分子各种属性的情况下区分结合剂/非结合剂分子。这里，分子属性表示数据集的要素，其绑定属性表示目标变量，其中正值表示绑定分子，负值表示非绑定分子。给定数据集中提供的分子属性，您将创建一个逻辑回归模型来预测分子的结合属性。</p>
			<p class="callout-heading">注意</p>
			<p class="callout"><code>qsar_androgen_receptor.csv</code>文件可以在这里找到:<a href="https://packt.link/hWvjc">https://packt.link/hWvjc</a>。</p>
			<p>执行以下步骤来完成本练习:</p>
			<ol>
				<li value="1">打开一个新的Jupyter笔记本来实现这个练习。</li>
				<li>导入TensorFlow和pandas库:<pre>import tensorflow as tf import pandas as pd</pre></li>
				<li>Load in the dataset using the pandas <code>read_csv</code> function:<pre>df = pd.read_csv(<strong class="bold">'qsar_androgen_receptor.csv'</strong>, \
                 sep=';')</pre><p class="callout-heading">注意</p><p class="callout">确保根据CSV文件在系统上的位置更改其路径(突出显示)。如果您从存储CSV文件的同一个目录运行Jupyter笔记本，那么您可以不做任何修改就运行前面的代码。</p></li>
				<li>删除任何具有空值的行:<pre>df.dropna(inplace=True)</pre></li>
				<li>创建目标和要素数据集:<pre>target = df['positive'].apply(lambda x: 1 if x=='positive' else 0) features = df.drop('positive', axis=1)</pre></li>
				<li>初始化<code>Sequential</code>类的Keras模型:<pre>model = tf.keras.Sequential()</pre></li>
				<li>使用模型的<code>add</code>方法向模型添加一个输入图层，并将<code>input_shape</code>设置为要素数据集中的列数:<pre>model.add(tf.keras.layers.InputLayer\          (input_shape=(features.shape[1],), \                        name='Input_layer'))</pre></li>
				<li>将<code>Dense</code>类的输出层添加到尺寸为<code>1</code>的模型中，表示目标变量:<pre>model.add(tf.keras.layers.Dense(1, name='Output_layer', \                                 activation='sigmoid'))</pre></li>
				<li>用RMSprop优化器和二进制交叉熵为损失编译模型，并计算准确度:<pre>model.compile(tf.optimizers.RMSprop(0.0001), \               loss='binary_crossentropy', metrics=['accuracy'])</pre></li>
				<li>创建张量板回调:<pre>tensorboard_callback = tf.keras.callbacks.TensorBoard\                        (log_dir="./logs")</pre></li>
				<li>Fit the model to the training data for <code>50</code> epochs, adding the TensorBoard callback with a validation split of 20%:<pre>model.fit(x=features.to_numpy(), y=target.to_numpy(), \
         epochs=50, callbacks=[tensorboard_callback] , \
         validation_split=0.2)</pre><p>您的输出应该类似于下图:</p><div><img src="img/B16341_04_13.jpg" alt="Figure 4.13: The output of the fitting process showing the epoch, training time per sample, and loss after each epoch&#13;&#10;"/></div><p class="figure-caption">图4.13:拟合过程的输出，显示了时期、每个样本的训练时间以及每个时期后的损失</p></li>
				<li>Evaluate the model on the training data:<pre>loss, accuracy = model.evaluate(features.to_numpy(), \
                                target.to_numpy())
print(f'loss: {loss}, accuracy: {accuracy}')</pre><p>您应该得到如下所示的输出:</p><pre>loss: 0.2781583094794838, accuracy: 0.9110320210456848</pre></li>
				<li>Visualize the model-fitting process in TensorBoard by calling the following command on the command line:<pre>tensorboard --logdir=logs/</pre><p>您应该会在浏览器中看到类似如下的屏幕:</p><div><img src="img/B16341_04_14.jpg" alt="Figure 4.14: A visual representation of the model architecture in TensorBoard&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">图4.14:tensor board中模型架构的可视化表示</p>
			<p>损失函数可以表示如下:</p>
			<p>图4.15:在TensorBoard的训练和验证分割上评估的作为历元函数的损失和精度的<a id="_idTextAnchor090"/>直观表示</p>
			<div><div><img src="img/B16341_04_15.jpg" alt="Figure 4.15: A visual representation of the loss and accuracy as a function of an epoch evaluated on the training and validation split in TensorBoard&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">您可以从TensorBoard中看到，随着模型编译过程中添加的<code>metrics</code>参数的增加，架构中有了一个额外的节点来计算准确性指标。在<code>SCALARS</code>选项卡中还有一个附加图表，显示了作为训练和验证分割时期的函数的精度指标。</p>
			<p>您可以从图表中看到，对于训练集来说，随着时间的推移，准确性会增加，而损失会减少，这是模型正在学习的积极迹象。但是，在验证拆分时，准确性开始降低，损失开始增加，这是模型可能过度拟合定型数据的迹象。</p>
			<p>在本练习中，您学习了如何构建分类模型，以根据不同分子的其他分子属性来区分不同分子的结合属性。分类模型相当于逻辑回归模型，因为它只有一层，前面是sigmoid激活函数。只有一个图层时，每个输入要素都有一个权重，偏差只有一个值。sigmoid激活函数将图层的输出转换为一个介于<code>0</code>和<code>1</code>之间的值，然后对该值进行舍入以表示您的两个类。<code>0.5</code>及以上代表一类，具有结合特性的分子，而<code>0.5</code>以下代表另一类，具有非结合特性的分子。</p>
			<p>下一个活动将结合您在<em class="italic">练习4.03 </em>、<em class="italic">用TensorFlow </em>创建多层ANN、<em class="italic">练习4.01 </em>、<em class="italic">用TensorFlow </em>创建多层ANN中所学的知识，以及您在<em class="italic">练习4.04 </em>、<em class="italic">中创建分类模型的知识，总结您在本章中的学习您将使用与上一活动中相同的数据集，但会更改目标变量，使其更适合分类任务。</em></p>
			<p><a id="_idTextAnchor091"/>活动4.02:使用TensorFlow创建多层分类人工神经网络</p>
			<h2 id="_idParaDest-90">特征数据集<code>superconductivity.csv</code>包含超导体的属性，包括材料的原子质量及其密度。重要的是，数据集还包含材料的临界温度，即材料表现出超导特性的温度。你需要确定哪些超导体将在氮的沸点(77.36 K)以上表现出超导特性，从而允许使用液氮实现超导，而液氮是很容易获得的。当临界温度高于77.36 K且低于<code>false</code>时，您的目标变量将具有<code>true</code>值，指示材料在氮的沸点以上是否表现出超导性质。</h2>
			<p>注意</p>
			<p class="callout-heading"><code>superconductivity.csv</code>文件可以在这里找到:<a href="http://packt.link/sOCPh">http://packt.link/sOCPh</a>。</p>
			<p class="callout">执行以下步骤来完成本练习:</p>
			<p>打开Jupyter笔记本，完成活动。</p>
			<ol>
				<li value="1">导入TensorFlow和pandas库。</li>
				<li>加载到<code>superconductivity.csv</code>数据集中。</li>
				<li>删除所有包含空值的行。</li>
				<li>当<code>critical_temp</code>栏的值高于<code>77.36</code>时，将目标值设置为<code>true</code>，低于<code>77.36</code>时，将目标值设置为<code>false</code>。要素数据集是数据集中剩余的列。</li>
				<li>使用标准缩放器重新缩放要素数据集。</li>
				<li>初始化Keras <code>Sequential</code>类的模型。</li>
				<li>向模型中添加一个输入层，三个大小为<code>32</code>、<code>16</code>和<code>8</code>的隐藏层，以及一个具有大小为<code>1</code>的<code>sigmoid</code>激活函数的输出层。</li>
				<li>使用RMSprop优化器编译模型，学习率等于<code>0.0001</code>和损失的二进制交叉熵，并计算准确性指标。</li>
				<li>添加回调以将日志写入TensorBoard。</li>
				<li>将模型拟合到<code>50</code>时期的训练数据，验证分割等于0%。</li>
				<li>根据训练数据评估模型。</li>
				<li>注意</li>
				<li>View the model architecture and model-fitting process in TensorBoard.<p class="callout-heading">此活动的解决方案可通过<a href="B16341_Solution_ePub.xhtml#_idTextAnchor263">此链接</a>找到。</p><p class="callout">在本节中，您已经开始尝试使用TensorFlow构建、训练和评估分类模型。您已经看到，它们的构建方式与回归任务的人工神经网络非常相似，主要区别在于输出层的激活函数。</p></li>
			</ol>
			<p><a id="_idTextAnchor092"/>总结</p>
			<h1 id="_idParaDest-91">在本章中，您开始了在TensorFlow中创建人工神经网络的旅程。您看到了利用Keras层创建回归和分类模型是多么简单。Keras层是不同的类，存在于后端使用TensorFlow的独立库中。由于它们的流行性和易用性，它们现在包含在TensorFlow中，可以像任何其他TensorFlow类一样调用。</h1>
			<p>您创建了具有完全连接层、不同层的人工神经网络，从类似线性回归算法的人工神经网络开始，这相当于单层人工神经网络。然后，您向ANN添加了层，并向层的输出添加了激活函数。激活函数可以用来确定一个单元是否被触发，或者可以用来绑定给定单元的输出值。回归模型旨在从提供的数据中预测连续变量。在本章的练习和活动中，你试图根据气象站的数据预测首尔的温度，并根据各种材料特性预测超导材料的临界温度。</p>
			<p>最后，您探索了分类模型，该模型旨在将数据分类到不同的类中。这些模型在建立方式上类似于回归模型；但是，在最终输出中使用激活来绑定两个数字之间的输出值，这两个数字表示数据点是否被分类到该类中。您从二进制分类模型开始，该模型旨在将数据分为两类，并通过一个练习演示了二进制分类的概念，在这个练习中，您将分子分类为基于分子属性的其他属性来表示其结合属性的类别。</p>
			<p>在下一章，你将更深入地探索分类模型。您将了解分类模型的一些复杂性和功能，包括如何对具有两个以上不同类的数据进行分类(称为多类分类)，以及数据点是否可以有多个正标签(称为多标签分类)。您将讨论如何构建体系结构以创建这些模型，训练时使用的适当损失函数，以及计算相关指标以了解模型是否表现良好。</p>
			<p>In the next chapter, you will explore classification models in more depth. You will learn some of the intricacies and capabilities of classification models, including how to classify data that has more than two distinct classes (known as multi-class classification), and whether data points can have more than one positive label (known as multi-label classification). You will address how to structure the architecture to create these models, the appropriate loss functions to use when training, and the relevant metrics to calculate to understand whether models are performing well.</p>
		</div>
		<div><div/>
		</div>
	

</body></html>