<html><head/><body>


	
		<title>B16341_05_ePub</title>
		
	
	
		<div><div/>
		</div>
		<div><h1 id="_idParaDest-92"><a id="_idTextAnchor093"/> 5。分类模型</h1>
		</div>
		<div><p class="callout-heading"><a id="_idTextAnchor094"/>概述</p>
			<p class="callout">在这一章中，你将探索不同类型的分类模型。您将获得使用TensorFlow构建二元、多类和多标签分类器的实践经验。最后，您将学习模型评估的概念，以及如何使用不同的度量来评估模型的性能。</p>
			<p class="callout">到本章结束时，你将很好地理解什么是分类模型，以及如何用TensorFlow编程。</p>
			<h1 id="_idParaDest-93"><a id="_idTextAnchor095"/>简介</h1>
			<p>在前一章中，你学习了目标变量连续的回归问题。连续变量可以取最小值和最大值之间的任何值。您学习了如何使用TensorFlow训练此类模型。</p>
			<p>在这一章中，你将看到另一种被称为分类的监督学习问题，其中目标变量是离散的，这意味着它只能取有限数量的值。在行业中，您很可能会遇到这样的项目，其中变量被聚合到组中，例如产品层、用户类别、客户或工资范围。分类器的目标是从数据中学习模式，并预测要观察的正确类别。</p>
			<p>例如，在贷款提供商的情况下，分类模型将试图根据客户的概况和财务状况来预测客户在未来一年中是否最有可能违约。这个结果只能取两个可能的值(<code>yes</code>或<code>no</code>)，这是一个二元分类。另一个分类器模型可以在给定用户先前的评级和关于新电影的信息的情况下，为用户预测新电影的评级1到5。当结果可能有两个以上的可能值时，您正在处理多类分类。最后，还有第三种类型的分类器，称为多标签，其中模型将预测多个类别。例如，模型将分析输入图像并预测图像中是否有猫、狗或老鼠。在这种情况下，模型将预测三种不同的二进制输出(或标签)。</p>
			<p>你将在本章中浏览每一种分类器，详述它们的特性，并探索如何测量这些模型的性能。</p>
			<h1 id="_idParaDest-94"><a id="_idTextAnchor096"/>二元分类</h1>
			<p>如前所述，二元分类是指一种监督学习，其中目标变量只能取两个可能的值(或类)，如真/假或是/否。例如，在医疗行业，您可能希望根据患者的个人信息(如年龄、身高、体重和/或医学测量值)来预测患者是否更有可能患有疾病。同样，在市场营销中，广告商可能会利用类似的信息来优化电子邮件活动。</p>
			<p>诸如随机森林分类器、支持向量分类器或逻辑回归等机器学习算法对于分类很有效。神经网络对于二分类也能取得很好的效果。将前一章中的回归模型转换成二元分类器是非常容易的。只需要两个关键变化:最后一层的激活函数和损失函数。</p>
			<h2 id="_idParaDest-95"><a id="_idTextAnchor097"/>逻辑回归</h2>
			<p><code>0</code>和<code>1</code>。值<code>0</code>通常对应于<code>false</code>(或<code>no</code>)，而值<code>1</code>是指<code>true</code>(或<code>yes</code>)。</p>
			<p>换句话说，逻辑回归的输出将是它为真的概率。例如，如果输出是<code>0.3</code>，你可以说有30%的概率结果应该是真的(或者是)。但是，由于只有两个可能的值，这也意味着有70%(100%–30%)的可能性得到错误(或否)的结果:</p>
			<div><div><img src="img/B16341_05_01.jpg" alt="Figure 5.1: Output of logistic regression&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.1:逻辑回归的输出</p>
			<p>现在您已经知道了逻辑回归的输出是什么，您只需要找到一个函数，它可以将一个连续的输入值转换为一个在<code>0</code>和<code>1</code>之间的值。幸运的是，这样的数学函数确实存在，它被称为<strong class="bold"> sigmoid函数</strong>。该函数的公式如下:</p>
			<div><div><img src="img/B16341_05_02.jpg" alt="Figure 5.2: Formula of the sigmoid function&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.2:sigmoid函数的公式</p>
			<p><img src="img/B16341_05_02a.png" alt="Text&#10;&#10;Description automatically generated with medium confidence"/>对应于应用于<code>x</code>的指数函数。指数函数的范围从0到正无穷大。所以，如果<code>x</code>有一个接近正无穷大的值，那么sigmoid的值就会趋向于<code>1</code>。另一方面，如果<code>x</code>非常接近负无穷大，那么sigmoid的值将趋向于<code>0</code>:</p>
			<div><div><img src="img/B16341_05_03.jpg" alt="Figure 5.3: Curve of the sigmoid function&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.3:sigmoid函数曲线</p>
			<p>因此，对线性回归模型的输出应用sigmoid函数会将其转换为逻辑回归。同样的逻辑也适用于神经网络:如果你将sigmoid函数应用于感知器模型(线性回归)，你将得到一个二元分类器。为此，您只需将sigmoid指定为感知器模型的最后一个全连接层的激活函数。在TensorFlow中，将<code>activation</code>参数指定为:</p>
			<pre>from tensorflow.keras.layers import Dense
Dense(1, activation='sigmoid')</pre>
			<p>前面的代码片段显示了如何用一个可以输出任何值的单元定义一个完全连接的层，并对其应用sigmoid激活函数。结果将在<code>0</code>和<code>1</code>内。现在，您已经知道如何修改神经网络的回归模型以将其转换为二元分类器，您需要指定相关的损失函数。</p>
			<h2 id="_idParaDest-96">二元交叉熵</h2>
			<p>在上一节中，您学习了如何将线性回归模型转换为二元分类器。对于神经网络，只需添加sigmoid作为最后一个完全连接层的激活函数。但是还有另一个因素会影响这个模型的训练:损失函数的选择。</p>
			<p>对于线性回归，最常用的损失函数是<strong class="bold">均方误差</strong>和<strong class="bold">平均绝对误差</strong>，参见<em class="italic">第4章</em>、<em class="italic">回归和分类模型</em>。这些函数将计算预测值和实际值之间的差异，神经网络模型将在反向传播期间相应地更新其所有权重。对于二进制分类，典型的损失函数是<strong class="bold">二进制交叉熵</strong>(也称为<strong class="bold">对数损失</strong>)。该函数的公式如下:</p>
			<div><div><img src="img/B16341_05_04.jpg" alt="Figure 5.4: Formula of binary cross-entropy&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.4:二元交叉熵公式</p>
			<p><img src="img/B16341_05_04a.png" alt="A picture containing text&#10;&#10;Description automatically generated"/>代表观察值<code>i</code>的实际值。</p>
			<p><img src="img/B16341_05_04b.png" alt="Formula"/>代表观察值<code>i</code>的预测概率。</p>
			<p><code>N</code>代表观察总数。</p>
			<p>这个公式看起来相当复杂，但逻辑却相当简单。考虑以下单次观察的例子:实际值是<code>1</code>，预测概率是<code>0.8</code>。如果应用前面的公式，结果将如下:</p>
			<p><img src="img/B16341_05_04c.png" alt="Formula"/></p>
			<p>请注意，等式的右边大约为零:</p>
			<p><img src="img/B16341_05_04d.png" alt="Formula"/></p>
			<p>因此，由于预测值非常接近实际值，损失值将非常小。</p>
			<p>现在考虑另一个例子，其中实际值是<code>0</code>，预测概率是<code>0.99</code>。结果将如下所示:</p>
			<p><img src="img/B16341_05_04e.png" alt="Formula"/></p>
			<p><img src="img/B16341_05_04f.png" alt="Formula"/></p>
			<p>这种情况下损失会很大，因为预测值与实际值相差很大。</p>
			<p>计算这个损失的<code>BinaryCrossentropy</code>:</p>
			<pre>from tensorflow.keras.losses import BinaryCrossentropy
bce = BinaryCrossentropy()</pre>
			<h2 id="_idParaDest-97">二进制分类体系结构</h2>
			<p>二元分类器的架构与线性回归的架构极为相似，参见<em class="italic">第4章</em>、<em class="italic">回归和分类模型</em>。它由读取输入数据集的每个观察值的输入层、负责预测响应变量的输出层以及学习导致正确预测的模式的一些隐藏层组成。下图显示了这种架构的一个示例:</p>
			<div><div><img src="img/B16341_05_05.jpg" alt="Figure 5.5: Architecture of the binary classifier&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.5:二元分类器的架构</p>
			<p>与线性回归相比，唯一的区别是输出，即<code>0</code>和<code>1</code>之间的概率值。这个概率表示两个可能值之一出现的可能性。如前所述，这是通过使用sigmoid激活函数和反向传播的二进制交叉熵实现的。</p>
			<p>既然您已经看到了构建二元分类器的所有元素，那么您可以通过一个练习将它付诸实践。</p>
			<h2 id="_idParaDest-98">练习5.0 <a id="_idTextAnchor100"/> 1:建立逻辑回归模型</h2>
			<p>在本练习中，您将在TensorFlow中构建和训练一个逻辑回归模型，该模型将使用有关Dota 2游戏的一些信息(如使用的模式和类型)来预测该游戏中的获胜队。</p>
			<p>你将在Dota 2数据集上工作。Dota 2是一款流行的电脑游戏。数据集包含与游戏相关的信息，目标变量指示哪个队赢了。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">训练数据集可以在这里访问:【https://packt.link/Tdvdj T21】。</p>
			<p class="callout">测试数据集可以在这里访问:<a href="https://packt.link/4PsPN">https://packt.link/4PsPN</a>。</p>
			<p class="callout">原始数据集可以在这里找到:<a href="https://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results">https://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results</a>。</p>
			<ol>
				<li>打开新的Jupyter笔记本。</li>
				<li>导入熊猫库，使用<code>pd</code>作为别名:<pre>import pandas as pd</pre></li>
				<li>创建一个名为<code>train_url</code>的变量，其中包含训练集的URL:<pre>train_url = 'https://raw.githubusercontent.com/PacktWorkshops'\             '/The-TensorFlow-Workshop/master/Chapter05'\             '/dataset/dota2Train.csv'</pre></li>
				<li>Load the training dataset into a <code>DataFrame()</code> function called <code>X_train</code> using <code>read_csv()</code> method, provide the URL to the CSV file, and set <code>header=None</code> as the dataset doesn't provide column names. Print the first five rows of the DataFrame using <code>head()</code>method:<pre>X_train = pd.read_csv(train_url, header=None)
X_train.head()</pre><p>预期产出如下:</p><div><img src="img/B16341_05_06.jpg" alt="Figure 5.6: The first five rows of the Dota 2 training set&#13;&#10;"/></div><p class="figure-caption">图5.6:Dota 2训练集的前五行</p><p>您可以看到数据集包含117列，它们都是数字。还要注意，目标变量(列<code>0</code>)包含两个不同的值:<code>-1</code>和<code>1</code>。由于您将训练一个逻辑回归模型，可能的值应该是<code>0</code>和<code>1</code>。您需要用<code>0</code>替换<code>-1</code>值。</p></li>
				<li>使用<code>pop()</code>方法提取目标变量(第0列)并保存在名为<code>y_train</code> : <pre>y_train = X_train.pop(0)</pre>的变量中</li>
				<li>Replace all values with <code>-1</code> with <code>0</code> from the target variable using <code>replace()</code>, and print the first five rows using <code>head()</code> method:<pre>y_train = y_train.replace(-1,0)
y_train.head()</pre><p>预期产出如下:</p><div><img src="img/B16341_05_07.jpg" alt="Figure 5.7: The first five rows of the Dota 2 target variable from the training set&#13;&#10;"/></div><p class="figure-caption">图5.7:训练集中Dota 2目标变量的前五行</p><p>现在，来自训练集的目标变量的所有值不是<code>0</code>就是<code>1</code>。</p></li>
				<li>创建一个名为<code>test_url</code>的变量，它包含测试集的URL:<pre>test_url = 'https://raw.githubusercontent.com/PacktWorkshops'\            '/The-TensorFlow-Workshop/master/Chapter05/dataset'\            '/dota2Test.csv'</pre></li>
				<li>Load the test dataset into a <code>DataFrame()</code> function called <code>X_test</code> using <code>read_csv()</code> method, provide the URL to the CSV file, and set <code>header=None</code> as the dataset doesn't provide column names. Print the first five rows using <code>head()</code> method:<pre>X_test = pd.read_csv(test_url, header=None)
X_test.head()</pre><p>预期产出如下:</p><div><img src="img/B16341_05_08.jpg" alt="Figure 5.8: The first five rows of the Dota 2 test set&#13;&#10;"/></div><p class="figure-caption">图5.8:Dota 2测试集的前五行</p><p>测试集与训练集非常相似，您需要对它执行相同的转换。</p></li>
				<li>使用<code>pop()</code>方法提取目标变量(第0列),并将其保存在名为<code>y_test</code> : <pre>y_test = X_test.pop(0)</pre>的变量中</li>
				<li>Replace all values with <code>-1</code> with <code>0</code> from the target variable using <code>replace()</code> method and print the first five rows using <code>head()</code> method:<pre>y_test = y_test.replace(-1,0)
y_test.head()</pre><p>预期产出如下:</p><div><img src="img/B16341_05_09.jpg" alt="Figure 5.9: The first five rows of the Dota 2 target variable from the test set&#13;&#10;"/></div><p class="figure-caption">图5.9:测试集中Dota 2目标变量的前五行</p></li>
				<li>导入TensorFlow库，使用<code>tf</code>作为别名:<pre>import tensorflow as tf</pre></li>
				<li>将TensorFlow的种子设置为<code>8</code>，使用<code>tf.random.set_seed()</code>获得可重复的结果:<pre>tf.random.set_seed(8)</pre></li>
				<li>使用<code>tf.keras.Sequential()</code>实例化一个顺序模型，并将其存储在一个名为<code>model</code> : <pre>model = tf.keras.Sequential()</pre>的变量中</li>
				<li>从<code>tensorflow.keras.layers</code> : <pre>from tensorflow.keras.layers import Dense</pre>导入<code>Dense()</code>类</li>
				<li>使用<code>Dense()</code>创建一个由<code>512</code>个单元组成的全连接图层，并将ReLu指定为激活函数，将输入形状指定为<code>(116,)</code>，这对应于数据集中的要素数量。将其保存在一个名为<code>fc1</code> : <pre>fc1 = Dense(512, input_shape=(116,), activation='relu')</pre>的变量中</li>
				<li>用<code>Dense()</code>创建一个全连接的<code>512</code>单元层，并将ReLu指定为激活函数。将它保存在一个名为<code>fc2</code> : <pre>fc2 = Dense(512, activation='relu')</pre>的变量中</li>
				<li>用<code>Dense()</code>创建一个全连接的<code>128</code>单元层，并将ReLu指定为激活函数。保存在一个名为<code>fc3</code> : <pre>fc3 = Dense(128, activation='relu')</pre>的变量中</li>
				<li>用<code>Dense()</code>创建一个全连接的<code>128</code>单元层，并将ReLu指定为激活函数。保存在一个名为<code>fc4</code> : <pre>fc4 = Dense(128, activation='relu')</pre>的变量中</li>
				<li>用<code>Dense()</code>创建一个完全连接的<code>128</code>单元层，并将sigmoid指定为激活函数。保存在一个名为<code>fc5</code> : <pre>fc5 = Dense(1, activation='sigmoid')</pre>的变量中</li>
				<li>使用<code>add()</code>方法:<pre>model.add(fc1) model.add(fc2) model.add(fc3) model.add(fc4) model.add(fc5)</pre>将所有五个完全连接的层依次添加到模型中</li>
				<li>Print the summary of the model using <code>summary()</code> method:<pre>model.summary()</pre><p>预期产出如下:</p><div><img src="img/B16341_05_10.jpg" alt="Figure 5.10: Summary of the model architecture&#13;&#10;"/></div><p class="figure-caption">图5.10:模型架构概要</p><p>前面的输出显示了您的模型中有五个层(如预期的那样),并显示了每个层的参数数量。例如，第一层包含59，904个参数，该模型的参数总数为404，855。所有这些参数将在拟合模型时被训练。</p></li>
				<li>从<code>tf.keras.losses</code>实例化一个<code>BinaryCrossentropy()</code>函数，并保存在一个名为<code>loss</code> : <pre>loss = tf.keras.losses.BinaryCrossentropy()</pre>的变量中</li>
				<li>将<code>tf.keras.optimizers</code>中的<code>Adam()</code>实例化为<code>0.001</code>作为学习率，并保存在一个名为<code>optimizer</code> : <pre>optimizer = tf.keras.optimizers.Adam(0.001)</pre>的变量中</li>
				<li>使用<code>compile()</code>函数编译模型，并指定您在前面的步骤中刚刚创建的优化器和损失:<pre>model.compile(optimizer=optimizer, loss=loss)</pre></li>
				<li>Start the model training process using <code>fit()</code> method on the training set for five epochs:<pre>model.fit(X_train, y_train, epochs=5)</pre><p>预期产出如下:</p><div><img src="img/B16341_05_11.jpg" alt="Figure 5.11: Logs of the training process&#13;&#10;"/></div><p class="figure-caption">图5.11:培训过程的日志</p><p>前面的输出显示了模型训练期间每个时期的日志。注意，处理单个时段花费了大约15秒，并且损失值从<code>0.6923</code>(第一时段)减少到<code>0.6650</code>(第五时段)，因此该模型正在通过减少二进制交叉熵损失来慢慢提高其性能。</p></li>
				<li>Predict the results of the test set using <code>predict()</code> method. Save it in a variable called <code>preds</code> and display its first five values:<pre>preds = model.predict(X_test)
preds[:5]</pre><p>预期产出如下:</p><div><img src="img/B16341_05_12.jpg" alt="Figure 5.12: Predictions of the first five rows of the test set&#13;&#10;"/></div><p class="figure-caption">图5.12:测试集前五行的预测</p><p>前面的输出显示了每个预测的概率。低于<code>0.5</code>的每个值将被归类为<code>0</code>(该输出中的第一个和最后一个观察值)，所有大于或等于<code>0.5</code>的值将被归类为<code>1</code>(第二至第四个观察值)。</p></li>
				<li>Display the first five true labels of the test set:<pre>y_test[:5]</pre><p>预期产出如下:</p><div><img src="img/B16341_05_13.jpg" alt="Figure 5.13: True labels of the first five rows of the test set&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">图5.13:测试集前五行的真实标签</p>
			<p>将此输出与测试集前五行的模型预测进行比较，会发现一些不正确的值:第三个预测(索引<code>2</code>)的值应该是<code>0</code>，最后一个预测的值应该是<code>0</code>。所以，在这五个观察中，你的二元分类器犯了两个错误。</p>
			<p>在前面的小节中，您将看到如何使用不同的度量标准正确地评估模型的性能。</p>
			<h1 id="_idParaDest-99">分类标准</h1>
			<p>在上一节中，您学习了如何训练一个二元分类器来预测正确的输出:不是<code>0</code>就是<code>1</code>。在<em class="italic">练习5.01 </em>、<em class="italic">构建逻辑回归模型</em>中，您查看了一些样本来评估所构建模型的性能。通常，您不只是在一个小的子集上评估模型，而是在整个数据集上使用一个性能度量标准(如准确性或F1分数)来评估模型。</p>
			<h2 id="_idParaDest-100">准确度和零交流准确度</h2>
			<p>分类问题最广泛使用的度量之一是准确性。它的公式很简单:</p>
			<div><div><img src="img/B16341_05_14.jpg" alt="Figure 5.14: Formula of the accuracy metric&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.14:准确性度量的公式</p>
			<p>精确度的最大值是<code>1</code>，这意味着模型正确预测100%的情况。其最小值为<code>0</code>，模型无法正确预测任何情况。</p>
			<p>对于二元分类器，正确预测的数量是将值<code>0</code>或<code>1</code>作为正确预测值的观察值的数量:</p>
			<div><div><img src="img/B16341_05_15.jpg" alt="Figure 5.15: Formula of the accuracy metric for a binary classifier&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.15:二元分类器的准确度公式</p>
			<p>假设您正在评估两个不同的二元分类器在测试集上预测10，000次观察结果的性能。第一个模型正确预测了值<code>0</code>的5000个实例和值<code>1</code>的3000个实例。其准确度得分如下:</p>
			<div><div><img src="img/B16341_05_16.jpg" alt="Figure 5.16: Formula for the accuracy of model1&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.16:模型1的精确度公式</p>
			<p>第二个模型正确预测了500个案例的值<code>0</code>和1500个观察的值<code>1</code>。其准确度得分如下:</p>
			<div><div><img src="img/B16341_05_17.jpg" alt="Figure 5.17: Formula for the accuracy of model2&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.17:模型2精度的公式</p>
			<p>第一个模型预测准确率为80%,而第二个模型只有20%。在这种情况下，你可以说模型1比模型2好。</p>
			<p>尽管<code>0.8</code>通常是一个相对较好的分数，但这并不一定意味着你的模型表现良好。例如，假设您的数据集包含9000个值为<code>0</code>的案例和1000个值为<code>1</code>的案例。一个总是预测值<code>0</code>的非常简单的模型将获得0.9的准确度分数。在这种情况下，第一个模型的表现甚至不如这个极其简单的模型。这种总是预测数据集的最频繁值的模型的特征被称为<code>0.9</code>，因为简单模型预测<code>0</code>，这在90%的情况下是正确的。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">精度和零精度度量并不特定于二进制分类，但也可以应用于其他类型的分类。</p>
			<p>TensorFlow提供了一个类<code>tf.keras.metrics.Accuracy</code>，它可以根据张量计算准确度分数。这个类有一个名为<code>update_state()</code>的方法，它将两个张量作为输入参数，并将计算它们之间的准确度分数。您可以通过调用<code>result()</code>方法来访问这个分数。输出结果将是一个张量。您可以使用<code>numpy()</code>方法将其转换为NumPy数组。以下是如何计算准确度分数的示例:</p>
			<pre>from tensorflow.keras.metrics import Accuracy
preds = [1, 1, 1, 1, 0, 0]
target = [1, 0, 1, 0, 1, 0]
acc = Accuracy()
acc.update_state(preds, target)
acc.result().numpy()</pre>
			<p>这将导致以下准确度分数:</p>
			<pre>0.5</pre>
			<p class="callout-heading">注意</p>
			<p class="callout">TensorFlow没有提供空精度度量的类，但是您可以使用<code>Accuracy()</code>轻松计算它，并提供一个仅使用<code>1</code>(或<code>0</code>)作为预测的张量。</p>
			<h2 id="_idParaDest-101">精度、召回和测试<a id="_idTextAnchor103"/>他的F1分数</h2>
			<p>在上一节中，您学习了如何使用准确性度量来评估模型的性能，并将其与称为零准确性的基线进行比较。准确性分数被广泛使用，因为它为非技术受众所熟知，但它确实有一些限制。考虑下面的例子。</p>
			<div><div><img src="img/B16341_05_18.jpg" alt="Figure 5.18: Example of model predictions versus actual values&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.18:模型预测与实际值的对比示例</p>
			<p>该模型达到了0.981 <img src="img/B16341_05_18a.png" alt="Diagram&#10;&#10;Description automatically generated"/>的准确度分数，这是相当高的。但如果用这个模型来预测一个人是否有疾病，只会在单一情况下预测正确。在九个案例中，它错误地预测这些人没有生病，而他们实际上患有特定的疾病。同时，它错误地预测了10个实际上健康的人患病。因此，这种模式的表现显然不能令人满意。不幸的是，准确性分数仅仅是一个总体分数，它不会告诉你模型在哪里表现不好。</p>
			<p>幸运的是，其他指标提供了对模型的更好的评估，如精确度、召回率或F1分数。所有这三个度量具有与准确度分数相同的值范围:<code>1</code>是完美的分数，其中所有的观察都被正确地预测，而<code>0</code>是最差的，其中根本没有正确的预测。</p>
			<p>但是在查看它们之前，您需要熟悉以下定义:</p>
			<ul>
				<li><strong class="bold">真阳性(TP) </strong>:实际值和对应的预测值都为真的所有观测值</li>
				<li><strong class="bold">真阴性(TN) </strong>:实际值和对应的预测值都为假的所有观察值</li>
				<li><strong class="bold">假阳性(FP) </strong>:预测为真，但值实际为假的所有观察值</li>
				<li><strong class="bold">假阴性(FN) </strong>:预测为假，但实际值为真的所有观察值</li>
			</ul>
			<p>以<em class="italic">图5.18 </em>为例，你会得到以下结果:</p>
			<ul>
				<li>TP = 1</li>
				<li>TN = 980</li>
				<li>FP = 10</li>
				<li>FN = 9</li>
			</ul>
			<p>这在下表中可以看到:</p>
			<div><div><img src="img/B16341_05_19.jpg" alt="Figure 5.19: Example of TP, TN, FP, and FN&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.19:TP、TN、FP和FN的例子</p>
			<p>精度分数是评估模型是否预测了大量FPs的度量。其公式如下:</p>
			<div><div><img src="img/B16341_05_20.jpg" alt="Figure 5.20: Formula of precision&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.20:精度公式</p>
			<p>在前面的例子中，精度分数将是<img src="img/B16341_05_20a.png" alt="A picture containing text&#10;&#10;Description automatically generated"/>。你可以看到这个模型犯了很多错误，并且与实际的TP相比预测了很多FPs。</p>
			<p>召回用于评估fn相对于TP的数量。其公式如下:</p>
			<div><div><img src="img/B16341_05_21.jpg" alt="Figure 5.21: Formula of recall&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.21:召回公式</p>
			<p>在前面的例子中，召回分数将是<img src="img/B16341_05_21a.png" alt="Text&#10;&#10;Description automatically generated with medium confidence"/>。使用此指标，您可以看到模型表现不佳，并且预测了大量fn。</p>
			<p>最后，F1分数是一个结合了精确度和召回率的指标(它是精确度和召回率的调和平均值)。其公式如下:</p>
			<div><div><img src="img/B16341_05_22.jpg" alt="Figure 5.22: Formula for the F1 score&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.22:F1分数的公式</p>
			<p>以与前述相同的例子为例，F1分数将为<img src="img/B16341_05_22a.png" alt="Formula"/></p>
			<p>该模型取得了F1分数<code>0.095</code>，与其准确度分数<code>0.981</code>相差甚远。因此，当您想要强调不正确的预测时，F1分数是一个很好的性能指标，该分数考虑了分数中fn和FPs的数量，以及TPs和TN的数量。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">与准确度、精确度和召回性能度量一样，F1分数也可以应用于其他类型的分类。</p>
			<p>通过使用<code>Precision()</code>和<code>Recall()</code>各自的类，您可以使用TensorFlow轻松计算精度和召回率:</p>
			<pre>from tensorflow.keras.metrics import Precision, Recall
preds = [1, 1, 1, 1, 0, 0]
target = [1, 0, 1, 0, 1, 0]
prec = Precision()
prec.update_state(preds, target)
print(f"Precision: {prec.result().numpy()}")
rec = Recall()
rec.update_state(preds, target)
print(f"Recall: {rec.result().numpy()}")</pre>
			<p>这会产生以下输出:</p>
			<p> </p>
			<div><div><img src="img/B16341_05_23.jpg" alt="Figure 5.23: Precision and recall scores of the provided example&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.23:所提供示例的精确度和召回分数</p>
			<p class="callout-heading">注意</p>
			<p class="callout">TensorFlow没有提供计算F1分数的类，但这可以通过创建自定义指标来轻松完成。这将在<em class="italic">练习5.02 </em>、<em class="italic">分类评估指标</em>中涉及。</p>
			<h2 id="_idParaDest-102"><a id="_idTextAnchor104"/>混淆矩阵</h2>
			<p>混淆矩阵本身并不是一个性能指标，而是一个图形化工具，用来将模型的预测与实际值进行对比。实际上，您已经在前面的<em class="italic">图5.18 </em>中看到了一个例子。</p>
			<p>混淆矩阵将在一个轴(例如，水平轴)上显示所有可能的预测值，在另一个轴(垂直轴)上显示实际值。在预测值和实际值的每个组合的交叉点，您将记录属于这种情况的观察值的数量。</p>
			<p>对于二元分类，混淆矩阵将如下所示:</p>
			<div><div><img src="img/B16341_05_24.jpg" alt="Figure 5.24: Confusion matrix for a binary classification&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.24:二元分类的混淆矩阵</p>
			<p>理想的情况是所有的值都位于这个矩阵的对角线上。这将意味着您的模型正确地预测了所有可能的值。这条对角线之外的所有值都是模型出错的地方。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">混淆矩阵也可以用于多类分类，而不仅仅局限于二元分类。</p>
			<p>运行下面的代码来查看混淆矩阵:</p>
			<pre>from tensorflow.math import confusion_matrix
preds = [1, 1, 1, 1, 0, 0]
target = [1, 0, 1, 0, 1, 0]
print(confusion_matrix(target, preds))</pre>
			<p>这将显示以下输出:</p>
			<div><div><img src="img/B16341_05_25.jpg" alt="Figure 5.25: TensorFlow confusion matrix&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.25:张量流混淆矩阵</p>
			<p>前面的输出显示了混淆矩阵。从中可以看出，模型已经预测了以下结果:两个TPs，一个TN，两个FPs，一个FN。</p>
			<p>在下一个练习中，您将把这些绩效指标应用于您在<em class="italic">练习5.01 </em>、<em class="italic">构建逻辑回归模型</em>中创建的相同逻辑回归模型。</p>
			<h2 id="_idParaDest-103">练习5.02:分类评估指标</h2>
			<p>在本练习中，您将重复使用与<em class="italic">练习5.01 </em>、<em class="italic">构建逻辑回归模型</em>中相同的逻辑回归模型，并通过查看不同的性能指标来评估其性能:准确度、精确度、召回率和F1分数。</p>
			<p>悉尼大学的Stephen Tridgell分享了原始数据集。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">训练数据集可以在这里访问:<a href="https://packt.link/QJGpA">https://packt.link/QJGpA</a>。</p>
			<p class="callout">测试数据集可以在这里访问:<a href="https://packt.link/ix5rW">https://packt.link/ix5rW</a>。</p>
			<p class="callout"><em class="italic">练习5.01 </em>、<em class="italic">建立逻辑回归模型</em>中的模型，可以在这里找到:<a href="https://packt.link/sSRQL">https://packt.link/sSRQL</a>。</p>
			<p>现在，运行以下指令:</p>
			<ol>
				<li value="1">打开新的Jupyter笔记本。</li>
				<li>导入熊猫库并使用<code>pd</code>作为别名:<pre>import pandas as pd</pre></li>
				<li>创建一个名为<code>train_url</code>的变量，其中包含训练集的URL:<pre>train_url = 'https://raw.githubusercontent.com/PacktWorkshops'\             '/The-TensorFlow-Workshop/master/Chapter05/dataset'\             '/dota2PreparedTrain.csv'</pre></li>
				<li>使用<code>read_csv()</code>方法将训练数据集加载到名为<code>X_train</code>的<code>DataFrame()</code>函数中，提供CSV文件的URL，并设置<code>header=None</code>为数据集不提供列名:<pre>X_train = pd.read_csv(train_url, header=None)</pre></li>
				<li>使用<code>pop()</code>方法提取目标变量(列<code>0</code>)并保存在名为<code>y_train</code> : <pre>y_train = X_train.pop(0)</pre>的变量中</li>
				<li>创建一个名为<code>test_url</code>的变量，它包含测试集的URL:<pre>test_url = 'https://raw.githubusercontent.com/PacktWorkshops'\            '/The-TensorFlow-Workshop/master/Chapter05/dataset'\            '/dota2PreparedTest.csv'</pre></li>
				<li>使用<code>read_csv()</code>方法将测试数据集加载到名为<code>X_test</code>的<code>DataFrame()</code>函数中，提供CSV文件的URL，并设置<code>header=None</code>为数据集不提供列名:<pre>X_test = pd.read_csv(test_url, header=None)</pre></li>
				<li>使用<code>pop()</code>方法提取目标变量(列<code>0</code>)并保存在名为<code>y_test</code> : <pre>y_test = X_test.pop(0)</pre>的变量中</li>
				<li>使用<code>tf</code>作为别名导入<code>tensorflow</code>库，并从<code>tensorflow.keras.utils</code> : <pre>import tensorflow as tf from tensorflow.keras.utils import get_file</pre>导入<code>get_file()</code>方法</li>
				<li>创建一个名为<code>model_url</code>的变量，包含模型的URL:<pre>model_url = 'https://github.com/PacktWorkshops'\             '/The-TensorFlow-Workshop/blob/master/Chapter05'\             'model/exercise5_01_model.h5?raw=true'</pre></li>
				<li>通过提供文件名(<code>exercise5_01_model.h5</code>)及其URL，使用<code>get_file()</code>方法在本地下载模型。将输出保存到名为<code>model_path</code> : <pre>model_path = get_file('exercise5_01_model.h5', model_url)</pre>的变量</li>
				<li>用<code>tf.keras.models.load_model()</code>加载模型，并指定模型的本地路径:<pre>model = tf.keras.models.load_model(model_path)</pre></li>
				<li>Print the model summary using the <code>summary()</code> method:<pre>model.summary()</pre><p>预期产出如下:</p><div><img src="img/B16341_05_26.jpg" alt="Figure 5.26: Summary of the model&#13;&#10;"/></div><p class="figure-caption">图5.26:模型总结</p><p>前面的输出显示了与<em class="italic">练习5.01 </em>、<em class="italic">构建逻辑回归模型</em>中的模型相同的架构。</p></li>
				<li>Predict the results of the test set using <code>predict()</code> method. Save it in a variable called <code>preds_proba</code> and display its first five values:<pre>preds_proba = model.predict(X_test)
preds_proba[:5]</pre><p>预期产出如下:</p><div><img src="img/B16341_05_27.jpg" alt="Figure 5.27: Predicted probabilities of the test set&#13;&#10;"/></div><p class="figure-caption">图5.27:测试集的预测概率</p><p>输出是对每个观察的<code>1</code>(或真实)的预测概率。你只需要将这些概率转换成<code>0</code>和<code>1</code>。为此，您需要考虑所有概率大于或等于<code>0.5</code>的情况为<code>1</code>(或真)，概率小于<code>0.5</code>的记录为<code>0</code>(或假)。</p></li>
				<li>Convert the predicted probabilities into <code>1</code> when the probability is greater than or equal to <code>0.5</code>, and <code>0</code> when below <code>0.5</code>. Save the results in a variable called <code>preds</code> and print its first five rows:<pre>preds = preds_proba &gt;= 0.5
preds[:5]</pre><p>预期产出如下:</p><div><img src="img/B16341_05_28.jpg" alt="Figure 5.28: Predictions of the test set&#13;&#10;"/></div><p class="figure-caption">图5.28:测试集的预测</p><p>现在预测已经被转换成二进制值:true(等于<code>1</code>)和false(等于<code>0</code>)。</p></li>
				<li>从<code>tensorflow.keras.metrics</code> : <pre>from tensorflow.keras.metrics import Accuracy, Precision, Recall</pre>导入<code>Accuracy</code>、<code>Precision</code>和<code>Recall</code></li>
				<li>实例化<code>Accuracy</code>、<code>Precision</code>和<code>Recall</code>对象，并分别保存在名为<code>acc</code>、<code>pres</code>和<code>rec</code>的变量中:<pre>acc = Accuracy() prec = Precision() rec = Recall()</pre></li>
				<li>Calculate the accuracy score on the test set with the <code>update_state()</code>, <code>result()</code>, and <code>numpy()</code> methods. Save the results in a variable called <code>acc_results</code> and print its content:<pre>acc.update_state(preds, y_test)
acc_results = acc.result().numpy()
acc_results</pre><p>预期产出如下:</p><pre>0.59650314</pre><p>该模型获得了<code>0.597</code>的准确度分数。</p></li>
				<li>Calculate the precision score on the test set with the <code>update_state()</code>, <code>result()</code>, and <code>numpy()</code> methods. Save the results in a variable called <code>prec_results</code> and print its content:<pre>prec.update_state(preds, y_test)
prec_results = prec.result().numpy()
prec_results</pre><p>预期产出如下:</p><pre>0.59578335</pre><p>这个模型取得了<code>0.596</code>的精度分数。</p></li>
				<li>Calculate the recall score on the test set with the <code>update_state()</code>, <code>result()</code>, and <code>numpy()</code> methods. Save the results in a variable called <code>rec_results</code> and print its content:<pre>rec.update_state(preds, y_test)
rec_results = rec.result().numpy()
rec_results</pre><p>预期产出如下:</p><pre>0.6294163</pre><p>这个模型取得了<code>0.629</code>的召回分数。</p></li>
				<li>Calculate the F1 score by applying the formula shown in the previous section. Save the result in a variable called <code>f1</code> and print its content:<pre>f1 = 2*(prec_results * rec_results) / (prec_results + rec_results)
f1</pre><p>预期产出如下:</p><pre>0.6121381493171637</pre><p>总的来说，该模型在所有四个不同的指标上取得了接近<code>0.6</code>的很低的分数:准确度、精确度、召回率和F1分数。所以，这个模型做出的正确预测几乎和错误预测一样多。你可以自己尝试建立另一个模型，看看是否能提高它的性能。</p></li>
			</ol>
			<p>在前面的部分中，您将看到使用多类分类将分类扩展到两个以上的可能值。</p>
			<h1 id="_idParaDest-104"><a id="_idTextAnchor107"/>多类分类</h1>
			<p>使用二进制<a id="_idTextAnchor108"/>分类，您只能处理只能取两个可能值的目标变量:<code>0</code>和<code>1</code>(假或真)。多类分类可以看作是这种分类的扩展，允许目标变量有两个以上的值(或者你可以说二元分类只是多类分类的一个子集)。例如，预测患者不同疾病严重程度的模型，或者根据用户过去的购物行为将用户分为不同组的模型，将是多类分类器。</p>
			<p>在下一节中，您将深入了解softmax函数，该函数用于多类分类。</p>
			<h2 id="_idParaDest-105"><a id="_idTextAnchor109"/>soft max功能</h2>
			<p>二元分类器<a id="_idTextAnchor110"/>需要一个特定的激活函数用于神经网络的最后一个全连接层，即sigmoid。针对多类分类器的激活函数是不同的。是softmax。其公式如下:</p>
			<div><div><img src="img/B16341_05_29.jpg" alt="Figure 5.29: Formula of softmax function&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.29:soft max函数的公式</p>
			<p><img src="img/B16341_05_29a.png" alt="Formula 1"/>对应于<code>i</code>等级的预测值。</p>
			<p><img src="img/B16341_05_29b.png" alt="Formula 1"/>对应于类别<code>j</code>的预测值。</p>
			<p>该公式将应用于目标变量的每个可能值。如果您有10个可能的值，那么这个激活函数将计算10个不同的softmax值。</p>
			<p>请注意，softmax对分子和分母的预测值进行幂运算。这背后的原因是指数函数放大了预测值之间的微小变化，并使概率更接近于<code>0</code>或<code>1</code>，以便解释最终输出。比如<code>exp(2) = 7.39</code>而<code>exp(2.2) = 9.03</code>。因此，如果两个类的预测值彼此接近，则它们的指数值之间的差异会大得多，因此选择较高的值会更容易。</p>
			<p>softmax函数的结果介于<code>0</code>和<code>1</code>之间，因为该方法将一个类的值除以所有类的总和。因此，softmax函数的实际输出是相关类成为最终预测的概率:</p>
			<div><div><img src="img/B16341_05_30.jpg" alt="Figure 5.30: Example of softmax transformation&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.30:soft max变换示例</p>
			<p>在前面的示例中，目标变量有五个不同的值，softmax函数将它们转换成概率。第一类(<code>0</code>)是概率最高的一类，这将是最终的预测。</p>
			<h2 id="_idParaDest-106"><a id="_idTextAnchor111"/>分类交叉熵</h2>
			<p>多类分类还需要特定的损失函数，该损失函数不同于二元分类器的二元交叉熵。对于多类分类，损失函数是类别交叉熵。其公式如下:</p>
			<div><div><img src="img/B16341_05_31.jpg" alt="Figure 5.31: Formula of categorical cross-entropy&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.31:分类交叉熵公式</p>
			<p><img src="img/B16341_05_31a.png" alt="Formula"/>代表观察值<code>i</code>的实际值属于<code>j</code>类的概率。</p>
			<p><img src="img/B16341_05_31b.png" alt="Formula 1"/>代表观察值<code>i</code>属于<code>j</code>类的预测概率。</p>
			<p>TensorFlow为此损失函数提供了两个不同的类别:<code>CategoricalCrossentropy()</code>和<code>SparseCategoricalCrossentropy()</code>:</p>
			<pre>from tensorflow.keras.losses import CategoricalCrossentropy, 
                                    SparseCategoricalCrossentropy
cce = CategoricalCrossentropy()
scce = SparseCategoricalCrossentropy()</pre>
			<p>两者的区别在于目标变量的格式。如果实际值被存储为代表实际类的一键编码，那么您将需要使用<code>CategoricalCrossentropy()</code>。另一方面，如果响应变量存储为整数来表示实际的类，您将不得不使用<code>SparseCategoricalCrossentropy()</code>:</p>
			<div><div><img src="img/B16341_05_32.jpg" alt="Figure 5.32: Loss function to be used depending on the format of the target variable&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.32:根据目标变量的格式使用的损失函数</p>
			<p>多类模型的输出将是一个向量，包含目标变量的每一类的概率，如下所示:</p>
			<pre>import numpy as np
preds_proba = np.array([0.54, 0.16, 0.09, 0.15, 0.06])</pre>
			<p>第一个值(<code>0.54</code>)对应于索引为0的类的概率，<code>0.016</code>是索引为1的类的概率，而<code>0.09</code>对应于索引为2的类的概率，依此类推。</p>
			<p>为了得到最终的预测(即概率最高的类)，您需要使用<code>argmax()</code>函数，该函数将查看来自一个向量的所有值，找到最大值，并返回与之关联的索引:</p>
			<pre>preds_proba.argmax()</pre>
			<p>这将显示以下输出:</p>
			<pre>0</pre>
			<p>在前面的例子中，最终预测是<code>class 0</code>，它对应于具有最高概率的向量索引(<code>0.54</code>)。</p>
			<h2 id="_idParaDest-107"><a id="_idTextAnchor112"/>多类分类架构</h2>
			<p>多类分类器的arc体系结构非常类似于逻辑回归，除了最后一层将包含更多的单元。它们中的每一个都对应于目标变量的一个类。例如，如果您正在构建一个模型，该模型将大小为6的向量作为输入，并使用单个隐藏层预测具有三个不同值的响应，其体系结构将如下所示:</p>
			<div><div><img src="img/B16341_05_33.jpg" alt="Figure 5.33: Architecture of a multi-class classifier&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.33:多类分类器的架构</p>
			<p>最后一层的softmax激活函数提供了每个可能类别的发生概率:<code>A</code>、<code>B</code>和<code>C</code>。这些概率是相互依赖的，因为最终应该只有一个类别被预测。如果类别<code>A</code>更有可能是预测值(如前一示例所示)，则其余类别(<code>B</code>和<code>C</code>)的概率应该较低。注意，所有类别概率的总和等于<code>1</code>。因此，他们确实是相互依赖的。</p>
			<p>现在您已经知道了所有的构建模块，您可以在下面的练习中构建一个多类分类器。</p>
			<h2 id="_idParaDest-108">练习5.03:建立一个多班级模型</h2>
			<p>在本练习中，您将在TensorFlow中构建和训练一个多类分类器，该分类器将使用该数据集中提供的九个不同的数字特征，根据八个不同的值来预测航天飞机的辐射器位置。</p>
			<p>目标变量(最后一列)包含七个不同的级别:<code>Rad.Flow</code>、<code>Fpv.Close</code>、<code>Fpv.Open</code>、<code>High</code>、<code>Bypass</code>、<code>Bpv.Close</code>和<code>Bpv.Open</code>。您的目标是使用数据集中的九个要素准确预测这七个级别之一。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">训练数据集可以在这里访问:<a href="https://packt.link/46iMY">https://packt.link/46iMY</a>。</p>
			<p class="callout">测试数据集可以在这里访问:<a href="https://packt.link/dcNPt">https://packt.link/dcNPt</a>。</p>
			<p class="callout">原始数据集可以在这里找到:<a href="http://archive.ics.uci.edu/ml/datasets/Statlog+%28Shuttle%29">http://archive . ics . UCI . edu/ml/datasets/Statlog+% 28 shuttle % 29</a>。</p>
			<p>执行以下步骤来完成练习:</p>
			<ol>
				<li value="1">打开新的Jupyter笔记本。</li>
				<li>导入熊猫库并使用<code>pd</code>作为别名:<pre>import pandas as pd</pre></li>
				<li>创建一个名为<code>train_url</code>的变量，其中包含训练集的URL:<pre>train_url = 'https://raw.githubusercontent.com/PacktWorkshops'\             '/The-TensorFlow-Workshop/master/Chapter05'\             '/dataset/shuttle.trn'</pre></li>
				<li>Load the training dataset into a DataFrame called <code>X_train</code> using the <code>read_table()</code> method, provide the URL to the CSV file, use <code>header=None</code> as the dataset doesn't provide column names, and use <code>sep=' '</code> as each column is separated by spaces in this dataset. Print the first five rows using <code>head()</code> method:<pre>X_train = pd.read_table(train_url, header=None, sep=' ')
X_train.head()</pre><p>预期产出如下:</p><div><img src="img/B16341_05_34.jpg" alt="Figure 5.34: The first five rows of the training set&#13;&#10;"/></div><p class="figure-caption">图5.34:训练集的前五行</p><p>您可以看到数据集包含10列，它们都是数字。另外，注意目标变量(列<code>9</code>)包含不同的类值。</p></li>
				<li>使用<code>pop()</code>方法提取目标变量(列<code>9</code>)并保存在名为<code>y_train</code> : <pre>y_train = X_train.pop(9)</pre>的变量中</li>
				<li>创建一个名为<code>test_url</code>的变量，它包含测试集的URL:<pre>test_url = 'https://raw.githubusercontent.com/PacktWorkshops'\            '/The-TensorFlow-Workshop/master/Chapter05/dataset'\            '/shuttle.tst'</pre></li>
				<li>Load the test dataset into a DataFrame called <code>X_test</code> using <code>read_table()</code>, provide the URL to the CSV file, set <code>header=None</code> as the dataset doesn't provide column names, and use <code>sep=' '</code> as each column is separated by a space in this dataset. Print the first five rows using <code>head()</code> method.<pre>X_test = pd.read_table(test_url, header=None, sep=' ')
X_test.head()</pre><p>预期产出如下:</p><div><img src="img/B16341_05_35.jpg" alt="Figure 5.35: The first five rows of the test set&#13;&#10;"/></div><p class="figure-caption">图5.35:测试集的前五行</p><p>您可以看到测试集与训练集非常相似。</p></li>
				<li>使用<code>pop()</code>方法提取目标变量(列<code>9</code>)并保存在名为<code>y_test</code> : <pre>y_test = X_test.pop(9)</pre>的变量中</li>
				<li>导入TensorFlow库并使用<code>tf</code>作为别名:<pre>import tensorflow as tf</pre></li>
				<li>使用<code>tf.random.set_seed()</code>将张量流的种子设置为<code>8</code>以获得可重复的结果:<pre>tf.random.set_seed(8)</pre></li>
				<li>使用<code>tf.keras.Sequential()</code>实例化一个序列模型，并将其存储在一个名为<code>model</code> : <pre>model = tf.keras.Sequential()</pre>的变量中</li>
				<li>从<code>tensorflow.keras.layers</code> : <pre>from tensorflow.keras.layers import Dense</pre>导入<code>Dense()</code>级</li>
				<li>使用<code>Dense()</code>创建一个由<code>512</code>个单元组成的全连接图层，并将ReLu指定为激活函数，将输入形状指定为<code>(9,)</code>，这对应于数据集中的要素数量。将其保存在一个名为<code>fc1</code> : <pre>fc1 = Dense(512, input_shape=(9,), activation='relu')</pre>的变量中</li>
				<li>用<code>Dense()</code>创建一个全连接的<code>512</code>单元层，并将ReLu指定为激活函数。将其保存在一个名为<code>fc2</code> : <pre>fc2 = Dense(512, activation='relu')</pre>的变量中</li>
				<li>用<code>Dense()</code>创建一个全连接的<code>128</code>单元层，并指定ReLu为激活函数。将其保存在一个名为<code>fc3</code> : <pre>fc3 = Dense(128, activation='relu')</pre>的变量中</li>
				<li>同样，用<code>Dense()</code>创建一个完全连接的<code>128</code>单元层，并将ReLu指定为激活函数。将它保存在一个名为<code>fc4</code> : <pre>fc4 = Dense(128, activation='relu')</pre>的变量中</li>
				<li>用<code>Dense()</code>创建一个128个单位的全连接层，并将softmax指定为激活函数。保存在一个名为<code>fc5</code> : <pre>fc5 = Dense(8, activation='softmax')</pre>的变量中</li>
				<li>使用<code>add()</code>方法将所有五个完全连接的层依次添加到模型中。<pre>model.add(fc1) model.add(fc2) model.add(fc3) model.add(fc4) model.add(fc5)</pre></li>
				<li>Print the summary of the model using <code>summary()</code> method:<pre>model.summary()</pre><p>预期产出如下:</p><div><img src="img/B16341_05_36.jpg" alt="Figure 5.36: Summary of the model architecture&#13;&#10;"/></div><p class="figure-caption">图5.36:模型架构概要</p><p>前面的输出显示您的模型中有五个层(如预期的那样),并告诉您每个层的参数数量。例如，第一层包含<code>5,120</code>个参数，该模型的参数总数为<code>350,984</code>。所有这些参数将在拟合模型时被训练。</p></li>
				<li>从<code>tf.keras.losses</code>实例化<code>SparseCategoricalCrossentropy()</code>并保存在一个名为<code>loss</code> : <pre>loss = tf.keras.losses.SparseCategoricalCrossentropy()</pre>的变量中</li>
				<li>用<code>0.001</code>作为学习率实例化<code>tf.keras.optimizers</code>中的<code>Adam()</code>，并保存在一个名为<code>optimizer</code> : <pre>optimizer = tf.keras.optimizers.Adam(0.001)</pre>的变量中</li>
				<li>使用<code>compile()</code>方法编译模型，并指定优化器和损耗参数，精确度作为要报告的度量:<pre>model.compile(optimizer=optimizer, loss=loss, \               metrics=['accuracy'])</pre></li>
				<li>Start the model training process using <code>fit()</code> method on the training set for five epochs:<pre>model.fit(X_train, y_train, epochs=5)</pre><p>预期产出如下:</p><div><img src="img/B16341_05_37.jpg" alt="Figure 5.37: Logs of the training process&#13;&#10;"/></div><p class="figure-caption">图5.37:培训过程的日志</p><p>前面的输出显示了模型训练期间每个时期的日志。注意，处理单个时期花费了大约7秒，并且损失值从<code>0.5859</code>(第一时期)减少到<code>0.0351</code>(第五时期)。</p></li>
				<li>Evaluate the performance of the model on the test set using the <code>evaluate()</code> method:<pre>model.evaluate(X_test, y_test)</pre><p>预期产出如下:</p><div><img src="img/B16341_05_38.jpg" alt="Figure 5.38: Performance of the model on the test set&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">图5.38:模型在测试集上的表现</p>
			<p>在本练习中，您学习了如何构建和训练一个多类分类器来预测由八个不同类组成的结果。你的模型在训练集和测试集上都达到了接近<code>0.997</code>的准确率，这是非常了不起的。这意味着您的模型在大多数情况下都能正确预测正确的类别。</p>
			<p>现在，让我们在下面的活动中巩固您的学习。</p>
			<h2 id="_idParaDest-109">活动5.01:用TensorFlow建立字符识别模型<a id="_idTextAnchor116"/> <a id="_idTextAnchor117"/></h2>
			<p>在本活动中，您的任务是构建和训练一个多类分类器，该分类器将从图像中识别字母表中的26个字母。在该数据集中，图像已被转换为16种不同的统计度量，这些度量将构成我们的特征。这个模型的目标是确定每个观察值属于26个字符中的哪一个。</p>
			<p>原始数据集由Odesta公司的David J. Slate分享，可以在这里找到:<a href="http://archive.ics.uci.edu/ml/datasets/Letter+Recognition">http://archive.ics.uci.edu/ml/datasets/Letter+Recognition</a>。</p>
			<p>可以从这里访问数据集:<a href="https://packt.link/j8m3L">https://packt.link/j8m3L</a>。</p>
			<p>以下步骤将帮助您完成活动:</p>
			<ol>
				<li value="1">用熊猫的<code>read_csv()</code>加载数据。</li>
				<li>用<code>pop()</code>方法从熊猫中提取目标变量。</li>
				<li>将数据分为定型集(前15，000行)和测试集(后5，000行)。</li>
				<li>分别用<code>512</code>、<code>512</code>、<code>128</code>、<code>128</code>和<code>26</code>单元的五个全连接层构建多类分类器。</li>
				<li>在训练集上训练此模型。</li>
				<li>使用TensorFlow的<code>evaluate()</code>方法在测试集上评估其性能。</li>
				<li>Print the confusion matrix with <code>confusion_matrix()</code> from TensorFlow.<p>预期产出如下:</p><p> </p><div><img src="img/B16341_05_39.jpg" alt="Figure 5.39: Confusion matrix of the test set&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">图5.39:测试集的混淆矩阵</p>
			<p class="callout-heading">注意</p>
			<p class="callout">此活动的解决方案可通过<a href="B16341_Solution_ePub.xhtml#_idTextAnchor265">此链接</a>找到。</p>
			<h1 id="_idParaDest-110"><a id="_idTextAnchor118"/>多标签分类</h1>
			<p>多标签分类<a id="_idTextAnchor119"/>是另一种类型的分类，在这种分类中，您不仅可以预测一个目标变量(如二元或多类分类),还可以同时预测多个响应变量。例如，您可以预测图像中出现的不同对象的多个输出(例如，一个模型将预测给定图片中是否有一只猫、一个人和一辆汽车)，或者您可以预测一篇文章的多个主题(例如，这篇文章是否是关于经济、国际新闻和制造业的)。</p>
			<p>用神经网络实现多标签分类极其容易，并且您已经了解了构建多标签分类所需的一切。在TensorFlow中，多标签分类器的架构看起来与多类的架构相同，最终输出层具有与您想要预测的目标变量数量相对应的多个单元。但是，您将分别使用sigmoid和二进制交叉熵作为激活函数和损失函数，而不是使用softmax作为激活函数和分类交叉熵作为损失函数。</p>
			<p>sigmoid函数将预测每个目标变量的发生概率:</p>
			<div><div><img src="img/B16341_05_40.jpg" alt="Figure 5.40: Architecture of the multi-label classifier&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图5.40:多标签分类器的架构</p>
			<p>在前面的例子中，您有三个目标变量，每个变量都有独立于其他变量的发生概率(它们的和不等于1)。该模型预测目标<code>2</code>和<code>3</code>很可能是该观察的输出。</p>
			<p>从概念上讲，多标签分类结合了几个逻辑回归模型。它们将共享相同的参数(权重和偏差)，但具有独立的二进制输出。TensorFlow中多类分类器示例的最后一层如下所示:</p>
			<pre>from tensorflow.keras.layers import Dense
Dense(3, activation='sigmoid')</pre>
			<p>要使用的损失函数将是二元交叉熵:</p>
			<pre>from tensorflow.keras.losses import BinaryCrossentropy
bce = BinaryCrossentropy()</pre>
			<p>现在，在接下来的活动中把你学到的东西付诸行动。</p>
			<h2 id="_idParaDest-111">活动5.02:用TensorFlow建立一个电影类型标签模型</h2>
			<p>在本活动中，您的任务是构建和训练一个多标签分类器，该分类器将从28个可能值中预测电影的类型。每部电影可以一次分配到多个类型。这些特征是从它的概要中提取的顶级关键词。用于此活动的数据集是原始数据集的子集，仅包含20，000行。</p>
			<p>原始数据集由http://www.uco.es/kdis/mllresources/#ImdbDesc分享，可以在这里找到:<a href="http://www.uco.es/kdis/mllresources/#ImdbDesc"/>。</p>
			<p>可以从这里访问数据集的特征:<a href="https://packt.link/yW5ru">https://packt.link/yW5ru</a>。</p>
			<p>数据集的目标可以从这里访问:<a href="https://packt.link/8f1mb">https://packt.link/8f1mb</a>。</p>
			<p>以下步骤将帮助您完成活动:</p>
			<ol>
				<li value="1">用熊猫的<code>read_csv()</code>加载特征和目标。</li>
				<li>将数据分为定型集(前15，000行)和测试集(后5，000行)。</li>
				<li>分别用<code>512</code>、<code>512</code>、<code>128</code>、<code>128</code>和<code>28</code>单元的五个全连接层构建多类分类器。</li>
				<li>在训练集上训练此模型。</li>
				<li>Evaluate its performance on the test set with <code>evaluate()</code> method from TensorFlow.<p>预期产出如下:</p><div><img src="img/B16341_05_41.jpg" alt="Formula"/></div></li>
			</ol>
			<p class="figure-caption">图5.41:活动5.02的预期产出</p>
			<p class="callout-heading">注意</p>
			<p class="callout">此活动的解决方案可通过<a href="B16341_Solution_ePub.xhtml#_idTextAnchor267">此链接</a>找到。</p>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor123"/>总结</h1>
			<p>在这一章中，你以对分类模型及其与回归模型的差异的<a id="_idTextAnchor124"/>介绍开始了你的旅程。您了解了分类器的目标变量只能包含有限数量的可能值。</p>
			<p>然后，您探索了二进制分类，其中响应变量只能来自两个可能的值:<code>0</code>或<code>1</code>。您发现了使用sigmoid激活函数和二进制交叉熵作为损失函数使用TensorFlow构建逻辑回归模型的特殊性，并且您构建了自己的二进制分类器来预测视频游戏Dota 2的获胜团队。</p>
			<p>在此之后，您了解了可用于评估分类器模型性能的不同性能指标。您练习了使用TensorFlow计算准确度、精确度、召回率和F1分数，还绘制了混淆矩阵，这是一种可视化工具，可以查看模型在哪些地方做出了正确和错误的预测。</p>
			<p>然后你就进入了多类分类的话题。这种模型和二元分类器之间的区别在于，它们的响应变量可以取两个以上的可能值。您查看了softmax激活函数和分类交叉熵损失函数，它们用于在TensorFlow中训练此类模型。</p>
			<p>最后，在上一节中，您学习了多标签分类，其中输出可以同时是多个类。在TensorFlow中，通过构建类似于多类分类的架构，但分别使用sigmoid和二进制交叉熵作为激活和损失函数，可以很容易地构建这样的模型。</p>
			<p>在下一章中，您将学习如何通过应用一些正则化技术来防止模型过度拟合，这将有助于模型更好地概括看不见的数据。</p>
		</div>
	

</body></html>