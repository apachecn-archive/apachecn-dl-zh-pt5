<html><head/><body>


	
		<title>B16341_10_ePub</title>
		
	
	
		<div><div/>
		</div>
		<div><h1 id="_idParaDest-184"><a id="_idTextAnchor208"/> 10。自定义TensorFlow组件</h1>
		</div>
		<div><p class="callout-heading">概观</p>
			<p class="callout">在本章中，您将深入TensorFlow框架并构建自定义模块。结束时，您将知道如何创建自定义张量流组件以在模型中使用，如损失函数和层。</p>
			<h1 id="_idParaDest-185"><a id="_idTextAnchor209"/>简介</h1>
			<p>在前面的章节中，您学习了如何从预定义的张量流模块构建CNN或RNN模型。您一直在使用TensorFlow提供的API之一，称为顺序API。这个API是用几行代码开始构建“简单”深度学习架构的好方法。但是，如果您想获得更高的性能，您可能需要构建自己的定制架构。在这种情况下，您将需要使用另一个名为functional API的API。研究人员在定义他们的模型架构时使用功能API。通过学习如何使用它，您将能够创建自定义的损失函数或模块，例如ResNet体系结构中的剩余块。</p>
			<h1 id="_idParaDest-186"><a id="_idTextAnchor210"/>tensor flow API</h1>
			<p>使用TensorFlow时，您可以从顺序API、函数API或子类API中进行选择来定义您的模型。对于大多数人来说，顺序API将是首选。然而，随着时间的推移，你接触到更多的复杂性，你的需求也会扩大。</p>
			<p><strong class="bold">顺序API </strong>是用于创建张量流模型的最简单的API。它的工作原理是将不同的层一层层堆叠起来。例如，您将创建一个顺序模型，其中第一个图层是卷积图层，接下来是分离图层，然后是完全连接图层。该模型是顺序的，因为输入数据将按顺序传递到每个定义的层。</p>
			<p><strong class="bold">功能API </strong>提供了更多的灵活性。您可以使用不同的层来定义模型，这些层之间的交互不是按顺序进行的。例如，您可以创建两个不同的层，这两个层都将馈入第三个层。这可以通过函数式API轻松实现。</p>
			<p><code>Layer</code>或<code>Model</code>。您可以定义自己的自定义层或模型，但这意味着您需要遵守继承的TensorFlow类的所有要求，例如编码强制方法。</p>
			<p>下图简要概述了TensorFlow提供的三种不同的API:</p>
			<div><div><img src="img/B16341_10_01.jpg" alt="Figure 10.1: Diagram showing a comparison of all three APIs&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图10.1:显示所有三个API比较的图表</p>
			<p>在前面的小节中，您将学习如何定义一个定制的损失函数。</p>
			<h1 id="_idParaDest-187"><a id="_idTextAnchor211"/>实现自定义损耗功能</h1>
			<p>有几种类型的损失函数通常用于机器学习。在<em class="italic">第五章</em>、<em class="italic">分类</em>中，你学习了不同类型的损失函数，并将其用于不同的分类模型。TensorFlow有相当多的内置损失函数可供选择。以下是一些更常见的损失函数:</p>
			<ul>
				<li>平均绝对误差</li>
				<li>均方误差</li>
				<li>二元交叉熵</li>
				<li>范畴交叉熵</li>
				<li>关键</li>
				<li>休伯</li>
				<li>均方对数误差(MSLE)</li>
			</ul>
			<p>快速提醒一下，你可以把损失函数想象成一种指南针，让你清楚地看到什么在算法中起作用，什么不起作用。损失越高，模型越不精确，等等。</p>
			<p>虽然TensorFlow有几个可用的损失函数，但在某些时候，您很可能需要根据自己的特定需求创建自己的损失函数。例如，如果您正在构建一个预测股票价格的模型，您希望定义一个损失函数来惩罚实质上不正确的值。</p>
			<p>下一节将向您展示如何构建自定义损失函数。</p>
			<h2 id="_idParaDest-188"><a id="_idTextAnchor212"/>用函数式API构建自定义损失函数</h2>
			<p>在前面的章节中，您已经了解了如何使用TensorFlow中的预定义损失函数。但是如果你想构建你自己的定制函数，你可以使用函数API或者模型子类化。假设您想要构建一个损失函数，将预测值和实际值之间的差值提高到4的幂:</p>
			<div><div><img src="img/B16341_10_02.jpg" alt="Figure 10.2: Formula for custom loss&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图10.2:客户损失公式</p>
			<p>创建自定义损失函数时，您将始终需要两个参数:<code>y_true</code>(实际值)和<code>y_pred</code>(预测值)。损失函数将计算这两个值之间的差值，并返回一个表示模型预测值与实际值相差多少的误差值。在MAE的情况下，这个损失函数将返回这个误差的绝对值。另一方面，MSE将对实际值和预测值之间的差进行平方。但是在前面的例子中，误差应该被提升到<code>4</code>的幂。</p>
			<p>让我们看看如何使用函数式API来实现这一点。首先，您需要使用以下命令导入TensorFlow库:</p>
			<pre>import tensorflow as tf</pre>
			<p>然后，您必须创建一个名为<code>custom_loss</code>的函数，它将<code>y_true</code>和<code>y_pred</code>参数作为输入。然后，您将使用<code>pow</code>函数将计算出的误差提升到<code>4</code>的幂。最后，您将返回计算出的误差:</p>
			<pre>def custom_loss(y_true, y_pred):
    custom_loss=tf.math.pow(y_true - y_pred, 4)
    return custom_loss</pre>
			<p>您已经使用函数式API创建了自己的定制损失函数。现在，在训练模型之前，您可以将它传递给<code>compile</code>方法，而不是预定义的损失函数:</p>
			<pre>model.compile(loss=custom_loss,optimizer=optimizer)</pre>
			<p>在这之后，你可以用和前几章完全一样的方法训练你的模型。TensorFlow将使用您的自定义损失函数来优化您的模型的学习过程。</p>
			<h2 id="_idParaDest-189"><a id="_idTextAnchor213"/>用子类化API构建自定义损失函数</h2>
			<p>还有另一种定义自定义损失函数的方法:使用子类化API。在这种情况下，您将为它定义一个自定义类，而不是构建一个函数。如果您想用额外的自定义属性或方法来扩展它，这是非常有用的。通过子类化，您可以创建一个自定义类，它将从<code>keras.losses</code>模块的<code>Loss</code>类继承属性和方法。然后你需要定义<code>__init__()</code>和<code>call()</code>方法，这在<code>Loss</code>类中是必需的。在<code>__init__</code>方法中，您将定义自定义类的所有属性，在<code>call()</code>方法中，您将指定计算损失的逻辑。</p>
			<p>下面是一个简单的例子，说明如何使用子类化API来实现定制的loss，其中错误应该被提升到<code>4</code>的幂:</p>
			<pre>class MyCustomLoss(keras.losses.Loss):
    def __init__(self, threshold=1.0, **kwargs):
        super().__init__(**kwargs)
    def call(self, y_true, y_pred):
        return tf.math.pow(y_true - y_pred, 4)</pre>
			<p>在前面的例子中，您已经重新实现了与前面相同的损失函数(4的幂)，但是使用了来自<code>keras.losses.Loss</code>的子类。首先，在<code>__init__()</code>方法中使用<code>self</code>参数初始化您的类的属性，该参数引用对象本身。</p>
			<p>然后，在<code>call()</code>方法中，您定义了损失函数的逻辑，它计算了误差并将其提升到4的幂。</p>
			<p>现在您已经熟悉了损失函数，是时候在下一个练习中构建一个了。</p>
			<h2 id="_idParaDest-190"><a id="_idTextAnchor214"/>练习10.01:构建自定义损失函数</h2>
			<p>在本练习中，您将创建自己的自定义损失函数来训练CNN模型，以区分苹果和西红柿的图像。</p>
			<p>在本练习中，您将使用<code>Apple-or-Tomato</code>数据集。该数据集是GitHub上<code>Fruits 360</code>数据集的子集。<code>Fruits 360</code>数据集由1948幅尺寸为100×100像素的彩色图像组成。<code>Apple-or-Tomato</code>数据集有992个苹果图像，其中662个在训练集中，330个在测试数据集中。总共有956幅番茄图像，其中638幅在训练数据集中，318幅在测试数据集中。</p>
			<p class="callout-heading"><strong class="bold">注</strong></p>
			<p class="callout">您可以在以下链接获得<code>Apple-or-Tomato</code>数据集:【https://packt.link/28kZY T21】。</p>
			<p class="callout">可以在这里找到<code>Fruits 360</code>数据集:<a href="https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip">https://github . com/horea 94/Fruit-Images-Dataset/archive/master . zip</a>。</p>
			<p>首先，打开一个新的Colab或Jupyter笔记本。如果您正在使用Google Colab，您需要首先将数据集下载到您的Google Drive中:</p>
			<ol>
				<li>打开新的Jupyter笔记本或Google Colab笔记本。</li>
				<li>如果您使用Google Colab，使用以下代码在本地上传您的数据集。否则，转到<em class="italic">步骤4 </em>。点击<code>Choose Files</code>导航至CSV文件，然后点击<code>Open</code>。将文件另存为<code>uploaded</code>。然后，转到保存数据集的文件夹:<pre>from google.colab import files uploaded = files.upload()</pre></li>
				<li>将数据集解压到当前文件夹:<pre>!unzip \*.zip</pre></li>
				<li>创建一个变量<code>directory</code>，它包含数据集的路径:<pre>directory = "/content/gdrive/My Drive/Datasets/apple-or-tomato/"</pre></li>
				<li>导入<code>pathlib</code>库:<pre>import pathlib</pre></li>
				<li>使用<code>pathlib.Path</code> : <pre>path = pathlib.Path(directory)</pre>创建一个包含数据集完整路径的变量<code>path</code></li>
				<li>创建两个变量<code>train_dir</code>和<code>validation_dir</code>，它们分别采用训练和验证文件夹的完整路径:<pre>train_dir = path / 'training_set' validation_dir = path / 'test_set'</pre></li>
				<li>创建四个变量，<code>train_apple_dir</code>、<code>train_tomato_dir</code>、<code>validation_apple_dir</code>和<code>validation_tomato_dir</code>，它们分别采用训练集和验证集的<code>apple</code>和<code>tomato</code>文件夹的完整路径:<pre>train_apple_dir = train_dir / 'apple' train_tomato_dir = train_dir /'tomato' validation_apple_dir = validation_dir / 'apple' validation_tomato_dir = validation_dir / 'tomato'</pre></li>
				<li>导入<code>os</code>包:<pre>import os</pre></li>
				<li>创建两个名为<code>total_train</code>和<code>total_val</code>的变量，这两个变量将分别获得训练集和验证集的图像数量:<pre>total_train = len(os.listdir(train_apple_dir)) + \               len(os.listdir(train_tomato_dir)) total_val = len(os.listdir(validation_apple_dir)) + \             len(os.listdir(validation_tomato_dir))</pre></li>
				<li>从<code>tensorflow.keras.preprocessing</code>模块导入<code>ImageDataGenerator</code>:<pre>from tensorflow.keras.preprocessing.image import ImageDataGenerator</pre></li>
				<li>实例化两个<code>ImageDataGenerator</code>类，<code>train_image_generator</code>和<code>validation_image_generator</code>，这将通过除以255来重新缩放图像:<pre>train_image_generator = ImageDataGenerator(rescale=1./255) validation_image_generator = ImageDataGenerator(rescale=1./255)</pre></li>
				<li>创建三个名为<code>batch_size</code>、<code>img_height</code>和<code>img_width</code>的变量，分别取值为<code>32</code>、<code>224</code>和<code>224</code>:<pre>batch_size = 32 img_height = 224 img_width = 224</pre></li>
				<li>使用<code> flow_from_directory()</code>创建一个名为<code>train_data_gen</code>的数据生成器，并指定批处理大小、训练文件夹的路径、<code>shuffle</code>参数的值、目标的大小和上课模式:<pre>train_data_gen = train_image_generator.flow_from_directory\                  (batch_size=batch_size, directory=train_dir, \                   shuffle=True, \                   target_size=(img_height, img_width), \                   class_mode='binary')</pre></li>
				<li>使用<code> flow_from_directory()</code>创建一个名为<code>val_data_gen</code>的数据生成器，并指定批处理大小、验证文件夹的路径、目标的大小和类模式:<pre>val_data_gen = validation_image_generator.flow_from_directory\                (batch_size=batch_size, directory=validation_dir, \                 target_size=(img_height, img_width), \                 class_mode='binary')</pre></li>
				<li>Import <code>matplotlib</code> and create a <code>for</code> loop that will iterate through five images from <code>train_data_gen</code> and plot them:<pre>import matplotlib.pyplot as plt
for _ in range(5):
    img, label = train_data_gen.next()
    plt.imshow(img[0])
    plt.show()</pre><p>您应该得到以下输出:</p><div><img src="img/B16341_10_03a.jpg" alt="Figure 10.3: Sample of images from the dataset&#13;&#10;"/></div><div><img src="img/B16341_10_03b.jpg" alt="10.3 b"/></div><div><img src="img/B16341_10_03c.jpg" alt="Figure 10.3: Sample of images from the dataset&#13;&#10;"/></div><p class="figure-caption">图10.3:数据集中的图像样本</p><p>上述结果显示了此数据集中包含的一些图像示例。</p></li>
				<li>导入张量流库:<pre>import tensorflow as tf</pre></li>
				<li>创建您的自定义损失函数，该函数将计算误差的平方:<pre>def custom_loss_function(y_true, y_pred):     print("y_pred ",y_pred)     print("y_true ", y_true)     squared_difference = tf.square(float(y_true)-float(y_pred))     return tf.reduce_mean(squared_difference, axis=-1)</pre></li>
				<li>从<code>tensorflow.keras.applications</code>模块导入<code>NASNetMobile</code>模型:<pre>from tensorflow.keras.applications import NASNetMobile</pre></li>
				<li>使用ImageNet权重实例化该模型，移除顶层，并指定正确的输入维度:<pre>base_model = NASNetMobile(include_top=False,\                           input_shape=(100, 100, 3), \                           weights='imagenet')</pre></li>
				<li>冻结该模型的所有层，这样就不会更新<code>NASNetMobile</code> : <pre>base_model.trainable = False</pre>的模型权重</li>
				<li>从<code>tensorflow.keras.layers</code>模块<pre>from tensorflow.keras.layers import Flatten, Dense</pre>导入<code>Flatten</code>和<code>Dense</code>图层</li>
				<li>创建一个新的模型，将<code>NASNetMobile</code>模型与两个新的顶层(分别为500和1个单位)以及ReLu和sigmoid组合起来作为激活函数:<pre>model = tf.keras.Sequential([     base_model,     layers.Flatten(),     layers.Dense(500, activation='relu'),     layers.Dense(1, activation='sigmoid') ])</pre></li>
				<li>Print the summary of your model:<pre>model.summary()</pre><p>您将获得以下输出:</p><div><img src="img/B16341_10_04.jpg" alt="Figure 10.4: Model summary&#13;&#10;"/></div><p class="figure-caption">图10.4:模型总结</p><p>在这里，你可以看到左手边的层。你已经展示了<code>Output Shape</code>，例如<code>(None, 224, 224, 3)</code>。然后，参数的数量显示在<code>Param #</code>下。在底部，您会发现摘要，包括可训练和不可训练的参数。</p></li>
				<li>通过提供您的自定义损失函数来编译此模型，Adam作为优化器，准确性作为要显示的度量:<pre>model.compile(         optimizer='adam',         loss=custom_loss_function,         metrics=['accuracy'])</pre></li>
				<li>Fit the model and provide the train and validation data generators, the number of steps per epoch, and the number of validation steps:<pre>history = model.fit(
    Train_data_gen,
    steps_per_epoch=total_train // batch_size,
    epochs=5,
    validation_data=val_data_gen,
    validation_steps=total_val // batch_size)</pre><p>您应该得到以下输出:</p><div><img src="img/B16341_10_05.jpg" alt="Figure 10.5: Screenshot of training progress&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">图10.5:培训进度截图</p>
			<p>前面的屏幕截图显示了TensorFlow在模型训练期间显示的信息。您可以看到每个时期的训练集和验证集所达到的精确度。在第五个时期，模型在训练集和验证集上都是<code>96%</code>准确的。</p>
			<p>在本练习中，您已经成功构建了自己的损失函数，并用它训练了一个二元分类器来识别苹果或西红柿的图像。在下一节中，您将更进一步，构建您自己的自定义层。</p>
			<h1 id="_idParaDest-191"><a id="_idTextAnchor215"/>实现自定义图层</h1>
			<p>之前，您研究了用TensorFlow函数式API或子类化方法实现您自己的定制损失函数。这些概念也可以应用于为深度学习模型创建自定义层。在本节中，您将从头开始构建一个ResNet模块。</p>
			<h2 id="_idParaDest-192"><a id="_idTextAnchor216"/>ResNet块简介</h2>
			<p><strong class="bold">残差神经网络</strong>，或<strong class="bold"> ResNet </strong>，由<em class="italic">何</em>于2015年在其论文<em class="italic">图像识别的深度残差学习</em>中首次提出。他引入了一个称为残差块的新概念，以解决梯度消失的问题，这限制了训练非常深的网络(有很多层)的能力。</p>
			<p>残差块由多层组成。但是残差块包含两个不同的路径，而不是具有每层被堆叠并顺序执行的单个路径。第一条路径有两个不同的卷积层。第二条路径称为<strong class="bold">跳过连接</strong>，它接收输入并将其转发到第一条路径的最后一层。因此，残差块的输入将通过具有卷积层序列的第一路径，其结果将与来自第二路径的原始输入合并(跳过连接)，如图<em class="italic">图10.6 </em>所示。无需过多考虑数学细节，这条额外的路径允许架构通过更深层次的梯度，而不会影响整体性能。</p>
			<div><div><img src="img/B16341_10_06.jpg" alt="Figure 10.6: Skip connection&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图10.6:跳过连接</p>
			<p>如您所见，如果您想为前面的剩余块构建一个架构，使用TensorFlow顺序API会非常困难。在这里，你需要建立一个非常定制的层。这就是为什么你需要使用函数API或者模型子类化的原因。</p>
			<h2 id="_idParaDest-193"><a id="_idTextAnchor217"/>使用功能API构建定制层</h2>
			<p>在本节中，您将看到如何使用TensorFlow functional API来构建自定义层。</p>
			<p>首先，您将构建一个函数，该函数将您的输入作为张量，并向其添加ReLU和批量规范化。例如，在下面的代码片段中，<code>relu_batchnorm_layer</code>函数接受输入，然后返回一个张量。这就形成了一个连续进行ReLU激活和批量标准化的复合层:</p>
			<pre>def relu_batchnorm_layer(input):
    return BatchNormalization()(ReLU()(input))</pre>
			<p>现在，为你的剩余块创建一个函数。您需要将一个张量作为输入，并将其传递给两个Conv2D层。然后，将第二个Conv2D层的输出添加到原始输入，表示跳过连接。这个加法的输出将被传递给您在前面的代码片段中定义的<code>relu_batchnorm_layer()</code>函数。输出将提供给另一个Conv2D层:</p>
			<pre>def simple_residual_block(input, filters: int, kernel_size: int = 3):
    int_output = Conv2D(filters=filters, kernel_size=kernel_size, 
                        padding="same")(input)
    int_output = Conv2D(filters=filters, kernel_size=1, strides=2,
                        padding="same")(int_output)
    output = Add()([int_output,input]) 
    output = relu_batchnorm_layer(output)
    return output</pre>
			<p>现在，您可以在您的模型中使用这个自定义层。在下面的代码片段中，您将定义一个简单的模型，该模型带有一个Conv2D层，后跟一个残差块:</p>
			<pre>inputs = Input(shape=(100, 100, 3))
num_filters = 32
    
t = BatchNormalization()(inputs)
t = Conv2D(kernel_size=3,
           strides=1,
           filters=32,
           padding="same")(t)
t = relu_batchnorm_layer(t)
t = residual_block(t, filters=num_filters)
    
t = AveragePooling2D(4)(t)
t = Flatten()(t)
outputs = Dense(1, activation='sigmoid')(t)
    
model = Model(inputs, outputs)</pre>
			<p>现在让我们在下一节中使用子类化来构建自定义层。</p>
			<h2 id="_idParaDest-194"><a id="_idTextAnchor218"/>使用子类化构建自定义层</h2>
			<p>之前，您已经了解了如何使用函数式API创建残差块的简化版本。现在，您将看到如何使用模型子类化来创建自定义层。</p>
			<p>首先，您需要将<code>Model</code>类和几个层一起导入:</p>
			<pre>from tensorflow.keras.models import Model 
from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate</pre>
			<p>然后，使用模型子类化创建一个具有两个密集层的模型。首先，定义一个表示为<code>MyModel</code>的模型子类。您将从此类生成的对象是具有两个密集层的模型。</p>
			<p>在<code>init</code>方法中定义两个密集层。例如，第一个可以有<code>64</code>单元和ReLU激活功能，而第二个可以有<code>10</code>单元而没有激活功能(在这种情况下，使用的默认激活功能是线性的)。在这之后，在<code>call</code>方法中，您通过调用先前定义的密集层来设置向前传递。首先，您可以放置<code>dense_1</code>层来获取输入，然后放置<code>dense_2</code>层来返回该层的输出:</p>
			<pre>class MyModel(Model): 
  def __init__(self): 
    super(MyModel, self).__init__()
    self.dense_1 = Dense(64, activation='relu')
    self.dense_2 = Dense(10)
    
  def call(self, inputs):, 
    X = self.dense_1(inputs)
    return self.dense_2(X)</pre>
			<p>下一步是实例化模型。为此，只需调用括号内没有参数的类。接下来，调用随机输入的模型来创建权重。对于输入，这个例子使用一个带有<code>10</code>元素的一维向量，但是可以随意使用不同的输入。然后，您可以打印模型的摘要，从中可以看到您之前定义的密集层。</p>
			<p>考虑以下模型摘要:</p>
			<pre>model = MyModel()
model(tf.random.uniform([1,10]))
model.summary()</pre>
			<p>结果输出应该如下所示:</p>
			<div><div><img src="img/B16341_10_07.jpg" alt="Figure 10.7: Model summary&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图10.7:模型总结</p>
			<p>现在，您可以通过包含一个名为<code>training</code>的关键字参数来修改<code>call</code>方法。如果你想在训练和推理中有不同的行为，这是很有用的。例如，您可以创建一个仅当<code>training</code>为<code>true</code>时才会被激活的脱离层。首先，给定你的学习速率<code>0.4</code>，你需要在<code>init</code>方法中定义一个辍学层。然后，在<code>call</code>方法中，编写一个<code>if</code>子句，默认情况下<code>training</code>关键字设置为<code>true</code>。在它里面，只需要调用dropout层:</p>
			<pre>class MyModel(Model):
  def __init__(self):
    super(MyModel, self).__init__()
    self.dense_1 = Dense(64, activation='relu')
    self.dense_2 = Dense(10)
    self.dropout = Dropout(0.4)  
  def call(self, inputs, training=True):
    X = self.dense_1(inputs)
    if training:                             
      X = self.dropout(X)                    
    return self.dense_2(X)</pre>
			<p>现在，考虑模型摘要:</p>
			<pre>model = MyModel()
model(tf.random.uniform([1,10]))
model.summary()</pre>
			<p>运行前面的命令后，摘要显示如下:</p>
			<div><div><img src="img/B16341_10_08.jpg" alt="Figure 10.8: Model summary&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图10.8:模型总结</p>
			<p>在以下练习中，您将构建一个自定义图层。</p>
			<h2 id="_idParaDest-195"><a id="_idTextAnchor219"/>练习10.02:构建自定义图层</h2>
			<p><code>Healthy-Pneumonia</code>数据集是<code>National Institute for Health NIH</code>数据集的子集。该数据集由9，930幅尺寸为100×100像素的彩色图像组成。<code>pneumonia-or-healthy</code>数据集总共有1965幅健康图像，其中1375幅图像在训练数据集中，590幅图像在测试数据集中。</p>
			<p>您将创建一个自定义ResNet块，它由一个Conv2D层、一个批处理规范化层和一个ReLU激活函数组成。您将对图像执行二元分类，以区分健康图像和肺炎图像。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">你可以在这里得到<code>pneumonia-or-healthy</code>数据集:<a href="https://packt.link/IOpUX">https://packt.link/IOpUX</a>。</p>
			<p>首先，打开一个新的Colab或Jupyter笔记本。如果您正在使用Google Colab，您需要首先将数据集下载到您的Google Drive中:</p>
			<ol>
				<li value="1">打开新的Jupyter笔记本或Google Colab。</li>
				<li>如果您正在使用Google Colab，您可以使用以下代码在本地上传您的数据集。否则，转到<em class="italic">步骤4 </em>。点击<code>Choose Files</code>导航至CSV文件，然后点击<code>Open</code>。将文件另存为<code>uploaded</code>。然后，转到保存数据集的文件夹:<pre>from google.colab import files uploaded = files.upload()</pre></li>
				<li>将数据集解压到当前文件夹:<pre>!unzip \*.zip</pre></li>
				<li>创建一个变量<code>directory</code>，它包含数据集的路径:<pre>directory = "/content/gdrive/My Drive/Datasets/pneumonia-or-healthy/"</pre></li>
				<li>导入<code>pathlib</code>库:<pre>import pathlib     </pre></li>
				<li>使用<code>pathlib.Path</code> : <pre>path = pathlib.Path(directory)</pre>创建一个包含数据完整路径的变量<code>path</code></li>
				<li>创建两个名为<code>train_dir</code>和<code>validation_dir</code>的变量，它们分别采用train和validation文件夹的完整路径:<pre>train_dir = path / 'training_set' validation_dir = path / 'test_set'</pre></li>
				<li>创建四个名为<code>train_healthy_dir</code>、<code>train_pneumonia_dir</code>、<code>validation_healthy_dir</code>和<code>validation_pneumonia_dir</code>的变量，它们分别采用训练集和验证集的健康和肺炎文件夹的完整路径:<pre>train_healthy_dir = train_dir / 'healthy' train_pneumonia_dir = train_dir /'pneumonia' validation_healthy_dir = validation_dir / 'healthy' validation_pneumonia_dir = validation_dir / 'pneumonia'</pre></li>
				<li>导入<code>os</code>包:<pre>import os     </pre></li>
				<li>创建两个变量<code>total_train</code>和<code>total_val</code>，分别获取训练集和验证集的图像数量:<pre>total_train = len(os.listdir(train_healthy_dir)) + \               len(os.listdir(train_pneumonia_dir)) total_val = len(os.listdir(validation_healthy_dir)) + \             len(os.listdir(validation_pneumonia_dir))</pre></li>
				<li>从<code>tensorflow.keras.preprocessing</code> : <pre>from tensorflow.keras.preprocessing.image import ImageDataGenerator</pre>导入<code>ImageDataGenerator</code></li>
				<li>实例化两个<code>ImageDataGenerator</code>类，并将其命名为<code>train_image_generator</code>和<code>validation_image_generator</code>，这将通过除以255来重新缩放图像:<pre>train_image_generator = ImageDataGenerator(rescale=1./255) validation_image_generator = ImageDataGenerator(rescale=1./255)</pre></li>
				<li>创建三个名为<code>batch_size</code>、<code>img_height</code>和<code>img_width</code>的变量，分别取值为<code>32</code>、<code>100</code>和<code>100</code>:<pre>batch_size = 32 img_height = 100 img_width = 100     </pre></li>
				<li>使用<code> flow_from_directory()</code>创建一个名为<code>train_data_gen</code>的数据生成器，并指定批处理大小、训练文件夹的路径、<code>shuffle</code>参数的值、目标的大小和课程模式:<pre>train_data_gen = train_image_generator.flow_from_directory\                  (batch_size=batch_size, directory=train_dir, \                   shuffle=True, \                   target_size=(img_height, img_width), \                   class_mode='binary')</pre></li>
				<li>使用<code> flow_from_directory()</code>创建一个名为<code>val_data_gen</code>的数据生成器，并指定批处理大小、验证文件夹的路径、目标的大小和类模式:<pre>val_data_gen = validation_image_generator.flow_from_directory\                (batch_size=batch_size, directory=validation_dir, \                 target_size=(img_height, img_width), \                 class_mode='binary')</pre></li>
				<li>Import <code>matplotlib</code> and create a <code>for</code> loop that will iterate through five images from <code>train_data_gen</code> and plot them:<pre>import matplotlib.pyplot as plt
for _ in range(5):
    img, label = train_data_gen.next()
    plt.imshow(img[0])
    plt.show()</pre><p>您应该会看到以下输出:</p><div><img src="img/B16341_10_09a.jpg" alt="Figure 10.9: Sample of images from the dataset&#13;&#10;"/></div><div><img src="img/B16341_10_09b.jpg" alt="10.9 b"/></div><div><img src="img/B16341_10_09c.jpg" alt="10.9 c"/></div><p class="figure-caption">图10.9:数据集中的图像样本</p><p>上述结果显示了此数据集中包含的一些图像示例。</p></li>
				<li>导入张量流库:<pre>import tensorflow as tf</pre></li>
				<li>导入<code>Input</code>、<code>Conv2D</code>、<code>ReLU</code>、<code>BatchNormalization</code>、<code>Add</code>、<code>AveragePooling2D</code>、<code>Flatten</code>、<code>Dense</code> : <pre>from tensorflow.keras.layers import Input, Conv2D, ReLU, \                                     BatchNormalization, Add, \                                     AveragePooling2D, Flatten, Dense</pre></li>
				<li>构建一个函数，将您的输入作为张量，并添加ReLU和批量标准化:<pre>def relu_batchnorm_layer(input):     return BatchNormalization()(ReLU()(input))</pre></li>
				<li>创建一个函数来构建您的剩余块。您需要将一个张量(<code>input</code>)作为您的输入，并以<code>2</code>的步幅将其传递给两个Conv2D层。接下来，将输入与输出相加，然后进行ReLU和批量归一化，返回一个张量。用<code>kernel_size=1</code>再添加一个Conv2D层。将其结果添加到前一个Conv2D层的输出中。最后，应用<code>relu_batchnorm_layer()</code>并返回其值。您将对所有Conv2D层应用完全相同的过滤器(数量和尺寸由构造函数的两个输入参数定义):<pre>def residual_block(input, filters: int, kernel_size: int = 3):     int_output = Conv2D(filters=filters, kernel_size=kernel_size,                          strides=(2),                          padding="same")(input)     int_output = relu_batchnorm_layer(int_output)     int_output = Conv2D(filters=filters, kernel_size=kernel_size,                          padding="same")(int_output)     int_output2 = Conv2D(filters=filters, kernel_size=1, strides=2,                         padding="same")(input)     output = Add()([int_output2, int_output])      output = relu_batchnorm_layer(output)     return output</pre></li>
				<li>导入<code>Model</code>模块:<pre>from tensorflow.keras.models import Model</pre></li>
				<li>使用<code>keras.layers.Input()</code>定义模型的输入层。这里，你的形状是100像素乘100像素，有三种颜色(RGB): <pre>inputs = Input(shape=(100, 100, 3))</pre></li>
				<li>对输入应用批处理归一化，然后是一个Conv2D层，具有大小为<code>3*3</code>的<code>32</code>滤镜、步幅<code>1</code>和<code>same</code>填充。最后，将<code>relu_batchnorm_layer()</code>函数应用到它的输出:<pre>t = BatchNormalization()(inputs) t = Conv2D(kernel_size=3,            strides=1,            filters=32,            padding="same")(t) t = relu_batchnorm_layer(t)</pre></li>
				<li>用<code>32</code>滤波器将前一层的输出提供给<code>residual_block()</code>功能。然后，将它的输出传递给一个有四个单元的平均池层，然后在将它馈送给一个以sigmoid为激活函数的<code>1</code>单元的全连接层之前，展平它的结果:<pre>t = residual_block(t, filters=32)      t = AveragePooling2D(4)(t) t = Flatten()(t) outputs = Dense(1, activation='sigmoid')(t)</pre></li>
				<li>用原始输入和全连接层的输出实例化一个<code>Model()</code>类:<pre>model = Model(inputs, outputs)</pre></li>
				<li>Get the summary of your model:<pre>model.summary()</pre><p>您将看到一个摘要，包括可训练和不可训练的参数，如下所示:</p><div><img src="img/B16341_10_10.jpg" alt="Figure 10.10: Model summary&#13;&#10;"/></div><p class="figure-caption">图10.10:模型总结</p></li>
				<li>通过提供二进制交叉熵作为损失函数、Adam作为优化器、准确性作为要显示的度量来编译模型:<pre>model.compile(         optimizer='adam',         loss=binary_crossentropy,         metrics=['accuracy'])</pre></li>
				<li>Fit the model and provide the train and validation data generators, the number of epochs, the steps per epoch, and the validation steps:<pre>history = model.fit(
    Train_data_gen,
    steps_per_epoch=total_train // batch_size,
    epochs=5,
    validation_data=val_data_gen,
    validation_steps=total_val // batch_size
)</pre><p>您应该得到如下输出:</p><div><img src="img/B16341_10_11.jpg" alt="Figure 10.11: Screenshot of training progress&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">图10.11:培训进度截图</p>
			<p>前面的屏幕截图显示了TensorFlow在模型训练期间显示的信息。您可以看到每个时期的训练集和验证集所达到的精确度。</p>
			<p>在本练习中，您为网络创建了自己的自定义图层。现在，让我们在下面的活动中测试一下到目前为止你已经掌握的知识。</p>
			<h2 id="_idParaDest-196"><a id="_idTextAnchor220"/>活动10.01:使用自定义图层和自定义损失函数构建模型</h2>
			<p><code>table-or-glass</code>数据集是取自<code>Open Images V6</code>数据集的图像子集。<code>Open Images V6</code>数据集大约有900万张图片。<code>table-or-glass</code>数据集由7，484幅尺寸为100×100像素的彩色图像组成。<code>table-or-glass</code>数据集总共有3741幅玻璃图像，其中2618幅在训练数据集中，1123幅在测试数据集中。总共有3，743个表图像，其中2，618个在训练数据集中，1，125个在测试数据集中。您需要训练一个更复杂的模型，该模型可以使用自定义ResNet块和自定义损失函数来区分眼镜和桌子的图像。</p>
			<p class="callout-heading">注意</p>
			<p class="callout">你可以在这里找到数据集:<a href="https://packt.link/bE5F6">https://packt.link/bE5F6</a>。</p>
			<p>以下步骤将帮助您完成此活动:</p>
			<ol>
				<li value="1">导入数据集并将文件解压缩到本地文件夹中。</li>
				<li>为训练集和测试集创建图像列表。</li>
				<li>分析目标变量的分布。</li>
				<li>对图像进行预处理(标准化和整形)。</li>
				<li>创建一个自定义损失函数来计算均方差。</li>
				<li>创建自定义剩余块构造函数。</li>
				<li>训练你的模型。</li>
				<li>Print the learning curves for accuracy and loss.<p class="callout-heading">注意</p><p class="callout">此活动的解决方案可通过<a href="B16341_Solution_ePub.xhtml#_idTextAnchor283">此链接</a>找到。</p></li>
			</ol>
			<h1 id="_idParaDest-197"><a id="_idTextAnchor221"/>总结</h1>
			<p>本章演示了如何构建和利用自定义TensorFlow组件。您学习了如何设计和实现自定义损失函数、层和残差块。使用TensorFlow函数式API或模型子类化允许您构建更复杂的深度学习模型，这些模型可能更适合您的项目。</p>
			<p>在下一章也是最后一章，您将探索和构建生成模型，这些模型可以学习数据中的模式和关系，并使用这些关系生成新的、唯一的数据。</p>
		</div>
	

</body></html>