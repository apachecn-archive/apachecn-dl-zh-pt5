<html><head/><body>


    
        <title>Handling Big Data Using Large-Scale Deep Learning</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">使用大规模深度学习处理大数据</h1>
                
            
            
                
<p>训练神经网络是一个需要大量时间的计算密集型过程。随着数据规模的增加和神经网络的深入，训练深度学习模型变得更加复杂，需要更多的计算能力和内存。为了有效地训练我们的模型，我们可以使用一个具有GPU功能的现代系统。R中的深度学习库在多个GPU上提供了对训练模型的支持，以加速训练过程。我们还可以使用云计算来建立深度学习模型。云基础设施可高效扩展，并允许用户以更低的成本和优化的性能更快地构建原型。大多数基于云的解决方案提供的按使用付费模式让生活变得更加舒适，因为人们可以快速扩展。本章将帮助您了解如何在各种云平台上创建可扩展的深度学习环境。您还将学习如何使用MXNet来构建不同的神经网络，并加速训练深度学习模型。</p>
<p>在本章中，我们将介绍以下配方:</p>
<ul>
<li>亚马逊网络服务上的深度学习</li>
<li>微软Azure上的深度学习</li>
<li>谷歌云平台上的深度学习</li>
<li>使用MXNet加速</li>
<li>使用MXNet实现深度神经网络</li>
<li>使用MXNet进行预测</li>
</ul>
<p class="mce-root"/>


            

            
        
    






    
        <title>Deep learning on Amazon Web Services</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">亚马逊网络服务上的深度学习</h1>
                
            
            
                
<p><strong>亚马逊网络服务</strong> ( <strong> AWS </strong>)提供可扩展的、可靠的、易于使用的按需云计算平台和API，按需付费。这是一个全面的平台，提供对众多服务的访问，例如计算、安全服务、分析、数据库、存储、开发人员工具和许多其他<strong>基础架构即服务</strong> ( <strong> IaaS </strong>)、<strong>平台即服务</strong> ( <strong> PaaS </strong>)和<strong>软件即服务</strong> ( <strong> SaaS </strong>)产品。凭借面向个人、盈利和非盈利企业以及教育机构的广泛服务，AWS被认为是最成功的云基础设施公司之一，占据了大部分市场份额。在本节中，我们将主要使用EC2，这是一个虚拟计算环境。我们还将使用一个<strong>亚马逊机器映像</strong> ( <strong> AMI </strong>)使用r进行深度学习，AMI上面预装了软件应用和库。</p>
<p>在AWS中，租赁虚拟机有三种选择:</p>
<ul>
<li class="mce-root"><strong>按需实例:</strong>通过这个选项，用户可以根据他们运行的实例按小时或秒为计算能力付费。根据应用程序的需求，可以灵活地增加或减少容量，适用于不需要任何长期承诺的情况。</li>
<li class="mce-root"><strong>现货实例:</strong>有了这个选项，你可以出价购买闲置的亚马逊EC2实例。投标价格根据需求和供应实时波动。一旦您的出价超过当前现货价格，并且容量可用，您的现货实例就会运行。对于具有灵活开始和结束时间的应用程序，建议使用该选项，因为使用该选项，AWS可以随时终止实例。</li>
<li class="mce-root"><strong>保留实例:</strong>该选项比按需定价几乎便宜50%左右，并且在您承诺在一定时间内租赁机器时提供容量保留。</li>
</ul>
<p class="mce-root">您可以根据自己的需求和便利性，使用前面的任何选项在AWS上设置深度学习实例。</p>
<p class="mce-root">在这个食谱中，我们将经历在AWS中建立深度学习环境来训练我们的模型的步骤。</p>
<p class="mce-root"/>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<div><p class="prompt input_prompt">在使用AWS服务之前，首先，如果您还没有一个AWS帐户，您需要创建一个。为此，你可以使用这个链接:<a href="https://portal.aws.amazon.com/billing/signup" target="_blank">https://portal.aws.amazon.com/billing/signup</a>。有关定价模式的更多详情，请参考此链接:<a href="https://aws.amazon.com/pricing/?nc2=h_ql_pr_ln" target="_blank">https://aws.amazon.com/pricing/?nc2=h_ql_pr_ln</a>。我们将使用来自RStudio的预构建的AWS AMI，其中安装了TensorFlow和<kbd>keras</kbd>库。</p>
</div>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="mce-root">创建AWS帐户后，按照以下步骤使用RStudio AMI启动EC2实例:</p>
<ol>
<li>使用您的凭据登录AWS控制台。您将看到以下屏幕:</li>
</ol>
<div><img src="img/29862d3c-e591-458c-9073-d92ddf98d1d0.png" style="width:119.83em;height:70.33em;"/></div>
<p class="mce-root"/>
<ol start="2">
<li>在“所有服务”选项卡中，单击EC2。这将引导您进入以下EC2控制台页面。单击启动实例以启动EC2实例:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1248 image-border" src="img/d5a5cc67-3797-4a38-866d-f02258ff0726.png" style="width:152.83em;height:70.58em;"/></p>
<ol start="3">
<li>您将被重定向到以下屏幕。接下来，单击AWS Marketplace选项，如下图所示，并在搜索框中键入r studio Server with tensor flow-GPU for AWS:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/7c469331-0aaf-4335-8a2e-0de855430d62.png" style="width:61.17em;height:27.17em;"/></p>
<p class="mce-root"/>
<ol start="4">
<li>在为AWS AMI选择带Tensorflow-GPU的RStudio服务器时，将出现以下弹出窗口提示您。单击“继续”继续:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1228 image-border" src="img/67bedd7a-55c6-4419-ad2f-3f9670c7833d.png" style="width:91.25em;height:56.75em;"/></p>
<p class="mce-root"/>
<ol start="5">
<li>在下一步中，将要求您选择一个实例类型。对于训练复杂的深度学习模型，建议使用带有GPU的实例。为此，从过滤方式下拉列表中选择GPU实例，然后从列表中选择<kbd>p2.xlarge</kbd>。单击下一步:配置实例详细信息按钮继续:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/e4a48795-d3f3-4f18-b986-8c6d103e7e7c.png" style="width:73.42em;height:32.50em;"/></p>
<ol start="6">
<li>在这一步中，您可以根据我们的要求配置实例。在这种情况下，我们只使用默认选项。单击“下一步:添加存储”按钮进入下一步:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1229 image-border" src="img/a5b0f426-1d8d-4eef-9eb6-4418dd1a80b2.png" style="width:124.08em;height:75.33em;"/></p>
<ol start="7">
<li class="mce-root">在下一步中，您可以根据数据的大小更改存储选项。要继续下一步，请单击下一步:添加标签按钮:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1230 image-border" src="img/fb17eb7a-7d99-4c44-b0e5-d3654a7c14e0.png" style="width:138.75em;height:59.67em;"/></p>
<p class="mce-root"/>
<ol start="8">
<li>在AWS中，可以将元数据以标签的形式分配给资源。您可以添加由键值对组成的标签。完成后，点击<strong>下一步:配置安全组</strong>按钮继续:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1249 image-border" src="img/070f4b7c-2cfd-416a-a9e5-6ff691a7ea64.png" style="width:97.83em;height:46.17em;"/></p>
<ol start="9">
<li class="mce-root">在下面的屏幕中，您可以通过添加规则来配置实例的安全选项。要继续下一步，请单击“查看并启动”按钮:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/43394619-b237-481d-9c97-bd3dfc77fb06.png" style="width:69.25em;height:32.50em;"/></p>
<ol start="10">
<li>这将引导您进入以下屏幕。在从通用 ( <strong> SSD </strong>)弹出的<strong>引导中，根据您的要求选择一个选项，然后单击下一步:</strong></li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1250 image-border" src="img/fd9745cd-6947-460c-97f2-e9765aca1aaa.png" style="width:113.75em;height:53.08em;"/></p>
<p style="padding-left: 60px">这将引导您进入以下屏幕。您需要处理某些警告消息。查看您的实例配置，然后单击启动:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/dc6d6177-1b8f-4741-a69a-f104018345ad.png" style="width:60.33em;height:33.58em;"/></p>
<p style="padding-left: 60px">如果您还没有创建密钥对，您可以选择创建一个；否则，使用现有的。下载密钥对并单击启动实例:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/667cecb3-c741-401d-a5e9-b72adf5c32e9.png" style="width:98.33em;height:53.00em;"/></p>
<ol start="11">
<li>现在，您可以返回到您的EC2仪表板，在这里您可以看到您有一个正在运行的实例，如下面的屏幕截图所示:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/7a3981de-3a06-4656-8207-0ebf8c08a95e.png" style="width:153.75em;height:70.50em;"/></p>
<p style="padding-left: 60px">您可以单击它来获得关于您的实例的更多详细信息。您将被导航到一个类似的屏幕，如下所示:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/abdf0dcf-5c75-43fc-954a-13bb651c36dc.png" style="width:69.58em;height:30.58em;"/></p>
<ol start="12">
<li class="mce-root">您将获得一个IP地址和一个端口号，以便在网页上启动AWS RStudio界面。为了连接到接口，使用rstudio-user作为用户名，使用您的实例ID作为密码。以下屏幕截图显示了AWS RStudio界面:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/4e4a4d3c-403e-490b-b909-c95fb1b8c9b0.png" style="width:69.50em;height:33.75em;"/></p>
<p>在前面的截图中，您可以看到我们已经成功地执行了R脚本来对手写数字进行分类。</p>


            

            
        
    






    
        <title>How it works...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p>在<em>步骤1 </em>和<em>步骤2 </em>中，我们演示了如何启动EC2实例，这是AWS中的一个虚拟服务器。在<em>步骤3 </em>和<em>步骤4 </em>中，我们选择了一个支持TensorFlow和Keras的RStudio服务器AMI。实例的所有软件配置细节，比如应用服务器、操作系统和其他应用程序，都存储在AMI模板中。</p>
<p class="mce-root">在<em>步骤5 </em>中，我们选择了基于GPU的实例类型。AWS为您的应用程序提供了多种资源选择。在<em>步骤6 </em>中，我们按照我们的需求配置了我们的实例。在配置实例时，也可以从同一个AMI启动多个实例。</p>
<p class="mce-root">接下来，我们根据所用数据的大小选择存储选项。如果需要，您可以配置存储设备设置并增加<strong>弹性块存储</strong> ( <strong> EBS </strong>)容量。EBS是一种灵活的块级存储设备，可以连接到EC2实例，并可用作频繁更新数据的主存储。</p>
<p class="mce-root">AWS根据性能和价格提供了四种类型的EBS卷:</p>
<ul>
<li class="mce-root">通用固态硬盘</li>
<li class="mce-root">调配IOPS固态硬盘</li>
<li class="mce-root">吞吐量优化的硬盘</li>
<li class="mce-root">冷硬盘</li>
<li class="mce-root">有吸引力的</li>
</ul>
<p class="mce-root">在设置实例时，我们没有定义任何标签。标记是将元数据分配给资源的一种方式，例如资源的用途、所有者详细信息和版本详细信息。</p>
<p class="mce-root">在下一步中，我们使用默认选项配置了安全组。安全组是一组防火墙规则，用于控制实例的流量。在<em>步骤10 </em>中，我们检查了实例配置并启动了它。我们还创建了一个由AWS存储的公钥和我们存储的私钥组成的密钥对。这个密钥对允许我们安全地访问我们的实例。这样，我们用RStudio AMI创建并配置了EC2实例。</p>
<p class="mce-root"/>
<p class="mce-root">一旦我们完成了实例的创建和配置，在<em>步骤11 </em>中，我们返回到我们的EC2仪表板并点击Running Instances选项来查看我们实例的细节。在我们的例子中，我们获得了一个IP地址，即18.188.193.201，使用的端口是8787。实例ID用作连接到RStudio实例的密码。在最后一步中，我们使用提供的凭证在另一个web页面上启动了由AWS提供的RStudio接口。我们执行了MNIST手写数字的分类模型。</p>


            

            
        
    






    
        <title>Deep learning on Microsoft Azure</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">微软Azure上的深度学习</h1>
                
            
            
                
<p>与AWS类似，微软是另一家领先的云服务提供商，通过微软管理的数据中心构建和管理应用程序。云服务的名字是微软Azure，它提供SaaS、PaaS和IaaS，并支持各种工具和框架。为了在Azure中运行深度学习模型，我们可以使用它的深度学习虚拟机，这些虚拟机安装了必要的深度学习库。微软Azure是一个快速、灵活、可扩展、廉价的平台，支持24/7。它为虚拟机提供自动补丁管理，以便用户可以专注于构建和部署他们的应用程序，而不是管理基础架构。在这个食谱中，我们将经历在Microsoft Azure上建立深度学习环境来训练我们的模型的步骤。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<p>在训练你的模型之前，你需要在Azure中创建一个帐户，并使用以下链接登录门户:<a href="https://portal.azure.com/" target="_blank">https://portal.azure.com/.</a>要了解Azure的定价细节，请参考以下链接:【https://azure.microsoft.com/en-in/pricing/】T2。<a href="https://azure.microsoft.com/en-in/pricing/" target="_blank"/></p>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p>在Azure中创建帐户后，登录Azure门户网站。按照以下步骤在it中创建深度学习虚拟环境:</p>
<ol>
<li>单击“创建资源”按钮:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/34dde183-c48f-431b-841b-3bcf3914c672.png" style="width:117.75em;height:65.25em;"/></p>
<p style="padding-left: 60px">您应该会看到下面的屏幕。在搜索栏中键入深度学习虚拟机:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/5e09c4cd-6478-4096-b60e-8a4809558c47.png" style="width:48.17em;height:40.00em;"/></p>
<ol start="2">
<li>选择深度学习虚拟机后，您应该会看到以下屏幕。现在，单击“创建”按钮:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/1d141eb1-55be-4fb9-8306-31fca3aa295b.png" style="width:91.50em;height:39.00em;"/></p>
<ol start="3">
<li>单击“Create”按钮后，您将导航到一个4步配置窗口，如下面的屏幕截图所示。在“基本”选项卡中，您可以提供实例的名称和操作系统的类型，以及用户名和密码以及您希望计费的订阅。如果没有资源组，请创建一个新的资源组。在“设置”选项卡中，确保选择与GPU兼容的适当虚拟机大小。在本例中，我们选择了1个标准ND6s大小的虚拟机。“摘要”选项卡总结了您的要求。单击“确定”继续。</li>
</ol>
<p style="padding-left: 90px">以下屏幕截图显示了“基本”选项卡:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/a3a24040-c8e8-403f-abed-0d077e2c2ff2.png" style="width:63.25em;height:51.42em;"/></p>
<p style="padding-left: 60px">以下屏幕截图显示了“设置”选项卡:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/d2811d98-eaf7-42b5-9517-086307330b77.png" style="width:45.58em;height:24.83em;"/></p>
<p style="padding-left: 60px">以下屏幕截图显示了“摘要”选项卡:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/f7f5dac3-460f-4b52-aa79-a2bf3c17969c.png" style="width:45.58em;height:24.75em;"/></p>
<p style="padding-left: 60px">下面的屏幕截图显示了购买选项卡。单击复选框，然后单击创建按钮:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/7abe4aaa-7025-4897-9e48-284409f21175.png" style="width:103.58em;height:75.00em;"/></p>
<ol start="4">
<li>创建资源后，选择左侧的“单击所有资源”,您将被定向到以下控制台窗口，其中显示了所有已调配的资源:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/b43b3534-b80e-48aa-a64c-7ff4b05163fb.png" style="width:126.58em;height:74.58em;"/></p>
<ol start="5">
<li>单击特定的资源，其中类型为虚拟机，名称与您在<em>步骤3 </em>中创建的资源相匹配。您将看到以下屏幕。点击屏幕上的连接按钮:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/69ea3a54-6eb1-442d-905f-9f6fcf3cf365.png" style="width:69.92em;height:32.50em;"/></p>
<ol start="6">
<li>屏幕右侧会出现一个窗口，提供一个下载RDP文件的按钮。单击该按钮，文件下载完成后，双击它:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/97bc4192-ae34-48f0-a03f-0f1d55ffd5d7.png" style="width:150.42em;height:75.17em;"/></p>
<p style="padding-left: 60px">以下是下载RDP文件的方法:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/700c43f1-91e1-4598-bef5-1b75ed9c7cdd.png" style="width:158.92em;height:75.00em;"/></p>
<ol start="7">
<li>现在，您将被重定向到一个登录窗口，以连接到云实例。您需要输入用户名和密码来连接到实例。连接后，您应该会看到类似如下的屏幕:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/1f23b43c-29ad-43c9-ad90-bf395da9fc30.png" style="width:68.75em;height:38.67em;"/></p>
<ol start="8">
<li>现在，您可以启动RStudio，因为已经安装了<kbd>keras</kbd>库，所以您可以在R:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/86858f73-1830-4f4f-81ef-5d0afaebb6b6.png" style="width:50.50em;height:45.58em;"/></p>
<p>这样就可以利用微软Azure的架构，用r写深度学习代码。</p>


            

            
        
    






    
        <title>How it works...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p>在<em>步骤1 </em>和<em> 2 </em>中，我们在Azure中创建了一个深度学习虚拟机。Azure中的深度学习虚拟机是一个预先配置的环境，使用基于GPU的VM实例来训练深度学习模型。它在Windows 2016或Ubuntu操作系统上受支持，并预装了许多数据科学工具，以支持构建高级分析应用程序。</p>
<p>在<em>步骤3 </em>中，我们根据我们的需求配置了虚拟机。在“基本”选项卡中，您需要提供以下详细信息:</p>
<ul>
<li>名称:这是虚拟机实例的名称。</li>
<li>操作系统类型:这是您需要的操作系统支持类型，Windows或Ubuntu。</li>
<li>用户名:这是您将用于登录虚拟机的用户名。</li>
<li>密码:这是您将用于登录虚拟机的密码。</li>
<li>订阅:这是您希望对VM实例进行计费的订阅，并且具有适当的资源创建权限。</li>
<li>资源组:这是Azure解决方案所有资源的逻辑容器。您需要创建一个新组或使用一个现有组。</li>
<li>位置:这是数据中心的位置。为了更快地访问，您可以选择离您的物理位置最近的中心或拥有您的大部分数据的中心。</li>
</ul>
<p class="mce-root">在“设置”选项卡中，您可以选择虚拟机的大小。ND6s是Azure中最便宜的支持ND系列GPU的虚拟机之一，专为AI和深度学习工作而设计。ND实例提供了良好的性能，并由NVIDIA Tesla P40 GPUs和英特尔至强E5-2690 v4(broad well)CPU提供支持。“摘要”选项卡总结了您对验证检查的要求。</p>
<p class="mce-root">在<em>步骤4 </em>中，我们看到了虚拟机中配置的所有资源的列表。在<em>步骤5 </em>、<em> 6 </em>、<em> 7 </em>中，我们通过<strong>远程桌面协议</strong> ( <strong> RDP </strong>)连接到配置好的虚拟机。最后，一旦我们连接到远程桌面机器，我们就启动一个RStudio会话，并运行一个分类模型来识别手写的MNIST数字。</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    






    
        <title>There's more...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">还有更多...</h1>
                
            
            
                
<p>我们都知道R是一个单线程的内存应用程序，但有多种工具和架构允许在使用R的同时实现并行处理。微软Azure已经在R中推出了一个名为<strong> doAzureParallel </strong>的包，它允许将并行计算分布到Azure中的一个集群。这个包使用户能够利用Azure批处理服务，使得直接从R会话运行并行模拟成为可能。这个包是R的<kbd>foreach</kbd>包的并行后端，支持跨多个Azure虚拟机的多个进程，因此不需要手动创建和配置多个虚拟机。还可以根据工作负载来扩展集群的规模。要了解<kbd>doParallelAzure</kbd>的安装说明和先决条件，请参考此链接:<a href="https://github.com/Azure/doAzureParallel">https://github.com/Azure/doAzureParallel</a>。</p>


            

            
        
    






    
        <title>See also</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">请参见</h1>
                
            
            
                
<p>Azure批处理服务通过管理Azure中的计算节点池来支持并行和高性能计算批处理作业。要了解更多关于Azure Batch的内容，请参考这个链接:<a href="https://docs.microsoft.com/en-us/azure/batch/batch-technical-overview">https://docs . Microsoft . com/en-us/Azure/Batch/Batch-technical-overview</a>。</p>


            

            
        
    






    
        <title>Deep learning on Google Cloud Platform</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">谷歌云平台上的深度学习</h1>
                
            
            
                
<p>在过去几年中，云计算服务使个人和企业能够在不同的云提供商上开发和部署解决方案。<strong>谷歌云平台</strong> ( <strong> GCP </strong>)是谷歌提供的一套相对较新的云计算服务，支持计算、存储、大数据、分析和应用开发等多种服务。它还支持GPU实例，并击败了其他云服务提供商提供的价格。Google强大的、可扩展的、创新的基础设施及其跨各种能力的简化解决方案允许用户以安全的方式在这个平台上轻松构建应用程序。在这个食谱中，我们将学习如何在GCP上训练深度学习模型。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<p>在使用CloudML之前，你需要做的第一件事是创建一个Google Cloud帐户。如果您没有帐户，您可以通过此链接创建您的帐户:<a href="https://console.cloud.google.com/" target="_blank">https://console.cloud.google.com</a>。要了解更多定价细节，请参考此链接:<a href="https://cloud.google.com/pricing/" target="_blank">https://cloud.google.com/pricing/</a>。<a href="https://cloud.google.com/pricing/" target="_blank"/></p>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p>在谷歌上创建账户后，按照以下步骤在<strong> GCP </strong>训练一个深度学习模型:</p>
<ol>
<li>登录Google Cloud portal，从菜单中选择APIs &amp; Services，如下图所示:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/645ae685-c0f2-41e2-a214-8285f7470210.png" style="width:159.92em;height:74.58em;"/></p>
<p class="mce-root"/>
<ol start="2">
<li>单击APIs &amp; Services链接后，您应该能够看到下面的屏幕。单击启用API和服务选项:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/a1fc9a10-0b01-432f-bb06-f0b440c488ab.png" style="width:159.75em;height:75.33em;"/></p>
<ol start="3">
<li>您将被定向到API库页面，如下面的屏幕截图所示。这些API被组织成组；点击机器学习组的查看全部，然后选择人工智能平台训练和预测API:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/e53bf1fc-1aa1-4b78-b1fb-370baaa6f017.png" style="width:159.75em;height:75.25em;"/></p>
<ol start="4">
<li>接下来，您将能够看到以下页面。点击启用按钮:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/91252f45-e42c-4d8a-8bc9-01c4012dec43.png" style="width:97.17em;height:70.17em;"/></p>
<ol start="5">
<li>启用该API后，转到RStudio并执行以下代码来安装<kbd>cloudml</kbd>库和Google Cloud SDK:</li>
</ol>
<pre style="padding-left: 60px">install.packages("cloudml")<br/> library(cloudml)<br/> gcloud_install()</pre>
<p class="mce-root"/>
<p style="padding-left: 60px">以下截图显示了Google Cloud SDK设置窗口:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/1374d84e-9d23-4ff6-923b-8df8f9162427.png" style="width:69.67em;height:36.92em;"/></p>
<ol start="6">
<li>安装Google Cloud SDK后，会要求您使用凭据登录。然后，终端窗口会提示您一系列选项，如下面的屏幕截图所示。选择一个已经存在的项目，您的Google帐户将链接到Google SDK:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/b5af39f5-9005-461e-8af3-e6fd59b5df2a.png" style="width:28.33em;height:19.83em;"/></p>
<ol start="7">
<li>现在，你可以使用谷歌的机器学习API提交作业来执行深度学习代码。在此示例中，我们将使用MNIST手写数字数据集训练一个多层深度神经网络来对数字进行分类:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/c08705d8-b020-42eb-82f3-a7ca39911308.png" style="width:68.83em;height:36.33em;"/></p>
<ol start="8">
<li>提交作业后，您可以使用AI平台菜单下的作业选项对其进行监控:</li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img src="img/3ffad657-d78f-495a-9961-855ba6741bac.png" style="width:138.58em;height:43.67em;"/></p>
<p style="padding-left: 60px">前面的截图显示了GCP的深度学习工作的状态。</p>


            

            
        
    






    
        <title>How it works...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p>在<em>步骤1 </em>和<em> 2 </em>中，我们登录到Google Cloud portal并导航到API和服务页面。这些API为访问从存储到计算和应用程序部署的任何服务提供了用户友好的界面。使用这些API，您可以使用各种编程语言和工具来自动化工作流，而无需担心硬件和软件供应。在<em>步骤3 </em>和<em> 4 </em>中，我们启用了AI平台训练和预测API，用于创建机器学习模型。</p>
<p>这个API使数据爱好者能够以一种可移植和经济高效的方式无缝地构建、部署和监控他们的机器学习应用程序。在<em>步骤5 </em>中，我们使用RStudio和Google Cloud SDK在R中安装了<kbd>cloudML</kbd>包。这个SDK由一些工具组成，这些工具允许我们从r。</p>
<p>安装过程中，需要指定Google Cloud的默认账号、项目、计算区域；这些细节将用于您所有的CloudML作业。在<em>步骤6 </em>中，我们提供了需要与Google Cloud SDK链接的Google帐户详细信息。在<em>步骤7 </em>中，我们提交了一个深度学习作业，在云上执行训练。一个好的实践是，首先在本地用较小的数据运行脚本，然后在输出结果符合预期时在云端提交作业。在这个例子中，我们使用MNIST手写数字数据集运行了一个分类模型。为此，我们创建了一个名为<kbd>mnist_mlp.R</kbd>的R脚本，然后将它保存在当前的工作目录中。本章的GitHub资源库中提供了R脚本。</p>
<p>然后，在一个新的R脚本中，我们执行以下代码将作业提交给GCP:</p>
<pre class="mce-root">library(cloudml)<br/>cloudml_train("mnist_mlp.R")</pre>
<p class="mce-root">最后一步，我们到Google Cloud portal来监控在<em>步骤7 </em>中提交的作业。</p>


            

            
        
    






    
        <title>There's more...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">还有更多...</h1>
                
            
            
                
<p>Google的<strong>云机器学习</strong> ( <strong> CloudML </strong>)引擎也提供了一个自动化的工具，用于模型超参数调优。它允许我们在训练模型时测试不同的超参数配置。为了提交一个超参数调优作业，我们需要将一个CloudML训练配置文件传递给<kbd>cloudml_train()</kbd>函数。我们在<em>中讨论了使用Keras的超参数调整，还有更多...在第一章、<em>了解神经网络和深度神经网络</em>中的<em>训练你的第一个深度神经网络</em>的</em>部分，我们展示了如何调整模型参数。我们首先为想要优化的参数定义了标志，然后在模型的定义中使用了这些标志。</p>
<p>同样，我们定义了使用CloudML执行超参数调优作业的标志和模型。在下面的代码块中，我们展示了如何为<em>中定义的模型编写一个配置文件...</em>一节的<em>训练你的第一个深度神经网络</em>菜谱在<a href="https://cdp.packtpub.com/deep_learning_with_r_cookbook/wp-admin/post.php?post=30&amp;action=edit#post_1034">第一章</a>，<em>了解神经网络和深度神经网络</em>:</p>
<pre class="mce-root">trainingInput:<br/>  scaleTier: CUSTOM<br/>  masterType: standard_gpu<br/>  hyperparameters:<br/>    goal: MAXIMIZE<br/>    hyperparameterMetricTag: acc<br/>    maxTrials: 10<br/>    maxParallelTrials: 2<br/>    params:<br/>      - parameterName: dense_units1<br/>        type: INTEGER<br/>        minValue: 8<br/>        maxValue: 16<br/>        scaleType: UNIT_LINEAR_SCALE<br/>      - parameterName: dropout1<br/>        type: DOUBLE<br/>        minValue: 0.2<br/>        maxValue: 0.4<br/>        scaleType: UNIT_LINEAR_SCALE<br/>      - parameterName: dense_units2<br/>        type: INTEGER<br/>        minValue: 8<br/>        maxValue: 16<br/>        scaleType: UNIT_LINEAR_SCALE<br/>      - parameterName: dropout2<br/>        type: DOUBLE<br/>        minValue: 0.2<br/>        maxValue: 0.4<br/>        scaleType: UNIT_LINEAR_SCALE</pre>
<p>在前面的配置文件中，goal表示目标函数，而<kbd>hyperparameterMetricTag</kbd>表示要优化的指标。<kbd>maxTrials</kbd>参数指定了优化参数需要尝试的次数。</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>在我们的例子中，目标是最大限度地提高准确性。<kbd>params</kbd>参数表示要调整的一组参数。参数可以是整数、双精度或分类类型，可以使用参数<kbd>type</kbd>指定。<kbd>minValue</kbd>和<kbd>maxValue</kbd>表示参数为整数或双精度类型时，优化参数定义的取值范围。对于分类参数，这些字段应该不设置。<kbd>scaleType</kbd>定义缩放参数的方法。关于配置文件的更多详情，请参考此链接:<a href="https://cloud.google.com/ml-engine/reference/rest/v1/projects.jobs#HyperparameterSpec">https://cloud . Google . com/ml-engine/reference/rest/v1/projects . jobs # HyperparameterSpec</a>。</p>
<p>在提交调优作业之前，我们需要将前面代码块的内容保存在一个<kbd>cloudml_tuning.yml</kbd>文件中，然后将配置文件的名称传递给<kbd>cloudml_train()</kbd>函数:</p>
<pre>cloudml_train("hyperparameter_tuning_model.R", config = "cloudml_tuning.yml")</pre>
<p>前面的代码演示了如何在训练模型时传递<kbd>.yml</kbd>文件。</p>


            

            
        
    






    
        <title>Accelerating with MXNet</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">使用MXNet加速</h1>
                
            
            
                
<p>MXNet代表混合和最大化。它是一个灵活、可扩展的深度学习框架，用于开发和部署深度学习模型。它能够以节省内存的方式在各种异构系统上运行。MXNet也受到各种云提供商的支持，如亚马逊Web服务和微软Azure。开发人员可以灵活地进行命令式和符号式编程，这使得调试和超参数调优更加容易，同时最大限度地提高效率。MXNet提供的另一个优势是它支持多种语言，如Python、R、Scala、Clojure、Julia、Perl、MATLAB和JavaScript。在这个菜谱中，我们将演示如何在Windows和Linux系统中设置MXNet。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<p>MXNet通过在多个CPU/GPU之间分配训练来提高性能。为了利用GPU功能，您的系统需要一个NVIDIA GPU，并且您需要安装CUDA工具包和<kbd>cuDNN</kbd>。安装CUDA工具包和cuDNN的说明可以分别在<a href="https://developer.nvidia.com/cuda-downloads" target="_blank">https://developer.nvidia.com/cuda-downloads</a>和<a href="https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html" target="_blank">https://docs . NVIDIA . com/deep learning/SDK/cud nn-install/index . html</a>找到。</p>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p class="mce-root">现在让我们在您的系统上安装MXNet。根据操作系统，您可以选择合适的方法:</p>
<ol>
<li>要在Windows操作系统上安装CPU版本，请使用以下命令:</li>
</ol>
<pre style="padding-left: 60px">cran &lt;- getOption("repos")<br/>cran["dmlc"] &lt;- "https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/"<br/>options(repos = cran)<br/>install.packages("mxnet")</pre>
<p>请注意MXNet需要R 3.5。在写这本书的时候，对3.6的支持还不可用。</p>
<ol start="2">
<li>要在Windows操作系统上安装GPU版本，请使用以下命令:</li>
</ol>
<pre style="padding-left: 60px">cran &lt;- getOption("repos")<br/>cran["dmlc"] &lt;- "https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/R/CRAN/GPU/cu100"<br/>options(repos = cran)<br/>install.packages("mxnet")</pre>
<p style="padding-left: 60px">对于不同版本的CUDA，将前面代码块的第二行更改为<kbd>cu92</kbd>或<kbd>cu101</kbd>。</p>
<ol start="3">
<li>要在Linux中安装GPU/CPU版本，请执行以下操作:</li>
</ol>
<p style="padding-left: 60px">安装MXNet需要Ubuntu 16.4。尚不支持更高版本。在安装之前，您需要安装Git、OpenBLAS和OpenCV。要安装这些依赖项，请在终端中执行以下命令:</p>
<pre style="padding-left: 60px">apt-get install -y build-essential git<br/>apt-get install -y libopenblas-dev liblapack-dev<br/>apt-get install -y libopencv-dev</pre>
<div><p>要在Linux平台上安装MXNet，我们需要高于3.4.4的R版本，并且需要GCC 4.8或更高版本来编译C++ 11。2.GNU Make。</p>
</div>
<div><div><div><p style="padding-left: 60px">安装完依赖项后，从GitHub克隆存储库:</p>
</div>
</div>
</div>
<div><div><pre style="padding-left: 60px">git clone --recursive https://github.com/apache/incubator-mxnet<br/>cd incubator-mxnet</pre></div>
<p style="padding-left: 60px">然后，更新配置文件以设置编译选项:</p>
<pre style="padding-left: 60px">echo "USE_OPENCV = 1" &gt;&gt; ./config.mk<br/>echo "USE_BLAS = openblas" &gt;&gt; ./config.mk</pre>
<p style="padding-left: 60px">执行以下命令来编译和构建MXNet:</p>
</div>
<pre style="padding-left: 60px">make -j $(nproc)<br/>make rpkg</pre>
<p style="padding-left: 60px">要安装GPU版本，您需要在构建MXnet之前设置以下选项:</p>
<pre style="padding-left: 60px">echo "USE_CUDA=1" &gt;&gt;config.mk<br/>echo "USE_CUDA_PATH=/usr/local/cuda" &gt;&gt;config.mk<br/>echo "USE_CUDNN=1" &gt;&gt;config.mk</pre>
<p>在本节中，我们看到了如何在各种操作系统上安装MXNet</p>


            

            
        
    






    
        <title>How it works...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p>对于Windows安装，我们使用预构建的二进制包安装MXNet。我们使用<kbd>getOption()</kbd>函数来获得R中的各种全局选项。<kbd>repos</kbd>参数用于提取R从中提取库的URL。为了安装MXNet，我们添加了一个新的URL来获取预先构建的<kbd>mxnet</kbd> R包。我们使用了<kbd>options()</kbd>函数来添加新的URL。请注意，安装CPU和GPU版本之间的唯一区别是我们添加的URL。我们也可以从源代码构建<kbd>mxnet</kbd>库。下面的网页提供了构建说明:<a href="https://mxnet.apache.org/get_started/windows_setup.html#install-mxnet-package-for-r" target="_blank">https://mxnet . Apache . org/get _ started/windows _ setup . html # install-mxnet-package-for-r</a>。</p>
<div><p>在Linux安装中，我们安装了安装MXNet的所有依赖项，然后克隆了MXNet源代码。然后，我们设置编译选项并构建库。</p>
</div>


            

            
        
    






    
        <title>There's more...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">还有更多...</h1>
                
            
            
                
<p>到目前为止，我们看到了如何在本地系统中设置MXNet。MXNet也受到AWS、微软Azure、GCP等各种云平台的支持。</p>
<p class="mce-root"/>
<p>对于使用AWS的MXNet，我们可以使用Amazon SageMaker，它提供了一个成熟的平台，以可扩展的方式构建、训练和部署深度学习模型。您还可以利用AWS深度学习ami，如NVIDIA深度学习ami，它们是预先配置的环境，可以快速构建深度学习应用程序的原型。在AWS中，也可以使用MXNet构建我们自己定制的深度学习环境。</p>
<p>GCP提供了NVIDIA GPU云映像，该映像提供了一个优化的环境来运行GPU优化的容器，以便使用MXNet运行深度学习应用程序。</p>
<p>微软Azure为深度学习和HPC提供了英伟达NGC映像，这是一个运行NGC容器注册中心GPU加速容器的优化环境，其中包括MXNet、CNTK和Theano等框架。</p>


            

            
        
    






    
        <title>Implementing a deep neural network using MXNet </title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">使用MXNet实现深度神经网络</h1>
                
            
            
                
<p>在上一个菜谱<em>用MXNet </em>加速中，我们介绍了MXNet，并演示了如何安装包。在这个菜谱中，我们将实现一个神经网络来预测波士顿郊区不同位置房屋的中值价格。我们将使用波士顿房价数据集。该数据集包含不同位置的房屋属性信息，如平均房间数、犯罪率和财产税税率。</p>
<p>你可以在<a href="https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html" target="_blank">https://www . cs . Toronto . edu/~ delve/data/Boston/Boston detail . html</a>了解数据的属性。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<p>波士顿房价数据集可以直接从keras图书馆访问。它有404个训练样本和102个测试样本。</p>
<p>让我们加载所需的库:</p>
<pre>library(mxnet)<br/>library(keras)</pre>
<p>我们加载数据集，并将其分成训练集和测试集:</p>
<pre>boston = dataset_boston_housing()<br/>train_x = boston$train$x<br/>train_y = boston$train$y<br/>test_x = boston$test$x<br/>test_y = boston$test$y</pre>
<p>现在让我们缩放数据集:</p>
<pre># normalize train set<br/>train_x &lt;- scale(train_x)<br/><br/># normalize test set<br/>train_means &lt;- attr(train_x, "scaled:center") <br/>train_stddevs &lt;- attr(train_x, "scaled:scale")<br/>test_x &lt;- scale(test_x, center = train_means, scale = train_stddevs)</pre>
<p>这就完成了数据预处理部分。</p>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p>我们现在已经熟悉了数据集。现在让我们继续构建和训练神经网络:</p>
<ol>
<li>让我们创建一个神经网络。以下代码块的第一行创建一个符号变量，接下来的几行添加隐藏层:</li>
</ol>
<pre style="padding-left: 60px">in_layer &lt;- mx.symbol.Variable("data")<br/>layer1 = mx.symbol.FullyConnected(in_layer,name="dense1",num_hidden=64)<br/>activation1 &lt;- mx.symbol.Activation(layer1, name="relu1", act_type="relu")<br/>layer2 = mx.symbol.FullyConnected(activation1,name="dense2",num_hidden=64)<br/>activation2 &lt;- mx.symbol.Activation(layer2, name="relu2", act_type="relu")<br/>layer3 = mx.symbol.FullyConnected(activation2,name="dense3",num_hidden=1)<br/>out = mx.symbol.LinearRegressionOutput(layer3)</pre>
<ol start="2">
<li>我们设置要使用的设备，用于训练模型:</li>
</ol>
<pre style="padding-left: 60px">devices &lt;- mx.cpu()</pre>
<p class="mce-root"/>
<ol start="3">
<li>我们继续设置种子并定义时期的数量。然后，我们训练模型:</li>
</ol>
<pre style="padding-left: 60px">mx.set.seed(0)<br/>epochs = 100<br/>model = mx.model.FeedForward.create(symbol =out,X =train_x,y = train_y,ctx = devices,num.round = epochs,optimizer = "rmsprop",array.batch.size = 50,learning.rate=0.001,eval.metric = mx.metric.rmse)</pre>
<ol start="4">
<li>让我们来看看这个模型:</li>
</ol>
<pre style="padding-left: 60px">graph.viz(model$symbol)</pre>
<p style="padding-left: 60px">下面的屏幕截图显示了模型的可视化效果:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/791c7c34-a7b7-4396-a72f-6982c20bb578.png" style="width:10.42em;height:38.08em;"/></p>
<ol start="5">
<li>我们在测试数据集上评估模型的性能:</li>
</ol>
<pre style="padding-left: 60px">predicted &lt;- predict(model,test_x)<br/>paste("Test error:",sqrt(mean((predicted-as.numeric(test_y))^2)))</pre>
<p style="padding-left: 60px">下面的屏幕截图显示了测试错误:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/ad77da12-259d-412a-9586-e6da131e6c37.png" style="width:12.33em;height:1.33em;"/></p>
<p style="padding-left: 60px">从前面的截图中，我们可以看到我们得到的测试误差在3.54左右。</p>


            

            
        
    






    
        <title>How it works...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p>在<em>步骤1 </em>中，我们创建了一个符号类型的变量。我们使用这个变量来配置网络。<kbd>mx.symbol.Variable("data")</kbd>函数用数据表示输入数据，即输入层。我们使用<kbd>mx.symbol.FullyConnected</kbd>函数添加了隐藏层；它的参数是类型为<kbd>symbol</kbd>的数据、层的名称和层中神经元的数量。我们使用<kbd>mx.symbol.Activation()</kbd>函数来应用激活层。在网络的末端，我们添加了一个回归输出层。在<em>步骤2 </em>中，我们选择设备来训练网络。我们也可以使用<kbd>mx.gpu()</kbd>功能在GPU上进行训练。</p>
<p>下一步，我们训练模型。在<em>步骤4 </em>中，我们可视化了我们的网络。在最后一步中，我们评估了模型的性能。</p>


            

            
        
    






    
        <title>Forecasting with MXNet</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">使用MXNet进行预测</h1>
                
            
            
                
<p>时间序列预测是深度学习中最受欢迎的应用之一。MXNet使机器学习爱好者能够利用其深度学习框架进行各种应用，包括时间序列预测。在这个菜谱中，我们将使用LSTM网络来实现一对一的预测解决方案，以预测洗发水的销售。在写这本书的时候，MXNet只支持序列预测问题的两种变体，一对一和多对一。</p>


            

            
        
    






    
        <title>Getting ready</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">做好准备</h1>
                
            
            
                
<p>在这个食谱中，我们将使用洗发水销售数据集，该数据集包含三年内洗发水的月销售额。原始数据集归功于Makridakis、Wheelwright和Hyndman (1998)。它也可以在本章的GitHub资源库中的<kbd>data</kbd>文件夹中找到。下载<kbd>shampoo_sales.txt</kbd>文件，并将其复制到工作目录中名为<kbd>data</kbd>的文件夹中。</p>
<p>让我们加载所需的库并读取数据集:</p>
<pre>library("mxnet")<br/>sales_data &lt;- read.table("data/shampoo_sales.txt",sep = ",",header = TRUE)<br/><br/># We require only one column from the dataset<br/>sales_data &lt;- as.data.frame(sales_data[,2])</pre>
<p>接下来，我们使用最小-最大归一化在0到1的范围内归一化数据:</p>
<pre>min_max_scaler &lt;- function(x) {<br/> (x - min(x))/(max(x) - min(x))<br/>}<br/><br/>norm_sales_data &lt;- min_max_scaler(sales_data)<br/>t_sales_data &lt;- t(norm_sales_data)</pre>
<p>为了使用MXNet-R训练一对一序列预测模型，我们需要将训练数据转换成合适的形式。训练特征集的形式应该是<kbd>(n_dim x seq_len * num_samples)</kbd>，训练标签的形式应该是<kbd>(seq_len x num_samples)</kbd>。由于我们有一维数据，<kbd>n_dim</kbd>等于<kbd>1</kbd>。</p>
<p>以下代码块将数据转换为所需的结构:</p>
<pre>n_dim &lt;- 1<br/>seq_len &lt;- 4<br/>num_samples &lt;- 7<br/><br/># extract only required data from dataset<br/>x_data &lt;- t_sales_data[1, 1:(seq_len * num_samples)]<br/>dim(x_data) &lt;- c(n_dim, seq_len, num_samples)<br/><br/>y_data &lt;- t_sales_data[1, 2:(1+(seq_len * num_samples))]<br/>dim(y_data) &lt;- c(seq_len, num_samples)</pre>
<p>在下一节中，我们将使用RNN和MXNet构建预测模型。</p>


            

            
        
    






    
        <title>How to do it...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">怎么做...</h1>
                
            
            
                
<p>让我们继续使用符号编程创建一个神经网络:</p>
<ol>
<li>我们首先将数据采样到训练和验证数据集中，并创建各自的迭代器:</li>
</ol>
<pre style="padding-left: 60px">batch_size &lt;- 3<br/>train_ids &lt;- 1:4<br/>val_ids &lt;- 5:6<br/><br/>## create data iterators<br/>train_data &lt;- mx.io.arrayiter(data = x_data[,,train_ids, drop = F],label = y_data[, train_ids], batch.size = batch_size,shuffle = TRUE)<br/>val_data &lt;- mx.io.arrayiter(data = x_data[,,val_ids, drop = F], label = y_data[, val_ids], batch.size = batch_size, shuffle = FALSE)</pre>
<ol start="2">
<li>现在，让我们创建一个具有一对一模型配置的RNN符号:</li>
</ol>
<pre style="padding-left: 60px">symbol &lt;- rnn.graph(num_rnn_layer = 2,<br/> num_hidden = 30,<br/> input_size = NULL,<br/> num_embed = NULL,<br/> num_decode = 1,<br/> masking = F, <br/> loss_output = "linear",<br/> ignore_label = -1, <br/> cell_type = "lstm", <br/> output_last_state = T,<br/> config = "one-to-one")</pre>
<ol start="3">
<li>接下来，我们定义损失函数:</li>
</ol>
<pre style="padding-left: 60px">seq_metric_mse &lt;- mx.metric.custom("MSE", function(label, pred) {<br/> label = mx.nd.reshape(label, shape = -1)<br/> pred = mx.nd.reshape(pred, shape = -1)<br/> res &lt;- mx.nd.mean(mx.nd.square(label - pred))<br/> return(as.array(res))<br/>})</pre>
<ol start="4">
<li>我们设置设备用于训练模型。然后，我们定义权重初始化并配置优化器:</li>
</ol>
<pre style="padding-left: 60px">ctx &lt;- mx.cpu()<br/>initializer &lt;- mx.init.Xavier(rnd_type = "gaussian",<br/> factor_type = "avg", <br/> magnitude = 1)<br/>optimizer &lt;- mx.opt.create("adadelta",<br/> rho = 0.9, <br/> eps = 1e-06, <br/> wd = 1e-06, <br/> clip_gradient = 1, <br/> rescale.grad = 1/batch_size)</pre>
<ol start="5">
<li>现在让我们用桶支持来训练50个纪元的网络:</li>
</ol>
<pre style="padding-left: 60px">model &lt;- mx.model.buckets(symbol = symbol, <br/> train.data = train_data, <br/> eval.data = val_data,<br/> num.round = 50, <br/> ctx = ctx, <br/> verbose = TRUE, <br/> metric = seq_metric_mse, <br/> initializer = initializer,<br/> optimizer = optimizer)</pre>
<ol start="6">
<li>在训练网络之后，我们从训练的模型中提取状态符号:</li>
</ol>
<pre style="padding-left: 60px">internals &lt;- model$symbol$get.internals()<br/>sym_state &lt;- internals$get.output(which(internals$outputs %in% "RNN_state"))<br/>sym_state_cell &lt;- internals$get.output(which(internals$outputs %in% "RNN_state_cell"))<br/>sym_output &lt;- internals$get.output(which(internals$outputs %in% "loss_output"))<br/>symbol &lt;- mx.symbol.Group(sym_output, sym_state, sym_state_cell)</pre>
<ol start="7">
<li class="mce-root">我们使用在<em>步骤6 </em>中创建的符号来创建RNN模型的推论。我们还使用第六个数据样本来获得RNN状态的初始值，这将用于启动未来时间戳的预测。</li>
</ol>
<p style="padding-left: 60px">请注意，只有在创建迭代器时才需要标签，它不会在推理中使用:</p>
<pre style="padding-left: 60px">data &lt;- mx.nd.array(x_data[, , 6, drop = F])<br/>label &lt;- mx.nd.array(y_data[, 6, drop = F])<br/><br/>inference_data &lt;- mx.io.arrayiter(data = data, <br/> label = label, <br/> batch.size = 1, <br/> shuffle = FALSE)<br/>infer &lt;- mx.infer.rnn.one(infer.data = inference_data, <br/> symbol = symbol, <br/> arg.params = model$arg.params,<br/> aux.params = model$aux.params, <br/> input.params = NULL, <br/> ctx = ctx)</pre>
<ol start="8">
<li>现在，我们对时间步长进行迭代，以生成第七个样本的三个时间步长的预测。为了预测一个时间步长，我们使用从前一个时间步长的实际值而不是预测值生成的RNN状态信息:</li>
</ol>
<pre style="padding-left: 60px">pred_length &lt;- 3<br/>predicted &lt;- numeric()<br/><br/>for (i in 1:pred_length) {<br/> data &lt;- mx.nd.array(x_data[, i, 7, drop = F])<br/> label &lt;- mx.nd.array(y_data[i, 7, drop = F])<br/> infer.data &lt;- mx.io.arrayiter(data = data, <br/> label = label, <br/> batch.size = 1, <br/> shuffle = FALSE)<br/> ## use previous RNN state values<br/> infer &lt;- mx.infer.rnn.one(infer.data = infer.data,<br/> symbol = symbol,<br/> ctx = ctx, <br/> arg.params = model$arg.params,<br/> aux.params = model$aux.params, <br/> input.params = <br/> list(rnn.state=infer[[2]], <br/> rnn.state.cell = infer[[3]]))<br/> pred &lt;- infer[[1]]<br/> predicted &lt;- c(predicted, as.numeric(as.array(pred)))<br/>}<br/><br/>predicted</pre>
<p class="mce-root">接下来，我们将了解本节中执行的步骤。</p>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    






    
        <title>How it works...</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">它是如何工作的...</h1>
                
            
            
                
<p>在<em>步骤1 </em>中，我们将输入数据分为训练和验证，并为每个数据创建了数据迭代器。这些数据迭代器是迭代器对象，允许通过调用next来顺序获取数据批次，每个批次包含一些训练示例及其各自的标签。在<em>步骤2 </em>中，我们创建了一个RNN符号。我们指定层数为2，隐藏单元数为30。我们将RNN单元的类型配置为<kbd>lstm</kbd>，并将配置参数设置为一对一。在下一步中，我们定义了损失函数。在<em>步骤4 </em>中，我们使用<kbd>mx.opt.create()</kbd>函数通过名称和参数创建一个优化器。我们创建了一个<kbd>adadelta</kbd>优化器并配置了它的参数。<kbd>wd</kbd>参数是L2正则化系数，而<kbd>clip_gradient</kbd>参数通过投影到盒子上来裁剪渐变，[ <kbd>-clip_gradient</kbd>，<kbd>clip_gradient</kbd> ]。我们使用Xavier权重初始化我们的模型。在这种类型的权重初始化中，每个经过的层的方差保持不变，从而防止网络消失或爆发梯度问题。</p>
<p>要了解更多关于这种技术的内容，请参考本文:<a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf" target="_blank">http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf</a>。</p>
<p>在<em>步骤5 </em>中，我们使用桶对网络进行了50个纪元的训练。分桶是一种用于训练多个网络的技术，这些网络具有不同但相似的架构，共享相同的参数集。在下一步中，我们从训练好的模型中提取状态符号以用于推理。在<em>的第7步</em>，我们创建了一个推理模型。最后，在最后一步中，我们预测了第一个测试样本的值。</p>


            

            
        
    


</body></html>