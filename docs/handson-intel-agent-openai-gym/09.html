<html><head/><body>
<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Exploring the Learning Environment Landscape - Roboschool, Gym-Retro, StarCraft-II, DeepMindLab</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="54VHA0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">探索学习环境景观-机器人学校，健身房-复古，星际争霸-II，DeepMindLab</h1>
                
            
            
                
<p class="calibre2">在构建智能代理来解决各种具有挑战性的问题的过程中，您已经取得了很大的进步。在前几章中，我们研究了OpenAI Gym中可用的几种环境。在这一章中，我们将把目光投向体育馆之外，看看其他一些可以用来训练智能代理或进行实验的发展良好的环境。</p>
<p class="calibre2">在我们查看其他为开发智能代理提供良好学习环境的开源库之前，我们先来看看最近添加到OpenAI Gym库中的一类环境。如果你像我一样对机器人感兴趣，你会非常喜欢这个。是啊！它是机器人类的环境，为机器人操作任务提供了非常有用的环境，比如用机械臂抓取、滑动、推动等等。这些机器人环境基于MuJoCo引擎，您可能还记得<a href="part0056.html#1LCVG0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre9">第3章</a> <a href="part0056.html#1LCVG0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre9">，</a><em class="calibre13">open ai Gym和深度强化学习入门</em>，MuJoCo引擎需要付费许可，除非您是学生，并将MuJoCo用于个人或课堂用途。这些机器人环境的摘要显示在下面的屏幕截图中，带有环境名称和每个环境的简要描述，因此如果您有兴趣探索此类问题，可以查看它们:</p>
<div><img src="img/00290.jpeg" class="calibre100"/></div>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Gym interface-compatible environments</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="55U1S0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">健身房界面兼容环境</h1>
                
            
            
                
<p class="calibre2">在本节中，我们将深入了解与健身房界面兼容的环境。您应该能够在这些环境中使用我们在前面章节中开发的任何代理。让我们开始，看看几个非常有用和有前途的学习环境。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Roboschool</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="56SIE0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">机器人学校</h1>
                
            
            
                
<p class="calibre2">roboschool<a href="https://github.com/openai/roboschool" class="calibre9">(https://github.com/openai/roboschool)</a>在模拟中提供了几种控制机器人的环境。它是由OpenAI发布的，该环境与我们在本书中使用的OpenAI Gym环境具有相同的界面。健身房基于MuJoCo的环境提供了丰富多样的机器人任务，但MuJoCo在免费试用后需要许可证才能使用。Roboschool提供了八个与MuJoCo非常接近的环境，这是一个好消息，因为它提供了一个免费的选择。除了这八个环境，Roboschool还提供了几个新的和具有挑战性的环境。</p>
<p class="calibre2">下表显示了MuJoCo体育馆环境和机器人学校环境之间的快速比较:</p>
<table border="1" class="calibre101">
<tbody class="calibre36">
<tr class="calibre102">
<td class="calibre103"><strong class="calibre1">简要说明</strong></td>
<td class="calibre104"><strong class="calibre1"> MuJoCo环境</strong></td>
<td class="calibre105"><strong class="calibre1">机器人学校环境</strong></td>
</tr>
<tr class="calibre106">
<td class="calibre107">
<p class="calibre2">让一个独腿2D机器人尽可能快地向前跳跃</p>
</td>
<td class="calibre108">
<p class="calibre2">漏斗-v2</p>
<p class="calibre2"><img src="img/00291.jpeg" class="calibre109"/></p>
</td>
<td class="calibre110">
<p class="calibre2">机器人学校-v1</p>
<p class="calibre2"><img src="img/00292.jpeg" class="calibre111"/></p>
</td>
</tr>
<tr class="calibre112">
<td class="calibre113">
<p class="calibre2">让2D机器人走路</p>
</td>
<td class="calibre114">
<p class="calibre2">Walker2d-v2</p>
<p class="calibre2"><img src="img/00293.jpeg" class="calibre115"/></p>
</td>
<td class="calibre116">
<p class="calibre2">RoboschoolWalker2d-v1</p>
<p class="calibre2"><img src="img/00294.jpeg" class="calibre117"/></p>
</td>
</tr>
<tr class="calibre118">
<td class="calibre119">Make a four-legged 3D robot walk<br class="title-page-name"/>
<p class="calibre2"/>
</td>
<td class="calibre120">
<p class="calibre2">蚂蚁v2</p>
<p class="calibre2"><img src="img/00295.jpeg" class="calibre121"/></p>
</td>
<td class="calibre122">
<p class="calibre2">机器人学校-v1</p>
<p class="calibre2"><img src="img/00296.jpeg" class="calibre123"/></p>
</td>
</tr>
<tr class="calibre124">
<td class="calibre125">
<p class="calibre2">让一个两足3D机器人在不摔倒的情况下尽可能快地向前走</p>
</td>
<td class="calibre126">
<p class="calibre2">人形机器人-v2</p>
<p class="calibre2"><img src="img/00297.jpeg" class="calibre127"/></p>
</td>
<td class="calibre128">
<p class="calibre2">RoboschoolHumanoid-v1</p>
<p class="calibre2"><img src="img/00298.jpeg" class="calibre129"/></p>
</td>
</tr>
</tbody>
</table>
<p class="calibre2"> </p>
<p class="calibre2">下表提供了作为Roboschool库一部分的完整环境列表，以及它们的状态和操作空间，供您快速参考:</p>
<table border="1" class="calibre130">
<thead class="calibre131">
<tr class="calibre37">
<th class="calibre132">
<p>环境ID</p>
</th>
<th class="calibre133">
<p>机器人学校环境</p>
</th>
<th class="calibre134">
<p>obs空间</p>
</th>
<th class="calibre135">
<p>行为空间</p>
</th>
</tr>
</thead>
<tbody class="calibre36">
<tr class="calibre37">
<td class="calibre136">roboschollinvertedpendulum-v1</td>
<td class="calibre137"><img src="img/00299.jpeg" class="calibre138"/></td>
<td class="calibre139">方框(5)</td>
<td class="calibre140">方框(1)</td>
</tr>
<tr class="calibre37">
<td class="calibre136">RoboschoolInvertedPendulumSwingup-v1</td>
<td class="calibre137"><img src="img/00300.jpeg" class="calibre138"/></td>
<td class="calibre139">方框(5)</td>
<td class="calibre140">方框(1)</td>
</tr>
<tr class="calibre37">
<td class="calibre136">RoboschoolInvertedDoublePendulum-v1</td>
<td class="calibre137"><img src="img/00301.jpeg" class="calibre141"/></td>
<td class="calibre139">方框9</td>
<td class="calibre140">方框(1)</td>
</tr>
<tr class="calibre37">
<td class="calibre136">RoboschoolReacher-v1</td>
<td class="calibre137"><img src="img/00302.jpeg" class="calibre142"/></td>
<td class="calibre139">方框9</td>
<td class="calibre140">方框(2)</td>
</tr>
<tr class="calibre37">
<td class="calibre136">机器人学校-v1</td>
<td class="calibre137"><img src="img/00303.jpeg" class="calibre143"/></td>
<td class="calibre139">方框15</td>
<td class="calibre140">方框(3)</td>
</tr>
<tr class="calibre37">
<td class="calibre136">RoboschoolWalker2d-v1</td>
<td class="calibre137"><img src="img/00304.jpeg" class="calibre142"/></td>
<td class="calibre139">方框(22，)</td>
<td class="calibre140">方框(6)</td>
</tr>
<tr class="calibre37">
<td class="calibre136">RoboschoolHalfCheetah-v1</td>
<td class="calibre137"><img src="img/00305.jpeg" class="calibre144"/></td>
<td class="calibre139">方框26</td>
<td class="calibre140">方框(6)</td>
</tr>
<tr class="calibre37">
<td class="calibre136">机器人学校-v1</td>
<td class="calibre137"><img src="img/00306.jpeg" class="calibre144"/></td>
<td class="calibre139">方框(28，)</td>
<td class="calibre140">方框(8)</td>
</tr>
<tr class="calibre37">
<td class="calibre136">RoboschoolHumanoid-v1</td>
<td class="calibre137"><img src="img/00307.jpeg" class="calibre142"/></td>
<td class="calibre139">方框(44，)</td>
<td class="calibre140">方框17</td>
</tr>
<tr class="calibre37">
<td class="calibre136">roboschoolhumanodflagrun-v1</td>
<td class="calibre137"><img src="img/00308.jpeg" class="calibre142"/></td>
<td class="calibre139">方框(44，)</td>
<td class="calibre140">方框17</td>
</tr>
<tr class="calibre37">
<td class="calibre136">RoboschoolHumanoidFlagrunHarder-v1</td>
<td class="calibre137"><img src="img/00309.jpeg" class="calibre145"/></td>
<td class="calibre139">方框(44，)</td>
<td class="calibre140">方框17</td>
</tr>
<tr class="calibre37">
<td class="calibre136">RoboschoolPong-v1</td>
<td class="calibre137"><img src="img/00310.jpeg" class="calibre144"/></td>
<td class="calibre139">方框13</td>
<td class="calibre140">方框(2)</td>
</tr>
</tbody>
</table>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Quickstart guide to setting up and running Roboschool environments</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="57R300-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">设置和运行机器人学校环境的快速入门指南</h1>
                
            
            
                
<p class="calibre2">机器人学校环境使用开源的Bulletphysics引擎，而不是专有的MuJoCo引擎。让我们快速地看一下Roboschool环境，这样你就知道如何使用Roboschool库中的任何环境，如果你碰巧发现它对你的工作有用的话。首先，我们必须在我们的<kbd class="calibre12">rl_gym_book</kbd> conda环境中安装Roboschool Python库。因为这个库依赖于几个组件，包括Bulletphysics引擎，所以涉及到几个安装步骤，在这里的Roboschool GitHub官方资源库中列出:<a href="https://github.com/openai/roboschool" class="calibre9">https://github.com/openai/roboschool</a>。为了使事情更简单，您可以在<kbd class="calibre12">ch9/setup_roboschool.sh </kbd>使用本书代码库中的脚本来自动编译和安装<kbd class="calibre12">Roboschool</kbd>库。按照以下步骤运行脚本:</p>
<ol class="calibre14">
<li value="1" class="calibre11">使用<kbd class="calibre12">source activate rl_gym_book</kbd>激活<kbd class="calibre12">rl_gym_book</kbd> conda环境。</li>
<li value="2" class="calibre11">用<kbd class="calibre12">cd ch9</kbd>导航到<kbd class="calibre12">ch9</kbd>文件夹。</li>
<li value="3" class="calibre11">确保脚本的执行位设置为<kbd class="calibre12">chmod a+x setup_roboschool.sh</kbd>。</li>
<li value="4" class="calibre11">用<kbd class="calibre12">sudo</kbd> : <kbd class="calibre12">./setup_roboschool.sh</kbd>运行脚本。</li>
</ol>
<p class="calibre2">这将安装所需的系统依赖项，获取并编译bullet3物理引擎的兼容源代码；将Roboschool源代码拉到您的主目录下的<kbd class="calibre12">software</kbd>文件夹中；最后在<kbd class="calibre12">rl_gym_book</kbd> conda环境中编译、构建和安装Roboschool库。如果安装成功完成，您将在控制台上看到以下消息:</p>
<pre class="calibre17">Setup completed successfully. You can now import roboschool and use it. If you would like to \test the installation, you can run: python ~/roboschool/agent_zoo/demo_race2.py"</pre>
<p class="calibre2">您可以使用以下命令运行快速入门演示脚本:</p>
<pre class="calibre17"><strong class="calibre1">`(rl_gym_book) praveen@ubuntu:~$ python ~/roboschool/agent_zoo/demo_race2.py`</strong></pre>
<p class="calibre2">这将会启动一场有趣的机器人比赛，你会看到一只跳跃者、半猎豹和人形机器人在赛跑！有趣的方面是，每个机器人都由基于强化学习的训练策略控制。这场比赛将类似于这张快照:</p>
<div><img src="img/00311.jpeg" class="calibre146"/></div>
<p class="calibre2">一旦安装完毕，您就可以创建一个Roboschool环境，并使用我们在前面章节中开发的一个代理在这些环境中进行训练和运行。</p>
<p class="calibre2">您可以使用本章代码库中的<kbd class="calibre12">run_roboschool_env.py</kbd>脚本，在<a href="https://github.com/PacktPublishing/Hands-On-Intelligent-Agents-with-OpenAI-Gym/tree/master/ch9" class="calibre9">https://github . com/packt publishing/Hands-On-Intelligent-Agents-with-open ai-Gym/tree/master/ch9</a>查看任何Roboschool环境。例如，要检查<kbd class="calibre12">RoboschoolInvertedDoublePendulum-v1</kbd>环境，您可以运行以下脚本:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/HOIAWOG/ch9$python run_roboschool_env.py --env RoboschoolInvertedDoublePendulum-v1</strong></pre>
<p class="calibre2">您可以使用上表中的任何其他Roboschool环境名称，也可以使用新的可用的Roboschool环境。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Gym retro</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="58PJI0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">健身房复古</h1>
                
            
            
                
<p class="calibre2">gym Retro(<a href="https://github.com/openai/retro" class="calibre9">https://github.com/openai/retro</a>)是open ai(<a href="https://blog.openai.com/gym-retro/" class="calibre9">https://blog.openai.com/gym-retro/</a>)发布的一个比较新的(2018年5月25日发布的)Python库，作为开发游戏玩的强化学习算法的研究平台。虽然在OpenAI Gym中提供了60+游戏的Atari套件，但可用的游戏总数有限。Gym Retro支持使用为多个主机/复古游戏平台开发的游戏，例如任天堂的NES、s NES、Game Boy主机、世嘉Genesis和世嘉主系统等。这可以通过使用Libretro API的模拟器来实现:</p>
<div><img src="img/00312.jpeg" class="calibre147"/></div>
<p class="calibre2">Gym Retro提供了方便的包装器，将1000多种这样的视频游戏转变为Gym界面兼容的学习环境！是不是很棒！几个新的学习环境，但具有相同的界面，这样我们就可以轻松地训练和测试我们迄今为止开发的代理，而无需对代码进行任何必要的更改...</p>
<p class="calibre2"/>
<p class="calibre2"/>
<p class="calibre2">为了感受一下使用Gym Retro中的环境有多简单，让我们暂时将安装步骤放在一边，快速查看一下代码，以便在安装后创建一个新的Gym Retro环境:</p>
<pre class="calibre17">import retro<br class="title-page-name"/>env = retro.make(game='Airstriker-Genesis', state='Level1')</pre>
<p class="calibre2">截取的这段代码将创建一个<kbd class="calibre12">env</kbd>对象，它具有与我们之前见过的所有健身房环境相同的接口和方法，例如<kbd class="calibre12">step(...)</kbd>、<kbd class="calibre12">reset()</kbd>和<kbd class="calibre12">render()</kbd>。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Quickstart guide to setup and run Gym Retro</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="59O440-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">设置和运行健身复古的快速入门指南</h1>
                
            
            
                
<p class="calibre2">让我们通过使用pip和以下命令安装预构建的二进制文件来快速尝试一下Gym Retro库:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/rl_gym_book/ch9$ pip install gym-retro</strong></pre>
<p class="calibre2">安装成功后，我们可以使用以下脚本先睹为快:</p>
<pre class="calibre17">#!/usr/bin/env python<br class="title-page-name"/>import retro
<br class="title-page-name"/>if __name__ == '__main__':<br class="title-page-name"/>   env = retro.make(game='Airstriker-Genesis', state='Level1')
    obs = env.reset()
    while True:
        obs, rew, done, info = env.step(env.action_space.sample())
        env.render()
        if done:
            obs = env.reset()</pre>
<p class="calibre2">运行这个脚本会弹出一个空袭游戏的窗口，显示飞船采取随机行动。游戏窗口看起来会像这样:</p>
<div><img src="img/00313.jpeg" class="calibre148"/></div>
<p class="calibre2">在我们继续之前，有一点要注意，包含整个游戏数据的<strong class="calibre4"> ROM </strong> ( <strong class="calibre4">只读存储器</strong>)文件并不是对所有游戏免费开放的。一些非商业主机游戏的rom，如Airstriker(在前面的脚本中使用)、Fire、Dekadrive、Automaton、Fire、Lost Marbles等，都包含在Gym Retro library中，可以免费使用。其他游戏，如索尼克系列(索尼克刺猬，索尼克刺猬2，索尼克3 &amp;指关节)需要从<a href="https://store.steampowered.com/app/71113/Sonic_The_Hedgehog/" class="calibre9"> Steam </a>等地方购买rom才能合法使用。这对于希望使用这种环境开发算法的爱好者、学生和其他爱好者来说是一个障碍。但至少这个障碍相对较小，因为《刺猬索尼克》的Steam售价约为1.69美元。一旦你有了游戏的ROM文件，健身房复古库提供了一个脚本将它们导入到库中，如下所示:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/rl_gym_book/ch9$ python -m retro.import /PATH/TO/YOUR/ROMs/DIRECTORY<br class="title-page-name"/>OpenAI Universe<br class="title-page-name"/></strong></pre>
<p class="calibre2">请注意，当创建一个新的健身房复古环境时，我们需要游戏的名称以及游戏的状态<kbd class="calibre12">retro.make(game='NAME_OF_GAME', state='NAME_OF_STATE')</kbd></p>
<p class="calibre2">要获得可用的Gym Retro环境列表，可以运行以下命令:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/rl_gym_book/ch9$ python -c "import retro; retro.list_games()"</strong><br class="title-page-name"/></pre>
<p class="calibre2">要获得可用游戏状态的列表，您可以运行以下Python脚本:</p>
<pre class="calibre17">#!/usr/bin/evn python<br class="title-page-name"/>import retro
for game in retro.list_games():
    print(game, retro.list_states(game))</pre>
<p class="calibre2">到目前为止，我们已经熟悉了健身房复古图书馆。我们来分析一下，除了我们已经看到和使用过的，这个库还为我们提供了哪些优势或新功能。首先，健身房复古图书馆利用比雅达利游戏机更新的游戏机(如SEGA创世纪)。相比之下，SEGA Genesis游戏机的内存是雅达利游戏机的500倍，具有更好的视觉效果和更大的控制范围。这为我们提供了相对复杂的学习环境，以及一些更复杂的任务和挑战，供我们的智能代理学习和解决。第二，这些主机游戏中的一些在本质上是渐进的，其中游戏的复杂性通常随着每个级别而增加，并且级别在某些方面(如目标、对象外观、物理等)具有若干相似性，同时还在其他方面提供多样性(如布局、新对象等)。这种难度逐渐增加的训练环境有助于开发智能代理，这些智能代理可以学习解决一般的任务，而不是非常特定于任务/环境(例如监督学习中的过拟合)。代理可以学习将他们的技能和学习从一个级别转移到另一个级别，然后转移到另一个游戏。这一领域正处于积极的研究中，通常被称为课程学习、阶段学习或增量进化。毕竟，最终我们感兴趣的是开发能够学习解决一般任务的智能代理，而不仅仅是代理被训练完成的特定任务。Gym Retro library提供了一些有用的，虽然只是游戏的环境来促进这样的实验和研究。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Other open source Python-based learning environments</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5AMKM0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">其他基于Python的开源学习环境</h1>
                
            
            
                
<p class="calibre2">在本节中，我们将讨论最近的基于Python的学习环境，这些环境为智能代理开发提供了一个良好的平台，但不一定具有与Gym兼容的环境界面。尽管它们不提供与健身房兼容的接口，我们将在这一部分讨论的环境是经过仔细选择的，以确保要么有一个健身房包装器(使其与健身房接口兼容)，要么它们易于实现，以便使用和试验我们通过本书开发的代理。正如您所猜测的，这个用于开发智能代理的基于Python的学习环境的列表在未来将会增长，因为这个领域目前正在被非常积极地研究。这本书的代码存储库将包含未来新环境的信息和快速入门指南。在该书的GitHub资源库注册更新通知，以获得这些更新。在接下来的几个小节中，我们将讨论一些最有前途的学习环境，这些环境随时可供使用。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>StarCraft II - PySC2</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5BL580-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">星际争霸2-pysc 2</h1>
                
            
            
                
<p class="calibre2">星际争霸2非常受欢迎，事实上是有史以来最成功的即时战略游戏之一，全世界有数百万人在玩。它甚至还有世界冠军联赛(<a href="https://wcs.starcraft2.com/en-us/" class="calibre9">https://wcs.starcraft2.com/en-us/</a>)！环境相当复杂，主要目标是建立一个军事基地，管理经济，保卫基地，摧毁敌人。玩家从场景的第三人称视角控制大本营和军队。如果你不熟悉StarCarft，你应该在网上看几个游戏，感受一下这个游戏有多复杂和快节奏。</p>
<p class="calibre2">对于人类来说，玩好这个即时战略游戏，需要大量的练习(甚至几个月；其实职业选手训练几年)，计划性，反应快。尽管软件代理可以每帧按几个软件按钮来快速移动，但行动速度并不是决定胜利的唯一因素。代理必须多任务和微观管理军队单位，并最大化他们的分数，这比雅达利游戏复杂几个数量级。</p>
<p class="calibre2">暴雪，制作星际争霸2的公司，发布了星际争霸2 API，它提供了必要的钩子来与星际争霸2游戏接口，并无限制地控制它。这使得一些新的可能性成为可能，例如我们所追求的智能代理的发展。他们甚至有一个单独的<strong class="calibre4">最终用户许可协议</strong> ( <strong class="calibre4"> EULA </strong>)在人工智能和机器学习许可下开放使用环境！对于像暴雪这样从事游戏制作和销售的公司来说，这是一个非常受欢迎的举措。开源了<strong class="calibre4"> StarCraft2 </strong> ( <strong class="calibre4"> SC2 </strong>)客户端协议实现，并提供了Linux安装包，以及一些附件，如地图包，可以从他们位于<a href="https://github.com/Blizzard/s2client-proto" class="calibre9">https://github.com/Blizzard/s2client-proto</a>的GitHub页面免费下载。最重要的是，谷歌DeepMind已经开源了他们的PySC2库，该库通过Python公开了SC2客户端接口，并提供了一个包装器，使其成为一个RL环境。</p>
<p class="calibre2">下面的屏幕截图显示了PySC2 UI，右侧显示了代理可观察到的要素层，左侧显示了游戏场景的简化概述:</p>
<p class="cdpaligncenter4"><img src="img/00314.jpeg" class="calibre149"/></p>
<p>如果您对这些类型的环境感兴趣，尤其是如果您是一名游戏开发人员，您可能也会对Dota 2环境感兴趣。Dota 2是一款即时战略游戏，像星际争霸2一样，在两队五名玩家之间进行，每个玩家控制一个英雄角色。您可以了解更多有关OpenAI如何开发一个由五个基于神经网络的代理组成的团队的信息，这些代理学会了在团队中工作，在一天内玩180年的游戏，学会了克服几个挑战(包括高维度和连续的状态和动作空间，以及长期视野)，同时使用self-play与自己对抗！你可以在https://blog.openai.com/openai-five/.阅读更多关于五个代理团队的内容</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Quick start guide to setup and run StarCraft II PySC2 environment</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5CJLQ0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">设置和运行星际争霸2 pysc 2环境的快速入门指南</h1>
                
            
            
                
<p class="calibre2">我们将看看你如何快速设置并开始使用星际争霸2的环境。像往常一样，使用代码库中的自述文件获取最新的说明，因为链接和版本可能会发生变化。如果您还没有这样做，请启动并查看该书的代码库，以获得有关更改和更新的通知。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Downloading the StarCraft II Linux packages</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5DI6C0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">下载星际争霸2 Linux包</h1>
                
            
            
                
<p class="calibre2">在<kbd class="calibre12">~/StarCraftII</kbd>从https://github.com/Blizzard/s2client-proto#downloads下载星际争霸游戏的最新Linux包并解压到你的硬盘上。例如，要将4.1.2版下载到您的<kbd class="calibre12">~/StarCraftII/</kbd>文件夹，您可以使用以下命令:</p>
<pre class="calibre17"><strong class="calibre1">wget http://blzdistsc2-a.akamaihd.net/Linux/SC2.4.1.2.60604_2018_05_16.zip -O ~/StarCraftII/SC2.4.1.2.zip</strong></pre>
<p class="calibre2">让我们将文件解压缩到<kbd class="calibre12">~/StarCraftII/</kbd>目录:</p>
<pre class="calibre17"><strong class="calibre1">unzip ~/StarCraftII/SC2.4.1.2.zip -d ~/StarCraftII/</strong></pre>
<p class="calibre2">注意，正如下载页面上提到的，这些文件使用密码<kbd class="calibre12">'iagreetotheeula</kbd>进行密码保护。</p>
<p class="calibre2">通过输入这些，暴雪确保我们同意受他们的人工智能和机器学习许可条款的约束，这些条款可以在下载页面上找到。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Downloading the SC2 maps</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5EGMU0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">下载SC2地图</h1>
                
            
            
                
<p class="calibre2">我们需要星际争霸2地图包和迷你游戏包来开始。</p>
<p class="calibre2">从https://github.com/Blizzard/s2client-proto#map-packs<a href="https://github.com/Blizzard/s2client-proto#map-packs" class="calibre9">下载地图包</a></p>
<p class="calibre2">将它们解压到你的<kbd class="calibre12">~/StarCraftII/Maps</kbd>目录中。</p>
<p class="calibre2">例如，让我们使用以下命令下载2018年第二季发布的阶梯地图:</p>
<pre class="calibre17"><strong class="calibre1">wget http://blzdistsc2-a.akamaihd.net/MapPacks/Ladder2018Season2_Updated.zip -O ~/StarCraftII/Maps/Ladder2018S2.zip</strong></pre>
<p class="calibre2">让我们将地图解压到<kbd class="calibre12">~/StarCraftII/Maps</kbd>目录:</p>
<pre class="calibre17"><strong class="calibre1">unzip ~/StarCraftII/Maps/Ladder2018S2.zip -d ~/StarCraftII/Maps/</strong></pre>
<p class="calibre2">接下来，我们将下载并解压缩迷你游戏地图文件:</p>
<pre class="calibre17"><strong class="calibre1">wget https://github.com/deepmind/pysc2/releases/download/v1.2/mini_games.zip -O ~/StarCraftII/Maps/mini_games1.2.zip</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">unzip ~/StarCraftII/Maps/mini_games1.2.zip -d ~/StarCraftII/Maps</strong></pre>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Installing PySC2</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5FF7G0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">安装PySC2</h1>
                
            
            
                
<p class="calibre2">让我们为RL环境接口安装PySC2库，以及所需的依赖项。这一步很简单，因为PySC2库有一个PyPi Python包:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/HOIAWOG/ch9$ pip install pysc2</strong></pre>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Playing StarCraftII yourself or running sample agents</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5GDO20-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">自己玩星际争霸1还是运行样本代理</h1>
                
            
            
                
<p class="calibre2">要测试安装是否顺利，并查看StarCarftII学习环境是什么样子，您可以使用以下命令在Simple64 map或CollectMineralShards map上快速启动一个随机代理:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/HOIAWOG/ch9$ python -m pysc2.bin.agent --map Simple64</strong></pre>
<p class="calibre2">您也可以为环境加载另一个可用的贴图。例如，以下命令加载CollectMineralShards地图:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/HOIAWOG/ch9$ python -m pysc2.bin.agent --map CollectMineralShards</strong></pre>
<p class="calibre2">这将弹出一个UI，显示随机代理采取的操作，让您了解什么是有效的操作，并帮助您直观地看到代理操作时环境中正在发生的事情。</p>
<p class="calibre2">为了自己玩游戏，PySC2提供了一个人类代理界面，这对于调试非常有用(如果你有兴趣，可以玩！)目的。下面是自己运行和玩游戏的命令:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/HOIAWOG/ch9$ python -m pysc2.bin.play --map Simple64</strong></pre>
<p class="calibre2">您还可以使用以下命令运行一个示例代理，该代理被编写为收集矿物碎片，这是游戏中的任务之一:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/HOIAWOG/ch9$ python -m pysc2.bin.agent --map CollectMineralShards --agent pysc2.agents.scripted_agent.CollectMineralShards</strong></pre>
<p class="calibre2">观看本书的代码库，获取新代理源代码和指导，以培训和测试具有高级技能的新代理。你也可以自定义我们上一章开发的代理来学习玩StarCraftII。如果你这样做了，给书的代码库发送一个pull请求，给作者发一封电子邮件，或者大声喊出来，这样每个人都知道你做了什么酷的事情！</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>DeepMind lab</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5HC8K0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">DeepMind实验室</h1>
                
            
            
                
<p class="calibre2">deep mind Lab(<a href="https://github.com/deepmind/lab" class="calibre9">https://github.com/deepmind/lab</a>)是一个3D学习环境，它提供了一套具有挑战性任务的环境，例如通过迷宫的3D导航和解谜。它是基于一些开源软件构建的，包括著名的雷神之锤3竞技场。</p>
<p class="calibre2">环境界面非常类似于我们在本书中广泛使用的健身房界面。要了解环境界面的实际情况，请查看下面的代码片段:</p>
<pre class="calibre17">import deepmind_lab<br class="title-page-name"/>num_steps = 1000<br class="title-page-name"/>config = {  <br class="title-page-name"/>    'width': 640,<br class="title-page-name"/>    'height': 480,<br class="title-page-name"/>    'fps': 30<br class="title-page-name"/>}<br class="title-page-name"/>...<br class="title-page-name"/>env = deepmind_lab.Lab(level, ['RGB_INTERLEAVED'], config=config, renderer='software')<br class="title-page-name"/><br class="title-page-name"/>for step in range(num_steps) <br class="title-page-name"/>if done:<br class="title-page-name"/>    env.reset()<br class="title-page-name"/>obs = env.observations()<br class="title-page-name"/>action = agent.get_action(...)<br class="title-page-name"/>reward = env.step(action, num_steps=1)<br class="title-page-name"/>done = not env.is_running()</pre>
<p class="calibre2">这段代码虽然不能与OpenAI Gym接口一一兼容，但提供了一个非常相似的接口。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>DeepMind Lab learning environment interface</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5IAP60-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">DeepMind实验室学习环境界面</h1>
                
            
            
                
<p class="calibre2">我们将简单讨论一下<strong class="calibre4"> DeepMind Lab (DM Lab) </strong>的环境接口，以便您熟悉它，可以看到与OpenAI Gym接口的相似之处，并可以在DM Lab环境中开始尝试代理！</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>reset(episode=-1, seed=None)</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5J99O0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">重置(剧集=-1，种子=无)</h1>
                
            
            
                
<p class="calibre2">这类似于我们在健身房界面看到的<kbd class="calibre12">reset()</kbd>方法，但与健身房环境不同，DM Lab的<kbd class="calibre12">reset</kbd>方法调用并不返回观察结果。我们将在后面看到如何获得观察结果，所以现在，我们将讨论DM实验室的<kbd class="calibre12">reset(episode=-1, seed=None)</kbd>方法。它将环境重置为初始状态，并需要在每集结束时调用，以便创建新的一集。可选的<kbd class="calibre12">episode</kbd>参数采用一个整数值来指定特定剧集中的级别。如果未设置<kbd class="calibre12">episode</kbd>值，或设置为<kbd class="calibre12">-1</kbd>，则按数字顺序加载等级。<kbd class="calibre12">seed</kbd>参数也是可选的，用于播种环境的随机数生成器，以实现可再现性。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>step(action, num_steps=1)</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5K7QA0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">步骤(操作，步骤数=1)</h1>
                
            
            
                
<p class="calibre2">这类似于Gym接口的<kbd class="calibre12">step(action)</kbd>方法，但是与<kbd class="calibre12">reset(...)</kbd>方法一样，对该方法的调用不返回下一个观察结果(或者奖励、完成和信息)。调用此方法使环境前进<kbd class="calibre12">num_steps</kbd>帧数，在每一帧中执行由<kbd class="calibre12">action</kbd>定义的动作。这种动作重复行为在我们希望相同的动作应用于四个左右连续帧的情况下很有用，实际上几名研究人员发现这有助于学习。有一些健身房环境包装器可以完成这种动作重复行为。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>observations()</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5L6AS0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">观察()</h1>
                
            
            
                
<p class="calibre2">这是我们在调用<kbd class="calibre12">reset(...)</kbd>或<kbd class="calibre12">step(action)</kbd>从DM实验室环境接收观察结果后使用的方法。该方法返回一个Python dictionary对象，其中包含我们从环境的可用类型列表中指定的每种观察类型。例如，如果我们想要关于环境的<strong class="calibre4"> RGBD </strong> ( <strong class="calibre4">红绿蓝深度</strong>)信息作为观察类型，我们可以指定当我们使用<kbd class="calibre12">'RGBD'</kbd>键初始化环境时，我们可以使用相同的<kbd class="calibre12">'RGBD'</kbd>键从返回的观察字典中检索该信息。这里显示了一个简单的示例来说明这一点:</p>
<pre class="calibre17">env = deepmind_lab.Lab('tests/empty_room_test', ['RGBD'])<br class="title-page-name"/>env.reset()<br class="title-page-name"/>obs = env.observations()['RGBD']</pre>
<p class="calibre2">DM实验室环境还支持其他观察类型。我们可以使用<kbd class="calibre12">observation_spec()</kbd>来获得一个受支持的观察类型的列表，我们将很快对此进行讨论。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>is_running()</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5M4RE0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">正在运行()</h1>
                
            
            
                
<p class="calibre2">这个方法类似于(在相反的意义上)Gym接口的<kbd class="calibre12">step(action)</kbd>方法返回的<kbd class="calibre12">done</kbd>布尔值。</p>
<p class="calibre2">当环境完成一集或停止运行时，该方法将返回<kbd class="calibre12">False</kbd>。只要环境在运行，它就会返回<kbd class="calibre12">True</kbd>。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>observation_spec()</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5N3C00-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">观察_规格()</h1>
                
            
            
                
<p class="calibre2">这种方法类似于我们在健身房环境中使用的<kbd class="calibre12">env.observation_space()</kbd>。该方法返回一个列表，指定DM实验室环境支持的所有可用观察。它还包括关于依赖于级别的自定义观察的规范。</p>
<p class="calibre2">规范包含张量或字符串的名称、类型和形状，如果在观察列表中指定了规范名称(如前面的<kbd class="calibre12">'RGBD'</kbd>示例)，将返回该规范。例如，下面的代码片段列出了列表中的两个项目，将返回这两个项目以让您了解规范包含的内容:</p>
<div><pre class="calibre17">{<br class="title-page-name"/>    'dtype': &lt;type 'numpy.uint8'&gt;, ## Array data type<br class="title-page-name"/>    'name': 'RGBD',                ## Name of observation.<br class="title-page-name"/>    'shape': (4, 180, 320)         ## shape of the array. (Heights, Width, Colors)<br class="title-page-name"/>}<br class="title-page-name"/><br class="title-page-name"/>{    <br class="title-page-name"/>    'name': 'RGB_INTERLEAVED', ## Name of observation.<br class="title-page-name"/>    'dtype': &lt;type 'numpy.uint8'&gt;, ## Data type array.     <br class="title-page-name"/>    'shape': (180, 320, 3) ## Shape of array. (Height, Width, Colors)<br class="title-page-name"/>}</pre></div>
<p class="calibre2">为了快速理解如何使用这个方法，让我们来看看下面几行代码和输出:</p>
<pre class="calibre17">import deepmind_lab<br class="title-page-name"/>import pprint<br class="title-page-name"/>env = deepmind_lab.Lab('tests/empty_room_test', [])
observation_spec = env.observation_spec()
pprint.pprint(observation_spec)
# Outputs:
[{'dtype': &lt;type 'numpy.uint8'&gt;, 'name': 'RGB_INTERLEAVED', 'shape': (180, 320, 3)},
 {'dtype': &lt;type 'numpy.uint8'&gt;, 'name': 'RGBD_INTERLEAVED', 'shape': (180, 320, 4)},
 {'dtype': &lt;type 'numpy.uint8'&gt;, 'name': 'RGB', 'shape': (3, 180, 320)},
 {'dtype': &lt;type 'numpy.uint8'&gt;, 'name': 'RGBD', 'shape': (4, 180, 320)},
 {'dtype': &lt;type 'numpy.uint8'&gt;, 'name': 'BGR_INTERLEAVED', 'shape': (180, 320, 3)},
 {'dtype': &lt;type 'numpy.uint8'&gt;, 'name': 'BGRD_INTERLEAVED', 'shape': (180, 320, 4)},
 {'dtype': &lt;type 'numpy.float64'&gt;, 'name': 'MAP_FRAME_NUMBER', 'shape': (1,)},
 {'dtype': &lt;type 'numpy.float64'&gt;, 'name': 'VEL.TRANS', 'shape': (3,)},
 {'dtype': &lt;type 'numpy.float64'&gt;, 'name': 'VEL.ROT', 'shape': (3,)},
 {'dtype': &lt;type 'str'&gt;, 'name': 'INSTR', 'shape': ()},
 {'dtype': &lt;type 'numpy.float64'&gt;, 'name': 'DEBUG.POS.TRANS', 'shape': (3,)},
 {'dtype': &lt;type 'numpy.float64'&gt;, 'name': 'DEBUG.POS.ROT', 'shape': (3,)},
 {'dtype': &lt;type 'numpy.float64'&gt;, 'name': 'DEBUG.PLAYER_ID', 'shape': (1,)},
# etc...</pre>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>action_spec()</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5O1SI0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">action_spec()</h1>
                
            
            
                
<p class="calibre2">类似于<kbd class="calibre12">observation_spec()</kbd>,<kbd class="calibre12">action_spec()</kbd>方法返回一个列表，其中包含最小值、最大值和空间中每个元素的名称。<kbd class="calibre12">min</kbd>和<kbd class="calibre12">max</kbd>值分别代表动作空间中相应元素可以设置的最小值和最大值。该列表的长度将等于动作空间的尺寸/形状。这类似于<kbd class="calibre12">env.action_space</kbd>，我们一直在健身房环境中使用。</p>
<p class="calibre2">下面的代码片段让我们快速了解了调用此方法的返回值是什么样的:</p>
<pre class="calibre17">import deepmind_lab<br class="title-page-name"/>import pprint<br class="title-page-name"/><br class="title-page-name"/>env = deepmind_lab.Lab('tests/empty_room_test', [])
action_spec = env.action_spec()
pprint.pprint(action_spec)
# Outputs:</pre>
<pre class="calibre17"># [{'max': 512, 'min': -512, 'name': 'LOOK_LEFT_RIGHT_PIXELS_PER_FRAME'},
#  {'max': 512, 'min': -512, 'name': 'LOOK_DOWN_UP_PIXELS_PER_FRAME'},
#  {'max': 1, 'min': -1, 'name': 'STRAFE_LEFT_RIGHT'},
#  {'max': 1, 'min': -1, 'name': 'MOVE_BACK_FORWARD'},
#  {'max': 1, 'min': 0, 'name': 'FIRE'},
#  {'max': 1, 'min': 0, 'name': 'JUMP'},
#  {'max': 1, 'min': 0, 'name': 'CROUCH'}]</pre>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>num_steps()</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5P0D40-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">步骤数()</h1>
                
            
            
                
<p class="calibre2">这个实用方法就像一个计数器，它计算自上次<kbd class="calibre12">reset()</kbd>调用以来环境执行的帧数。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>fps()</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5PUTM0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">fps()</h1>
                
            
            
                
<p class="calibre2">这个实用程序方法返回每秒实际执行的帧数(或环境步数)。这对于跟踪环境执行速度以及代理从环境中采样的速度非常有用。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>events()</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5QTE80-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">事件()</h1>
                
            
            
                
<p class="calibre2">这个实用程序方法对于调试非常有用，因为它返回了自上次调用<kbd class="calibre12">reset()</kbd>或<kbd class="calibre12">step(...)</kbd>以来发生的事件列表。返回的元组包含一个名称和一个观察列表。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>close()</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5RRUQ0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">关闭()</h1>
                
            
            
                
<p class="calibre2">与健身房环境中可用的<kbd class="calibre12">close()</kbd>方法一样，该方法也关闭环境实例并释放底层资源，例如Quake III Arena实例。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Quick start guide to setup and run DeepMind Lab</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5SQFC0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">设置和运行DeepMind实验室的快速入门指南</h1>
                
            
            
                
<p class="calibre2">随着我们在上一节中对DeepMind实验室环境界面的简短讨论后所熟悉的内容，我们已经准备好获得关于这种学习环境的一些实践经验。在下面的小节中，我们将详细介绍设置DeepMind Lab和运行示例代理的步骤。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Setting up and installing DeepMind Lab and its dependencies</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5TOVU0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">设置和安装DeepMind Lab及其依赖项</h1>
                
            
            
                
<p class="calibre2">DeepMind实验室库使用Bazel作为构建工具，这反过来需要Java。这本书的代码库中有一个脚本，您可以运行它来轻松设置DeepMind实验室。您可以在<a href="https://github.com/PacktPublishing/Hands-On-Intelligent-Agents-with-OpenAI-Gym/tree/master/ch9" class="calibre9">https://github . com/packt publishing/Hands-On-Intelligent-Agents-with-open ai-Gym/tree/master/ch9</a>的chapter9文件夹下找到该脚本。您可以使用以下命令运行该脚本:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/HOIAWOG/ch9$./setup_deepmindlab.sh</strong></pre>
<p class="calibre2">这个脚本需要一些时间来完成，但是会自动安装所有必需的包和库，包括Bazel及其依赖项，并为您设置好一切。</p>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Playing the game, testing a randomly acting agent, or training your own!</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5UNGG0-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">玩游戏，测试随机代理，或训练你自己的！</h1>
                
            
            
                
<p class="calibre2">安装完成后，您可以通过运行以下命令，使用键盘输入来测试游戏:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/HOIAWOG/ch9$ cd deepmindlab</strong><br class="title-page-name"/><br class="title-page-name"/><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/HOIAWOG/ch9/deepmindlab$ bazel run :game -- --level_script=tests/empty_room_test</strong></pre>
<p class="calibre2">您还可以使用以下命令，在随机代理的帮助下测试它:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/HOIAWOG/ch9/deepmindlab$ bazel run :python_random_agent --define graphics=sdl -- --length=5000</strong></pre>
<p class="calibre2">要开始开发您自己的代理，您可以使用已经配置为与DeepMind实验室环境交互的示例代理脚本。可以在<kbd class="calibre12">~/HOIAWOG/ch9/deepmindlab/python/random_agent.py</kbd>找到剧本。要开始训练该代理，可以使用以下命令:</p>
<pre class="calibre17"><strong class="calibre1">(rl_gym_book) praveen@ubuntu:~/HOIAWOG/ch9/deepmindlab$ bazel run :python_random_agent</strong></pre>


            

            
        
    </body></html>


<html xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <title>Summary</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="5VM120-22c7fc7f93b64d07be225c00ead6ce12" class="calibre">
        

                            
                    <h1 class="header-title" id="calibre_pb_0">摘要</h1>
                
            
            
                
<p class="calibre2">在这一章中，我们看了几个有趣且有价值的学习环境，了解了它们的界面是如何设置的，甚至还使用每种环境的快速入门指南和书中代码库中可用的设置脚本实际操作了这些环境。我们首先查看了具有与我们现在非常熟悉的OpenAI Gym接口兼容的接口的环境。特别是在这个类别中，我们探索了机器人学校和健身房的复古环境。</p>
<p class="calibre2">我们还研究了其他有用的学习环境，它们不一定具有与健身房兼容的环境接口，但具有非常相似的API，因此很容易修改我们的代理代码或实现学习环境的包装器，使其与健身房API兼容。具体来说，我们探索了著名的基于即时战略游戏的星际争霸2环境和DeepMind实验室环境。我们还非常简要地提到了DOTA2环境，该环境用于训练单个代理和由OpenAI训练的代理团队，open ai在DOTA 2比赛中成功击败了业余人类玩家，甚至一些职业游戏团队。</p>
<p class="calibre2">我们看到了每个学习环境库中可用的不同任务和环境集，并尝试了一些示例来了解环境，以及如何使用我们在前面章节中开发的代理来训练和解决这些相对较新的学习环境中的挑战性任务。</p>


            

            
        
    </body></html>
</body></html>