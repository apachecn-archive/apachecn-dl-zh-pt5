<html><head/><body><html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Training and Visualizing a Neural Network in R</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:4a8cbe4a-e61d-4c74-886d-1da985c44432" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">在R中训练和可视化神经网络</h1>

                

            

            

                

<p>如在<a href="b283a577-2201-43eb-877c-f281677370bf.xhtml" target="_blank">第1章</a>、<em>神经网络和人工智能概念</em>和<a href="9318274a-72ac-4475-a140-7aaf92253400.xhtml" target="_blank">第2章</a>、<em>神经网络中的学习过程</em>中所见，训练神经网络模型形成了构建神经网络的基础。</p>

<p>前馈和反向传播是用于确定模型的权重和偏差的技术。权重永远不会为零，但偏差可以为零。首先，将权重初始化为一个随机数，通过梯度下降，误差被最小化；我们得到了模型的一组可能的最佳权重和偏差。</p>

<p>一旦使用任何R函数训练了模型，我们就可以传递自变量来预测目标或未知变量。在本章中，我们将使用公开可用的数据集来训练、测试和可视化神经网络模型。将涵盖以下项目:</p>

<ul>

<li>使用神经网络模型训练、测试和评估数据集</li>

<li>可视化神经网络模型</li>

<li>提前停止</li>

<li>避免过度拟合</li>

<li>神经网络的推广</li>

<li>神经网络参数的缩放</li>

<li>集合模型</li>

</ul>

<p>本章结束时，我们将了解如何使用神经网络模型训练、测试和评估数据集。我们将学习如何在R环境中可视化神经网络模型。我们将涵盖早期停止、避免过度拟合、神经网络的泛化和神经网络参数的缩放等概念。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Data fitting with neural network</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:4a8cbe4a-e61d-4c74-886d-1da985c44432" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">神经网络数据拟合</h1>

                

            

            

                

<p>数据拟合是构建一条曲线或一个数学函数的过程，它与一组先前收集的点具有最佳匹配。曲线拟合可以涉及插值(需要精确的数据点)和平滑(构建逼近数据的平坦函数)。从数据拟合中获得的近似曲线可用于帮助显示数据，在没有数据可用的情况下预测函数值，以及总结两个或多个变量之间的关系。下图显示了收集数据的线性插值:</p>

<div><img class="image-border" src="img/efb9d783-594e-4002-bb33-b119120bc6d0.png"/></div>

<p>数据拟合是根据一组输入训练神经网络以产生一组相关的目标输出的过程。一旦神经网络拟合了数据，它就形成了输入-输出关系的一般化，并可用于为未经训练的输入生成输出。</p>

<p>全球主要制造商一直在研究车辆的油耗。在一个以加油问题甚至更大的空气污染问题为特征的时代，车辆的燃料消耗已经成为一个关键因素。在本例中，我们将构建一个神经网络，目的是根据某些特征预测车辆的燃油消耗量。</p>

<p>为此，使用包含在<kbd>ISLR</kbd>包中的<kbd>Auto</kbd>数据集，我们已经在<a href="b5f75068-f1e3-465e-969d-a8f1ad48378d.xhtml">第3章</a>、<em>使用多层神经网络的深度学习</em>中的一个示例中使用了该数据集。<kbd>Auto</kbd>数据集包含392辆汽车的汽油里程、马力和其他信息。这是一个数据框架，包含以下九个变量的392个观察值:</p>

<ul>

<li><kbd>mpg</kbd>:每加仑英里数</li>

<li><kbd>cylinders</kbd>:气缸数量在4到8之间</li>

<li><kbd>displacement</kbd>:发动机排量(立方英寸)</li>

<li><kbd>horsepower</kbd>:发动机马力</li>

<li><kbd>weight</kbd>:车辆重量(磅)</li>

<li><kbd>acceleration</kbd>:从0加速到60英里/小时的时间(秒)</li>

<li><kbd>year</kbd>:年款(以100为模)</li>

<li><kbd>origin</kbd>:汽车产地(美国、欧洲、日本)</li>

<li><kbd>name</kbd>:车辆名称</li>

</ul>

<p>下面是我们将在本例中使用的代码:</p>

<pre class="mce-root"><strong>###########################################################################</strong><br/><strong>########Chapter 5 - Introduction to Neural Networks - using R##############         </strong><br/><strong>##########R program to build, train and test neural networks############### </strong><br/><strong>###########################################################################</strong><br/><strong>library("neuralnet")</strong><br/><strong>library("ISLR")</strong><br/><br/><strong>data = Auto</strong><br/><strong>View(data)</strong><br/><br/><strong>plot(data$weight, data$mpg, pch=data$origin,cex=2)</strong><br/><strong>par(mfrow=c(2,2))</strong><br/><strong>plot(data$cylinders, data$mpg, pch=data$origin,cex=1)</strong><br/><strong>plot(data$displacement, data$mpg, pch=data$origin,cex=1)</strong><br/><strong>plot(data$horsepower, data$mpg, pch=data$origin,cex=1)</strong><br/><strong>plot(data$acceleration, data$mpg, pch=data$origin,cex=1)</strong><br/><br/><strong>mean_data &lt;- apply(data[1:6], 2, mean)</strong><br/><strong>sd_data &lt;- apply(data[1:6], 2, sd)</strong><br/><br/><strong>data_scaled &lt;- as.data.frame(scale(data[,1:6],center = mean_data, scale = sd_data))</strong><br/><strong>head(data_scaled, n=20)</strong><br/><br/><strong>index = sample(1:nrow(data),round(0.70*nrow(data)))</strong><br/><strong>train_data &lt;- as.data.frame(data_scaled[index,])</strong><br/><strong>test_data &lt;- as.data.frame(data_scaled[-index,])</strong><br/><br/><strong>n = names(data_scaled)</strong><br/><strong>f = as.formula(paste("mpg ~", paste(n[!n %in% "mpg"], collapse = " + ")))</strong><br/><br/><strong>net = neuralnet(f,data=train_data,hidden=3,linear.output=TRUE)</strong><br/><strong>plot(net)</strong><br/><br/><strong>predict_net_test &lt;- compute(net,test_data[,2:6])</strong><br/><strong>MSE.net &lt;- sum((test_data$mpg - predict_net_test$net.result)^2)/nrow(test_data)</strong><br/><br/><strong>Lm_Mod &lt;- lm(mpg~., data=train_data)</strong><br/><strong>summary(Lm_Mod)</strong><br/><strong>predict_lm &lt;- predict(Lm_Mod,test_data)</strong><br/><strong>MSE.lm &lt;- sum((predict_lm - test_data$mpg)^2)/nrow(test_data)</strong><br/><br/><strong>par(mfrow=c(1,2))</strong><br/><strong>plot(test_data$mpg,predict_net_test$net.result,col='black',main='Real vs predicted for neural network',pch=18,cex=4)</strong><br/><strong>abline(0,1,lwd=5)</strong><br/><strong>plot(test_data$mpg,predict_lm,col='black',main='Real vs predicted for linear regression',pch=18,cex=4)</strong><br/><strong>abline(0,1,lwd=5)</strong><br/><strong>###########################################################################</strong></pre>

<p>像往常一样，我们将逐行分析代码，详细解释用于捕获结果的所有特性。</p>

<pre class="mce-root"><strong>library("neuralnet")</strong><br/><strong>library("ISLR")</strong></pre>

<p class="mce-root">初始代码的前两行用于加载运行分析所需的库。</p>

<p>记住，要安装R的初始发行版中没有的库，必须使用<kbd>install.package</kbd>函数。这是安装包的主要功能。它接受一个名称向量和一个目的库，从存储库中下载包并安装它们。这个函数应该只使用一次，而不是每次运行代码时都使用。</p>

<p><kbd>neuralnet</kbd>库用于使用反向传播、<strong>弹性反向传播</strong> ( <strong> RPROP </strong>)带或不带权重回溯，或修改的<strong>全局收敛版本</strong> ( <strong> GRPROP </strong>)来训练神经网络。该功能允许通过自定义选择错误和激活功能进行灵活设置。此外，还实现了广义权重的计算。</p>

<p><kbd>ISLR</kbd>库包含一组可免费用于我们示例的数据集。这是在研究中心进行的主要研究中收集的一系列数据。</p>

<pre class="mce-root"><strong>data = Auto</strong><br/><strong>View(data)</strong></pre>

<p class="mce-root">这个命令加载了<kbd>Auto</kbd>数据集，正如我们所预料的，它包含在<kbd>ISLR</kbd>库中，并将其保存在给定的数据帧中。使用<kbd>View</kbd>功能查看任意R物体结构的紧凑显示。下面的截图显示了包含在<kbd>Auto</kbd>数据集中的一些数据:</p>

<div><img class="image-border" src="img/d1bd382e-ad14-4e8e-9eb4-269fb98aa10f.png"/></div>

<p>如您所见，数据库由392行和9列组成。这些行代表了从1970年到1982年的392辆商用车辆。这些列代表为每辆车收集的9个特征，依次为:<kbd>mpg</kbd>、<kbd>cylinders</kbd>、<kbd>displacement</kbd>、<kbd>horsepower</kbd>、<kbd>weight</kbd>、<kbd>acceleration</kbd>、<kbd>year</kbd>、<kbd>origin</kbd>和<kbd>name</kbd>。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Exploratory analysis</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:4a8cbe4a-e61d-4c74-886d-1da985c44432" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">探索性分析</h1>

                

            

            

                

<p>在通过构建和训练神经网络开始数据分析之前，我们进行探索性分析，以了解数据是如何分布的，并提取初步知识。</p>

<p>我们可以通过描绘预测值与目标值的关系图来开始探索性分析。在这方面，我们记得在我们的分析中，预测因子是以下变量:<kbd>cylinders</kbd>、<kbd>displacement</kbd>、<kbd>horsepower</kbd>、<kbd>weight</kbd>、<kbd>acceleration</kbd>、<kbd>year</kbd>、<kbd>origin</kbd>和<kbd>name</kbd>。目标是包含392辆样车的每加仑英里数的<kbd>mpg</kbd>变量。</p>

<p>假设我们想要检查来自三个不同产地的汽车的重量和里程，如下图所示，使用以下代码:</p>

<pre><strong>plot(data$weight, data$mpg, pch=data$origin,cex=2)</strong></pre>

<p>为了绘制图表，我们使用了<kbd>plot()</kbd>函数，指定在<em> x </em>轴(<kbd>weight</kbd>)上指向什么，在<em> y </em>轴(<kbd>mpg</kbd>)上指向什么，最后，根据哪个变量对数据进行分组(<kbd>origin</kbd>)，如下图所示:</p>

<div><img class="image-border" height="355" src="img/8821f910-6f74-4a0e-8ead-575047efee90.png" width="524"/></div>

<p>记住<kbd>origin</kbd>栏中的数字对应以下区域:1=美国，2 =欧洲，3 =日本)。通过对上图的分析，我们可以发现油耗随着体重的增加而增加。让我们记住，目标衡量的是每加仑的英里数，那么一加仑燃料能跑多少英里。由此得出结论，mpg(每加仑英里数)值越大，油耗越低。</p>

<p>另一个来自情节分析的考虑是，美国生产的汽车更重。事实上，在图表的右边部分(对应于较高的重量值)，只有该地区生产的汽车。</p>

<p>最后，如果我们将分析的重点放在图表的左侧，在对应最低油耗的上部，我们会发现大多数情况下是日本和欧洲的汽车。总之，我们可以注意到油耗最低的车是日本的。</p>

<p>现在，让我们看看其他图表，也就是说，如果我们绘制剩余的数字预测值(<kbd>cylinders</kbd>、<kbd>displacement</kbd>、<kbd>horsepower</kbd>和<kbd>acceleration</kbd>)与目标值(<kbd>mpg</kbd>)的关系，我们会得到什么。</p>

<pre><strong>par(mfrow=c(2,2))</strong><br/><strong>plot(data$cylinders, data$mpg, pch=data$origin,cex=1)</strong><br/><strong>plot(data$displacement, data$mpg, pch=data$origin,cex=1)</strong><br/><strong>plot(data$horsepower, data$mpg, pch=data$origin,cex=1)</strong><br/><strong>plot(data$acceleration, data$mpg, pch=data$origin,cex=1)</strong></pre>

<p>由于篇幅原因，我们决定将四个图表放在一起。使用<kbd>par()</kbd>函数，r可以很容易地将多个图合并成一个总图。使用par()函数，我们可以包含选项mfrow=c(nrows，ncols)来创建一个由nrows x ncols图组成的矩阵，这些图按行填充。例如，选项mfrow=c(3，2)创建一个3行2列的矩阵图。此外，选项mfcol=c(nrows，ncols)按列填充矩阵。</p>

<p>下图显示了以2行2列矩阵排列的4个图:</p>

<div><img class="image-border" src="img/6718c5b1-2ad5-4135-8f0f-7363f406618d.png"/></div>

<p>通过对上图的分析，我们发现前面已经提到的内容得到了证实。我们可以注意到马力越大的车油耗越高。同样的事情我们可以说关于发动机排量；同样在这种情况下，排量越高的车油耗越高。还是那句话，马力和排量值更高的车都是美国生产的。</p>

<p>相反，加速值较高的汽车油耗较低。这是因为这种汽车的重量较轻。通常情况下，重型车加速较慢。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Neural network model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:4a8cbe4a-e61d-4c74-886d-1da985c44432" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">神经网络模型</h1>

                

            

            

                

<p>在<a href="9318274a-72ac-4475-a140-7aaf92253400.xhtml" target="_blank">第2章</a>、<em>神经网络的学习过程</em>中，我们在构建网络之前对数据进行了缩放。在那种情况下，我们指出，在训练神经网络之前对数据进行标准化是一种很好的做法。通过规范化，消除了数据单元，使您可以轻松地比较不同位置的数据。</p>

<p>并不总是需要规范化数字数据。然而，已经表明，当数值被归一化时，神经网络的形成通常更有效，并且导致更好的预测。事实上，如果数值数据没有被归一化，并且两个预测值的大小相差很远，则神经网络权重值的变化对更高的值具有更大的相对影响。</p>

<p>有几种标准化技术；在<a href="9318274a-72ac-4475-a140-7aaf92253400.xhtml" target="_blank">第二章</a>、<em>神经网络</em>的学习过程中，我们采用了min-max标准化。在这种情况下，我们将采用<em>Z</em>-分数归一化。该技术包括将列中的每个值减去列的平均值，然后将结果除以列的标准偏差。实现这一点的公式如下:</p>

<p style="padding-left: 210px"><img height="44" src="img/168996a2-44bf-4d44-9670-c053db61d302.jpg" width="121"/></p>

<p>总之，<em> Z </em>得分(也称为标准得分)代表观察点或数据的值大于观察或测量的平均值的标准偏差的数量。高于平均值的值具有正的<em> Z </em>分数，而低于平均值的值具有负的<em> Z </em>分数。<em>Z</em>-得分是一个无量纲的量，通过从单个粗略得分中减去总体平均值，然后将差值除以总体的标准差来获得。</p>

<p>在应用为规范化选择的方法之前，必须计算每个数据库列的平均值和标准偏差值。为此，我们使用了<kbd>apply</kbd>函数。此函数返回一个向量、一个数组或一组通过对数组或矩阵的边距应用函数而获得的值。让我们理解一下所用论据的含义。</p>

<p>第一行允许我们计算每个变量的平均值，第二行允许我们计算每个变量的标准差。让我们看看如何使用函数<kbd>apply()</kbd>。<kbd>apply</kbd>函数的第一个参数指定了要将函数应用到的数据集，在我们的例子中，数据集名为data。特别是，我们只考虑了前六个数值变量；其他的我们会用于其他目的。第二个参数必须包含一个向量，该向量给出函数将应用到的下标。在我们的例子中，一个表示行，两个表示列。第三个参数必须包含要应用的函数；在我们的例子中，第一行的<kbd>mean()</kbd>函数和第二行的<kbd>sd()</kbd>函数。结果如下所示:</p>

<pre><strong>mean_data &lt;- apply(data[1:6], 2, mean)</strong><br/><strong>sd_data &lt;- apply(data[1:6], 2, sd)</strong></pre>

<p>为了规范化数据，我们使用了<kbd>scale()</kbd>函数，这是一个通用函数，它的默认方法是居中和/或缩放数字矩阵的列:</p>

<pre><strong>&gt; mean_data</strong><br/><strong>         mpg    cylinders displacement   horsepower       weight </strong><br/><strong>   23.445918     5.471939   194.411990   104.469388  2977.584184   </strong><br/><strong>acceleration</strong><br/><strong>   15.541327</strong>
<strong>&gt; sd_data</strong><br/><strong>         mpg    cylinders displacement    horsepower       weight </strong><br/><strong>    7.805007     1.705783    04.644004     38.491160   849.402560 </strong><br/><strong>acceleration</strong><br/><strong>    2.758864</strong></pre>

<p>让我们来看看通过规范化转换的数据:</p>

<pre><strong>data_scaled &lt;- as.data.frame(scale(data[,1:6],center = mean_data, scale = sd_data))</strong></pre>

<p>结果如下:</p>

<pre><strong>head(data_scaled, n=20)</strong></pre>

<p>现在，让我们拆分培训和测试的数据:</p>

<pre><strong>&gt; head(data_scaled, n=20)</strong><br/><strong>           mpg  cylinders displacement horsepower     weight acceleration</strong><br/><strong>1  -0.69774672  1.4820530   1.07591459  0.6632851  0.6197483  -1.28361760</strong><br/><strong>2  -1.08211534  1.4820530   1.48683159  1.5725848  0.8422577  -1.46485160</strong><br/><strong>3  -0.69774672  1.4820530   1.18103289  1.1828849  0.5396921  -1.64608561</strong><br/><strong>4  -0.95399247  1.4820530   1.04724596  1.1828849  0.5361602  -1.28361760</strong><br/><strong>5  -0.82586959  1.4820530   1.02813354  0.9230850  0.5549969  -1.82731962</strong><br/><strong>6  -1.08211534  1.4820530   2.24177212  2.4299245  1.6051468  -2.00855363</strong><br/><strong>7  -1.21023822  1.4820530   2.48067735  3.0014843  1.6204517  -2.37102164</strong><br/><strong>8  -1.21023822  1.4820530   2.34689042  2.8715843  1.5710052  -2.55225565</strong><br/><strong>9  -1.21023822  1.4820530   2.49023356  3.1313843  1.7040399  -2.00855363</strong><br/><strong>10 -1.08211534  1.4820530   1.86907996  2.2220846  1.0270935  -2.55225565</strong><br/><strong>11 -1.08211534  1.4820530   1.80218649  1.7024847  0.6892089  -2.00855363</strong><br/><strong>12 -1.21023822  1.4820530   1.39126949  1.4426848  0.7433646  -2.73348966</strong><br/><strong>13 -1.08211534  1.4820530   1.96464205  1.1828849  0.9223139  -2.18978763</strong><br/><strong>14 -1.21023822  1.4820530   2.49023356  3.1313843  0.1276377  -2.00855363</strong><br/><strong>15  0.07099053 -0.8629108  -0.77799001 -0.2460146 -0.7129531  -0.19621355</strong><br/><strong>16 -0.18525522  0.3095711   0.03428778 -0.2460146 -0.1702187  -0.01497955</strong><br/><strong>17 -0.69774672  0.3095711   0.04384399 -0.1940546 -0.2396793  -0.01497955</strong><br/><strong>18 -0.31337809  0.3095711   0.05340019 -0.5058145 -0.4598340   0.16625446</strong><br/><strong>19  0.45535916 -0.8629108  -0.93088936 -0.4278746 -0.9978592  -0.37744756</strong><br/><strong>20  0.32723628 -0.8629108  -0.93088936 -1.5190342 -1.3451622   1.79736053</strong></pre>

<p>在刚刚建议的代码的第一行中，数据集被分成70:30，目的是使用70%的数据来训练网络，剩余的30%用于测试网络。在第二行和第三行，名为data的数据帧的数据被细分成两个新的数据帧，称为<kbd>train_data</kbd>和<kbd>test_data</kbd>。现在我们必须构建提交给网络的函数:</p>

<pre><strong>index = sample(1:nrow(data),round(0.70*nrow(data)))</strong><br/><strong>train_data &lt;- as.data.frame(data_scaled[index,])</strong><br/><strong>test_data &lt;- as.data.frame(data_scaled[-index,])</strong></pre>

<p>在第一行中，我们使用<kbd>names()</kbd>函数恢复了<kbd>data_scaled</kbd>数据帧中的所有变量名。在第二行中，我们构建将用于训练网络的公式。这个公式代表什么？</p>

<pre><strong>n = names(data_scaled)</strong><br/><strong>f = as.formula(paste("mpg ~", paste(n[!n %in% "mpg"], collapse = " + ")))</strong></pre>

<p>由<kbd>neuralnet()</kbd>功能拟合的模型以紧凑的符号形式指定。~运算符是形成这种模型的基础。形式为<em> y </em> ~ model的表达式被解释为响应<em> y </em>由模型象征性指定的预测器建模的规范。这种模型由一系列用+运算符分隔的术语组成。术语本身由变量和因子名称组成，用:运算符分隔。该术语被解释为术语中出现的所有变量和因素的相互作用。让我们来看看我们设定的公式:</p>

<p>现在我们可以建立和训练网络。</p>

<pre><strong>&gt; f</strong><br/><strong>mpg ~ cylinders + displacement + horsepower + weight + acceleration</strong></pre>

<p>在<a href="b5f75068-f1e3-465e-969d-a8f1ad48378d.xhtml" target="_blank">第三章</a>、<em>使用多层神经网络进行深度学习</em>中，我们说过要选择最佳的神经元数量，我们需要知道:</p>

<p>少量的神经元会导致系统的高误差，因为对于少量的神经元来说，预测因素可能太复杂而难以捕捉</p>

<ul>

<li>大量的神经元会使你的训练数据过拟合，不能很好地概括</li>

<li>每个隐藏层中的神经元数量应该介于输入层和输出层的大小之间，可能是平均值</li>

<li>每个隐藏层中的神经元数量不应该超过输入神经元数量的两倍，因为在这一点上你可能会严重超载</li>

<li>在这种情况下，我们有五个输入变量(<kbd>cylinders</kbd>、<kbd>displacement</kbd>、<kbd>horsepower</kbd>、<kbd>weight</kbd>和<kbd>acceleration</kbd>)和一个变量输出(<kbd>mpg</kbd>)。我们选择在隐藏层设置三个神经元。</li>

</ul>

<p>hidden参数接受一个带有每个隐藏层神经元数量的向量，而参数<kbd>linear.output</kbd>用于指定我们是要进行回归(<kbd>linear.output=TRUE</kbd>)还是分类(<kbd>linear.output=FALSE</kbd>)。</p>

<pre><strong>net = neuralnet(f,data=train_data,hidden=3,linear.output=TRUE)</strong></pre>

<p>默认情况下，<kbd>neuralnet()</kbd>中使用的算法基于无权重回溯的弹性反向传播，并额外修改一个学习率，或者是与最小绝对梯度(<kbd>sag</kbd>)相关的学习率，或者是最小学习率(<kbd>slr</kbd>)本身。<kbd>neuralnet()</kbd>函数返回一个类为<kbd>nn</kbd>的对象。类别<kbd>nn</kbd>的对象是最多包含下表所示组件的列表:</p>

<p><strong>组件</strong></p>

<table>

<tbody>

<tr>

<td>

<p><strong>描述</strong></p>

</td>

<td>

<p><kbd>call</kbd></p>

</td>

</tr>

<tr>

<td>

<p>匹配的呼叫。</p>

</td>

<td>

<p><kbd>response</kbd></p>

</td>

</tr>

<tr>

<td>

<p>摘自<kbd>data</kbd>论据。</p>

</td>

<td>

<p><kbd>covariate</kbd></p>

</td>

</tr>

<tr>

<td>

<p>从数据参数中提取的变量。</p>

</td>

<td>

<p><kbd>model.list</kbd></p>

</td>

</tr>

<tr>

<td>

<p>包含协变量和从<kbd>formula</kbd>参数中提取的<kbd>response</kbd>变量的列表。</p>

</td>

<td>

<p><kbd>err.fct</kbd></p>

</td>

</tr>

<tr>

<td>

<p>误差函数。</p>

</td>

<td>

<p><kbd>act.fct</kbd></p>

</td>

</tr>

<tr>

<td>

<p>激活功能。</p>

</td>

<td>

<p><kbd>data</kbd></p>

</td>

</tr>

<tr>

<td>

<p>数据参数。</p>

</td>

<td>

<p><kbd>net.result</kbd></p>

</td>

</tr>

<tr>

<td>

<p>包含神经网络每次重复的总体结果的列表。</p>

</td>

<td>

<p><kbd>weights</kbd></p>

</td>

</tr>

<tr>

<td>

<p>包含每次重复的神经网络拟合权重的列表。</p>

</td>

<td>

<p><kbd>generalized.weights</kbd></p>

</td>

</tr>

<tr>

<td>

<p>包含每次重复的神经网络广义权重的列表。</p>

</td>

<td>

<p><kbd>result.matrix</kbd></p>

</td>

</tr>

<tr>

<td>

<p>包含达到的阈值、需要的步数、误差、AIC和BIC(如果计算的话)以及每次重复的权重的矩阵。每一列代表一次重复。</p>

</td>

<td>

<p><kbd>startweights</kbd></p>

</td>

</tr>

<tr>

<td>

<p>包含每次重复的神经网络的起始权重的列表。</p>

</td>

<td>

<p>A list containing the startweights of the neural network for every repetition.</p>

</td>

</tr>

</tbody>

</table>

<p>为了生成模型结果的结果摘要，我们使用了<kbd>summary()</kbd>函数:</p>

<p>对于神经网络模型的每个组件，显示了三个特征:</p>

<pre><strong>&gt; summary(net)</strong><br/><strong>                    Length Class      Mode   </strong><br/><strong>call                   5   -none-     call  </strong><br/><strong>response             274   -none-     numeric</strong><br/><strong>covariate           1370   -none-     numeric</strong><br/><strong>model.list             2   -none-     list   </strong><br/><strong>err.fct                1   -none-     function</strong><br/><strong>act.fct                1   -none-     function</strong><br/><strong>linear.output          1   -none-     logical</strong><br/><strong>data                   6   data.frame list   </strong><br/><strong>net.result             1   -none-     list   </strong><br/><strong>weights                1   -none-     list   </strong><br/><strong>startweights           1   -none-     list   </strong><br/><strong>generalized.weights    1   -none-     list   </strong><br/><strong>result.matrix         25   -none-     numeric</strong> </pre>

<p><strong> Length </strong>:这是组件长度，也就是包含了多少个该类型的元素</p>

<ul>

<li><strong>类别</strong>:包含组件类别的具体指示</li>

<li><strong>模式</strong>:这是组件的类型(数字、列表、函数、逻辑等)</li>

<li>为了用每个连接上的权重绘制模型的图形表示，我们可以使用<kbd>plot()</kbd>函数。<kbd>plot()</kbd>函数是一个通用函数，用于表示r中的对象。通用函数意味着它适用于不同类型的对象，从变量到表格到复杂的函数输出，产生不同的结果。应用于一个名义变量，它会产生一个条形图。应用于基数变量，它将产生一个散点图。应用于同一个变量，但制成表格，即其频率分布，它会产生一个直方图。最后，应用于两个变量，一个名义变量和一个基数变量，它将产生一个箱线图。</li>

</ul>

<p>神经网络图如下图所示:</p>

<pre><strong>plot(net)</strong></pre>

<p>在前面的图中，黑线(这些线从输入节点开始)显示了每个层之间的连接以及每个连接上的权重，而蓝线(这些线从由数字1区分的偏差节点开始)显示了每个步骤中添加的偏差项。偏差可以被认为是线性模型的截距。</p>

<div><img class="image-border" src="img/c1539544-8a0a-477c-a684-cdd006cd1105.png"/></div>

<p>虽然随着时间的推移，我们已经了解了许多作为神经网络基础的机制，但在许多方面，我们建立和训练的模型仍然是一个黑盒。配件、重量和型号不够清楚。我们可以确信训练算法是收敛的，然后模型就可以使用了。</p>

<p>我们可以在视频上打印重量和偏差:</p>

<p>可以看出，这些值与我们在网络图中看到的值相同。例如，<kbd>cylinders.to.1layhid1 = 0.291091600669</kbd>是输入圆柱体和隐藏层第一个节点之间连接的权重。</p>

<pre><strong>&gt; net$result.matrix</strong><br/><strong>                                         1</strong><br/><strong>error                      21.800203210980</strong><br/><strong>reached.threshold           0.009985137179</strong><br/><strong>steps                    9378.000000000000</strong><br/><strong>Intercept.to.1layhid1      -1.324633695625</strong><br/><strong>cylinders.to.1layhid1       0.291091600669</strong><br/><strong>displacement.to.1layhid1   -2.243406161080</strong><br/><strong>horsepower.to.1layhid1      0.616083122568</strong><br/><strong>weight.to.1layhid1          1.292334492287</strong><br/><strong>acceleration.to.1layhid1   -0.286145921068</strong><br/><strong>Intercept.to.1layhid2     -41.734205163355</strong><br/><strong>cylinders.to.1layhid2      -5.574494023650</strong><br/><strong>displacement.to.1layhid2   33.629686446649</strong><br/><strong>horsepower.to.1layhid2    -28.185856598271</strong><br/><strong>weight.to.1layhid2        -50.822997942647</strong><br/><strong>acceleration.to.1layhid2   -5.865256284330</strong><br/><strong>Intercept.to.1layhid3       0.297173606203</strong><br/><strong>cylinders.to.1layhid3       0.306910802417</strong><br/><strong>displacement.to.1layhid3   -5.897977831914</strong><br/><strong>horsepower.to.1layhid3      0.379215333054</strong><br/><strong>weight.to.1layhid3          2.651777936654</strong><br/><strong>acceleration.to.1layhid3   -1.035618563747</strong><br/><strong>Intercept.to.mpg           -0.578197055155</strong><br/><strong>1layhid.1.to.mpg           -3.190914666614</strong><br/><strong>1layhid.2.to.mpg            0.714673177354</strong><br/><strong>1layhid.3.to.mpg            1.958297807266</strong></pre>

<p>现在我们可以利用网络进行预测。为此，我们在<kbd>test_data</kbd>数据帧中留出了30%的数据。是时候使用它了。</p>

<p>在我们的例子中，我们将函数应用于<kbd>test_data</kbd>数据集，仅使用从<kbd>2</kbd>到<kbd>6</kbd>的列，代表网络的输入变量。为了评估网络性能，我们可以使用<strong>均方误差</strong> ( <strong> MSE </strong>)来衡量我们的预测与真实数据的差距。</p>

<pre><strong>predict_net_test &lt;- compute(net,test_data[,2:6])</strong></pre>

<p>这里<kbd>test_data$mpg</kbd>是实际数据，而<kbd>predict_net_test$net.result</kbd>是分析目标的预测数据。以下是结果:</p>

<pre><strong>MSE.net &lt;- sum((test_data$mpg - predict_net_test$net.result)^2)/nrow(test_data)</strong></pre>

<p>看起来是个不错的结果，但是我们拿什么来比呢？为了了解网络预测的准确性，我们可以建立一个线性回归模型:</p>

<pre><strong>&gt; MSE.net</strong><br/><strong>[1] 0.2591064572</strong></pre>

<p>我们使用<kbd>lm</kbd>函数建立一个线性回归模型。该函数用于拟合线性模型。它可用于执行回归、单层方差分析和协方差分析。为了对获得的模型拟合结果进行汇总，我们使用了<kbd>summary()</kbd>函数，该函数返回以下结果:</p>

<pre><strong>Lm_Mod &lt;- lm(mpg~., data=train_data)</strong><br/><strong>summary(Lm_Mod)</strong></pre>

<p>现在，我们使用包含在<kbd>test_data</kbd>数据框架中的数据，通过线性回归模型进行预测:</p>

<pre><strong>&gt; summary(Lm_Mod)</strong><br/><strong>Call:</strong><br/><strong>lm(formula = mpg ~ ., data = train_data)</strong><br/><strong>Residuals:</strong><br/><strong>        Min          1Q      Median          3Q         Max</strong><br/><strong>-1.48013031 -0.34128989 -0.04310873  0.27697893  1.77674878</strong><br/><strong>Coefficients:</strong><br/><strong>                Estimate  Std. Error  t value        Pr(&gt;|t|)   </strong><br/><strong>(Intercept)   0.01457260  0.03268643  0.44583        0.656080  </strong><br/><strong>cylinders    -0.14056198  0.10067461 -1.39620        0.163809  </strong><br/><strong>displacement  0.06316568  0.13405986  0.47118        0.637899   </strong><br/><strong>horsepower   -0.16993594  0.09180870 -1.85098        0.065273 . </strong><br/><strong>weight       -0.59531412  0.09982123 -5.96380 0.0000000077563 ***</strong><br/><strong>acceleration  0.03096675  0.05166132  0.59942        0.549400   </strong><br/><strong>---</strong><br/><strong>Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</strong><br/><strong>Residual standard error: 0.5392526 on 268 degrees of freedom</strong><br/><strong>Multiple R-squared:  0.7183376, Adjusted R-squared:  0.7130827</strong><br/><strong>F-statistic: 136.6987 on 5 and 268 DF,  p-value: &lt; 0.00000000000000022204</strong></pre>

<p>最后，我们计算回归模型的MSE:</p>

<pre><strong>predict_lm &lt;- predict(Lm_Mod,test_data)</strong></pre>

<p>以下是结果:</p>

<pre><strong>MSE.lm &lt;- sum((predict_lm - test_data$mpg)^2)/nrow(test_data)</strong></pre>

<p>从两个模型(神经网络模型对线性回归模型)之间的比较来看，神经网络再次获胜(0.26对0.31)。</p>

<pre><strong>&gt; MSE.lm</strong><br/><strong>[1] 0.3124200509</strong></pre>

<p>我们现在通过在图表上绘制实际值与预测值的对比来进行视觉比较，首先是神经网络，然后是线性回归模型:</p>

<p>神经网络模型(左侧)和线性回归模型(右侧)在测试集上的性能比较如下图所示:</p>

<pre><strong>par(mfrow=c(1,2))</strong><br/><br/><strong>plot(test_data$mpg,predict_net_test$net.result,col='black',main='Real vs predicted for neural network',pch=18,cex=4)</strong><br/><strong>abline(0,1,lwd=5)</strong><br/><br/><strong>plot(test_data$mpg,predict_lm,col='black',main='Real vs predicted for linear regression',pch=18,cex=4)</strong><br/><strong>abline(0,1,lwd=5)</strong></pre>

<p>正如我们可以看到的，神经网络的预测比线性回归模型的预测更集中在线周围，即使您没有注意到很大的差异。</p>

<div><img class="image-border" src="img/f4ad374a-ea11-4a8d-8a97-1455e42991aa.png"/></div>

<p>用神经网络对乳腺癌进行分类</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Classifing breast cancer with a neural network</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:4a8cbe4a-e61d-4c74-886d-1da985c44432" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">乳房由一组腺体和脂肪组织组成，位于皮肤和胸壁之间。事实上，它不是一个单一的腺体，而是一组腺体结构，称为小叶，连接在一起形成一个叶。一个乳房有15到20个叶。乳汁通过称为乳管的小管从小叶到达乳头。<br/>乳腺癌如果长期得不到发现和治疗，是一种潜在的严重疾病。它是由乳腺中一些转化为恶性细胞的细胞不受控制的增殖引起的。这意味着它们有能力从产生它们的组织中脱离出来，侵入周围的组织，并最终侵入身体的其他器官。理论上，所有类型的乳腺组织都可以形成癌症，但最常见的是腺细胞或形成导管壁的细胞。</h1>

                

            

            

                

<p>此示例的目的是识别多个良性或恶性类别中的每一个。为此，我们将使用包含在<kbd>mlbench</kbd>包中的名为<kbd>BreastCancer</kbd>(威斯康星乳腺癌数据库)的数据集中的数据。这些数据是从UCI机器学习数据库中获取的，DNA样本定期到达，沃尔伯格博士报告了他的临床病例。因此，数据库反映了数据的时间分组。这种分组信息立即出现，已经从数据本身中删除。除了第一个变量之外，每个变量都被转换成11个原始的数值属性，值的范围从0到10。缺少16个值。</p>

<p>数据帧包含11个变量的699个观察值——1个是字符变量，9个是有序或名义变量，1个是目标类:</p>

<p><kbd>Id</kbd>:样本代码编号</p>

<ul>

<li><kbd>Cl.thickness</kbd>:团块厚度</li>

<li><kbd>Cell.size</kbd>:细胞大小均匀</li>

<li><kbd>Cell.shape</kbd>:细胞形状的均匀性</li>

<li><kbd>Marg.adhesion</kbd>:边缘粘连</li>

<li><kbd>Epith.c.size</kbd>:单个上皮细胞大小</li>

<li><kbd>Bare.nuclei</kbd>:裸核</li>

<li><kbd>Bl.cromatin</kbd>:平淡的染色质</li>

<li><kbd>Normal.nucleoli</kbd>:正常核仁</li>

<li><kbd>Mitoses</kbd>:有丝分裂</li>

<li><kbd>Class</kbd>:类别</li>

<li>如前所述，本示例的目的是识别多个良性或恶性类别中的每一个。下面是我们将在本例中使用的代码:</li>

</ul>

<p>我们开始逐行分析代码，详细解释用于捕获结果的所有特性。</p>

<pre class="mce-root"><strong>###########################################################################</strong><br/><strong>########Chapter 5 - Introduction to Neural Networks - using R##############         </strong><br/><strong>####################Classifing breast cancer with R######################## </strong><br/><strong>###########################################################################<br/></strong><br/><strong>library("mlbench")</strong><br/><strong>library(neuralnet)</strong><br/><br/><strong>data(BreastCancer)</strong><br/><strong>summary(BreastCancer)</strong><br/><br/><strong>mvindex = unique (unlist (lapply (BreastCancer, function (x) which (is.na (x)))))</strong><br/><strong>data_cleaned &lt;- na.omit(BreastCancer) </strong><br/><strong>summary(data_cleaned)</strong><br/><br/><strong>boxplot(data_cleaned[,2:10])</strong><br/><strong>hist(as.numeric(data_cleaned$Mitoses))</strong><br/><br/><strong>par(mfrow=c(3, 3))</strong><br/><strong>hist(as.numeric(data_cleaned$Cl.thickness))</strong><br/><strong>hist(as.numeric(data_cleaned$Cell.size))</strong><br/><strong>hist(as.numeric(data_cleaned$Cell.shape))</strong><br/><strong>hist(as.numeric(data_cleaned$Marg.adhesion))</strong><br/><strong>hist(as.numeric(data_cleaned$Epith.c.size))</strong><br/><strong>hist(as.numeric(data_cleaned$Bare.nuclei))</strong><br/><strong>hist(as.numeric(data_cleaned$Bl.cromatin))</strong><br/><strong>hist(as.numeric(data_cleaned$Normal.nucleoli))</strong><br/><strong>hist(as.numeric(data_cleaned$Mitoses))</strong><br/><br/><strong>str(data_cleaned)</strong><br/><strong>input&lt;-data_cleaned[,2:10]</strong><br/><strong>indx &lt;- sapply(input, is.factor)</strong><br/><strong>input &lt;- as.data.frame(lapply(input, function(x) as.numeric(as.character(x))))</strong><br/><br/><strong>max_data &lt;- apply(input, 2, max)</strong><br/><strong>min_data &lt;- apply(input, 2, min)</strong><br/><strong>input_scaled &lt;- as.data.frame(scale(input,center = min_data, scale = max_data - min_data))</strong><br/><strong>View(input_scaled)</strong><br/><br/><strong>Cancer&lt;-data_cleaned$Class</strong><br/><strong>Cancer&lt;-as.data.frame(Cancer)</strong><br/><strong>Cancer&lt;-with(Cancer, data.frame(model.matrix(~Cancer+0)))</strong><br/><br/><strong>final_data&lt;-as.data.frame(cbind(input_scaled,Cancer))</strong><br/><br/><strong>index = sample(1:nrow(final_data),round(0.70*nrow(final_data)))</strong><br/><strong>train_data &lt;- as.data.frame(final_data[index,])</strong><br/><strong>test_data &lt;- as.data.frame(final_data[-index,])</strong><br/><br/><strong>n = names(final_data[1:9])</strong><br/><strong>f = as.formula(paste("Cancerbenign + Cancermalignant ~", paste(n, collapse = " + ")))</strong><br/><br/><strong>net = neuralnet(f,data=train_data,hidden=5,linear.output=FALSE)</strong><br/><strong>plot(net)</strong><br/><br/><strong>predict_net_test &lt;- compute(net,test_data[,1:9])</strong><br/><strong>predict_result&lt;-round(predict_net_test$net.result, digits = 0)</strong><br/><strong>net.prediction = c("benign", "malignant")[apply(predict_result, 1, which.max)]</strong><br/><strong>predict.table = table(data_cleaned$Class[-index], net.prediction)</strong><br/><strong>predict.table</strong><br/><br/><strong>library(gmodels)</strong><br/><strong>CrossTable(x = data_cleaned$Class[-index], y = net.prediction,</strong><br/><strong> prop.chisq=FALSE)</strong><br/><strong>###########################################################################</strong></pre>

<p>初始代码的前两行用于加载运行分析所需的库。</p>

<pre class="mce-root"><strong>library("mlbench")</strong><br/><strong>library("neuralnet")</strong></pre>

<p class="mce-root">记住，要安装R的初始发行版中没有的库，必须使用<kbd>install.package</kbd>函数。这是安装包的主要功能。它接受一个名称向量和一个目的库，从存储库中下载包并安装它们。这个函数应该只使用一次，而不是每次运行代码时都使用。</p>

<p><kbd>mlbench</kbd>库包含一系列人工和真实世界的机器学习基准问题，例如，包括来自UCI知识库的几个数据集。</p>

<p><kbd>neuralnet</kbd>库用于使用反向传播、带或不带权重回溯的RPROP或修改的GRPROP来训练神经网络。该功能允许通过自定义选择错误和激活功能进行灵活设置。此外，还实现了广义权重的计算。下表显示了摘自官方文档的对nnet包的简要描述:</p>

<p><kbd>neuralnet</kbd>:神经网络的训练</p>

<table>

<tbody>

<tr>

<td><strong>描述</strong>:</td>

</tr>

<tr>

<td>使用反向传播、有(Riedmiller，1994)或没有权重回溯(Riedmiller和Braun，1993)的弹性反向传播或阿纳斯塔夏迪斯等人(2005)的修改的全局收敛版本来训练神经网络。该软件包允许通过自定义选择错误和激活功能进行灵活设置。</td>

</tr>

<tr>

<td><strong>详情</strong>:</td>

</tr>

<tr>

<td>包:<kbd>neuralnet</kbd>T11类型:包<br/>版本:1.33 <br/>日期:2016-08-05 <br/>许可证:GPL-2</td>

</tr>

<tr>

<td><strong>作者</strong>:</td>

</tr>

<tr>

<td>斯蒂芬·弗里奇<br/>弗劳克·根特<br/>马克·苏林<br/>塞巴斯蒂安·穆勒</td>

</tr>

<tr>

<td>

<p class="mce-root">Stefan Fritsch<br/>

Frauke Guenther<br/>

Marc Suling<br/>

Sebastian M. Mueller</p>

</td>

</tr>

</tbody>

</table>

<p>回到代码，此时我们必须加载要分析的数据:</p>

<p>使用这个命令，我们上传名为<kbd>BreastCancer</kbd>的数据集，如前所述，在<kbd>mlbench</kbd>库中。</p>

<pre><strong>data(BreastCancer)</strong></pre>

<p>探索性分析</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Exploratory analysis</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:4a8cbe4a-e61d-4c74-886d-1da985c44432" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">在通过构建和训练神经网络开始数据分析之前，我们进行探索性分析，以了解数据是如何分布的，并提取初步知识。</h1>

                

            

            

                

<p>使用该命令，我们将看到使用<kbd>summary()</kbd>功能的简要总结。</p>

<pre><strong>summary(BreastCancer)</strong></pre>

<p>请记住，<kbd>summary()</kbd>函数是一个通用函数，用于生成各种模型拟合函数的结果汇总。该函数调用依赖于第一个参数的类的特定方法。</p>

<p>在这种情况下，该函数被应用于dataframe，结果如下面的屏幕截图所示:</p>

<p><kbd>summary()</kbd>函数返回每个变量的一组统计数据。特别是，突出显示为包含癌块诊断的<kbd>class</kbd>变量提供的结果是有用的。在这种情况下，检测出458例良性<kbd>class</kbd>和241例<kbd>malignant</kbd>级。另一个需要强调的特性是Bare.nuclei变量。对于该变量，检测到16例缺失值。</p>

<div><img class="image-border" src="img/84badf45-3949-4334-a257-5ffaa567a19c.png"/></div>

<p>缺失值是其值未知的值。缺失值在R中用<kbd>NA</kbd>符号表示。<kbd>NA</kbd>是一个特殊值，其性质不同于其他值。<kbd>NA</kbd>是R中为数不多的保留字；你不能给任何东西起这个名字。例如，当您在Excel电子表格中读取空单元格时，可能会出现<kbd>NA</kbd>。当你尝试某些不合法或没有意义的操作时，你也会看到<kbd>NA</kbd>。缺失值不一定是由错误引起的；往往在现实生活中，缺乏检测。</p>

<p>一个问题油然而生:我们是否要担心价值缺失的存在？不幸的是，是的，这是因为几乎每个在<kbd>NA</kbd>上执行的操作都会产生一个<kbd>NA</kbd>。那么数据集中缺失值的存在会导致我们稍后进行的计算出错。这就是为什么我们被迫删除丢失的值。</p>

<p>要删除丢失的值，我们必须首先识别它们。<kbd>is.na()</kbd>函数为我们找到缺失的值；该函数返回一个与其参数长度相同的逻辑向量，其中<em> T </em>表示缺失值，而<em> F </em>表示非缺失值。想要知道缺失值的索引是很常见的，而<kbd>which()</kbd>函数可以帮助我们做到这一点。要查找至少有一个<kbd>NA</kbd>的数据帧中的所有行，请尝试:</p>

<p><kbd>lapply()</kbd>函数将函数应用于每一列并返回一个列表，其第<em> i </em>个元素是一个向量，包含第<em> i </em>列中缺少值的元素的索引。函数<kbd>unlist()</kbd>将列表转换成一个向量，<kbd>unique()</kbd>去掉重复的列表。</p>

<pre><strong>mvindex = unique (unlist (lapply (BreastCancer, function (x) which (is.na (x)))))</strong></pre>

<p>现在我们有了缺失值(<kbd>NA</kbd>)出现的行数，如下所示:</p>

<p>现在我们知道数据库中有丢失的值，并且知道它们在哪里。我们只需从原始数据集中移除这些线。为此，我们可以使用以下函数:</p>

<pre><strong>&gt; mvindex</strong><br/><strong> [1] 24 41 140 146 159 165 236 250 276 293 295 298 316 322 412 618</strong></pre>

<p><kbd>na.omit</kbd>:删除任何缺少值的行，并且永远忘记它们</p>

<ul>

<li><kbd>na.exclude</kbd>:删除缺少值的行，但是跟踪它们的位置，这样当您进行预测时，例如，您会得到一个长度为原始响应长度的向量</li>

<li>我们将使用第一种选择，从而永远消灭它们:</li>

</ul>

<p>要确认删除出现缺失值的行，再次应用<kbd>summary()</kbd>功能:</p>

<pre><strong>data_cleaned &lt;- na.omit(BreastCancer)</strong> </pre>

<p>结果如以下截图所示:</p>

<pre><strong>summary(data_cleaned)</strong></pre>

<p>正如您现在看到的，不再有丢失的值了。</p>

<div><img class="image-border" height="173" src="img/2590f334-caf7-4085-b75c-e365ec588bdf.png" width="461"/></div>

<p>现在，让我们进入探索性分析。我们能做的第一件事是绘制变量的箱线图。通过查看<kbd>summary()</kbd>函数的结果，已经有了第一个想法。自然地，我们将只限于数值变量。</p>

<p>在下图中，显示了包含在已清理数据集(<kbd>data_cleaned</kbd>)中的数值变量(从2到10)的箱线图:</p>

<pre><strong>boxplot(data_cleaned[,2:10])</strong></pre>

<p>从上图的分析中，我们可以注意到几个变量有异常值，其中变量<kbd>Mitoses</kbd>的数值最大。</p>

<div><img class="image-border" height="278" src="img/41516887-e68a-40f4-a484-1439d567a7d9.png" width="436"/></div>

<p>异常值在数值上不同于收集的其他数据。从包含异常值的样本中得出的统计数据可能会产生误导。</p>

<p>为了更好地识别异常值的存在，我们可以绘制数据库中变量的直方图。直方图是数字数据分布的精确图形表示。它是对连续变量的概率分布的估计。要构建直方图，第一步是指定值的范围(即，将整个值范围分成一系列区间)，然后计算每个区间内有多少个值。箱通常被指定为变量的连续的、不重叠的区间。箱子必须是相邻的，并且通常大小相等。使用直方图，我们可以看到数据分布的中间位置，数据离中间位置有多近，以及可能的异常值在哪里。</p>

<p>在R环境中，我们可以通过使用<kbd>hist()</kbd>函数简单地制作一个直方图，该函数计算给定数据值的直方图。我们必须将数据集的名称放在这个函数的括号之间。为了在同一个窗口中绘制多个图形，我们将使用<kbd>par()</kbd>函数，该函数已经在前面的示例中使用过:</p>

<p>由于函数<kbd>hist()</kbd>需要一个向量作为参数，我们使用<kbd>as.numeric(</kbd>函数将包含在数据集列中的值转换成数字向量。该函数创建或强制<kbd>numeric</kbd>类型的对象。下图显示了包含在已清理数据集(<kbd>data_cleaned</kbd>)中的数值变量(从2到10)的直方图:</p>

<pre><strong>par(mfrow=c(3, 3))</strong><br/><strong>hist(as.numeric(data_cleaned$Cl.thickness))</strong><br/><strong>hist(as.numeric(data_cleaned$Cell.size))</strong><br/><strong>hist(as.numeric(data_cleaned$Cell.shape))</strong><br/><strong>hist(as.numeric(data_cleaned$Marg.adhesion))</strong><br/><strong>hist(as.numeric(data_cleaned$Epith.c.size))</strong><br/><strong>hist(as.numeric(data_cleaned$Bare.nuclei))</strong><br/><strong>hist(as.numeric(data_cleaned$Bl.cromatin))</strong><br/><strong>hist(as.numeric(data_cleaned$Normal.nucleoli))</strong><br/><strong>hist(as.numeric(data_cleaned$Mitoses))</strong></pre>

<p>从直方图的分析中，可以注意到一些变量有异常值。</p>

<div><img class="image-border" src="img/f11a74d0-9d36-4dfd-b72a-9e125cca2ab8.png"/></div>

<p>神经网络模型</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Neural network model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:4a8cbe4a-e61d-4c74-886d-1da985c44432" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">正如我们在前面的示例中所做的那样，在构建和训练网络之前，我们必须运行数据标准化。在这种情况下，我们将采用最小-最大标准化。</h1>

                

            

            

                

<p>请记住，在训练神经网络之前对数据进行规范化是一种很好的做法。通过规范化，消除了数据单元，使您可以轻松地比较不同位置的数据。</p>

<p>开始之前，使用<kbd>str()</kbd>功能做进一步检查。该功能提供对象内部结构的紧凑显示、诊断功能以及<kbd>summary()</kbd>功能的替代功能。理想情况下，每个基本结构只显示一行。它特别适合紧凑地显示(可能是嵌套的)列表的(缩写的)内容。这个想法是为任何R对象提供合理的输出。</p>

<p>结果如以下截图所示:</p>

<pre><strong>str(data_cleaned)</strong></pre>

<p>可以注意到，变量是作为一个因素出现的。我们需要为我们的计算做一个转换。</p>

<div><img class="image-border" height="187" src="img/d189938d-1f84-455a-937a-84f6e52a0286.png" width="709"/></div>

<p class="mce-root">我们首先识别因子类型的变量，然后将它们转换成数字类型。我们现在可以标准化。</p>

<pre><strong>input&lt;-data_cleaned[,2:10]</strong><br/><strong>indx &lt;- sapply(input, is.factor)</strong><br/><strong>input &lt;- as.data.frame(lapply(input, function(x) as.numeric(as.character(x))))</strong></pre>

<p>对于本例，我们将使用最小-最大方法(通常称为特征缩放)来获取范围<em>【0，1】</em>内的所有缩放数据。实现这一点的公式如下:</p>

<p class="mce-root">在应用为规范化选择的方法之前，必须计算每个数据库列的最小值和最大值。为此，我们使用了<kbd>apply()</kbd>函数。此函数返回一个向量、一个数组或一组通过对数组或矩阵的边距应用函数而获得的值。让我们理解一下所用论据的含义。</p>

<div><img height="73" src="img/5a9c4174-bfdb-4108-b9bb-707d1596383a.jpg" width="193"/></div>

<p>apply函数的第一个参数指定了要将函数应用到的数据集，在我们的例子中，数据集名为<kbd>data</kbd>。第二个参数必须包含一个向量，该向量给出函数将应用到的下标。在我们的例子中，一个表示行，两个表示列。第三个参数必须包含要应用的函数；在我们的例子中，最大值函数。我们接下来要做的是计算每列的最小值:</p>

<pre><strong>max_data &lt;- apply(data_cleaned[,2:10], 2, max)</strong></pre>

<p>最后，为了规范化数据，我们使用了<kbd>scale()</kbd>函数，这是一个通用函数，它的默认方法是居中和/或缩放数字矩阵的列，如下面的代码所示:</p>

<pre><strong>min_data &lt;- apply(data_cleaned[,2:10], 2, min)</strong></pre>

<p>为了确认数据的标准化，让我们看看我们创建的新矩阵的前20行。为此，我们将使用<kbd>View()</kbd>功能:</p>

<pre><strong>data_scaled &lt;- scale(</strong><strong>data_cleaned[,2:10]</strong><strong>,center = min_data, scale = max_data - min_data)</strong></pre>

<p class="NormalPACKT">正如你现在看到的，数据在0和1之间。此时，我们重建数据集，添加我们的目标(即<kbd>class</kbd>变量)，它代表癌症的诊断(<kbd>benign</kbd>或<kbd>malignant</kbd>)。这个话题需要我们注意:正如我们之前看到的，这个变量(<kbd>class</kbd>)是绝对的。特别是在数据帧中是作为一个因素存在的，为了使我们能在网络中恰当地使用它，我们必须对它进行必要的转换。我们的目标是一个二分变量(只有两个值:<kbd>benign</kbd>和<kbd>malignant</kbd>)，所以它可以很容易地转换成两个哑变量。</p>

<div><img class="image-border" src="img/1b581a71-242e-406e-b7c6-6877fb902a34.png"/></div>

<p class="NormalPACKT">虚拟变量是一个取值<kbd>0</kbd>或<kbd>1</kbd>的变量，用来表示可能会改变结果的某种分类效应的存在与否。</p>

<p>我们要做的是创建两个新变量(<kbd>Cancerbenign</kbd>和<kbd>Cancermalignant</kbd>)，从代表我们目标的<kbd>Class</kbd>变量开始。<kbd>Cancerbenign</kbd>变量将在<kbd>Class</kbd>变量中出现的<kbd>benign</kbd>值每次出现时包含值1，在其他情况下包含值0。相反，<kbd>Cancermalignant</kbd>变量将在<kbd>Class</kbd>变量中出现的<kbd>malignant</kbd>值每次出现时包含值1，在其他情况下包含值0。</p>

<p>为了获得两个新的虚拟变量，我们使用了<kbd>model.matrix()</kbd>函数。该函数通过将因子扩展为一组虚拟变量(取决于对比)以及类似地扩展交互来创建模型矩阵。最后，我们将新变量添加到数据集:</p>

<pre><strong>Cancer&lt;-data_cleaned$Class</strong><br/><strong>Cancer&lt;-as.data.frame(Cancer)</strong><br/><strong>Cancer&lt;-with(Cancer, data.frame(model.matrix(~Cancer+0)))</strong></pre>

<p>训练网络的时候到了。</p>

<pre><strong>final_data&lt;-as.data.frame(cbind(input_scaled,Cancer))</strong></pre>

<p class="NormalPACKT">网络培训阶段</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>The network training phase</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:4a8cbe4a-e61d-4c74-886d-1da985c44432" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">人工神经网络由并行操作的简单元件组成。网络元件之间的连接是基本的，因为它们决定网络功能。这些连接通过其权重影响结果，权重在神经网络训练阶段进行调节。下图显示了串行和并行处理之间的比较:</h1>

                

            

            

                

<p class="NormalPACKT">然后，在训练阶段，通过改变连接权重来调节网络，使得特定的输入将导向特定的目的地。例如，可以通过比较输出(我们实际计算的)和目标(我们想要得到的)来调整网络，直到网络输出与目标匹配。为了获得足够可靠的结果，需要许多输入/目标对来形成网络。下图显示了培训阶段的简单流程图:</p>

<div><img class="image-border" height="207" src="img/c4e790ba-e79d-464b-838b-c7d21c504fc7.png" width="354"/></div>

<p class="NormalPACKT">这些权重的调整方式由我们采用的特定算法来定义。在强调了算法在网络训练中的重要性之后，必须将更多的兴趣放在准备提供给网络的数据上。</p>

<div><img class="image-border" height="291" src="img/6b8aea2c-cbf4-4f28-8bc2-99322adc0eb6.png" width="440"/></div>

<p>在网络训练中，必须调整权重和偏差以优化网络性能。它代表了整个过程中最重要的阶段，因为网络越好，概化就能越好地处理未知的新数据。在这个阶段，部分收集的数据是随机获取的(通常是70%的可用案例)。</p>

<p>在神经网络训练之后，我们可以使用该网络，在该阶段，随机抽取一部分收集的数据(通常是可用案例的30 %)传递给网络进行测试。然后，可以保存神经网络对象，并根据需要多次使用任何新数据。下图显示了原始数据集的分割方式:</p>

<p>代码中的数据细分如下所示:</p>

<div><img class="image-border" height="175" src="img/02acde4d-d536-485b-aee4-1bddbfd12f30.png" width="364"/></div>

<p>在刚刚建议的代码的第一行中，数据集被分成70:30，目的是使用70%的数据来训练网络，剩余的30%用于测试网络。在第二行和第三行，名为<kbd>data</kbd>的数据帧的数据被细分为两个新的数据帧，名为<kbd>train_data</kbd>和<kbd>test_data</kbd>。现在我们必须构建提交给网络的函数:</p>

<pre><strong>index = sample(1:nrow(final_data),round(0.70*nrow(final_data)))</strong><br/><strong>train_data &lt;- as.data.frame(final_data[index,])</strong><br/><strong>test_data &lt;- as.data.frame(final_data[-index,])</strong></pre>

<p>在第一行中，我们使用<kbd>names()</kbd>函数恢复了<kbd>data_scaled</kbd>数据帧中前九个变量的名称。在第二行中，我们构建将用于训练网络的公式。这个公式代表什么？</p>

<pre><strong>n = names(final_data[1:9])</strong><br/><strong>f = as.formula(paste("Cancerbenign + Cancermalignant ~", paste(n, collapse = " + ")))</strong></pre>

<p>由<kbd>neuralnet()</kbd>功能拟合的模型以紧凑的符号形式指定。~运算符是形成这种模型的基础。形式为<em> y </em> ~ model的表达式被解释为响应<em> y </em>由model象征性指定的预测器建模的规范。这种模型由一系列用+运算符分隔的术语组成。术语本身由变量和因子名称组成，用:运算符分隔。该术语被解释为术语中出现的所有变量和因素的相互作用。让我们来看看我们设定的公式:</p>

<p>我们现在有了我们需要的一切，我们可以创建和训练网络。我们回忆一下我们在前面的例子中给出的关于正确选择隐藏层中神经元数量的建议。我们有八个输入变量(<kbd>Cl.thickness</kbd>、<kbd>Cell.size</kbd>、<kbd>Cell.shape</kbd>、<kbd>Marg.adhesion</kbd>、<kbd>Epith.c.size</kbd>、<kbd>Bare.nuclei</kbd>、<kbd>Bl.cromatin</kbd>、<kbd>Normal.nucleoli</kbd>和<kbd>Mitoses</kbd>)和一个输出变量(<kbd>Cancer</kbd>)。然后我们选择在隐藏层设置五个神经元:</p>

<pre><strong>&gt; f</strong><br/><strong>Cancerbenign + Cancermalignant ~ Cl.thickness + Cell.size + Cell.shape + </strong><br/><strong>    Marg.adhesion + Epith.c.size + Bare.nuclei + Bl.cromatin + </strong><br/><strong>    Normal.nucleoli + Mitoses</strong></pre>

<p><kbd>hidden</kbd>参数接受一个带有每个隐藏层的神经元数量的向量，而<kbd>linear.output</kbd>参数用于指定我们是想要进行回归(<kbd>linear.output=TRUE</kbd>)还是分类(<kbd>linear.output=FALSE</kbd>(我们的例子)。</p>

<pre><strong>net = neuralnet(f,data=train_data,hidden=5,linear.output=FALSE)</strong></pre>

<p>默认情况下，<kbd>neuralnet()</kbd>中使用的算法基于无权重回溯的弹性反向传播，并额外修改一个学习率，或者是与最小绝对梯度(<kbd>sag</kbd>)相关联的学习率，或者是最小学习率(<kbd>slr</kbd>)本身。</p>

<p>要用每个连接的权重绘制模型的图形表示，我们可以使用<kbd>plot()</kbd>函数，该函数已在前面的章节中广泛解释过:</p>

<p>神经网络图如下图所示:</p>

<pre><strong>plot(net)</strong></pre>

<p>在前面的图中，黑线(这些线从输入节点开始)显示了每个层之间的连接以及每个连接上的权重，而蓝线(这些线从由数字1区分的偏差节点开始)显示了每个步骤中添加的偏差项。偏差可以被认为是线性模型的截距。</p>

<div><img class="image-border" src="img/e2e5a78b-76e7-4966-a901-20808ead3b7c.png"/></div>

<p>测试网络</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Testing the network</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:4a8cbe4a-e61d-4c74-886d-1da985c44432" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">我们终于训练好了网络，可以使用了。现在，我们可以用它来做预测。请记住，我们已经留出了30%的可用数据，然后用它们来测试网络。是时候用了。</h1>

                

            

            

                

<p>为了预测数据，我们使用了compute函数，该函数在给定一个训练好的神经网络的情况下，针对特定的任意协变量向量计算所有神经元的输出。让我们通过打印前十行来看看结果:</p>

<pre><strong>predict_net_test &lt;- compute(net,test_data[,1:9])</strong></pre>

<p>正如我们所看到的，这些是有几个小数的实数。为了将它们与数据集中包含的数据进行比较，我们必须将它们四舍五入到最接近的整数。为此，我们将使用<kbd>round()</kbd>函数，该函数将第一个参数中的值四舍五入到指定的小数位数(默认为零)。</p>

<pre><strong>&gt; head(predict_net_test$net.result,n=10)</strong><br/><strong>                 [,1]                       [,2]</strong><br/><strong>1  0.9999999935589190 0.000000003587253510720848</strong><br/><strong>2  0.0000011083596034 0.999999376764558189911725</strong><br/><strong>4  0.9792070465712006 0.017164709664531079685856</strong><br/><strong>5  0.9999999746453074 0.000000021909385204003642</strong><br/><strong>9  0.9999993390597798 0.000000327298596658228207</strong><br/><strong>14 0.9999999999953126 0.000000000000889095157872</strong><br/><strong>17 0.9999999999989946 0.000000000000442776879837</strong><br/><strong>19 0.0000001409393993 0.999999920006766185309743</strong><br/><strong>21 0.0000024771345578 0.999998553964539960148272</strong><br/><strong>23 0.9999999999999967 0.000000000000001305142352</strong></pre>

<p>我们现在重建起始变量。我们不再需要这两个虚拟变量。他们做得很好，但现在我们不再需要他们了。</p>

<pre><strong>predict_result&lt;-round(predict_net_test$net.result, digits = 0)</strong></pre>

<p>现在，我们可以构建混淆矩阵来检查我们的分类器的性能。</p>

<pre><strong>net.prediction = c("benign", "malignant")[apply(predict_result, 1, which.max)]</strong></pre>

<p>混淆矩阵如下所示:</p>

<pre><strong>predict.table = table(data_cleaned$Class[-index], net.prediction)</strong></pre>

<p>虽然用一种简单的方式，矩阵告诉我们，我们只犯了八个错误。关于混淆矩阵的更多信息，我们可以使用包含在<kbd>gmodels</kbd>包中的<kbd>CrossTable()</kbd>函数。和往常一样，在加载书之前，你需要安装它。</p>

<pre><strong>&gt; predict.table</strong><br/><strong>           net.prediction</strong><br/><strong>            benign malignant</strong><br/><strong>  benign       132         5</strong><br/><strong>  malignant      3        65</strong></pre>

<p>使用<kbd>CrossTable()</kbd>函数得到的混淆矩阵如下截图所示:</p>

<pre><strong>library(gmodels)</strong><br/><strong>CrossTable(x = data_cleaned$Class[-index], y = net.prediction,</strong><br/><strong>           prop.chisq=FALSE)</strong></pre>

<p>落在主对角线上的单元包含分类器正确分类的实例的计数。在左上角标有<kbd>TN</kbd>的单元格中，是真正的阴性结果。这205个值中的132个指示癌症是<kbd>benign</kbd>的情况，并且算法正确地将其识别为T5。右下角标有<kbd>TP</kbd>的单元格表示真正的阳性结果，其中分类器和临床确定的标签一致认为质量为<kbd>malignant</kbd>。总共205个预测中有65个是真阳性。</p>

<div><img class="image-border" src="img/bda37acc-23f4-4655-822c-fea862516d84.png"/></div>

<p>落在另一条对角线上的单元包含分类器错误分类的例子的计数。左下<kbd>FN</kbd>单元格中的三个例子是假阴性结果；在这种情况下，预测值是<kbd>benign</kbd>，但癌症实际上是<kbd>malignant</kbd>。在这个方向上的错误可能会付出极其高昂的代价，因为它们可能会导致患者认为她没有患癌症，而实际上疾病可能会继续扩散。标记为<kbd>FP</kbd>的单元格将包含假阳性结果，如果有的话。当模型将癌症分类为恶性而实际上是良性时，就会出现这些值。虽然这种错误没有假阴性结果危险，但是也应该避免，因为它们可能导致卫生保健系统的额外经济负担，或者患者的额外压力，因为可能必须提供额外的测试或治疗。</p>

<p>神经网络训练中的早期停止</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Early stopping in neural network training</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:4a8cbe4a-e61d-4c74-886d-1da985c44432" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">历元是对权重和偏差的前向传播训练和反向传播更新的每次往返的测量。一旦我们收敛(最小误差项)或者在预设的迭代次数之后，训练的往返必须停止。</h1>

                

            

            

                

<p>早期停止是一种用于处理模型过度拟合的技术(在接下来的几页中有更多关于过度拟合的内容)。训练集分为两部分:一部分用于训练，另一部分用于验证。我们已经将我们的<kbd>IRIS</kbd>数据集分成两部分:一部分75 %,另一部分25%。</p>

<p>利用训练数据，我们计算梯度并更新网络权重和偏差。第二组数据，即测试或验证数据，用于验证模型过拟合。如果验证期间的误差增加了指定的迭代次数(<kbd>nnet.abstol</kbd> / <kbd>reltol</kbd>)，则停止训练，模型使用该点的权重和偏差。这种方法叫做<em>提前停车。</em></p>

<p>早期停止的神经网络集成泛化误差与由传统算法训练的最佳结构的单个神经网络相当。单个神经网络需要复杂而完美的调整，才能在不提前停止的情况下实现这种泛化。</p>

<p>避免模型中的过度拟合</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Avoiding overfitting in the model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:4a8cbe4a-e61d-4c74-886d-1da985c44432" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">训练数据的拟合使得模型确定权重和偏差以及激活函数值。当算法在一些训练数据集中表现得太好时，它被认为与该特定数据集太一致。当测试数据与训练数据非常不同时，这导致输出值的高变化。这种高估计方差被称为<strong>过拟合</strong>。预测会受到所提供的训练数据的影响。</h1>

                

            

            

                

<p>有许多可能的方法来处理神经网络中的过拟合。第一种是正则化，类似于回归。有两种正则化:</p>

<p>L1或拉索正则化</p>

<ul>

<li>L2或岭正则化</li>

<li>最大范数约束</li>

<li>神经网络中的辍学</li>

<li>正则化引入了影响激活函数的成本项。它试图通过在目标函数中引入更多的特征来改变大多数系数。因此，它试图将许多变量的系数推到零，并减少成本项。</li>

</ul>

<p><strong>套索或L1正则化或L1惩罚</strong>:这有一个惩罚项，它使用绝对权重的总和，从而优化权重以减少过拟合。<strong>最小绝对收缩和选择算子</strong> ( <strong>套索</strong>)引入惩罚权重，使网络权重向零收缩。</p>

<ul>

<li><strong> L2惩罚或岭回归</strong>:这与L1相似，但惩罚是基于平方权重而不是绝对权重之和。重量越大惩罚越重。</li>

<li>对于这两种情况，只有权重被考虑用于优化，偏差(或偏移或截距)被排除在练习之外。</li>

</ul>

<p><strong>最大范数约束</strong>:这是另一种正则化技术，通过这种技术，我们对每个神经元的输入权重向量的幅度施加绝对上限，并且由于这种约束，投影梯度下降不能修改权重。这里，参数向量不会失去控制(即使学习率太高)，因为对权重的更新总是有限的。</p>

<ul>

<li style="margin: 0in;margin-bottom: .0001pt;background: white"><strong>脱落</strong>:这是另一种防过拟合技术。在训练时，通过以某种概率<em> p </em>(一个超参数)保持神经元活动或者否则将其设置为零来实现退出。这意味着一些神经元可能在训练过程中不存在，从而退出。网络不受影响，甚至在缺少某些信息的情况下变得更加准确。这防止了网络变得过于依赖任何一个(或任何小的组合)神经元。下图解释了退出的过程。红色(或黑色)神经元是被丢弃的神经元，神经网络模型在没有这些神经元的情况下仍然存在，并且提供了更少的过拟合和更高的准确性:</li>

<li style="margin: 0in;margin-bottom: .0001pt;background: white">神经网络的泛化</li>

</ul>

<div><img class="image-border" height="213" src="img/7149a1ea-27e0-4cb8-9212-257dd8a64fd7.png" width="389"/></div>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Generalization of neural networks</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:4a8cbe4a-e61d-4c74-886d-1da985c44432" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">概括的目的是拟合训练数据。这是我们在神经网络模型上所做训练的延伸。它寻求最小化模型在训练数据上的误差平方和(例如使用普通的最小二乘法)并降低模型的复杂性。</h1>

                

            

            

                

<p>概括的方法如下:</p>

<p>提前停止训练</p>

<ul>

<li>用不同训练数据重新训练神经网络</li>

<li>使用随机抽样、分层抽样或任何目标数据的良好组合<ul>

<li>训练多个神经网络并平均它们的输出</li>

</ul>

</li>

<li>神经网络模型中的数据缩放</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Scaling of data in neural network models</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:4a8cbe4a-e61d-4c74-886d-1da985c44432" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">数据缩放或规范化是一个以标准格式制作模型数据的过程，这样可以提高训练的质量、准确性和速度。神经网络中缩放数据的方法类似于任何机器学习问题中的数据规范化。</h1>

                

            

            

                

<p>下面列出了一些简单的数据标准化方法:</p>

<p><strong> Z分数归一化</strong>:如前几节所预期的，首先计算给定数据的算术平均值和标准偏差。标准化分数或<em>Z</em>-分数计算如下:</p>

<ul>

<li><strong>Z-score normalization</strong>: As anticipated in previous sections, the arithmetic mean and standard deviation of the given data are calculated first. The standardized score or <em>Z</em>-score is then calculated as follows:</li>

</ul>

<div><img height="31" src="img/8fe30670-d690-4655-99c8-593320e3e18c.jpg" width="108"/></div>

<p>这里，<em> X </em>是数据元素的值，μ是均值，σ是标准差。<em>Z</em>-分数或标准分数表示数据元素与平均值的标准偏差。由于均值和标准差对异常值很敏感，因此这种标准化对异常值也很敏感。</p>

<p style="padding-left: 60px"><strong>最小-最大标准化</strong>:计算每个数据元素的以下内容:</p>

<ul>

<li>这里，<em> x </em> <sub> <em> i </em> </sub>为数据元素，<em> min(x) </em>为所有数据值的最小值，<em> max(x) </em>为所有数据值的最大值。这种方法将所有的分数转换成一个普通的范围[0，1]。然而，它受到离群值敏感性的影响。</li>

</ul>

<div><img height="57" src="img/fe8d34b3-4d44-42e1-9fe7-6dcfdcd67adf.jpg" width="171"/></div>

<p style="padding-left: 60px"><strong>中位数和MAD </strong>:中位数和中位数绝对偏差(MAD)归一化使用以下公式计算归一化数据值:</p>

<ul>

<li>这里，<em xmlns:epub="http://www.idpf.org/2007/ops">x<sub>I</sub>T16】表示每个数据值。这种方法对异常值和分布极端尾部的点不敏感，因此是稳健的。然而，这种技术不保留输入分布，并且不将分数转换到公共数值范围。</em></li>

</ul>

<div><img height="63" src="img/f459d0ec-eb59-4c70-aa28-14de709a5b90.jpg" width="145"/></div>

<p style="padding-left: 60px">使用神经网络的集合预报</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Ensemble predictions using neural networks</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:4a8cbe4a-e61d-4c74-886d-1da985c44432" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">另一种正则化方法包括组合神经网络模型并平均结果。得到的模型是最精确的。</h1>

                

            

            

                

<p>神经网络集成是一组神经网络模型，通过平均各个模型的结果来做出决策。集成技术是一种提高泛化能力的简单方法，尤其是在由噪声数据或小数据集引起的情况下。我们训练多个神经网络并平均它们的输出。</p>

<p>作为一个例子，我们对同一个学习问题取20个神经网络，我们在训练过程中调整各种参数，然后将均方误差与其平均值的均方误差进行比较。</p>

<p>以下是遵循的步骤:</p>

<p>数据集被加载并分成训练集和测试集。对于不同的神经网络模型，百分比分割可以不同。</p>

<ol>

<li>通过调整<kbd>nnet()</kbd>功能中的参数，使用不同的训练集创建多个模型。</li>

<li>所有模型都经过训练，每个模型中的误差都被制成表格。</li>

<li>找到测试数据中每一行的平均误差，并计算每个模型的均方误差。</li>

<li>将均方误差与平均值的均方误差进行比较。</li>

<li>从比较中选择最佳模型，并进一步用于预测。</li>

<li>这种方法允许我们处理数据和函数参数，以达到模型的最佳设置。我们可以在集合中选择任意数量的模型，并使用r。</li>

</ol>

<p>过度拟合被大大减少，并且模型的最佳参数在这里达到。</p>

<p>摘要</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Summary</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:4a8cbe4a-e61d-4c74-886d-1da985c44432" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">在本章中，我们介绍了使用r对简单神经网络进行训练和可视化。在这里，我们可以更改神经元的数量、隐藏层的数量、激活函数等，以确定模型的训练。</h1>

                

            

            

                

<p>而处理一个回归问题，最后一层是单个单元，会给出连续的值。对于一个分类问题，有n个终端单元，每个终端单元用其概率表示输出的类别。乳腺癌示例有两个输出神经元来表示从神经网络输出的两类值。</p>

<p class="mce-root">我们已经学习了如何使用神经网络模型来训练、测试和评估数据集。我们还学习了如何在R环境中可视化NN模型。我们已经介绍了早期停止、避免过拟合、神经网络泛化和神经网络参数缩放等概念。</p>

<p class="mce-root">We have learned how to train, test, and evaluate a dataset using NN model. We have also learned how to visualize the NN model in R environment. We have covered the concepts like early stopping, avoiding overfitting, generalization of NN, and scaling of NN parameters.</p>





            



            

        

    </body>



</html></body></html>