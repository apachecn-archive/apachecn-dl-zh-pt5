<html><head/><body>
<html>
  <head>
    <title>Chapter 1. Theano Basics</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0">第一章。泰诺基础</h1></div></div></div><p class="calibre8">本章介绍了作为计算引擎的ano以及使用ano进行符号计算的基础知识。符号计算包括构建操作图，这些操作图将在以后针对特定的体系结构进行优化，使用可用于该体系结构的计算库。</p><p class="calibre8">虽然这一章看起来离实际应用还有很长的路要走，但是理解后面几章的技术是很重要的；它有什么能力，能带来什么价值？接下来的所有章节都将讨论在构建所有可能的深度学习架构时，Theano的应用。</p><p class="calibre8">the no<a id="id0" class="calibre1"/>可以定义为科学计算的库；它从2007年开始提供，特别适合深度学习。两个重要的功能是任何深度学习库的核心:张量运算，以及在CPU或<strong class="calibre2">图形计算单元</strong> ( <strong class="calibre2"> GPU </strong>)上运行代码的能力。这两个特性使我们能够处理大量的多维数据。此外，Theano提出了自动微分，这是一个非常有用的功能，可以解决比深度学习问题更广泛的数值优化。</p><p class="calibre8">本章涵盖以下主题:</p><div><ul class="itemizedlist"><li class="listitem">安装和装载</li><li class="listitem">张量和代数</li><li class="listitem">符号编程</li><li class="listitem">图表</li><li class="listitem">自动微分</li><li class="listitem">GPU编程</li><li class="listitem">压型</li><li class="listitem">配置</li></ul></div></div></body></html>


<html>
  <head>
    <title>Chapter 1. Theano Basics</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h1 class="title" id="calibre_pb_1"><a id="ch01lvl1sec08" class="calibre1"/>需要张量</h1></div></div></div><p class="calibre8">通常，输入的<a id="id1" class="calibre1"/>数据用多维数组表示:</p><div><ul class="itemizedlist"><li class="listitem"><strong class="calibre2">图像有三个维度</strong>:图像的通道数、宽度和高度</li><li class="listitem"><strong class="calibre2">声音和时间序列有一维</strong>:持续时间</li><li class="listitem"><strong class="calibre2">自然语言序列可以用二维数组表示</strong>:时长和字母表长度或词汇长度</li></ul></div><p class="calibre8">我们将在以后的章节中看到更多输入数据数组的例子。</p><p class="calibre8">在Theano中，多维数组是通过一个名为<strong class="calibre2"> tensor </strong>的抽象类实现的，与Python等计算机语言中的传统数组相比，它提供了更多的变换。</p><p class="calibre8">在神经网络的每个阶段，诸如矩阵乘法之类的计算涉及对这些多维数组的多次运算。</p><p class="calibre8">编程语言中的经典数组没有足够的内置功能来快速充分地处理多维计算和操作。</p><p class="calibre8">多维数组上的计算有很长的优化历史，有大量的库和硬件。GPU的大规模并行架构实现了最重要的速度提升，能够在从数百到数千的大量内核上进行计算。</p><p class="calibre8">与传统的CPU相比，例如，四核、12核或32核引擎，即使部分代码仍在CPU上执行(数据加载、GPU引导和结果输出)，GPU的增益也可以从5倍到100倍不等。使用GPU的主要瓶颈通常是CPU的内存和GPU的内存之间的数据传输，但是，当编程良好时，GPU的使用有助于将速度显著提高一个数量级。在几天而不是几个月，或者几个小时而不是几天内得到结果，对于实验来说是一个不可否认的好处。</p><p class="calibre8">Theano引擎旨在从一开始就解决多维数组和架构抽象的挑战。</p><p class="calibre8">对于科学计算，ano还有另一个不可否认的好处:多维数组函数的自动微分，这是一个非常适合通过目标函数最小化进行模型参数推断的特性。这种特性通过减轻计算导数的痛苦来促进实验，这可能并不复杂，但容易出现许多错误。</p></div></div></body></html>


<html>
  <head>
    <title>Installing and loading Theano</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch01lvl1sec09" class="calibre1"/>安装和装载自动售货机</h1></div></div></div><p class="calibre8">在这个<a id="id3" class="calibre1"/>部分，我们将安装Theano，在CPU和GPU设备上运行它，然后<a id="id4" class="calibre1"/>保存配置。</p></div></body></html>


<html>
  <head>
    <title>Installing and loading Theano</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch01lvl2sec07" class="calibre1"/>康达包装和环境经理</h2></div></div></div><p class="calibre8">安装Theano最简单的<a id="id5" class="calibre1"/>方法是使用<code class="email">conda</code>，一个跨平台的包和环境管理器。</p><p class="calibre8">如果<code class="email">conda</code>还没有安装在你的操作系统上，安装<code class="email">conda</code>最快的方法是从<a class="calibre1" href="https://conda.io/miniconda.html">https://conda.io/miniconda.html</a>下载<code class="email">miniconda</code>安装程序。例如，对于<code class="email">conda under Linux 64 bit and Python 2.7</code>，使用以下命令:</p><div><pre class="programlisting">
<strong class="calibre2">wget</strong> https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh
<strong class="calibre2">chmod</strong> +x Miniconda2-latest-Linux-x86_64.sh
<strong class="calibre2">bash</strong> ./Miniconda2-latest-Linux-x86_64.sh</pre></div><p class="calibre8">Conda使我们能够创建新的环境，其中Python的版本(2或3)和安装的包可能不同。<code class="email">conda</code>根环境使用的Python版本与安装了<code class="email">conda</code>的系统上安装的版本相同。</p></div></div></body></html>


<html>
  <head>
    <title>Installing and loading Theano</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch01lvl2sec08" class="calibre1"/>在CPU上安装并运行Theano</h2></div></div></div><p class="calibre8">让我们<a id="id7" class="calibre1"/>安装这个编号:</p><div><pre class="programlisting">
<strong class="calibre2">conda</strong> install theano</pre></div><p class="calibre8">运行一个<a id="id8" class="calibre1"/> Python会话，并尝试以下命令来检查您的配置:</p><div><pre class="programlisting">&gt;&gt;&gt; from theano import theano

&gt;&gt;&gt; theano.config.device
'cpu'

&gt;&gt;&gt; theano.config.floatX
'float64'

&gt;&gt;&gt; print(theano.config)</pre></div><p class="calibre8">最后一个命令打印了所有的配置。对象包含许多配置选项的键。</p><p class="calibre8">为了<a id="id10" class="calibre1"/>推断配置选项，ano首先查看<code class="email">~/.theanorc </code>文件，然后查看任何可用的环境变量，这些变量会覆盖前面的选项，最后查看代码中优先级最高的变量集:</p><div><pre class="programlisting">&gt;&gt;&gt; theano.config.floatX='float32'</pre></div><p class="calibre8">有些属性可能是只读的，不能在代码中更改，但是<code class="email">floatX</code>是可以在代码中直接更改的属性之一，它为floats设置默认的浮点精度。</p><div><h3 class="title2"><a id="note02" class="calibre1"/>注意</h3><p class="calibre8">建议使用<code class="email">float32</code>，因为GPU历史悠久，没有<code class="email">float64</code>。<code class="email"> float64</code>在GPU上的执行速度比较慢，有时候慢很多(在最新一代Pascal硬件上是2倍到32倍)，而<code class="email">float32</code>的精度在实际中已经足够了。</p></div></div></div></body></html>


<html>
  <head>
    <title>Installing and loading Theano</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch01lvl2sec09" class="calibre1"/> GPU驱动程序和库</h2></div></div></div><p class="calibre8">这个no <a id="id11" class="calibre1"/>支持GPU的使用，GPU是通常用来计算显示在计算机屏幕上的图形的单元。</p><p class="calibre8">为了让<a id="id12" class="calibre1"/>也能在GPU上工作，你的系统上需要一个GPU后端库。</p><p class="calibre8">CUDA库(仅适用于NVIDIA GPU卡)是GPU计算的主要选择。还有OpenCL标准，它是开放源码的，但远没有开发成熟，在ano上更具实验性和初级性。</p><p class="calibre8">目前大多数科学计算仍然发生在NVIDIA卡上。如果你有英伟达GPU卡，从英伟达网站<a class="calibre1" href="https://developer.nvidia.com/cuda-downloads">https://developer.nvidia.com/cuda-downloads</a>下载CUDA，安装。如果尚未安装最新版本的GPU驱动程序，安装程序将首先安装它们。它将在<code class="email">/usr/local/cuda </code>目录中安装CUDA库。</p><p class="calibre8">安装cuDNN库，这是NVIDIA的一个库，它为GPU提供了一些更快的操作实现。要安装的话，我一般会把<code class="email">/usr/local/cuda </code>目录复制到一个新的目录下，<code class="email">/usr/local/cuda-{CUDA_VERSION}-cudnn-{CUDNN_VERSION}</code>，这样我就可以根据自己使用的深度学习技术及其兼容性来选择CUDA和cuDNN的版本。</p><p class="calibre8">在你的。<code class="email">bashrc</code> profile，添加下面一行来设置<code class="email">$PATH</code>和<code class="email">$LD_LIBRARY_PATH</code>变量:</p><div><pre class="programlisting">
<strong class="calibre2">export</strong> PATH=/usr/local/cuda-8.0-cudnn-5.1/bin:$PATH
<strong class="calibre2">export</strong> LD_LIBRARY_PATH=/usr/local/cuda-8.0-cudnn-5.1/lib64:/usr/local/cuda-8.0-cudnn-5.1/lib:$LD_LIBRARY_PATH</pre></div></div></div></body></html>


<html>
  <head>
    <title>Installing and loading Theano</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_4"><a id="ch01lvl2sec10" class="calibre1"/>在GPU上安装并运行Theano</h2></div></div></div><p class="calibre8">n维<a id="id14" class="calibre1"/> GPU数组已经用Python实现在六个<a id="id15" class="calibre1"/>不同的GPU库中(<code class="email">Theano/CudaNdarray,PyCUDA</code> / <code class="email">GPUArray,CUDAMAT</code> / <code class="email">CUDAMatrix</code>、<code class="email">PYOPENCL</code> / <code class="email">GPUArray</code>、<code class="email">Clyther</code>、<code class="email">Copperhead</code>)，是<code class="email">NumPy.ndarray</code>的子集。<code class="email">Libgpuarray</code>是一个后端库，让它们在一个公共接口上具有相同的属性。</p><p class="calibre8">要用<code class="email">conda</code>安装<code class="email">libgpuarray</code>，使用以下命令:</p><div><pre class="programlisting">
<strong class="calibre2">conda</strong> install pygpu</pre></div><p class="calibre8">为了<a id="id16" class="calibre1"/>在GPU模式下运行Theano，您需要在执行前配置<code class="email">config.device</code>变量，因为一旦代码运行，它就是一个只读变量。使用<code class="email">THEANO_FLAGS</code>环境变量运行此<a id="id17" class="calibre1"/>命令:</p><div><pre class="programlisting">THEANO_FLAGS="device=cuda,floatX=float32" <strong class="calibre2">python</strong>
&gt;&gt;&gt; <strong class="calibre2">import</strong> theano
Using cuDNN version 5110 on context None
Mapped name None to device cuda: Tesla K80 (0000:83:00.0)

&gt;&gt;&gt; theano.config.device
'gpu'

&gt;&gt;&gt; theano.config.floatX
'float32'</pre></div><p class="calibre8">第一个返回显示GPU设备已被正确检测到，并指定它使用哪个GPU。</p><p class="calibre8">默认情况下，Theano激活CNMeM，这是一个更快的CUDA内存分配器。可以使用<code class="email">gpuarra.preallocate</code>选项指定初始预分配。最后，我的发射命令如下:</p><div><pre class="programlisting">THEANO_FLAGS="device=cuda,floatX=float32,gpuarray.preallocate=0.8" <strong class="calibre2">python</strong>
&gt;&gt;&gt; <strong class="calibre2">from</strong> theano import <strong class="calibre2">theano</strong>
Using cuDNN version 5110 on context None
Preallocating 9151/11439 Mb (0.800000) on cuda
Mapped name None to device cuda: Tesla K80 (0000:83:00.0)</pre></div><p class="calibre8">第一行确认cuDNN是活动的，第二行确认内存预分配。第三行给出了默认的<strong class="calibre2">上下文名称</strong>(即<code class="email">flag device=cuda</code>置位时的<code class="email">None</code>)和使用的GPU型号，而CPU的默认上下文名称将始终是<code class="email">cpu</code>。</p><p class="calibre8">可以指定与第一个不同的GPU，将设备设置为<code class="email">cuda0</code>、<code class="email">cuda1</code>，...对于多GPU计算机。也可以在多个GPU上并行或顺序运行程序(当一个GPU的内存不足时)，特别是当训练非常深的神经网络时，如第7章<a class="calibre1" title="Chapter 7. Classifying Images with Residual Networks" href="part0075_split_000.html#27GQ61-ccdadb29edc54339afcb9bdf9350ba6b">、<em class="calibre12">使用残差网络对图像进行分类</em>中描述的对完整图像进行分类。在这种情况下，<code class="email">contexts=dev0-&gt;cuda0;dev1-&gt;cuda1;dev2-&gt;cuda2;dev3-&gt;cuda3</code>标志激活多个GPU而不是一个，并为代码中使用的每个GPU设备指定上下文名称。以下是一个4 GPU实例的示例:</a></p><div><pre class="programlisting">THEANO_FLAGS="contexts=dev0-&gt;cuda0;dev1-&gt;cuda1;dev2-&gt;cuda2;dev3-&gt;cuda3,floatX=float32,gpuarray.preallocate=0.8" <strong class="calibre2">python</strong>
&gt;&gt;&gt; <strong class="calibre2">import</strong> theano
Using cuDNN version 5110 on context None
Preallocating 9177/11471 Mb (0.800000) on cuda0
Mapped name dev0 to device cuda0: Tesla K80 (0000:83:00.0)
Using cuDNN version 5110 on context dev1
Preallocating 9177/11471 Mb (0.800000) on cuda1
Mapped name dev1 to device cuda1: Tesla K80 (0000:84:00.0)
Using cuDNN version 5110 on context dev2
Preallocating 9177/11471 Mb (0.800000) on cuda2
Mapped name dev2 to device cuda2: Tesla K80 (0000:87:00.0)
Using cuDNN version 5110 on context dev3
Preallocating 9177/11471 Mb (0.800000) on cuda3
Mapped name dev3 to device cuda3: Tesla K80 (0000:88:00.0)</pre></div><p class="calibre8">为了在这个多GPU设置中将计算分配给特定的GPU，我们选择的名称<code class="email">dev0</code>、<code class="email">dev1</code>、<code class="email">dev2</code>和<code class="email">dev3</code>已经映射到每个设备(<code class="email">cuda0</code>、<code class="email">cuda1</code>、<code class="email">cuda2</code>、<code class="email">cuda3</code>)。</p><p class="calibre8">这个<a id="id18" class="calibre1"/>名称映射允许编写独立于底层GPU分配和库(CUDA或其他)的代码。</p><p class="calibre8">为了在不使用环境变量的情况下，在每个Python会话或执行中保持当前配置标志有效，将您的配置保存在<code class="email">~/.theanorc</code>文件中，如下所示:</p><div><pre class="programlisting"> [global]
 floatX = float32
 device = cuda0
 [gpuarray]
 preallocate = 1</pre></div><p class="calibre8">现在你可以简单地运行<code class="email">python</code>命令。您现在一切就绪。</p></div></div></body></html>


<html>
  <head>
    <title>Tensors</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch01lvl1sec10" class="calibre1"/>张量</h1></div></div></div><p class="calibre8">在Python中，一些科学库如NumPy提供了多维数组。Theano并不能取代<a id="id20" class="calibre1"/> Numpy，但它可以与之协同工作。NumPy用于张量的初始化。</p><p class="calibre8">要在CPU和GPU上执行相同的计算，变量是符号化的，由张量类(一种抽象)表示，编写数值表达式包括构建变量节点和应用节点的计算图。根据编译计算图形的平台，张量由以下任一项代替:</p><div><ul class="itemizedlist"><li class="listitem">一个<code class="email">TensorType</code>变量，它必须在CPU上</li><li class="listitem">一个<code class="email">GpuArrayType</code>变量，它必须在GPU上</li></ul></div><p class="calibre8">通过这种方式，代码的编写可以不受执行平台的影响。</p><p class="calibre8">以下是一些张量对象:</p><div><table border="1" class="calibre14"><colgroup class="calibre15"><col class="calibre16"/><col class="calibre16"/><col class="calibre16"/></colgroup><thead class="calibre17"><tr class="calibre18"><th valign="bottom" class="calibre19">
<p class="calibre20">对象类别</p>
</th><th valign="bottom" class="calibre19">
<p class="calibre20">维度数量</p>
</th><th valign="bottom" class="calibre19">
<p class="calibre20">例子</p>
</th></tr></thead><tbody class="calibre21"><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">theano.tensor.scalar</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">0维数组</p>
</td><td valign="top" class="calibre22">
<p class="calibre20">1, 2.5</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">theano.tensor.vector</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">一维数组</p>
</td><td valign="top" class="calibre22">
<p class="calibre20">[0,3,20]</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">theano.tensor.matrix</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">二维数组</p>
</td><td valign="top" class="calibre22">
<p class="calibre20">[[2,3][1,5]]</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">theano.tensor.tensor3</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">三维阵列</p>
</td><td valign="top" class="calibre22">
<p class="calibre20">[[[2,3][1,5]],[[1,2],[3,4]]]</p>
</td></tr></tbody></table></div><p class="calibre8">在Python shell中使用这些Theano对象让我们有了更好的想法:</p><div><pre class="programlisting">&gt;&gt;&gt; <strong class="calibre2">import</strong> theano.tensor <strong class="calibre2">as</strong> T

&gt;&gt;&gt; T.scalar()
&lt;TensorType(float32, scalar)&gt;

&gt;&gt;&gt; T.iscalar()
&lt;TensorType(int32, scalar)&gt;

&gt;&gt;&gt; T.fscalar()
&lt;TensorType(float32, scalar)&gt;

&gt;&gt;&gt; T.dscalar()
&lt;TensorType(float64, scalar)&gt;</pre></div><p class="calibre8">在对象名称前加上<code class="email">i</code>、<code class="email">l</code>、<code class="email">f</code>或<code class="email">d</code>，可以初始化给定类型的张量、<code class="email">integer32</code>、<code class="email">integer64</code>、<code class="email">float32</code>或<code class="email">float64</code>。对于实值(浮点)数据，建议使用直接形式<code class="email">T.scalar()</code>而不是<code class="email">f</code>或<code class="email">d</code>变量，因为直接形式将使用您当前的浮点配置:</p><div><pre class="programlisting">&gt;&gt;&gt; theano.config.floatX <strong class="calibre2">= </strong>'float64'

&gt;&gt;&gt; T.scalar()
&lt;TensorType(float64, scalar)&gt;

&gt;&gt;&gt; T.fscalar()
&lt;TensorType(float32, scalar)&gt;

&gt;&gt;&gt; theano.config.floatX = 'float32'

&gt;&gt;&gt; T.scalar()
&lt;TensorType(float32, scalar)&gt;</pre></div><p class="calibre8">符号<a id="id21" class="calibre1"/>变量执行以下任一操作:</p><div><ul class="itemizedlist"><li class="listitem">扮演占位符的角色，作为构建数字运算(如加法、乘法)图形的起点:图形编译完成后，占位符在计算过程中接收输入数据流</li><li class="listitem">表示中间或输出结果</li></ul></div><p class="calibre8">符号变量和操作都是计算图的一部分，将在CPU或GPU上编译以快速执行。让我们写下第一个计算图，包括一个简单的加法:</p><div><pre class="programlisting">&gt;&gt;&gt; x = T.matrix('x')

&gt;&gt;&gt; y = T.matrix('y')

&gt;&gt;&gt; z = x + y

&gt;&gt;&gt; theano.pp(z)
'(x + y)'

&gt;&gt;&gt; z.eval({x: [[1, 2], [1, 3]], y: [[1, 0], [3, 4]]})
array([[ 2.,  2.],
       [ 4.,  7.]], dtype=float32)</pre></div><p class="calibre8">首先，创建两个符号变量，或称<em class="calibre12">变量节点</em>，命名为<code class="email">x</code>和<code class="email">y</code>，在它们之间应用加法运算<em class="calibre12">应用节点</em>，在计算图中创建一个新的符号变量<code class="email">z</code>。</p><p class="calibre8">漂亮的打印函数<code class="email">pp</code>，打印由ano符号变量表示的表达式。当前两个变量<code class="email">x</code>和<code class="email">y</code>用两个数值二维数组初始化时，<code class="email">Eval</code>计算输出变量<code class="email">z</code>的值。</p><p class="calibre8">以下示例显示了变量<code class="email">x</code>和<code class="email">y</code>及其名称<code class="email">x</code>和<code class="email">y</code>之间的差异:</p><div><pre class="programlisting">&gt;&gt;&gt; a = T.matrix()

&gt;&gt;&gt; b = T.matrix()

&gt;&gt;&gt; theano.pp(a + b)
'(&lt;TensorType(float32, matrix)&gt; + &lt;TensorType(float32, matrix)&gt;)'<em class="calibre12">.</em>
</pre></div><p class="calibre8">如果没有名称，在大型图形中跟踪节点会更加复杂。打印计算图时，名称对诊断问题有很大帮助，而变量仅用于处理图中的对象:</p><div><pre class="programlisting">&gt;&gt;&gt; x = T.matrix('x')

&gt;&gt;&gt; x = x + x

&gt;&gt;&gt; theano.pp(x)
<em class="calibre12">'(x + x)'</em>
</pre></div><p class="calibre8">这里，名为<code class="email">x</code>的原始符号变量没有改变，仍然是计算图的一部分。<code class="email">x + x</code>创建一个新的符号变量，我们将其分配给Python变量<code class="email">x</code>。</p><p class="calibre8">注意<a id="id22" class="calibre1"/>对于名字，复数形式同时初始化多个张量:</p><div><pre class="programlisting">&gt;&gt;&gt; x, y, z = T.matrices('x', 'y', 'z')</pre></div><p class="calibre8">现在，让我们看看显示图形的不同函数。</p></div></body></html>


<html>
  <head>
    <title>Graphs and symbolic computing</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch01lvl1sec11" class="calibre1"/>图形和符号计算</h1></div></div></div><p class="calibre8">让我们回到简单的加法示例，展示显示相同信息的不同方式:</p><div><pre class="programlisting">&gt;&gt;&gt; x = T.matrix('x')

&gt;&gt;&gt; y = T.matrix('y')

&gt;&gt;&gt; z = x + y

&gt;&gt;&gt; z

Elemwise{add,no_inplace}.0

&gt;&gt;&gt; theano.pp(z)

<em class="calibre12">'(x + y)</em>

&gt;&gt;&gt; theano.printing.pprint(z)

<em class="calibre12">'(x + y)'</em>

&gt;&gt;&gt; theano.printing.debugprint(z)
Elemwise{add,no_inplace} [id A] ''   
 |x [id B]
 |y [id C]</pre></div><p class="calibre8">这里，<code class="email">debugprint</code>函数打印预编译图，即未优化的图。在这种情况下，它是由两个变量节点<code class="email">x</code>和<code class="email">y</code>组成的<a id="id24" class="calibre1"/>，以及一个应用节点，即带有<code class="email">no_inplace</code>选项的元素加法。<code class="email">inplace</code>选项将用于优化图形，以节省内存并重新使用输入的内存来存储操作结果。</p><p class="calibre8">如果已经安装了<code class="email">graphviz</code>和<code class="email">pydot</code>库，<code class="email">pydotprint</code>命令输出图形的PNG图像:</p><div><pre class="programlisting">&gt;&gt;&gt; theano.printing.pydotprint(z)
The output file is available at ~/.theano/compiledir_Linux-4.4--generic-x86_64-with-Ubuntu-16.04-xenial-x86_64-2.7.12-64/theano.pydotprint.gpu.png.
</pre></div><div><img src="img/00002.jpeg" alt="Graphs and symbolic computing" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">您可能已经注意到了<code class="email">z.eval</code>命令第一次执行时花费了一些时间。此<a id="id25" class="calibre1"/>延迟的原因是优化数学表达式和在评估之前为CPU或GPU编译代码所需的时间。</p><p class="calibre8"><a id="id26" class="calibre1"/>编译后的表达式可以显式获得，并作为一个函数使用，其行为类似于传统的Python函数:</p><div><pre class="programlisting">&gt;&gt;&gt; addition = theano.function([x, y], [z])

&gt;&gt;&gt; addition([[1, 2], [1, 3]], [[1, 0], [3, 4]])
[array([[ 2.,  2.],
       [ 4.,  7.]], dtype=float32)]</pre></div><p class="calibre8">函数创建中的第一个参数是表示图的输入节点的变量列表。第二个参数是输出变量的数组。要打印编译后图形，请使用以下命令:</p><div><pre class="programlisting">&gt;&gt;&gt; theano.printing.debugprint(addition)
HostFromGpu(gpuarray) [id A] ''   3
 |GpuElemwise{Add}[(0, 0)]&lt;gpuarray&gt; [id B] ''   2
   |GpuFromHost&lt;None&gt; [id C] ''   1
   | |x [id D]
   |GpuFromHost&lt;None&gt; [id E] ''   0
     |y [id F]

&gt;&gt;&gt; theano.printing.pydotprint(addition)

The output file is available at ~/.theano/compiledir_Linux-4.4--generic-x86_64-with-Ubuntu-16.04-xenial-x86_64-2.7.12-64/theano.pydotprint.gpu.png:</pre></div><div><img src="img/00003.jpeg" alt="Graphs and symbolic computing" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">此<a id="id27" class="calibre1"/>案例已在使用GPU时打印。在编译过程中，每个操作都选择了可用的GPU实现。主程序仍然运行在数据驻留的CPU上，但是一个<code class="email">GpuFromHost</code>指令执行从CPU到GPU的数据传输以进行输入，而相反的操作<code class="email">HostFromGpu</code>获取结果供主程序显示:</p><div><img src="img/00004.jpeg" alt="Graphs and symbolic computing" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">Theano执行一些数学优化，例如对元素操作进行分组，向以前的加法中添加一个新值:</p><div><pre class="programlisting">&gt;&gt;&gt; z= z * x

&gt;&gt;&gt; theano.printing.debugprint(theano.function([x,y],z))
HostFromGpu(gpuarray) [id A] ''   3
 |GpuElemwise{Composite{((i0 + i1) * i0)}}[(0, 0)]&lt;gpuarray&gt; [id B] ''   2
   |GpuFromHost&lt;None&gt; [id C] ''   1
   | |x [id D]
   |GpuFromHost&lt;None&gt; [id E] ''   0
     |y [id F]</pre></div><p class="calibre8">图中的节点数量没有增加:两个增加的节点被合并为一个节点。这样的<a id="id29" class="calibre1"/>优化使得调试变得更加棘手，所以我们将在本章的最后向您展示如何为调试禁用优化。</p><p class="calibre8">最后，让我们进一步了解如何用NumPy设置初始值:</p><div><pre class="programlisting">&gt;&gt;&gt; theano.config.floatX
'float32'

&gt;&gt;&gt; x = T.matrix()

&gt;&gt;&gt; x
&lt;TensorType(float32, matrix)&gt;

&gt;&gt;&gt; y = T.matrix()

&gt;&gt;&gt; addition = theano.function([x, y], [x+y])

&gt;&gt;&gt; addition(numpy.ones((2,2)),numpy.zeros((2,2)))
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "/usr/local/lib/python2.7/site-packages/theano/compile/function_module.py", line 786, in __call__
    allow_downcast=s.allow_downcast)

  File "/usr/local/lib/python2.7/site-packages/theano/tensor/type.py", line 139, in filter
    raise TypeError(err_msg, data)
TypeError: ('Bad input argument to theano function with name "&lt;stdin&gt;:1"  at index 0(0-based)', 'TensorType(float32, matrix) cannot store a value of dtype float64 without risking loss of precision. If you do not mind this loss, you can: 1) explicitly cast your data to float32, or 2) set "allow_input_downcast=True" when calling "function".', array([[ 1.,  1.],
       [ 1.,  1.]]))</pre></div><p class="calibre8">在NumPy数组上执行函数会抛出一个与精度损失相关的错误，因为这里的NumPy数组有<code class="email">float64</code>和<code class="email">int64</code> <code class="email">dtypes</code>，而<code class="email">x</code>和<code class="email">y</code>是<code class="email">float32</code>。对此有多种解决方案；第一个是用正确的<code class="email">dtype</code>创建NumPy数组:</p><div><pre class="programlisting">&gt;&gt;&gt; <strong class="calibre2">import</strong> numpy

&gt;&gt;&gt; addition(numpy.ones((2,2), dtype=theano.config.floatX),numpy.zeros((2,2), dtype=theano.config.floatX))
[array([[ 1.,  1.],
        [ 1.,  1.]], dtype=float32)]</pre></div><p class="calibre8">或者，转换NumPy数组(特别是对于<code class="email">numpy.diag</code>，它不允许我们直接选择<code class="email">dtype</code>):</p><div><pre class="programlisting">&gt;&gt;&gt; addition(numpy.ones((2,2)).astype(theano.config.floatX),numpy.diag((2,3)).astype(theano.config.floatX))
[array([[ 3.,  1.],
        [ 1.,  4.]], dtype=float32)]</pre></div><p class="calibre8">或者我们可以允许向下转换:</p><div><pre class="programlisting">&gt;&gt;&gt; addition = theano.function([x, y], [x+y],allow_input_downcast=True)

&gt;&gt;&gt; addition(numpy.ones((2,2)),numpy.zeros((2,2)))
[array([[ 1.,  1.],
        [ 1.,  1.]], dtype=float32)]</pre></div></div></body></html>


<html>
  <head>
    <title>Operations on tensors</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch01lvl1sec12" class="calibre1"/>张量上的运算</h1></div></div></div><p class="calibre8">我们已经看到了如何在GPU或CPU上创建由符号变量和操作组成的计算图，并编译结果表达式以进行评估或作为函数。</p><p class="calibre8">由于张量对于深度学习非常重要，Theano提供了许多算子来处理张量。大多数存在于科学计算库中的操作符，比如NumPy中的数值数组，在Theano中有它们的等价操作符，并且有一个相似的名字，以便为NumPy的用户所熟悉。但与NumPy相反，用Theano编写的表达式既可以在CPU上编译，也可以在GPU上编译。</p><p class="calibre8">例如，张量创建就是这种情况:</p><div><ul class="itemizedlist"><li class="listitem"><code class="email">T.zeros()</code>、<code class="email">T.ones()</code>、<code class="email">T.eye()</code>运算符将形状元组作为输入</li><li class="listitem"><code class="email">T.zeros_like()</code>、<code class="email">T.one_like()</code>、<code class="email">T.identity_like()</code>使用张量的形状论证</li><li class="listitem"><code class="email">T.arange()</code>、<code class="email">T.mgrid()</code>、<code class="email">T.ogrid()</code>用于范围和网格阵列</li></ul></div><p class="calibre8">让我们看看Python的外壳:</p><div><pre class="programlisting">&gt;&gt;&gt; a = T.zeros((2,3))

&gt;&gt;&gt; a.eval()
array([[ 0.,  0.,  0.],
       [ 0.,  0.,  0.]])

&gt;&gt;&gt; b = T.identity_like(a)

&gt;&gt;&gt; b.eval()
array([[ 1.,  0.,  0.],
        [ 0.,  1.,  0.]])

&gt;&gt;&gt; c = T.arange(10)

&gt;&gt;&gt; c.eval()
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</pre></div><p class="calibre8">维度数量<code class="email">ndim</code>和类型<code class="email">dtype</code>等信息在张量创建时定义，以后不能修改:</p><div><pre class="programlisting">&gt;&gt;&gt; c.ndim
<em class="calibre12">1</em>

&gt;&gt;&gt; c.dtype
'int64'

&gt;&gt;&gt; c.type
TensorType(int64, vector)</pre></div><p class="calibre8">其他一些信息，如形状，由计算图评估:</p><div><pre class="programlisting">&gt;&gt;&gt; a = T.matrix()

&gt;&gt;&gt; a.shape
Shape.0

&gt;&gt;&gt; a.shape.eval({a: [[1, 2], [1, 3]]})
array([2, 2])

&gt;&gt;&gt; shape_fct = theano.function([a],a.shape)

&gt;&gt;&gt; shape_fct([[1, 2], [1, 3]])
array([2, 2])

&gt;&gt;&gt; n = T.iscalar()

&gt;&gt;&gt; c = T.arange(n)

&gt;&gt;&gt; c.shape.eval({n:10})
array([10])</pre></div></div></body></html>


<html>
  <head>
    <title>Operations on tensors</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch01lvl2sec11" class="calibre1"/>维度操作符</h2></div></div></div><p class="calibre8">第一种<a id="id32" class="calibre1"/>张量运算符用于<strong class="calibre2">维度操作</strong>。这种<a id="id33" class="calibre1"/>类型的运算符将一个张量作为输入，并返回一个新的张量:</p><div><table border="1" class="calibre14"><colgroup class="calibre15"><col class="calibre16"/><col class="calibre16"/></colgroup><thead class="calibre17"><tr class="calibre18"><th valign="bottom" class="calibre19">
<p class="calibre20">操作员</p>
</th><th valign="bottom" class="calibre19">
<p class="calibre20">描述</p>
</th></tr></thead><tbody class="calibre21"><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.reshape</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">重塑张量的维度</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.fill</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">用相同的值填充数组</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.flatten</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">返回一维张量(向量)中的所有元素</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.dimshuffle</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">改变维度的顺序，或多或少类似于NumPy的转置方法——主要的区别是它可以用来添加或删除可扩展维度(长度为1)。</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.squeeze</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">通过删除等于1的尺寸来调整形状</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.transpose</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">移项</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.swapaxes</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">交换维度</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.sort, T.argsort</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">排序张量，或有序指数</p>
</td></tr></tbody></table></div><p class="calibre8">例如，整形操作的输出表示一个新的张量，包含相同顺序但形状不同的相同元素:</p><div><pre class="programlisting">&gt;&gt;&gt; a = T.arange(10)

&gt;&gt;&gt; b = T.reshape( a, (5,2) )

&gt;&gt;&gt; b.eval()
array([[0, 1],
       [2, 3], 
       [4, 5],
       [6, 7],
       [8, 9]])</pre></div><p class="calibre8">运算符可以链接在一起:</p><div><pre class="programlisting">&gt;&gt;&gt; T.arange(10).reshape((5,2))[::-1].T.eval()
array([[8, 6, 4, 2, 0],
       [9, 7, 5, 3, 1]])</pre></div><p class="calibre8">注意Python中使用传统的<code class="email">[::-1]</code>数组索引访问，而<code class="email">.T</code>用于<code class="email">T.transpose</code>。</p></div></div></body></html>


<html>
  <head>
    <title>Operations on tensors</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch01lvl2sec12" class="calibre1"/>元素式运算符</h2></div></div></div><p class="calibre8">多维数组上的第二种类型的操作是元素操作。</p><p class="calibre8">第一类元素式操作采用两个相同维数的输入张量，并应用函数<code class="email">f</code>，元素式操作意味着在各个张量<code class="email">f([a,b],[c,d]) = [ f(a,c), f(b,d)]</code>中具有相同坐标的所有元素对上进行操作。例如，下面是乘法:</p><div><pre class="programlisting">&gt;&gt;&gt; a, b = T.matrices('a', 'b')

&gt;&gt;&gt; z = a * b

&gt;&gt;&gt; z.eval({a:numpy.ones((2,2)).astype(theano.config.floatX), b:numpy.diag((3,3)).astype(theano.config.floatX)})
array([[ 3.,  0.],
       [ 0.,  3.]])</pre></div><p class="calibre8"><a id="id36" class="calibre1"/>同样的乘法可以写成:</p><div><pre class="programlisting">&gt;&gt;&gt; z = T.mul(a, b)</pre></div><p class="calibre8"><code class="email">T.add</code>和<code class="email">T.mul</code>接受任意数量的输入:</p><div><pre class="programlisting">&gt;&gt;&gt; z = T.mul(a, b, a, b)</pre></div><p class="calibre8">一些元素操作符只接受一个输入张量<code class="email">f([a,b]) = [f(a),f(b)])</code>:</p><div><pre class="programlisting">&gt;&gt;&gt; a = T.matrix()

&gt;&gt;&gt; z = a ** 2 

&gt;&gt;&gt; z.eval({a:numpy.diag((3,3)).astype(theano.config.floatX)})
array([[ 9.,  0.], 
       [ 0.,  9.]])</pre></div><p class="calibre8">最后，我想介绍一下<strong class="calibre2">广播</strong>的机制。当输入张量不具有<a id="id38" class="calibre1"/>相同的维数时，丢失的维数将被广播，这意味着张量将沿着该维数重复，以匹配另一个张量的维数。例如，取一个多维张量和一个标量(0维)张量，该标量将在与多维张量相同形状的数组中重复，从而最终形状将匹配，并且将应用逐元素运算，<code class="email">f([a,b], c) = [ f(a,c), f(b,c) ]</code>:</p><div><pre class="programlisting">&gt;&gt;&gt; a = T.matrix()

&gt;&gt;&gt; b = T.scalar()

&gt;&gt;&gt; z = a * b

&gt;&gt;&gt; z.eval({a:numpy.diag((3,3)).astype(theano.config.floatX),b:3})
array([[ 6.,  0.],
       [ 0.,  6.]])</pre></div><p class="calibre8">以下是elementwise操作的列表:</p><div><table border="1" class="calibre14"><colgroup class="calibre15"><col class="calibre16"/><col class="calibre16"/><col class="calibre16"/></colgroup><thead class="calibre17"><tr class="calibre18"><th valign="bottom" class="calibre19">
<p class="calibre20">操作员</p>
</th><th valign="bottom" class="calibre19">
<p class="calibre20">其他形式</p>
</th><th valign="bottom" class="calibre19">
<p class="calibre20">描述</p>
</th></tr></thead><tbody class="calibre21"><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.add, T.sub, T.mul, T.truediv</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">+, -, *, /</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">加、减、乘、除</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.pow, T.sqrt</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">**, T.sqrt</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">平方根乘方</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.exp, T.log</code></p>
</td><td valign="top" class="calibre22"> </td><td valign="top" class="calibre22">
<p class="calibre20">指数、对数</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.cos, T.sin, T.tan</code></p>
</td><td valign="top" class="calibre22"> </td><td valign="top" class="calibre22">
<p class="calibre20">余弦、正弦、正切</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.cosh, T.sinh, T.tanh</code></p>
</td><td valign="top" class="calibre22"> </td><td valign="top" class="calibre22">
<p class="calibre20">双曲三角函数</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.intdiv, T.mod</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">//, %</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">整数除法，模数</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.floor, T.ceil, T.round</code></p>
</td><td valign="top" class="calibre22"> </td><td valign="top" class="calibre22">
<p class="calibre20">舍入运算符</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.sgn</code></p>
</td><td valign="top" class="calibre22"> </td><td valign="top" class="calibre22">
<p class="calibre20">符号</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.and_, T.xor, T.or_, T.invert</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">&amp;,^,|,~</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">按位运算符</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.gt, T.lt, T.ge, T.le</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">&gt;, &lt;, &gt;=, &lt;=</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">比较运算符</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.eq, T.neq, T.isclose</code></p>
</td><td valign="top" class="calibre22"> </td><td valign="top" class="calibre22">
<p class="calibre20">平等、不平等或接近宽容</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.isnan</code></p>
</td><td valign="top" class="calibre22"> </td><td valign="top" class="calibre22">
<p class="calibre20">与NaN(非数字)的比较</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.abs_</code></p>
</td><td valign="top" class="calibre22"> </td><td valign="top" class="calibre22">
<p class="calibre20">绝对值</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.minimum, T.maximum</code></p>
</td><td valign="top" class="calibre22"> </td><td valign="top" class="calibre22">
<p class="calibre20">最小和最大元素</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.clip</code></p>
</td><td valign="top" class="calibre22"> </td><td valign="top" class="calibre22">
<p class="calibre20">在最大值和最小值之间剪裁值</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.switch </code></p>
</td><td valign="top" class="calibre22"> </td><td valign="top" class="calibre22">
<p class="calibre20">转换</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.cast</code></p>
</td><td valign="top" class="calibre22"> </td><td valign="top" class="calibre22">
<p class="calibre20">张量型铸造</p>
</td></tr></tbody></table></div><p class="calibre8">elementwise运算符总是返回与输入数组大小相同的数组。<code class="email">T.switch</code>和<code class="email">T.clip</code>接受三个输入。</p><p class="calibre8">特别是，<code class="email">T.switch</code>将执行传统的<code class="email">switch </code>操作符:</p><div><pre class="programlisting">&gt;&gt;&gt; cond = T.vector('cond')

&gt;&gt;&gt; x,y = T.vectors('x','y')

&gt;&gt;&gt; z = T.switch(cond, x, y)

&gt;&gt;&gt; z.eval({ cond:[1,0], x:[10,10], y:[3,2] })
array([ 10.,   2.], dtype=float32)</pre></div><p class="calibre8">在<a id="id39" class="calibre1"/>相同位置<code class="email">cond</code>张量为真，结果为<code class="email">x</code>值；否则，如果为假，则具有<code class="email">y</code>值。</p><p class="calibre8">对于<code class="email">T.switch</code>运算符，有一个特定的等价形式<code class="email">ifelse</code>，它采用标量条件而不是<a id="id40" class="calibre1"/>张量条件。但是它不是一个元素式的操作，并且支持惰性求值(如果在完成之前答案是已知的，则不是所有的元素都被计算):</p><div><pre class="programlisting">&gt;&gt;&gt; <strong class="calibre2">from</strong> theano.ifelse <strong class="calibre2">import</strong> ifelse

&gt;&gt;&gt; z=ifelse(1, 5, 4)

&gt;&gt;&gt; z.eval()
array(5, dtype=int8)</pre></div></div></div></body></html>


<html>
  <head>
    <title>Operations on tensors</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch01lvl2sec13" class="calibre1"/>归约运算符</h2></div></div></div><p class="calibre8">张量的另一种<a id="id41" class="calibre1"/>操作是归约，在大多数情况下将所有元素归约为一个<a id="id42" class="calibre1"/>标量值，为此，需要扫描张量的所有元素来计算输出:</p><div><table border="1" class="calibre14"><colgroup class="calibre15"><col class="calibre16"/><col class="calibre16"/></colgroup><thead class="calibre17"><tr class="calibre18"><th valign="bottom" class="calibre19">
<p class="calibre20">操作员</p>
</th><th valign="bottom" class="calibre19">
<p class="calibre20">描述</p>
</th></tr></thead><tbody class="calibre21"><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.max, T.argmax, T.max_and_argmax</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">最大值，最大值的索引</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.min, T.argmin</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">最小值，最小值的索引</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.sum, T.prod</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">元素的和或积</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.mean, T.var, T.std</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">均值、方差和标准差</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.all, T.any</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">对所有元素进行AND和OR运算</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.ptp</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">元素范围(最小值、最大值)</p>
</td></tr></tbody></table></div><p class="calibre8">这些<a id="id43" class="calibre1"/>操作也可通过指定<a id="id44" class="calibre1"/>轴和尺寸(沿其执行缩减)来按行或按列进行:</p><div><pre class="programlisting">&gt;&gt;&gt; a = T.matrix('a')

&gt;&gt;&gt; T.max(a).eval({a:[[1,2],[3,4]]})
array(4.0, dtype=float32)

&gt;&gt;&gt; T.max(a,axis=0).eval({a:[[1,2],[3,4]]})
array([ 3.,  4.], dtype=float32)

&gt;&gt;&gt; T.max(a,axis=1).eval({a:[[1,2],[3,4]]})
array([ 2.,  4.], dtype=float32)</pre></div></div></div></body></html>


<html>
  <head>
    <title>Operations on tensors</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_4"><a id="ch01lvl2sec14" class="calibre1"/>线性代数算子</h2></div></div></div><p class="calibre8">第三类<a id="id45" class="calibre1"/>运算是线性代数运算，如矩阵乘法:</p><div><img src="img/00005.jpeg" alt="Linear algebra operators" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8"><a id="id46" class="calibre1"/>也称为向量的内积:</p><div><img src="img/00006.jpeg" alt="Linear algebra operators" class="calibre9"/></div><p class="calibre10"> </p><div><table border="1" class="calibre14"><colgroup class="calibre15"><col class="calibre16"/><col class="calibre16"/></colgroup><thead class="calibre17"><tr class="calibre18"><th valign="bottom" class="calibre19">
<p class="calibre20">操作员</p>
</th><th valign="bottom" class="calibre19">
<p class="calibre20">描述</p>
</th></tr></thead><tbody class="calibre21"><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.dot</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">矩阵乘法/内积</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">T.outer</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">外部产品</p>
</td></tr></tbody></table></div><p class="calibre8">有一些通用的(<code class="email">T.tensordot</code>来指定轴)，或者批量的(<code class="email">batched_dot, batched_tensordot</code>)版本的操作符。</p><p class="calibre8">最后，还有一些运算符非常有用，但它们不属于前面的任何类别:<code class="email">T.concatenate</code>沿着指定的维度连接张量，<code class="email">T.stack</code>创建一个新的维度来堆叠输入张量，<code class="email">T.stacklist</code>创建新的模式来将张量堆叠在一起:</p><div><pre class="programlisting">&gt;&gt;&gt; a = T.arange(10).reshape((5,2))

&gt;&gt;&gt; b = a[::-1]

&gt;&gt;&gt; b.eval()
array([[8, 9],
       [6, 7],
       [4, 5],
       [2, 3],
       [0, 1]])
&gt;&gt;&gt; a.eval()
array([[0, 1],
       [2, 3],
       [4, 5],
       [6, 7],
       [8, 9]])
&gt;&gt;&gt; T.concatenate([a,b]).eval()
array([[0, 1],
       [2, 3],
       [4, 5],
       [6, 7],
       [8, 9],
       [8, 9],
       [6, 7],
       [4, 5],
       [2, 3],
       [0, 1]])
&gt;&gt;&gt; T.concatenate([a,b],axis=1).eval()
array([[0, 1, 8, 9],
       [2, 3, 6, 7],
       [4, 5, 4, 5],
       [6, 7, 2, 3],
       [8, 9, 0, 1]])

&gt;&gt;&gt; T.stack([a,b]).eval()
array([[[0, 1],
        [2, 3],
        [4, 5],
        [6, 7],
        [8, 9]],
       [[8, 9],
        [6, 7],
        [4, 5],
        [2, 3],
        [0, 1]]])</pre></div><p class="calibre8">NumPy表达式<code class="email">a[5:] = 5</code>和<code class="email">a[5:] += 5</code>的等价<a id="id47" class="calibre1"/>作为两个函数存在:</p><div><pre class="programlisting">&gt;&gt;&gt; a.eval()
array([[0, 1],
       [2, 3],
       [4, 5],
       [6, 7],
       [8, 9]])

&gt;&gt;&gt; T.set_subtensor(a[3:], [-1,-1]).eval()

array([[ 0,  1],
       [ 2,  3],
       [ 4,  5],
       [-1, -1],
       [-1, -1]])

&gt;&gt;&gt; T.inc_subtensor(a[3:], [-1,-1]).eval()
array([[0, 1],
       [2, 3],
       [4, 5],
       [5, 6],
       [7, 8]])</pre></div><p class="calibre8">与NumPy的语法不同，原始张量没有被修改；相反，会创建一个新变量来表示修改的结果<a id="id49" class="calibre1"/>。因此，原来的<a id="id50" class="calibre1"/>变量<code class="email">a</code>仍然引用原来的值，返回的变量(此处未赋值)代表更新的变量，用户应该在剩余的计算中使用这个新变量。</p></div></div></body></html>


<html>
  <head>
    <title>Memory and variables</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch01lvl1sec13" class="calibre1"/>记忆和变量</h1></div></div></div><p class="calibre8">始终将浮点数组转换为<code class="email">theano.config.floatX</code>类型是<a id="id51" class="calibre1"/>的好习惯:</p><div><ul class="itemizedlist"><li class="listitem">要么用<code class="email">numpy.array(array, dtype=theano.config.floatX)</code>创建数组</li><li class="listitem">或者将数组转换为<code class="email">array.as_type(theano.config.floatX)</code>，以便在GPU上编译时使用正确的类型</li></ul></div><p class="calibre8">对于<a id="id52" class="calibre1"/>示例，让我们手动将数据传输到GPU(默认上下文为None)，为此，我们需要使用<code class="email">float32</code>值:</p><div><pre class="programlisting">&gt;&gt;&gt; theano.config.floatX = 'float32'

&gt;&gt;&gt; a = T.matrix()

&gt;&gt;&gt; b = a.transfer(None)

&gt;&gt;&gt; b.eval({a:numpy.ones((2,2)).astype(theano.config.floatX)})
gpuarray.array([[ 1.  1.]
 [ 1.  1.]], dtype=float32)

 &gt;&gt;&gt; theano.printing.debugprint(b)
GpuFromHost&lt;None&gt; [id A] ''   
 |&lt;TensorType(float32, matrix)&gt; [id B]</pre></div><p class="calibre8"><code class="email">transfer(device)</code>功能，如<code class="email">transfer('cpu')</code>，使我们能够将数据从一个设备移动到另一个设备。当图形的各个部分必须在不同的设备上执行时，它特别有用。否则，Theano会在优化阶段自动将传递函数添加到GPU中:</p><div><pre class="programlisting">&gt;&gt;&gt; a = T.matrix('a')

&gt;&gt;&gt; b = a ** 2

&gt;&gt;&gt; sq = theano.function([a],b)

&gt;&gt;&gt; theano.printing.debugprint(sq)
HostFromGpu(gpuarray) [id A] ''   2
 |GpuElemwise{Sqr}[(0, 0)]&lt;gpuarray&gt; [id B] ''   1
   |GpuFromHost&lt;None&gt; [id C] ''   0
     |a [id D]</pre></div><p class="calibre8">通过显式使用传递函数，Theano删除了返回CPU的传递。将输出张量留在GPU上可以节省昂贵的传输费用:</p><div><pre class="programlisting">&gt;&gt;&gt; b = b.transfer(None)

&gt;&gt;&gt; sq = theano.function([a],b)

&gt;&gt;&gt; theano.printing.debugprint(sq)
GpuElemwise{Sqr}[(0, 0)]&lt;gpuarray&gt; [id A] ''   1
 |GpuFromHost&lt;None&gt; [id B] ''   0
   |a [id C]</pre></div><p class="calibre8">CPU的<a id="id53" class="calibre1"/>默认上下文是<code class="email">cpu</code>:</p><div><pre class="programlisting">&gt;&gt;&gt; b = a.transfer('cpu')

&gt;&gt;&gt; theano.printing.debugprint(b)
&lt;TensorType(float32, matrix)&gt; [id A]</pre></div><p class="calibre8">数值和符号变量之间的一个混合概念是共享变量。它们还可以通过避免传输来提高GPU的性能。用标量零初始化共享变量:</p><div><pre class="programlisting">&gt;&gt;&gt; state = shared(0)

&gt;&gt;&gt; state

&lt;TensorType(int64, scalar)&gt;

&gt;&gt;&gt; state.get_value()
array(0)

&gt;&gt;&gt; state.set_value(1)

&gt;&gt;&gt; state.get_value()
array(1)</pre></div><p class="calibre8">共享值被设计为在函数之间共享。它们也可以被视为一种内部状态。它们可以从GPU或CPU编译代码中随意使用。默认情况下，共享变量是在默认设备(这里是<code class="email">cuda</code>)上创建的，除了标量整数值(就像前面的例子一样)。</p><p class="calibre8">可以指定另一个上下文，例如<code class="email">cpu</code>。在多个GPU实例的情况下，您将在Python命令行中定义上下文，并决定在哪个上下文中创建共享变量:</p><div><pre class="programlisting">PATH=/usr/local/cuda-8.0-cudnn-5.1/bin:$PATH THEANO_FLAGS="contexts=dev0-&gt;cuda0;dev1-&gt;cuda1,floatX=float32,gpuarray.preallocate=0.8" <strong class="calibre2">python</strong>
</pre></div><div><pre class="programlisting">&gt;&gt;&gt; from theano import theano
Using cuDNN version 5110 on context dev0
Preallocating 9151/11439 Mb (0.800000) on cuda0
Mapped name dev0 to device cuda0: Tesla K80 (0000:83:00.0)
Using cuDNN version 5110 on context dev1
Preallocating 9151/11439 Mb (0.800000) on cuda1
Mapped name dev1 to device cuda1: Tesla K80 (0000:84:00.0)

&gt;&gt;&gt; import theano.tensor as T

&gt;&gt;&gt; import numpy

&gt;&gt;&gt; theano.shared(numpy.random.random((1024, 1024)).astype('float32'),target='dev1')
&lt;GpuArrayType&lt;dev1&gt;(float32, (False, False))&gt;</pre></div></div></body></html>


<html>
  <head>
    <title>Functions and automatic differentiation</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch01lvl1sec14" class="calibre1"/>功能和自动微分</h1></div></div></div><p class="calibre8"><a id="id55" class="calibre1"/>上一节介绍了编译表达式的<code class="email">function</code>指令。在本节中，我们在其签名中开发了以下一些参数:</p><div><pre class="programlisting">
<strong class="calibre2">def</strong> theano.function(inputs, 
	<strong class="calibre2">outputs</strong>=None, <strong class="calibre2">updates</strong>=None, <strong class="calibre2">givens</strong>=None,
 <strong class="calibre2">allow_input_downcast</strong>=None, <strong class="calibre2">mode</strong>=None, <strong class="calibre2">profile</strong>=None,
  	)</pre></div><p class="calibre8">我们已经使用了<code class="email">allow_input_downcast</code>特性将数据从<code class="email">float64</code>转换成<code class="email">float32</code>、<code class="email">int64</code>转换成<code class="email">int32</code>等等。还显示了<code class="email">mode</code> <strong class="calibre2"> </strong>和<code class="email">profile</code> <strong class="calibre2"> </strong>特性，因为它们将出现在优化和调试部分。</p><p class="calibre8">Theano函数的输入变量应该包含在一个列表中，即使只有一个输入。</p><p class="calibre8">对于输出，在并行计算多个输出的情况下，可以使用列表:</p><div><pre class="programlisting">&gt;&gt;&gt; a = T.matrix()

&gt;&gt;&gt; ex = theano.function([a],[T.exp(a),T.log(a),a**2])

&gt;&gt;&gt; ex(numpy.random.randn(3,3).astype(theano.config.floatX))
[array([[ 2.33447003,  0.30287042,  0.63557744],
       [ 0.18511547,  1.34327984,  0.42203984],
       [ 0.87083125,  5.01169062,  6.88732481]], dtype=float32),
array([[-0.16512829,         nan,         nan],
       [        nan, -1.2203927 ,         nan],
       [        nan,  0.47733498,  0.65735561]], dtype=float32),
array([[ 0.71873927,  1.42671108,  0.20540957],
       [ 2.84521151,  0.08709242,  0.74417454],
       [ 0.01912885,  2.59781313,  3.72367549]], dtype=float32)]</pre></div><p class="calibre8">第二个有用的属性是<code class="email">updates</code>属性，用于在表达式求值后为共享变量设置新值:</p><div><pre class="programlisting">&gt;&gt;&gt; w = shared(1.0)

&gt;&gt;&gt; x = T.scalar('x')

&gt;&gt;&gt; mul = theano.function([x],updates=[(w,w*x)])

&gt;&gt;&gt; mul(4)
[]

&gt;&gt;&gt; w.get_value()
array(4.0)</pre></div><p class="calibre8">这种机制可以用作内部状态。共享变量<code class="email">w</code>已在函数外定义。</p><p class="calibre8">使用<code class="email">givens</code>参数，可以改变图形中任何符号变量的值，而不改变图形。新值将被指向它的所有其他表达式使用。</p><p class="calibre8">Theano中最后也是最重要的特性是自动微分，这意味着Theano计算所有以前张量算子的导数。这种区分通过<code class="email">theano.grad</code>操作器执行:</p><div><pre class="programlisting">&gt;&gt;&gt; a = T.scalar()

&gt;&gt;&gt; pow = a ** 2

&gt;&gt;&gt; g = theano.grad(pow,a)

&gt;&gt;&gt; theano.printing.pydotprint(g)

&gt;&gt;&gt; theano.printing.pydotprint(theano.function([a],g))</pre></div><div><img src="img/00007.jpeg" alt="Functions and automatic differentiation" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">在<a id="id57" class="calibre1"/>优化图中，<code class="email">theano.grad</code>已经计算了<img src="img/00008.jpeg" alt="Functions and automatic differentiation" class="calibre23"/>相对于<code class="email">a</code>的梯度，这是一个等价于<em class="calibre12"> 2 * a </em>的符号表达式。</p><p class="calibre8">注意<a id="id58" class="calibre1"/>只可能取标量的梯度，但是<em class="calibre12"> wrt </em>变量可以是任意的张量。</p></div></body></html>


<html>
  <head>
    <title>Loops in symbolic computing</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch01lvl1sec15" class="calibre1"/>符号计算中的循环</h1></div></div></div><p class="calibre8"><a id="id59" class="calibre1"/> Python <code class="email">for</code>循环可以在符号图之外使用，就像在普通的Python程序中一样。但是在图形之外，传统的Python <code class="email">for</code>循环没有被编译，因此它将<a id="id60" class="calibre1"/>不会使用并行和代数库进行优化，不能自动区分，并且如果计算子图已经针对GPU进行了优化，则会引入昂贵的数据传输。</p><p class="calibre8">这就是为什么符号操作符<code class="email">T.scan</code>被设计成创建一个<code class="email">for</code>循环作为图中的操作符。Theano会将循环展开到图结构中，整个展开的循环将在目标架构上编译，作为计算图的其余部分。其签名如下:</p><div><pre class="programlisting">
<strong class="calibre2">def</strong> scan(fn,
         <strong class="calibre2">sequences</strong>=None,
         <strong class="calibre2">outputs_info</strong>=None,
         <strong class="calibre2">non_sequences</strong>=None,
         <strong class="calibre2">n_steps</strong>=None,
         <strong class="calibre2">truncate_gradient</strong>=-1,
         <strong class="calibre2">go_backwards</strong>=False,
         <strong class="calibre2">mode</strong>=None,
         <strong class="calibre2">name</strong>=None,
         <strong class="calibre2">profile</strong>=False,
         <strong class="calibre2">allow_gc</strong>=None,
         <strong class="calibre2">strict</strong>=False)</pre></div><p class="calibre8"><code class="email">scan</code>操作符对于实现数组循环、归约、映射、多维导数(如Jacobian或Hessian)以及递归非常有用。</p><p class="calibre8"><code class="email">scan</code>操作员在<code class="email">n_steps</code>内重复运行<code class="email">fn</code>功能。如果<code class="email">n_steps</code>是<code class="email">None</code>，操作员将根据序列的长度找出:</p><div><h3 class="title2"><a id="note03" class="calibre1"/>注</h3><p class="calibre8">step <code class="email">fn</code>函数是一个构建符号图的函数，这个函数只会被调用一次。然而，该图将被编译成另一个将被重复调用的Theano函数。一些用户试图传递一个编译Theano函数作为<code class="email">fn</code>，这是不可能的。</p></div><p class="calibre8">序列<a id="id61" class="calibre1"/>是要循环的输入变量列表。步骤的编号<a id="id62" class="calibre1"/>将对应于列表中最短的顺序。让我们来看看:</p><div><pre class="programlisting">&gt;&gt;&gt; a = T.matrix()

&gt;&gt;&gt; b = T.matrix()

&gt;&gt;&gt; def fn(x): return x + 1

&gt;&gt;&gt; results, updates = theano.scan(fn, sequences=a)

&gt;&gt;&gt; f = theano.function([a], results, updates=updates)

&gt;&gt;&gt; f(numpy.ones((2,3)).astype(theano.config.floatX))

array([[ 2.,  2.,  2.],
       [ 2.,  2.,  2.]], dtype=float32)</pre></div><p class="calibre8"><code class="email">scan</code>操作符对输入张量<code class="email">a</code>中的所有元素运行函数，并保持与输入张量<code class="email">(2,3)</code>相同的形状。</p><div><h3 class="title2"><a id="note04" class="calibre1"/>注</h3><p class="calibre8">将<code class="email">theano.scan</code>返回的更新添加到<code class="email">theano.function</code>中是一个很好的做法，即使这些更新是空的。</p></div><p class="calibre8">给<code class="email">fn</code>函数的参数可能要复杂得多。<code class="email">T.scan</code>将在每一步使用以下参数列表调用<code class="email">fn</code>函数，顺序如下:</p><div><pre class="programlisting">fn( <strong class="calibre2">sequences</strong> (if any), <strong class="calibre2">prior results</strong> (if needed), <strong class="calibre2">non-sequences</strong> (if any) )</pre></div><p class="calibre8">如下图所示，三个箭头指向<code class="email">fn</code>阶跃函数，代表循环中每个时间步长的三种可能输入:</p><div><img src="img/00009.jpeg" alt="Loops in symbolic computing" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">如果指定，<code class="email">outputs_info</code>参数是用于开始重复的初始状态。参数<a id="id63" class="calibre1"/>名字听起来不太好，但是初始状态也<a id="id64" class="calibre1"/>给出了最后一个状态的形状信息，以及其他所有状态。初始状态可以看作是第一个输出。最终输出将是一个状态数组。</p><p class="calibre8">例如，要计算一个矢量中的累积和，其和的初始状态为<code class="email">0</code>，使用以下代码:</p><div><pre class="programlisting">&gt;&gt;&gt; a = T.vector()

&gt;&gt;&gt; s0 = T.scalar("s0")

&gt;&gt;&gt; def fn( current_element, prior ):
...   return prior + current_element

&gt;&gt;&gt; results, updates = theano.scan(fn=fn,outputs_info=s0,sequences=a)

&gt;&gt;&gt; f = theano.function([a,s0], results, updates=updates)

&gt;&gt;&gt; f([0,3,5],0)
<em class="calibre12">array([ 0.,  3.,  8.], dtype=float32)</em>
</pre></div><p class="calibre8">当<code class="email">outputs_info</code>被设置时，<code class="email">outputs_info</code>和序列变量的第一维是时间步长。第二个维度是每个时间步的数据维度。</p><p class="calibre8">特别是，<code class="email">outputs_info</code>有计算第一步所需的先前时间步数。</p><p class="calibre8">下面是同一个示例，但在每个时间步长使用矢量代替输入数据的标量:</p><div><pre class="programlisting">&gt;&gt;&gt; a = T.matrix()

&gt;&gt;&gt; s0 = T.scalar("s0")

&gt;&gt;&gt; def fn( current_element, prior ):
...   return prior + current_element.sum()

&gt;&gt;&gt; results, updates = theano.scan(fn=fn,outputs_info=s0,sequences=a)

&gt;&gt;&gt; f = theano.function([a,s0], results, updates=updates)

&gt;&gt;&gt; f(numpy.ones((20,5)).astype(theano.config.floatX),0)

array([   5.,   10.,   15.,   20.,   25.,   30.,   35.,   40.,   45.,
         50.,   55.,   60.,   65.,   70.,   75.,   80.,   85.,   90.,
         95.,  100.], dtype=float32)</pre></div><p class="calibre8">沿着行的二十个<a id="id65" class="calibre1"/>步骤(次)已经累积了所有元素的总和。注意由<code class="email">outputs_info</code>参数给出的初始状态(这里是<code class="email">0</code>)不是输出<a id="id66" class="calibre1"/>序列的一部分。</p><p class="calibre8">得益于<code class="email">non_sequences</code>扫描参数，循环函数<code class="email">fn</code>可提供一些固定数据，与循环中的步长无关:</p><div><pre class="programlisting">&gt;&gt;&gt; a = T.vector()

&gt;&gt;&gt; s0 = T.scalar("s0")

&gt;&gt;&gt; def fn( current_element, prior, non_seq ):
...   return non_seq * prior + current_element

&gt;&gt;&gt; results, updates = theano.scan(fn=fn,n_steps=10,sequences=a,outputs_info=T.constant(0.0),non_sequences=s0)

&gt;&gt;&gt; f = theano.function([a,s0], results, updates=updates)

&gt;&gt;&gt; f(numpy.ones((20)).astype(theano.),5)
array([  1.00000000e+00,   6.00000000e+00,   3.10000000e+01,
         1.56000000e+02,   7.81000000e+02,   3.90600000e+03,
         1.95310000e+04,   9.76560000e+04,   4.88281000e+05,
         2.44140600e+06], dtype=float32)</pre></div><p class="calibre8">它将先前的值乘以<code class="email">5</code>并添加新元素。</p><p class="calibre8">请注意，GPU上优化图中的<code class="email">T.scan</code>不会并行执行循环的不同迭代，即使没有递归。</p></div></body></html>


<html>
  <head>
    <title>Configuration, profiling and debugging</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch01lvl1sec16" class="calibre1"/>配置、剖析和调试</h1></div></div></div><p class="calibre8">出于<a id="id67" class="calibre1"/>调试<a id="id68" class="calibre1"/>的目的，ano可以打印更详细的<a id="id69" class="calibre1"/>信息，并提供不同的优化模式:</p><div><pre class="programlisting">&gt;&gt;&gt; theano.config.exception_verbosity='high'

&gt;&gt;&gt; theano.config.mode
'Mode'

&gt;&gt;&gt; theano.config.optimizer='fast_compile'</pre></div><p class="calibre8">为了使ano使用<code class="email">config.optimizer</code>值，模式必须设置为<code class="email">Mode</code>，否则将使用<code class="email">config.mode</code>中的值:</p><div><table border="1" class="calibre14"><colgroup class="calibre15"><col class="calibre16"/><col class="calibre16"/><col class="calibre16"/></colgroup><thead class="calibre17"><tr class="calibre18"><th valign="bottom" class="calibre19">
<p class="calibre20">配置模式/功能模式</p>
</th><th valign="bottom" class="calibre19">
<p class="calibre20">config.optimizer (*)</p>
</th><th valign="bottom" class="calibre19">
<p class="calibre20">描述</p>
</th></tr></thead><tbody class="calibre21"><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">FAST_RUN</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">fast_run</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">违约；最佳运行性能，缓慢编译</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">FAST_RUN</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">None</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">禁用优化</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">FAST_COMPILE</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">fast_compile</code></p>
</td><td valign="top" class="calibre22">
<p class="calibre20">减少优化次数，提高编译速度</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">None</code></p>
</td><td valign="top" class="calibre22"> </td><td valign="top" class="calibre22">
<p class="calibre20">使用默认模式，相当于<code class="literal">FAST_RUN</code>；<code class="literal">optimizer=None</code></p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">NanGuardMode</code></p>
</td><td valign="top" class="calibre22"> </td><td valign="top" class="calibre22">
<p class="calibre20">NaNs、Infs和异常大的值会引发错误</p>
</td></tr><tr class="calibre18"><td valign="top" class="calibre22">
<p class="calibre20"><code class="literal">DebugMode</code></p>
</td><td valign="top" class="calibre22"> </td><td valign="top" class="calibre22">
<p class="calibre20">编译期间的自检和断言</p>
</td></tr></tbody></table></div><p class="calibre8">与<code class="email">config.mode</code>中相同的参数可用于函数编译中的<code class="email">Mode</code>参数:</p><div><pre class="programlisting">&gt;&gt;&gt; f = theano.function([a,s0], results, updates=updates, mode='FAST_COMPILE')</pre></div><p class="calibre8">禁用<a id="id70" class="calibre1"/>优化并选择高详细度将有助于在计算图中找到错误<a id="id71" class="calibre1"/>。</p><p class="calibre8">对于GPU上的<a id="id72" class="calibre1"/>调试，您需要用环境变量<code class="email">CUDA_LAUNCH_BLOCKING</code>设置同步执行，因为GPU执行默认是完全异步的:</p><div><pre class="programlisting">  CUDA_LAUNCH_BLOCKING=1 <strong class="calibre2">python</strong>
</pre></div><p class="calibre8">为了找出计算图中延迟的来源，Theano提供了一种分析模式。</p><p class="calibre8">激活分析:</p><div><pre class="programlisting">&gt;&gt;&gt; theano.config.profile=True </pre></div><p class="calibre8">激活内存分析:</p><div><pre class="programlisting">&gt;&gt;&gt; theano.config.profile_memory=True</pre></div><p class="calibre8">激活优化阶段的分析:</p><div><pre class="programlisting">&gt;&gt;&gt; theano.config.profile_optimizer=True </pre></div><p class="calibre8">或者直接在编译期间:</p><div><pre class="programlisting">&gt;&gt;&gt; f = theano.function([a,s0], results, profile=True)

&gt;&gt;&gt; f.profile.summary()
Function profiling
==================
  Message: &lt;stdin&gt;:1
  Time in 1 calls to Function.__call__: 1.490116e-03s
  Time in Function.fn.__call__: 1.251936e-03s (84.016%)
  Time in thunks: 1.203537e-03s (80.768%)
  Total compile time: 1.720619e-01s
    Number of Apply nodes: 14
    Theano Optimizer time: 1.382768e-01s
       Theano validate time: 1.308680e-03s
    Theano Linker time (includes C, CUDA code generation/compiling): 2.405691e-02s
       Import time 1.272917e-03s
       Node make_thunk time 2.329803e-02s

Time in all call to theano.grad() 0.000000e+00s
Time since theano import 520.661s
Class
---
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;time per call&gt; &lt;type&gt; &lt;#call&gt; &lt;#apply&gt; &lt;Class name&gt;
  58.2%    58.2%       0.001s       7.00e-04s     Py       1       1   theano.scan_module.scan_op.Scan
  27.3%    85.4%       0.000s       1.64e-04s     Py       2       2   theano.sandbox.cuda.basic_ops.GpuFromHost
   6.1%    91.5%       0.000s       7.30e-05s     Py       1       1   theano.sandbox.cuda.basic_ops.HostFromGpu
   5.5%    97.0%       0.000s       6.60e-05s     C        1       1   theano.sandbox.cuda.basic_ops.GpuIncSubtensor
   1.1%    98.0%       0.000s       3.22e-06s     C        4       4   theano.tensor.elemwise.Elemwise
   0.7%    98.8%       0.000s       8.82e-06s     C        1       1   theano.sandbox.cuda.basic_ops.GpuSubtensor
   0.7%    99.4%       0.000s       7.87e-06s     C        1       1   theano.sandbox.cuda.basic_ops.GpuAllocEmpty
   0.3%    99.7%       0.000s       3.81e-06s     C        1       1   theano.compile.ops.Shape_i
   0.3%   100.0%       0.000s       1.55e-06s     C        2       2   theano.tensor.basic.ScalarFromTensor
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;time per call&gt; &lt;type&gt; &lt;#call&gt; &lt;#apply&gt; &lt;Op name&gt;
  58.2%    58.2%       0.001s       7.00e-04s     Py       1        1   forall_inplace,gpu,scan_fn}
  27.3%    85.4%       0.000s       1.64e-04s     Py       2        2   GpuFromHost
   6.1%    91.5%       0.000s       7.30e-05s     Py       1        1   HostFromGpu
   5.5%    97.0%       0.000s       6.60e-05s     C        1        1   GpuIncSubtensor{InplaceSet;:int64:}
   0.7%    97.7%       0.000s       8.82e-06s     C        1        1   GpuSubtensor{int64:int64:int16}
   0.7%    98.4%       0.000s       7.87e-06s     C        1        1   GpuAllocEmpty
   0.3%    98.7%       0.000s       4.05e-06s     C        1        1   Elemwise{switch,no_inplace}
   0.3%    99.0%       0.000s       4.05e-06s     C        1        1   Elemwise{le,no_inplace}
   0.3%    99.3%       0.000s       3.81e-06s     C        1        1   Shape_i{0}
   0.3%    99.6%       0.000s       1.55e-06s     C        2        2   ScalarFromTensor
   0.2%    99.8%       0.000s       2.86e-06s     C        1        1   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}
   0.2%   100.0%       0.000s       1.91e-06s     C        1        1   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)]
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
&lt;% time&gt; &lt;sum %&gt; &lt;apply time&gt; &lt;time per call&gt; &lt;#call&gt; &lt;id&gt; &lt;Apply name&gt;
  58.2%    58.2%       0.001s       7.00e-04s      1    12   forall_inplace,gpu,scan_fn}(TensorConstant{10}, GpuSubtensor{int64:int64:int16}.0, GpuIncSubtensor{InplaceSet;:int64:}.0, GpuFromHost.0)
  21.9%    80.1%       0.000s       2.64e-04s      1     3   GpuFromHost(&lt;TensorType(float32, vector)&gt;)
   6.1%    86.2%       0.000s       7.30e-05s      1    13   HostFromGpu(forall_inplace,gpu,scan_fn}.0)
   5.5%    91.6%       0.000s       6.60e-05s      1     4   GpuIncSubtensor{InplaceSet;:int64:}(GpuAllocEmpty.0, CudaNdarrayConstant{[ 0.]}, Constant{1})
   5.3%    97.0%       0.000s       6.41e-05s      1     0   GpuFromHost(s0)
   0.7%    97.7%       0.000s       8.82e-06s      1    11   GpuSubtensor{int64:int64:int16}(GpuFromHost.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})
   0.7%    98.4%       0.000s       7.87e-06s      1     1   GpuAllocEmpty(TensorConstant{10})
   0.3%    98.7%       0.000s       4.05e-06s      1     8   Elemwise{switch,no_inplace}(Elemwise{le,no_inplace}.0, TensorConstant{0}, TensorConstant{0})
   0.3%    99.0%       0.000s       4.05e-06s      1     6   Elemwise{le,no_inplace}(Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0, TensorConstant{0})
   0.3%    99.3%       0.000s       3.81e-06s      1     2   Shape_i{0}(&lt;TensorType(float32, vector)&gt;)
   0.3%    99.6%       0.000s       3.10e-06s      1    10   ScalarFromTensor(Elemwise{switch,no_inplace}.0)
   0.2%    99.8%       0.000s       2.86e-06s      1     5   Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}(TensorConstant{10}, Shape_i{0}.0)
   0.2%   100.0%       0.000s       1.91e-06s      1     7   Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)](Elemwise{le,no_inplace}.0, TensorConstant{0}, Elemwise{Composite{Switch(LT(i0, i1), i0, i1)}}.0, Shape_i{0}.0)
   0.0%   100.0%       0.000s       0.00e+00s      1     9   ScalarFromTensor(Elemwise{Composite{Switch(i0, i1, minimum(i2, i3))}}[(0, 2)].0)
   ... (remaining 0 Apply instances account for 0.00%(0.00s) of the runtime)</pre></div></div></body></html>


<html>
  <head>
    <title>Summary</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch01lvl1sec17" class="calibre1"/>总结</h1></div></div></div><p class="calibre8">第一个概念是符号计算，它包括构建图形，可以编译图形，然后在Python代码中我们决定的任何地方执行图形。编译后的图形就像一个函数，可以在代码中的任何地方调用。符号计算的目的是获得一个架构的抽象，图形将在这个架构上执行，以及用哪个库来编译它。如前所述，在编译期间，为目标体系结构键入符号变量。</p><p class="calibre8">第二个概念是张量，以及用来操作张量的操作符。其中大部分已经存在于基于CPU的计算库中，比如NumPy或SciPy。它们被简单地移植到符号计算中，要求在GPU上有它们的对等物。他们使用底层加速库，如BLAS、Nvidia Cuda和cuDNN。</p><p class="calibre8">Theano引入的最后一个概念是自动微分——这是深度学习中一个非常有用的功能，可以反向传播误差并根据梯度调整权重，这个过程被称为<em class="calibre12">梯度下降</em>。此外，<code class="email">scan</code>操作符使我们能够在GPU上编程循环(<code class="email">while...</code>、<code class="email">for...</code>、),并且像其他操作符一样，也可以通过反向传播来实现，这大大简化了模型的训练。</p><p class="calibre8">我们现在准备在接下来的几章中将其应用于深度学习，并在实践中了解这些知识。</p></div></body></html>
</body></html>