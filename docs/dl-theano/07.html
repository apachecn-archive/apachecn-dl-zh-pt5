<html><head/><body>
<html>
  <head>
    <title>Chapter 7. Classifying Images with Residual Networks</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch07" class="calibre1"/>第七章。用残差网络分类图像</h1></div></div></div><p class="calibre8">本章介绍用于图像分类的最新深度网络。</p><p class="calibre8">残差网络已经成为最新的架构，在准确性和更大的简单性方面有了巨大的改进。</p><p class="calibre8">在<a id="id284" class="calibre1"/>残网之前，已经有了很长的架构历史，比如<strong class="calibre2"> AlexNet </strong>、<strong class="calibre2"> VGG </strong>、<strong class="calibre2">Inception</strong>(<strong class="calibre2">Google net</strong>)、<strong class="calibre2"> Inception v2、v3、v4 </strong>。研究人员<a id="id286" class="calibre1"/>在寻找不同的概念，而<a id="id287" class="calibre1"/>发现了一些设计更好架构的潜在规则。</p><p class="calibre8">本章<a id="id288" class="calibre1"/>将阐述以下主题:</p><div><ul class="itemizedlist"><li class="listitem">用于图像分类评估的主要数据集</li><li class="listitem">图像分类的网络体系结构</li><li class="listitem">批量标准化</li><li class="listitem">全球平均池</li><li class="listitem">剩余连接</li><li class="listitem">随机深度</li><li class="listitem">密集连接</li><li class="listitem">多GPU</li><li class="listitem">数据扩充技术</li></ul></div></div></body></html>


<html>
  <head>
    <title>Chapter 7. Classifying Images with Residual Networks</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h1 class="title" id="calibre_pb_1"><a id="ch07lvl1sec67" class="calibre1"/>自然图像数据集</h1></div></div></div><p class="calibre8">图像分类通常包括比MNIST手写数字更广泛的物体和场景。其中大多数是自然图像，即人类在现实世界中观察到的图像，如风景、室内场景、道路、山脉、海滩、人物、动物和汽车，而不是合成图像或计算机生成的图像。</p><p class="calibre8">为了评估自然图像的图像分类网络的性能，研究人员通常使用三个主要的<a id="id291" class="calibre1"/>数据集来比较性能:</p><div><ul class="itemizedlist"><li class="listitem">Cifar-10, a dataset of 60,000 small images (32x32) regrouped into 10 classes only, which you can easily download:<div><pre class="programlisting">
<strong class="calibre2">wget</strong> https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz -P /sharedfiles
<strong class="calibre2">tar</strong> xvzf /sharedfiles/cifar-10-python.tar.gz -C /sharedfiles/</pre></div><p class="calibre24">以下是每个类别的一些示例图像:</p><div><img src="img/00106.jpeg" alt="Natural image datasets" class="calibre9"/><div><p class="calibre29">带有样本的Cifar 10数据集类【https://www.cs.toronto.edu/~kriz/cifar.html T21】</p></div></div><p class="calibre27"> </p></li><li class="listitem">Cifar-100是一个包含60，000幅图像的数据集，分为100个类别和20个超类别</li><li class="listitem">ImageNet，一个包含120万张图片的数据集，标注了广泛的类别(1000)。由于ImageNet仅用于非商业用途，因此可以下载Food 101，这是一个包含101种膳食的数据集，每种膳食包含1，000张图像:<div> <pre class="programlisting"> <strong class="calibre2">wget</strong> http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz -P /sharedfiles <strong class="calibre2">tar</strong> xvzf food-101.tar.gz -C /sharedfiles/</pre> </div></li></ul></div><p class="calibre8">在介绍残差架构之前，让我们讨论两种提高分类网准确度的方法:批量标准化和全局平均池。</p></div></div></body></html>


<html>
  <head>
    <title>Chapter 7. Classifying Images with Residual Networks</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch07lvl2sec23" class="calibre1"/>批量归一化</h2></div></div></div><p class="calibre8">更深的<a id="id293" class="calibre1"/>网络，超过100层<a id="id294" class="calibre1"/>可以帮助几百个类别的图像分类。深层网络的主要问题是确保输入流以及梯度从网络的一端很好地传播到另一端。</p><p class="calibre8">然而，网络中的非线性变得饱和，梯度<a id="id295" class="calibre1"/>变为零，这并不罕见。此外，网络中的每一层都必须适应其输入分布的不断变化，这种现象被称为<strong class="calibre2">内部协变量转移</strong>。</p><p class="calibre8">众所周知，网络训练更快，输入数据被线性处理以具有零均值<a id="id296" class="calibre1"/>和单位方差(被称为<strong class="calibre2">网络输入归一化</strong>)，并且独立地而不是共同地归一化每个输入特征。</p><p class="calibre8">为了<a id="id297" class="calibre1"/>标准化网络中每一层的输入，这有点复杂:将输入的平均值置零将忽略前一个<a id="id298" class="calibre1"/>层的学习偏差，对于单位方差，问题甚至更糟。当该层的输入被归一化时，前一层的参数可以无限增长，而损耗保持不变。</p><p class="calibre8">因此，对于<strong class="calibre2">层输入归一化</strong>，一个<strong class="calibre2">批量归一化层</strong>重新学习归一化后的标度和偏差:</p><div><img src="img/00107.jpeg" alt="Batch normalization" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">它不是使用整个数据集，而是使用批处理来计算归一化的统计数据，并在训练时使用移动平均值来接近整个数据集的统计数据。</p><p class="calibre8">批处理规范化图层具有以下优点:</p><div><ul class="itemizedlist"><li class="listitem">它减少了不良初始化或过高学习率的影响</li><li class="listitem">它大幅提高了网的精确度</li><li class="listitem">它加速了训练</li><li class="listitem">它减少了过度拟合，规范了模型</li></ul></div><p class="calibre8">当<a id="id299" class="calibre1"/>引入批量归一化层时，可以消除漏失，提高学习率，降低L2权重<a id="id300" class="calibre1"/>归一化。</p><p class="calibre8">注意将非线性放置在BN层之后，并消除前一层中的偏置:</p><div><pre class="programlisting">l = NonlinearityLayer(
      BatchNormLayer(
        ConvLayer(l_in,
          <strong class="calibre2">num_filters</strong>=n_filters[0],
          <strong class="calibre2">filter_size</strong>=(3,3),
          <strong class="calibre2">stride</strong>=(1,1),
          <strong class="calibre2">nonlinearity</strong>=<strong class="calibre2">None</strong>,
          <strong class="calibre2">pad</strong>=<strong class="calibre2">'same'</strong>,
          <strong class="calibre2">W</strong>=he_norm)
      ),
      <strong class="calibre2">nonlinearity</strong>=rectify
  )</pre></div></div></div></div></body></html>


<html>
  <head>
    <title>Chapter 7. Classifying Images with Residual Networks</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch07lvl2sec24" class="calibre1"/>全球平均池</h2></div></div></div><p class="calibre8">传统上，分类网络的最后两层是全连接层和softmax层。全连接图层<a id="id302" class="calibre1"/>输出的要素数量等于类的数量，softmax图层将这些值归一化为总和为1的概率。</p><p class="calibre8">首先，可以用stride 2的新卷积层替换stride 2的max-pooling层:全卷积网络的性能甚至更好。</p><p class="calibre8">其次，移除完全连接的层也是可能的。如果由最后一个卷积层输出的特征地图的数量被选择为等于类的数量，则全局空间平均将每个特征地图减少到标量值，表示在不同的<em class="calibre12">宏</em>空间位置平均的类的分数:</p><div><img src="img/00108.jpeg" alt="Global average pooling" class="calibre9"/></div><p class="calibre10"> </p></div></div></div></body></html>


<html>
  <head>
    <title>Residual connections</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch07lvl1sec68" class="calibre1"/>残留连接</h1></div></div></div><p class="calibre8">虽然<a id="id303" class="calibre1"/>非常深的架构(有许多层)性能更好，但它们更难训练，因为输入信号通过层会减少。一些人尝试在多个阶段训练深层网络。</p><p class="calibre8">除了传统的卷积<a id="id306" class="calibre1"/>层(名为<strong class="calibre2">残差</strong>)之外，这种逐层训练的另一种<a id="id304" class="calibre1"/>方法是添加一个补充连接来快捷化一个层块，名为<strong class="calibre2">身份连接</strong>，不加修改地传递<a id="id305" class="calibre1"/>信号，形成一个<strong class="calibre2">残差块</strong>，如下图所示:</p><div><img src="img/00109.jpeg" alt="Residual connections" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">这样的<a id="id307" class="calibre1"/>一个残差块由六层组成。</p><p class="calibre8">残差网络是由多个残差块组成的网络。通过第一次卷积处理输入，然后进行批量归一化和非线性处理:</p><div><img src="img/00110.jpeg" alt="Residual connections" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">例如，对于在尺寸为<em class="calibre12"> 28x28 </em>的输入图像上的第一卷积中由两个残差块和八个特征映射组成的残差网络，层输出形状将如下:</p><div><pre class="programlisting">InputLayer                       (None, 1, 28, 28)
Conv2DDNNLayer                   (None, 8, 28, 28)
BatchNormLayer                   (None, 8, 28, 28)
NonlinearityLayer                (None, 8, 28, 28)
Conv2DDNNLayer                   (None, 8, 28, 28)
BatchNormLayer                   (None, 8, 28, 28)
NonlinearityLayer                (None, 8, 28, 28)
Conv2DDNNLayer                   (None, 8, 28, 28)
ElemwiseSumLayer                 (None, 8, 28, 28)
BatchNormLayer                   (None, 8, 28, 28)
NonlinearityLayer                (None, 8, 28, 28)
Conv2DDNNLayer                   (None, 8, 28, 28)
BatchNormLayer                   (None, 8, 28, 28)
NonlinearityLayer                (None, 8, 28, 28)
Conv2DDNNLayer                   (None, 8, 28, 28)
ElemwiseSumLayer                 (None, 8, 28, 28)
BatchNormLayer                   (None, 8, 28, 28)
NonlinearityLayer                (None, 8, 28, 28)
Conv2DDNNLayer                   (None, 16, 14, 14)
BatchNormLayer                   (None, 16, 14, 14)
NonlinearityLayer                (None, 16, 14, 14)
Conv2DDNNLayer                   (None, 16, 14, 14)
Conv2DDNNLayer                   (None, 16, 14, 14)
ElemwiseSumLayer                 (None, 16, 14, 14)
BatchNormLayer                   (None, 16, 14, 14)
NonlinearityLayer                (None, 16, 14, 14)
Conv2DDNNLayer                   (None, 16, 14, 14)
BatchNormLayer                   (None, 16, 14, 14)
NonlinearityLayer                (None, 16, 14, 14)
Conv2DDNNLayer                   (None, 16, 14, 14)
ElemwiseSumLayer                 (None, 16, 14, 14)
BatchNormLayer                   (None, 16, 14, 14)
NonlinearityLayer                (None, 16, 14, 14)
Conv2DDNNLayer                   (None, 32, 7, 7)
BatchNormLayer                   (None, 32, 7, 7)
NonlinearityLayer                (None, 32, 7, 7)
Conv2DDNNLayer                   (None, 32, 7, 7)
Conv2DDNNLayer                   (None, 32, 7, 7)
ElemwiseSumLayer                 (None, 32, 7, 7)
BatchNormLayer                   (None, 32, 7, 7)
NonlinearityLayer                (None, 32, 7, 7)
Conv2DDNNLayer                   (None, 32, 7, 7)
BatchNormLayer                   (None, 32, 7, 7)
NonlinearityLayer                (None, 32, 7, 7)
Conv2DDNNLayer                   (None, 32, 7, 7)
ElemwiseSumLayer                 (None, 32, 7, 7)
BatchNormLayer                   (None, 32, 7, 7)
NonlinearityLayer                (None, 32, 7, 7)
GlobalPoolLayer                  (None, 32)
DenseLayer                       (None, 10)</pre></div><p class="calibre8"><a id="id308" class="calibre1"/>输出特征图的数量增加，而每个输出特征图的尺寸减小:这种<strong class="calibre2">减小特征图尺寸/增加维数的漏斗技术保持每层参数的数量</strong>不变，这是构建网络的常见最佳实践。</p><p class="calibre8">增加维数的三个转变发生，第一个在第一残余块之前，第二个在n个残余块之后，第三个在<em class="calibre12"> 2xn </em>残余块之后。在每次转换之间，过滤器的数量在一个数组中定义:</p><div><pre class="programlisting"># 8 -&gt; 8 -&gt; 16 -&gt; 32
n_filters = {0:8, 1:8, 2:16, 3:32}</pre></div><p class="calibre8">由相应残差块的第一层来执行尺寸增加。由于输入与输出的形状不同，简单的恒等式连接不能<a id="id309" class="calibre1"/>与块的层的输出连接，而是由尺寸投影代替，以将输出的尺寸减小到块输出的尺寸。这种投影可以用步长为<code class="email">2</code>的内核<em class="calibre12"> 1x1 </em>的卷积来完成:</p><div><pre class="programlisting">
<strong class="calibre2">def</strong> residual_block(l, transition=<strong class="calibre2">False</strong>, first=<strong class="calibre2">False</strong>, filters=16):
    <strong class="calibre2">if</strong> transition:
        first_stride = (2,2)
    <strong class="calibre2">else</strong>:
        first_stride = (1,1)

    <strong class="calibre2">if</strong> first:
        bn_pre_relu = l
    <strong class="calibre2">else</strong>:
        bn_pre_conv = BatchNormLayer(<strong class="calibre2">l</strong>)
        bn_pre_relu = NonlinearityLayer(bn_pre_conv, rectify)

    conv_1 = NonlinearityLayer(BatchNormLayer(ConvLayer(bn_pre_relu, <strong class="calibre2">num_filters</strong>=filters, <strong class="calibre2">filter_size</strong>=(3,3), <strong class="calibre2">stride</strong>=first_stride, 
          <strong class="calibre2">nonlinearity</strong>=<strong class="calibre2">None</strong>, 
          <strong class="calibre2">pad</strong>='same', 
          <strong class="calibre2">W</strong>=he_norm)),<strong class="calibre2">nonlinearity</strong>=<strong class="calibre2">rectify</strong>)

    conv_2 = ConvLayer(conv_1, <strong class="calibre2">num_filters</strong>=filters, <strong class="calibre2">filter_size</strong>=(3,3), <strong class="calibre2">stride</strong>=(1,1), <strong class="calibre2">nonlinearity</strong>=<strong class="calibre2">None</strong>, <strong class="calibre2">pad</strong>=<strong class="calibre2">'</strong>same', <strong class="calibre2">W</strong>=he_norm)

  
  # add shortcut connections
    <strong class="calibre2">if </strong>transition:
        # projection shortcut, as option B in paper
        projection = ConvLayer(bn_pre_relu, <strong class="calibre2">num_filters</strong>=filters, <strong class="calibre2">filter_size</strong>=(1,1), <strong class="calibre2">stride</strong>=(2,2), <strong class="calibre2">nonlinearity</strong>=<strong class="calibre2">None</strong>, <strong class="calibre2">pad</strong>='same', <strong class="calibre2">b</strong>=None)
    <strong class="calibre2">elif</strong> conv_2.output_shape<strong class="calibre2"> ==</strong> l.output_shape:
        projection=l
    <strong class="calibre2">else:</strong>
        projection = ConvLayer(bn_pre_relu, <strong class="calibre2">num_filters</strong>=filters, <strong class="calibre2">filter_size</strong>=(1,1), <strong class="calibre2">stride</strong>=(1,1), <strong class="calibre2">nonlinearity</strong>=<strong class="calibre2">None</strong>, <strong class="calibre2">pad</strong>='same', <strong class="calibre2">b</strong>=<strong class="calibre2">None</strong>)

    <strong class="calibre2">return</strong> ElemwiseSumLayer([conv_2, projection])</pre></div><p class="calibre8">还发明了残余块的一些变体。</p><p class="calibre8">前一个残差块的<a id="id310" class="calibre1"/>宽版本(Wide-ResNet)简单地包括随着残差块到达末尾，将每个残差块的输出数量增加一个因子:</p><div><pre class="programlisting">n_filters = {0:num_filters, 1:num_filters*width, 2:num_filters*2*width, 3:num_filters*4*width}</pre></div><p class="calibre8">瓶颈版本包括减少每层的参数数量，以创建一个具有降维效果的瓶颈，实现一起触发的Hebbian理论<em class="calibre12">神经元</em>，并帮助残余块捕获信号中特定类型的模式:</p><div><img src="img/00111.jpeg" alt="Residual connections" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8">瓶颈是同时减少要素地图的大小和输出的数量，而不是像以前的实践那样保持每个图层的参数数量不变:</p><div><pre class="programlisting">
<strong class="calibre2">def</strong> residual_bottleneck_block(l, <strong class="calibre2">transition</strong>=<strong class="calibre2">False</strong>, <strong class="calibre2">first</strong>=<strong class="calibre2">False</strong>, <strong class="calibre2">filters</strong>=16):
    <strong class="calibre2">if</strong> transition:
        first_stride = (2,2)
    <strong class="calibre2">else:</strong>
        first_stride = (1,1)

    <strong class="calibre2">if</strong> first:
        bn_pre_relu = l
   <strong class="calibre2"> else:</strong>
        bn_pre_conv = BatchNormLayer(l)
        bn_pre_relu = NonlinearityLayer(bn_pre_conv, rectify)

    bottleneck_filters = filters / 4

    conv_1 = NonlinearityLayer(BatchNormLayer(ConvLayer(bn_pre_relu, <strong class="calibre2">num_filters</strong>=bottleneck_filters,<strong class="calibre2"> filter_size</strong>=(1,1), <strong class="calibre2">stride</strong>=(1,1), <strong class="calibre2">nonlinearity</strong>=<strong class="calibre2">None</strong>, <strong class="calibre2">pad</strong>='same', <strong class="calibre2">W</strong>=he_norm)),<strong class="calibre2">nonlinearity</strong>=rectify)

    conv_2 = NonlinearityLayer(BatchNormLayer(ConvLayer(conv_1, <strong class="calibre2">num_filters</strong>=bottleneck_filters, <strong class="calibre2">filter_size</strong>=(3,3), <strong class="calibre2">stride</strong>=first_stride, <strong class="calibre2">nonlinearity</strong>=<strong class="calibre2">None</strong>,<strong class="calibre2"> pad</strong>='same', <strong class="calibre2">W</strong>=he_norm)),<strong class="calibre2">nonlinearity</strong>=rectify)

    conv_3 = ConvLayer(conv_2, <strong class="calibre2">num_filters</strong>=filters, <strong class="calibre2">filter_size</strong>=(1,1), <strong class="calibre2">stride</strong>=(1,1), <strong class="calibre2">nonlinearity</strong>=None, <strong class="calibre2">pad</strong>='same', <strong class="calibre2">W</strong>=he_norm)

   <strong class="calibre2"> if</strong> transition:
        projection = ConvLayer(bn_pre_relu, <strong class="calibre2">num_filters</strong>=filters, <strong class="calibre2">filter_size</strong>=(1,1), <strong class="calibre2">stride</strong>=(2,2), <strong class="calibre2">nonlinearity</strong>=<strong class="calibre2">None</strong>, <strong class="calibre2">pad</strong>='same', <strong class="calibre2">b</strong>=<strong class="calibre2">None</strong>)
    <strong class="calibre2">elif</strong> first:
        <strong class="calibre2">projection</strong> = ConvLayer(bn_pre_relu, <strong class="calibre2">num_filters</strong>=filters, <strong class="calibre2">filter_size</strong>=(1,1), <strong class="calibre2">stride</strong>=(1,1),<strong class="calibre2"> nonlinearity</strong>=<strong class="calibre2">None</strong>, <strong class="calibre2">pad</strong>='same', <strong class="calibre2">b</strong>=None)
    <strong class="calibre2">else:</strong>
        projection = l

    <strong class="calibre2">return</strong> ElemwiseSumLayer([conv_3, projection])</pre></div><p class="calibre8">现在，<a id="id311" class="calibre1"/>由三个剩余块堆叠而成的完整网络由以下部分构成:</p><div><pre class="programlisting">
<strong class="calibre2">def</strong> model(shape, n=18, num_filters=16, num_classes=10, width=1, <strong class="calibre2">block</strong>='normal'):
  l_in = InputLayer(shape=(<strong class="calibre2">None</strong>, shape[1], shape[2], shape[3]))
  l = NonlinearityLayer(BatchNormLayer(ConvLayer(l_in, <strong class="calibre2">num_</strong>filters=n_filters[0], <strong class="calibre2">filter_size</strong>=(3,3), <strong class="calibre2">stride</strong>=(1,1), <strong class="calibre2">nonlinearity</strong>=<strong class="calibre2">None</strong>, <strong class="calibre2">pad</strong>='same', <strong class="calibre2">W</strong>=he_norm)),<strong class="calibre2">nonlinearity</strong>=rectify)

  l = residual_block(l, <strong class="calibre2">first</strong>=<strong class="calibre2">True</strong>, <strong class="calibre2">filters</strong>=n_filters[1])
 <strong class="calibre2"> for </strong>_ <strong class="calibre2">in</strong> range(1,n):
      l = residual_block(l, <strong class="calibre2">filters</strong>=n_filters[1])

  l = residual_block(l, <strong class="calibre2">transition</strong>=True, <strong class="calibre2">filters</strong>=n_filters[2])
  <strong class="calibre2">for</strong> _ <strong class="calibre2">in</strong> range(1,n):
      l = residual_block(l, <strong class="calibre2">filters</strong>=n_filters[2])

  l = residual_block(l, <strong class="calibre2">transition</strong>=True, <strong class="calibre2">filters</strong>=n_filters[3])
  <strong class="calibre2">for</strong> _ <strong class="calibre2">in</strong> range(1,n):
      l = residual_block(l, filters=n_filters[3])

  bn_post_conv = BatchNormLayer(l)
  bn_post_relu = NonlinearityLayer(bn_post_conv, rectify)
  avg_pool = GlobalPoolLayer(bn_post_relu)
  <strong class="calibre2">return </strong>DenseLayer(avg_pool, <strong class="calibre2">num_units</strong>=num_classes, <strong class="calibre2">W</strong>=HeNormal(), <strong class="calibre2">nonlinearity</strong>=softmax)</pre></div><p class="calibre8">MNIST训练的<a id="id312" class="calibre1"/>命令:</p><div><pre class="programlisting">
<strong class="calibre2">    python</strong> train.py --dataset=mnist --n=1 --num_filters=8 --batch_size=500</pre></div><p class="calibre8">这给出了98%的最高准确率。</p><p class="calibre8">在Cifar 10上，超过100层的剩余网络需要将批大小减少到64，以适应GPU的内存:</p><div><ul class="itemizedlist"><li class="listitem">对于ResNet-110(6 x 18+2):<div><pre class="programlisting"> <strong class="calibre2">    python</strong> train.py --dataset=cifar10 --n=18 --num_filters=16 --batch_size=64</pre></div></li><li class="listitem">ResNet-164(6 x 27+2):<div><pre class="programlisting"> <strong class="calibre2">    python</strong> train.py --dataset=cifar10 --n=27 --num_filters=16 --batch_size=64</pre></div></li><li class="listitem"><div> <pre class="programlisting"> <strong class="calibre2">    python</strong> train.py --dataset=cifar10 --n=18 --num_filters=16 --width=4 --batch_size=64</pre>广ResNet-110:</div></li><li class="listitem">同ResNet-瓶颈-164: <div> <pre class="programlisting"> <strong class="calibre2">    python</strong> train.py --dataset=cifar10 --n=18 --num_filters=16 --block=bottleneck --batch_size=64</pre> </div></li><li class="listitem">对于食品-101，我进一步减少了ResNet 110的批量:<div> <pre class="programlisting"> <strong class="calibre2">    python</strong> train.py --dataset=food101 --batch_size=10 --n=18 --num_filters=16</pre> </div></li></ul></div></div></body></html>


<html>
  <head>
    <title>Stochastic depth</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch07lvl1sec69" class="calibre1"/>随机深度</h1></div></div></div><p class="calibre8">由于信号通过各层的<a id="id313" class="calibre1"/>传播可能容易在任何残留块中出错，随机深度的思想是通过随机移除一些残留块，并用相同的连接替换它们，来训练网络的鲁棒性。</p><p class="calibre8">首先，训练快得多，因为参数的数量更少。第二，在实践中，<a id="id314" class="calibre1"/>的鲁棒性得到了验证，它提供了更好的分类结果:</p><div><img src="img/00112.jpeg" alt="Stochastic depth" class="calibre9"/></div><p class="calibre10"> </p></div></body></html>


<html>
  <head>
    <title>Dense connections</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch07lvl1sec70" class="calibre1"/>密集连接</h1></div></div></div><p class="calibre8">随机<a id="id315" class="calibre1"/>深度通过创建直接连接跳过一些随机层。更进一步，除了移除一些随机层，另一种做同样事情的方法是添加与先前层的身份连接:</p><div><img src="img/00113.jpeg" alt="Dense connections" class="calibre9"/><div><p class="calibre29">密集块(密集连接的卷积网络)</p></div></div><p class="calibre10">至于残差块，密集连接的卷积网络由重复的密集块组成，以创建层块的堆栈:</p><p class="calibre8">具有密集块的网络(密集连接的卷积网络)</p><div><img src="img/00114.jpeg" alt="Dense connections" class="calibre9"/><div><p class="calibre29">A network with dense blocks (densely connected convolutional networks)</p></div></div><p class="calibre10">这种<a id="id316" class="calibre1"/>架构选择遵循的原则与第十章、<em class="calibre12">使用高级RNN </em>预测时间序列中的原则相同，对于高速公路网络:身份连接有助于信息通过网络正确传播和反向传播，当层数较高时，减少<em class="calibre12">爆炸/消失梯度</em>的影响。</p><p class="calibre8">在Python中，我们用密集连接的块替换剩余块:</p><p class="calibre8">另请注意，批量归一化是逐个特征完成的，由于每个模块的输出都已归一化，因此不需要第二次再归一化。用简单的仿射层代替批量归一化层，学习连接的归一化特征的比例和偏差就足够了:</p><div><pre class="programlisting">
<strong class="calibre2">def</strong> dense_block(network, <strong class="calibre2">transition</strong>=<strong class="calibre2">False</strong>, <strong class="calibre2">first</strong>=<strong class="calibre2">False</strong>, <strong class="calibre2">filters</strong>=16):
    <strong class="calibre2">if</strong> transition:
        network = NonlinearityLayer(BatchNormLayer(network), <strong class="calibre2">nonlinearity</strong>=rectify)
        network = ConvLayer(network,network.output_shape[1], 1, <strong class="calibre2">pad</strong>='same', <strong class="calibre2">W</strong>=he_norm, <strong class="calibre2">b</strong>=<strong class="calibre2">None</strong>, <strong class="calibre2">nonlinearity</strong>=<strong class="calibre2">None</strong>)
        network = Pool2DLayer(network, 2, <strong class="calibre2">mode</strong>='average_inc_pad')

    network = NonlinearityLayer(BatchNormLayer(network), <strong class="calibre2">nonlinearity</strong>=rectify)
    conv = ConvLayer(network,filters, 3, <strong class="calibre2">pad</strong>='same', <strong class="calibre2">W</strong>=he_norm, <strong class="calibre2">b</strong>=<strong class="calibre2">None</strong>, <strong class="calibre2">nonlinearity</strong>=<strong class="calibre2">None</strong>)
    <strong class="calibre2">return</strong> ConcatLayer([network, conv], <strong class="calibre2">axis</strong>=1)</pre></div><p class="calibre8">用于<a id="id317" class="calibre1"/>培训DenseNet-40:</p><div><pre class="programlisting">
<strong class="calibre2">def</strong> dense_fast_block(network, <strong class="calibre2">transition</strong>=<strong class="calibre2">False</strong>, <strong class="calibre2">first</strong>=<strong class="calibre2">False</strong>, <strong class="calibre2">filters</strong>=16):
    <strong class="calibre2">if</strong> transition:
        network = NonlinearityLayer(BiasLayer(ScaleLayer(network)), <strong class="calibre2">nonlinearity</strong>=rectify)
        network = ConvLayer(network,network.output_shape[1], 1, <strong class="calibre2">pad</strong>='same', <strong class="calibre2">W</strong>=he_norm, <strong class="calibre2">b</strong>=<strong class="calibre2">None</strong>, <strong class="calibre2">nonlinearity</strong>=<strong class="calibre2">None</strong>)
        network = BatchNormLayer(Pool2DLayer(network, 2, <strong class="calibre2">mode</strong>='average_inc_pad'))

    network = NonlinearityLayer(BiasLayer(ScaleLayer(network)), <strong class="calibre2">nonlinearity</strong>=rectify)
    conv = ConvLayer(network,filters, 3, <strong class="calibre2">pad</strong>='same', W=he_norm, <strong class="calibre2">b</strong>=<strong class="calibre2">None</strong>, <strong class="calibre2">nonlinearity</strong>=<strong class="calibre2">None</strong>)
    <strong class="calibre2">return</strong> ConcatLayer([network, BatchNormLayer(conv)], <strong class="calibre2">axis</strong>=<strong class="calibre2">1</strong>)</pre></div><p class="calibre8"><a id="ch07lvl1sec71" class="calibre1"/>多GPU</p><div><pre class="programlisting">
<strong class="calibre2">python</strong> train.py --dataset=cifar10 --n=13 --num_filters=16 --block=dense_fast --batch_size=64</pre></div></div></body></html>


<html>
  <head>
    <title>Multi-GPU</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0">Cifar <a id="id318" class="calibre1"/>和MNIST图像仍然很小，低于35x35像素。对自然图像的训练需要保留图像中的细节。因此，举例来说，一个好的输入大小是224x224，这是40倍。当具有这种输入大小的图像分类网络具有几百层时，GPU内存将批量大小限制为十几幅图像，因此训练一批图像需要很长时间。</h1></div></div></div><p class="calibre8">要在多GPU模式下工作:</p><p class="calibre8">模型参数在共享变量中，意味着在CPU / GPU 1 / GPU 2 / GPU 3 / GPU 4之间共享，就像在单GPU模式中一样。</p><div><ol class="orderedlist"><li class="listitem" value="1">该批被分成四份，每份被发送到不同的GPU进行计算。基于分割计算网络输出，并将梯度反向传播到每个权重。GPU返回每个权重的梯度值。</li><li class="listitem" value="2">每个权重的梯度从多个GPU取回至CPU并堆叠在一起。堆叠的梯度代表整个初始批次的梯度。</li><li class="listitem" value="3">更新规则应用于批渐变并更新共享模型权重。</li><li class="listitem" value="4">见下图:</li></ol><div/></div><p class="calibre8">稳定版本只支持每个进程一个GPU，所以在主程序中使用第一个GPU，并为每个GPU启动子进程进行训练。请注意，上图中描述的循环需要模型更新的同步，以避免每个GPU在不同步的模型上进行训练。一个排(【https://github.com/mila-udem/platoon】)框架致力于在一个节点内跨多个GPU训练你的模型，而不是自己重新编程<a id="id320" class="calibre1"/>。</p><div><img src="img/00115.jpeg" alt="Multi-GPU" class="calibre9"/></div><p class="calibre10">还要注意，在多个GPU之间同步批处理归一化均值和方差也将更加准确。</p><p class="calibre8"><a id="ch07lvl1sec72" class="calibre1"/>数据增强</p><p class="calibre8">数据<a id="id321" class="calibre1"/>增强是提高分类精度的一项非常重要的技术。数据扩充包括从现有样本创建新样本，方法是添加一些抖动，例如:</p></div></body></html>


<html>
  <head>
    <title>Data augmentation</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0">随机标度</h1></div></div></div><p class="calibre8">随机大小的作物</p><div><ul class="itemizedlist"><li class="listitem">水平翻转</li><li class="listitem">随机旋转</li><li class="listitem">照明噪声</li><li class="listitem">亮度抖动</li><li class="listitem">饱和抖动</li><li class="listitem">对比度抖动</li><li class="listitem">这将有助于模型对现实生活中常见的不同光照条件更加鲁棒。</li><li class="listitem">模型在每个时期发现不同的样本，而不是总是看到相同的数据集。</li></ul></div><p class="calibre8">请注意，输入规范化对于获得更好的结果也很重要。</p><p class="calibre8"><a id="ch07lvl1sec73" class="calibre1"/>延伸阅读</p><p class="calibre8">您可以参考以下标题了解更多信息:</p></div></body></html>


<html>
  <head>
    <title>Further reading</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0">密集连接的卷积网络，作者:黄高、刘庄、基里安·q·温伯格和劳伦斯·范德马腾，2016年12月</h1></div></div></div><p class="calibre8">代码受到了千层面库的启发:<div><ul class="itemizedlist1"><li class="listitem"><a class="calibre1" href="https://github.com/Lasagne/Recipes/blob/master/papers/deep_residual_learning/Deep_Residual_Learning_CIFAR-10.py">https://github . com/Lasagne/Recipes/blob/master/papers/Deep _ Residual _ Learning/Deep _ Residual _ Learning _ CIFAR-10 . py</a></li><li class="listitem"><a class="calibre1" href="https://github.com/Lasagne/Recipes/tree/master/papers/densenet">https://github . com/Lasagne/Recipes/tree/master/papers/dense net</a></li></ul></div></p><div><ul class="itemizedlist"><li class="listitem"><a class="calibre1" href="https://github.com/Lasagne/Recipes/blob/master/papers/deep_residual_learning/Deep_Residual_Learning_CIFAR-10.py">https://github . com/Lasagne/Recipes/blob/master/papers/Deep _ Residual _ Learning/Deep _ Residual _ Learning _ CIFAR-10 . py</a></li><li class="listitem"><a class="calibre1" href="https://github.com/Lasagne/Recipes/tree/master/papers/densenet">https://github . com/Lasagne/Recipes/tree/master/papers/dense net</a></li><li class="listitem">重新思考计算机视觉的盗梦空间架构，Christian Szegedy、Vincent Vanhoucke、Sergey Ioffe、黄邦贤·施伦斯和兹比格涅夫·沃伊纳，2015年</li><li class="listitem">广泛的剩余网络，Sergey Zagoruyko和Nikos Komodakis，2016年</li><li class="listitem">深层剩余网络中的身份映射，，何，，，任，，2016年7月</li><li class="listitem">网络中的网络，林敏，，水城燕，2013</li><li class="listitem"><a id="ch07lvl1sec74" class="calibre1"/>总结</li><li class="listitem">已经提出了新的技术来实现最先进的分类结果，例如批量标准化、全局平均池、剩余连接和密集块。</li></ul></div></div></body></html>


<html>
  <head>
    <title>Summary</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0">这些技术导致了剩余网络和密集连接网络的建立。</h1></div></div></div><p class="calibre8">使用多个GPU有助于训练图像分类网络，该网络具有大量卷积层、大接收场，并且图像的批量输入对内存使用量很大。</p><p class="calibre8">最后，我们研究了数据增强技术如何能够增加数据集的大小，减少模型过度拟合的可能性，以及为更健壮的网络学习权重。</p><p class="calibre8">在下一章中，我们将了解如何使用这些网络的早期层作为特征来构建编码器网络，以及如何反转卷积来重建输出图像以执行逐像素预测。</p><p class="calibre8">Lastly, we looked at how data augmentation techniques will enable an increase of the size of the dataset, reducing the potential of model overfitting, and learning weights for more robust networks.</p><p class="calibre8">In the next chapter, we'll see how to use the early layers of these networks as features to build encoder networks, as well as how to reverse the convolutions to reconstruct an output image to perform pixel-wise predictions.</p></div></body></html>
</body></html>