<html><head/><body>
<html>
  <head>
    <title>Chapter 8. Translating and Explaining with Encoding – decoding Networks</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch08" class="calibre1"/>第八章。用编码-解码网络翻译和解释</h1></div></div></div><p class="calibre8">当输入和输出属于同一个空间时，就会出现编码-解码技术。例如，图像分割包括将输入图像转换成新图像，即分割掩模；翻译包括将一个字符序列转换成一个新的字符序列；问答包括用一个新的单词序列来回答一个单词序列。</p><p class="calibre8">为了应对这些挑战，编码-解码网络是由两个对称部分组成的网络:编码网络和解码网络。编码器网络将输入数据编码成矢量，解码器网络将使用该矢量来产生输出，例如输入问题的<em class="calibre12">翻译</em>、回答的<em class="calibre12">、解释</em>的<em class="calibre12">或者输入句子或输入图像的<em class="calibre12">注释</em>。</em></p><p class="calibre8">编码器网络通常由前面章节中介绍的网络类型的第一层组成，没有用于维度缩减和分类的最后一层。这样一个截断的网络产生一个多维向量，称为<em class="calibre12">特征</em>，它给出一个<em class="calibre12">内部状态表示</em>，由解码器用来产生输出表示。</p><p class="calibre8">本章分解为以下几个关键概念:</p><div><ul class="itemizedlist"><li class="listitem">序列间网络</li><li class="listitem">机器翻译的应用</li><li class="listitem">应用于聊天机器人</li><li class="listitem">去进化</li><li class="listitem">应用于图像分割</li><li class="listitem">应用于图像字幕</li><li class="listitem">解码技术的改进</li></ul></div></div></body></html>


<html>
  <head>
    <title>Chapter 8. Translating and Explaining with Encoding – decoding Networks</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h1 class="title" id="calibre_pb_1"><a id="ch08lvl1sec75" class="calibre1"/>用于自然语言处理的序列对序列网络</h1></div></div></div><p class="calibre8">基于规则的系统正在被端到端的神经网络所取代，因为它们在性能上有所提高<a id="id323" class="calibre1"/>。</p><p class="calibre8">一个<a id="id324" class="calibre1"/>端到端的神经网络意味着网络通过例子直接推断所有可能的规则，而不知道底层的规则，例如语法和共轭；单词(或字符)作为输入直接送入<a id="id325" class="calibre1"/>网络。输出格式也是如此，可以直接是word索引本身。网络的结构负责学习带有系数的规则。</p><p class="calibre8">这种应用于<strong class="calibre2">自然语言处理</strong> ( <strong class="calibre2"> NLP </strong>)的端到端编解码网络的架构选择是<strong class="calibre2">序列到序列网络</strong>，如下图所示:</p><div><img src="img/00116.jpeg" alt="Sequence-to-sequence networks for natural language processing" class="calibre9"/></div><p class="calibre10">利用查找表将单词索引转换成它们在嵌入空间中的连续多维值。在<a class="calibre1" title="Chapter 3. Encoding Word into Vector" href="part0040_split_000.html#164MG1-ccdadb29edc54339afcb9bdf9350ba6b">第3章</a>、<em class="calibre12">将单词编码成向量</em>中介绍的这种转换是将离散单词索引编码成神经网络可以处理的高维空间的关键步骤。</p><p class="calibre8">然后，对输入单词嵌入运行第一LSTM堆栈，以编码输入并产生思维向量。以该向量作为初始内部状态来启动第二个LSTM堆栈，并且期望为目标句子中的每个单词产生下一个单词。</p><p class="calibre8">在<a id="id326" class="calibre1"/>的核心，是LSTM单元的经典阶跃函数，具有输入、遗忘、输出和单元门:</p><p class="calibre8">一个简单的闭包比一个类更好。一个类没有足够的方法和参数。写作课强制加很多<code class="email">self</code>。在所有变量之前，一个<code class="email">__init__</code>方法。</p><div><pre class="programlisting">
<strong class="calibre2">def </strong>LSTM( hidden_size):
  W <strong class="calibre2">=</strong> shared_norm((hidden_size, 4<strong class="calibre2">*</strong>hidden_size))
  U <strong class="calibre2">=</strong> shared_norm((hidden_size, 4<strong class="calibre2">*</strong>hidden_size))
  b <strong class="calibre2">=</strong> shared_zeros(4<strong class="calibre2">*</strong>hidden_size)

  params <strong class="calibre2">=</strong> [W, U, b]

  <strong class="calibre2">def</strong> forward(m, X, h_, C_ ):
    XW = T.dot(X, W)
    h_U = T.dot(h_, U)
    bfr_actv = XW + h_U + b

    f = T.nnet.sigmoid( bfr_actv[:, 0:hidden_size] )
    i = T.nnet.sigmoid( bfr_actv[:, 1<strong class="calibre2">*</strong>hidden_size:2*hidden_size] )
    o = T.nnet.sigmoid( bfr_actv[:, 2<strong class="calibre2">*</strong>hidden_size:3*hidden_size] )
    Cp = T.tanh( bfr_actv[:, 3<strong class="calibre2">*</strong>hidden_size:4*hidden_size] )

    C = i<strong class="calibre2">*</strong>Cp + f<strong class="calibre2">*</strong>C_
    h = o<strong class="calibre2">*</strong>T.tanh( C )
    C = m[:, None]<strong class="calibre2">*</strong>C + (1.0 - m)[:, None]<strong class="calibre2">*</strong>C_
    h = m[:, None]<strong class="calibre2">*</strong>h + (1.0 - m)[:, None]<strong class="calibre2">*</strong>h_

    h, C = T.cast(h, theano.config.floatX), T.cast(h, theano.config.floatX)
    <strong class="calibre2">return</strong> h, C

  <strong class="calibre2">return</strong> forward<strong class="calibre2">, </strong>params</pre></div><p class="calibre8">为了降低计算成本，将层的全部堆叠构建到单步函数中，并将递归添加到最后一层的输出为每个时间步长产生的全部堆叠阶跃函数的顶部。其他一些实现的每一层都是独立循环的，效率要低得多(慢了两倍多)。</p><p class="calibre8">在<em class="calibre12"> X </em>输入的顶部，屏蔽变量<code class="email">m</code>在设置为零时停止循环:当没有更多数据时(屏蔽值为零)，隐藏和单元格状态保持不变。因为输入是成批处理的，所以每批中的句子可以具有不同的长度，并且由于有了掩码，一批中的所有句子可以以相同数量的步骤并行处理，对应于最大的句子长度。对于批中的每一行，重复在不同的位置停止。</p><p class="calibre8"><a id="id327" class="calibre1"/>关闭一个类的原因是因为该模型不能像前面的例子那样直接应用于一些符号输入变量:事实上，该模型应用于递归循环内的序列(使用扫描操作符)。由于这个原因，在许多高级深度学习框架中，每一层都被设计为一个模块，该模块公开了一种前向/后向方法，以添加到各种架构中(并行分支和递归)，如本例所示。</p><p class="calibre8">编码器/解码器的全堆栈阶跃函数被放置在它们各自的递归循环中，可以设计如下:</p><p class="calibre8"><a id="id328" class="calibre1"/>第一部分是输入到嵌入空间的转换。第二部分是LSTM层的堆栈。对于解码器(当<code class="email">target_voca_size != 0</code>时)，增加一个线性层来计算输出。</p><div><pre class="programlisting">
<strong class="calibre2">def stack</strong>( voca_size, hidden_size, num_layers, <strong class="calibre2">embedding</strong>=<strong class="calibre2">None</strong>, <strong class="calibre2">target_voca_size</strong>=0):
    params <strong class="calibre2">=</strong> []

    <strong class="calibre2">if</strong> embedding <strong class="calibre2">==</strong> None:
        embedding = shared_norm( (voca_size, hidden_size) )
        params.append(embedding)

    layers = []
    <strong class="calibre2">for</strong> i <strong class="calibre2">in</strong> range(num_layers):
        f, p = LSTM(hidden_size)
        layers.append(f)
        params += p

    <strong class="calibre2">def </strong>forward( mask, inputs, h_, C_, <strong class="calibre2">until_symbol</strong> = <strong class="calibre2">None</strong>):
        <strong class="calibre2">if</strong> until_symbol <strong class="calibre2">== </strong>None :
            output = embedding[inputs]
        <strong class="calibre2">else</strong>:
            output = embedding[T.cast( inputs.argmax(axis=-1), "int32" )]

        hos = []
        Cos = []
      <strong class="calibre2">for</strong> i <strong class="calibre2">in</strong> range(num_layers):
            hs, Cs = layers[i](mask, output, h_[i], C_[i])
            hos.append(hs)
            Cos.append(Cs)
            output = hs

        <strong class="calibre2">if</strong> target_voca_size <strong class="calibre2">!=</strong> 0:
            output_embedding = shared_norm((hidden_size, target_voca_size))
            params.append(output_embedding)
            output = T.dot(output, output_embedding)

        outputs = (T.cast(output, theano.config.floatX),T.cast(hos, theano.config.floatX),T.cast(Cos, theano.config.floatX))

        <strong class="calibre2">if</strong> until_symbol <strong class="calibre2">!=</strong> None:
            <strong class="calibre2">return </strong>outputs, theano.scan_module.until( T.eq(output.argmax(<strong class="calibre2">axis</strong>=-1)[0], until_symbol) )

        <strong class="calibre2">return</strong> outputs

    <strong class="calibre2">return</strong> forward<strong class="calibre2">, </strong>params</pre></div><p class="calibre8">现在我们已经有了编码器/解码器步进函数，让我们来构建完整的编码器-解码器网络。</p><p class="calibre8">首先，编码器-解码器网络必须将输入编码为内部状态表示:</p><p class="calibre8">为了对输入进行编码，对每个单词循环运行编码堆栈步骤函数。</p><div><pre class="programlisting">encoderInputs, encoderMask = T.imatrices(2)
h0,C0 = T.tensor3s(2)

encoder, encoder_params = stack(valid_data.source_size, opt.hidden_size, opt.num_layers)

([encoder_outputs, hS, CS], encoder_updates) = theano.scan(
  <strong class="calibre2">fn</strong> = encoder,
  <strong class="calibre2">sequences</strong> = [encoderMask, encoderInputs],
  <strong class="calibre2">outputs_info</strong> = [<strong class="calibre2">None</strong>, h0, C0])</pre></div><p class="calibre8">当<code class="email">outputs_info</code>由三个变量组成时，扫描操作者认为扫描操作的输出由三个值组成。</p><p class="calibre8">这些输出来自编码堆栈阶跃函数，对应于:</p><p class="calibre8">堆栈的输出</p><div><ul class="itemizedlist"><li class="listitem">堆栈的隐藏状态，以及</li><li class="listitem">对于输入句子的每个步骤/单词，堆栈的单元状态</li><li class="listitem">在<code class="email">outputs_info</code>中，<code class="email">None</code>表示考虑编码器会产生三个输出，但只有最后两个会反馈到阶跃函数中(<code class="email">h0 -&gt; h_</code>和<code class="email">C0 -&gt; C_</code>)。</li></ul></div><p class="calibre8">假定<a id="id329" class="calibre1"/>序列指向两个序列，扫描操作的阶跃函数必须处理四个参数。</p><p class="calibre8">然后，一旦输入的句子被编码成向量，编码器-解码器网络就对其进行解码:</p><p class="calibre8">编码器网络的最后状态<code class="email">hS[-1]</code>、<code class="email">CS[-1]]</code>作为解码器网络的初始隐藏和单元状态。</p><div><pre class="programlisting">decoderInputs, decoderMask, decoderTarget = T.imatrices(<strong class="calibre2">3</strong>)

decoder, decoder_params = stack(valid_data.target_size, opt.hidden_size, opt.num_layers, <strong class="calibre2">target_voca_size</strong>=valid_data.target_size)

([decoder_outputs, h_vals, C_vals], decoder_updates) = theano.scan(
  <strong class="calibre2">fn</strong> = decoder,
  <strong class="calibre2">sequences</strong> = [decoderMask, decoderInputs],
  <strong class="calibre2">outputs_info</strong> = [None, hS[<strong class="calibre2">-1</strong>], CS[<strong class="calibre2">-1</strong>]])

params = <strong class="calibre2">encoder_params</strong> + <strong class="calibre2">decoder_params</strong>
</pre></div><p class="calibre8">在输出的基础上计算对数似然性与上一章序列中的相同。</p><p class="calibre8">为了进行评估，必须将最后一个预测的字输入到解码器的输入端，以预测下一个字，这与输入和输出序列已知的训练有点不同:</p><p class="calibre8">For evaluation, the last predicted word has to be fed into the input of the decoder to predict the next word, which is a bit different from training, where input and output sequences are known:</p><div><img src="img/00117.jpeg" alt="Sequence-to-sequence networks for natural language processing" class="calibre9"/></div><p class="calibre10">在这种情况下，<code class="email">outputs_info</code>中的<code class="email">None</code>可以替换为初始值<code class="email">prediction_start</code>，即<code class="email">start</code>令牌。由于不再是<code class="email">None</code>，只要与<code class="email">h0</code>和<code class="email">C0</code>在一起，这个初始值将<a id="id330" class="calibre1"/>馈入解码器的步进函数。扫描算子认为在每一步有三个先前的值馈入解码器函数(而不是像以前那样有两个)。由于从输入序列中删除了<code class="email">decoderInputs</code>,解码器堆栈阶跃函数的参数数量仍为4:使用之前的预测输出值代替输入值。这样，相同的解码器功能可以用于训练和预测:</p><p class="calibre8">非序列参数<code class="email">valid_data.idx_stop</code>向解码器步进函数<a id="id331" class="calibre1"/>指示其处于预测模式，意味着输入不是字索引，而是其先前的输出(需要找到最大索引)。</p><div><pre class="programlisting">prediction_mask = theano.shared(np.ones(( opt.max_sent_size, 1), <strong class="calibre2">dtype=</strong>"int32"))

prediction_start = np.zeros(( 1, valid_data.target_size), dtype=theano.config.floatX)
prediction_start[0, valid_data.idx_start] = 1
prediction_start = theano.shared(prediction_start)

([decoder_outputs, h_vals, C_vals], decoder_updates) = theano.scan(
  <strong class="calibre2">fn</strong> = decoder,
  <strong class="calibre2">sequences</strong> = [prediction_mask],
  <strong class="calibre2">outputs_info</strong> = [prediction_start, hS[-1], CS[-1]],
  <strong class="calibre2">non_sequences</strong> = valid_data.idx_stop
  )</pre></div><p class="calibre8">同样在预测模式下，一次预测一句话(批量大小为<code class="email">1</code>)。由于解码器堆栈阶跃函数中的<code class="email">theano.scan_module.until</code>输出，当<code class="email">end</code>令牌产生时，循环停止，并且不需要解码更多的字。</p><p class="calibre8"><a id="ch08lvl1sec76" class="calibre1"/> Seq2seq为翻译</p></div></div></body></html>


<html>
  <head>
    <title>Seq2seq for translation</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0"><strong class="calibre2">序列对序列</strong> ( <strong class="calibre2"> Seq2seq </strong>)网络<a id="id332" class="calibre1"/>首次应用于语言翻译。</h1></div></div></div><p class="calibre8">已经为计算语言学协会的会议设计了翻译任务，数据集WMT16由不同语言的新闻翻译组成。该数据集的目的是评估新的翻译系统或技术。我们将使用德语-英语数据集。</p><p class="calibre8">首先，对数据进行预处理:<div> <pre class="programlisting"> <strong class="calibre2">python</strong> 0-preprocess_translations.py --srcfile data/src-train.txt --targetfile data/targ-train.txt --srcvalfile data/src-val.txt --targetvalfile data/targ-val.txt --outputfile data/demo First pass through data to get vocab... Number of sentences in training: 10000 Number of sentences in valid: 2819 Source vocab size: Original = 24995, Pruned = 24999 Target vocab size: Original = 35816, Pruned = 35820 (2819, 2819) Saved 2819 sentences (dropped 181 due to length/unk filter) (10000, 10000) Saved 10000 sentences (dropped 0 due to length/unk filter) Max sent length (before dropping): 127</pre> </div></p><div><ol class="orderedlist"><li class="listitem" value="1">乍一看，你会注意到一个历元的GPU时间是<em class="calibre12"> 445.906425953 </em>，因此比在CPU上快十倍(<em class="calibre12"> 4297.15962195 </em>)。</li><li class="listitem" value="2">Train the <code class="email">Seq2seq</code> network:<div><pre class="programlisting">
<strong class="calibre2">python</strong> 1-train.py  --dataset translation</pre></div><p class="calibre24">一旦<a id="id335" class="calibre1"/>训练完毕，将你的英语句子翻译成德语，加载训练好的模型:<div> <pre class="programlisting"> <strong class="calibre2">python</strong> 1-train.py  --dataset translation --model model_translation_e100_n2_h500</pre> </div></p></li><li class="listitem" value="3"><a id="ch08lvl1sec77" class="calibre1"/>聊天机器人的Seq2seq</li></ol><div/></div></div></body></html>


<html>
  <head>
    <title>Seq2seq for chatbots</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0">序列对序列网络的第二个目标应用是问答或聊天机器人。</h1></div></div></div><p class="calibre8">为此，下载康奈尔电影对话语料库并对其进行预处理:</p><p class="calibre8">这个语料库包含了从原始电影剧本中提取的大量元数据丰富的虚构对话。</p><div><pre class="programlisting">
<strong class="calibre2">wget</strong> http://www.mpi-sws.org/~cristian/data/cornell_movie_dialogs_corpus.zip -P /sharedfiles/
<strong class="calibre2">unzip</strong> /sharedfiles/cornell_movie_dialogs_corpus.zip  -d /sharedfiles/cornell_movie_dialogs_corpus

<strong class="calibre2">python </strong>0-preprocess_movies.py</pre></div><p class="calibre8">由于源句子和目标句子使用相同的语言，它们使用相同的词汇，解码网络可以使用与编码网络相同的单词嵌入:</p><p class="calibre8">同样的命令也适用于<code class="email">chatbot</code>数据集:</p><div><pre class="programlisting">
<strong class="calibre2">if</strong> opt.dataset <strong class="calibre2">==</strong> "chatbot":
    embeddings = encoder_params[0]</pre></div><p class="calibre8"><a id="ch08lvl1sec78" class="calibre1"/>提高序列间网络的效率</p><div><pre class="programlisting">
<strong class="calibre2">python</strong> 1-train.py  --dataset chatbot # training
<strong class="calibre2">python</strong> 1-train.py  --dataset chatbot --model model_chatbot_e100_n2_h500 # answer my question</pre></div></div></body></html>


<html>
  <head>
    <title>Improving efficiency of sequence-to-sequence network</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0">在聊天机器人的例子中，首先要注意的有趣的一点是逆序输入序列:这种技术已经被证明可以改善结果。</h1></div></div></div><p class="calibre8">对于翻译，通常使用双向LSTM来计算内部状态，如<a class="calibre1" title="Chapter 5. Analyzing Sentiment with a Bidirectional LSTM" href="part0060_split_000.html#1P71O2-ccdadb29edc54339afcb9bdf9350ba6b">第5章</a>、<em class="calibre12">使用双向LSTM分析情绪</em>所示:两个lstm，一个以正向顺序运行，另一个以反向顺序运行，在序列上并行运行，并且它们的输出被连接:</p><p class="calibre8">For translation, it is very common then to use a bidirectional LSTM to compute the internal state as seen in <a class="calibre1" title="Chapter 5. Analyzing Sentiment with a Bidirectional LSTM" href="part0060_split_000.html#1P71O2-ccdadb29edc54339afcb9bdf9350ba6b">Chapter 5</a>, <em class="calibre12">Analyzing Sentiment with a Bidirectional LSTM</em>: two LSTMs, one running in the forward order, the other in the reverse order, run in parallel on the sequence, and their outputs are concatenated:</p><div><img src="img/00118.jpeg" alt="Improving efficiency of sequence-to-sequence network" class="calibre9"/></div><p class="calibre10">考虑到未来和过去，这种机制可以获取更好的信息。</p><p class="calibre8">另一项技术是<em class="calibre12">注意力机制</em>，这将是下一章的重点。</p><p class="calibre8">最后，<em class="calibre12">细化技术</em>已经开发完成，并通过二维网格LSTM进行了测试，这些技术离叠加LSTM不远(唯一的区别是深度/叠加方向上的门控机制):</p><p class="calibre8">网格长短期记忆</p><div><img src="img/00119.jpeg" alt="Improving efficiency of sequence-to-sequence network" class="calibre9"/><div><p class="calibre29">Grid long short-term memory</p></div></div><p class="calibre10">细化的原则是在输入句子上按两种顺序运行堆栈。这一公式背后的想法是让编码器网络在正向编码句子后重新访问或重新编码句子，并隐式捕获<a id="id338" class="calibre1"/>一些时间模式。还要注意，2D网格为这种重新编码提供了更多可能的相互作用，在每个预测步骤对向量进行重新编码，使用先前输出的单词作为下一个预测单词的方向。所有这些改进都与更大的<a id="id339" class="calibre1"/>计算能力有关，对于这个再编码器网络来说为<strong class="calibre2">O(n m)</strong>(<em class="calibre12">n</em>和<em class="calibre12"> m </em>表示输入和目标句子的长度)，而对于编码器-解码器网络来说为<strong class="calibre2"> O(n+m) </strong>。</p><p class="calibre8">所有这些技术都减少了困惑。训练模型时，也考虑使用<strong class="calibre2">波束搜索算法</strong>，该算法将在每个时间步跟踪前N个可能的预测及其概率，而不是一个，以避免第一个位置的一个坏预测排序可能导致进一步错误预测的可能性。</p><p class="calibre8"><a id="ch08lvl1sec79" class="calibre1"/>图像去卷积</p></div></body></html>


<html>
  <head>
    <title>Deconvolutions for images</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0">在图像的<a id="id340" class="calibre1"/>案例中，研究人员一直在寻找与编码卷积相反的解码操作。</h1></div></div></div><p class="calibre8">第一个应用是对卷积网络的分析和理解，如在第2章、<em class="calibre12">中看到的，使用前馈网络</em>对手写数字进行分类，该网络由卷积层、最大池层和校正线性单元组成。为了更好地理解网络，其思想是将图像中对于网络的给定单元最有区别的部分可视化:高级特征图中的一个单个神经元保持非零，并且从该激活，信号被反向传播回2D输入。</p><p class="calibre8">为了通过最大汇集层重建<a id="id341" class="calibre1"/>信号，想法是在正向传递期间跟踪每个汇集区域内的最大值的位置。名为<strong class="calibre2"> DeConvNet </strong>的这种架构可以表示为:</p><p class="calibre8">可视化和理解卷积网络</p><div><img src="img/00120.jpeg" alt="Deconvolutions for images" class="calibre9"/><div><p class="calibre29">Visualizing and understanding convolutional networks</p></div></div><p class="calibre10">信号被反向传播到在正向传递期间具有最大值的位置。</p><p class="calibre8">为了通过ReLU层重建信号，已经提出了三种方法:</p><p class="calibre8"><em class="calibre12">反向传播</em>仅反向传播到正的位置</p><div><ul class="itemizedlist"><li class="listitem"><em class="calibre12">反向去配置</em>仅反向传播正梯度</li><li class="listitem"><em class="calibre12">导向反向传播</em>仅反向传播到满足前两个条件的位置，即正向传递期间的正输入和正梯度</li><li class="listitem"><a id="id342" class="calibre1"/>方法如下图所示:</li></ul></div><p class="calibre8">The <a id="id342" class="calibre1"/>methods are illustrated in the following figure:</p><div><img src="img/00121.jpeg" alt="Deconvolutions for images" class="calibre9"/></div><p class="calibre10">来自第一层的反向传播给出了各种类型的滤波器:</p><p class="calibre8">The retro-propagation from the first layers gives various sorts of filter:</p><div><img src="img/00122.jpeg" alt="Deconvolutions for images" class="calibre9"/></div><p class="calibre10">然而，<a id="id343" class="calibre1"/>从网络中的更高层，引导反向传播给出了更好的结果:</p><p class="calibre8">However, <a id="id343" class="calibre1"/>from higher layers in the network, the guided back-propagation gives much better results:</p><div><img src="img/00123.jpeg" alt="Deconvolutions for images" class="calibre9"/></div><p class="calibre10">还可以对输入图像的反向传播进行调节，这将激活一个以上的神经元，反向传播将从这些神经元应用，以获得更精确的输入可视化:</p><p class="calibre8">It is also possible to condition the back-propagation on an input image, that will activate more than one neuron, from which the retro-propagation will be applied, to get a more precise input visualization:</p><div><img src="img/00124.jpeg" alt="Deconvolutions for images" class="calibre9"/></div><p class="calibre10"><a id="id344" class="calibre1"/>反向传播也可以应用于原始输入图像，而不是空白图像，这一过程被Google <a id="id345" class="calibre1"/> research命名为<strong class="calibre2">概念主义</strong>，当反向传播用于增加输出概率时:</p><p class="calibre8">The <a id="id344" class="calibre1"/>back-propagation can also be applied to the original input image rather than a blank one, a process that has been named <strong class="calibre2">Inceptionism</strong> by Google <a id="id345" class="calibre1"/>research, when retro-propagation is used to augment the output probability:</p><div><img src="img/00125.jpeg" alt="Deconvolutions for images" class="calibre9"/></div><p class="calibre10">但是<a id="id346" class="calibre1"/>去卷积的主要目的是用于场景分割或图像语义分析，其中去卷积由学习的<a id="id347" class="calibre1"/>上采样卷积代替，例如在<strong class="calibre2"> SegNet网络</strong>中:</p><p class="calibre8">SegNet:一种用于图像分割的深度卷积编解码器架构</p><div><img src="img/00126.jpeg" alt="Deconvolutions for images" class="calibre9"/><div><p class="calibre29"> SegNet: A deep convolutional encoder-decoder architecture for image segmentation</p></div></div><p class="calibre10">在去卷积过程的每一步，较低的输入特征通常被连接到<a id="id348" class="calibre1"/>当前特征以进行上采样。</p><p class="calibre8"><strong class="calibre2">深度遮罩网络</strong>采用了一种混合方法，只对包含<a id="id349" class="calibre1"/>物体的面片进行解卷积。为此，它在包含对象的224x224的输入小块上(平移+/- 16像素)而不是在整个图像上进行训练:</p><p class="calibre8">学习分割候选对象</p><div><img src="img/00127.jpeg" alt="Deconvolutions for images" class="calibre9"/><div><p class="calibre29">Learning to segment object candidates</p></div></div><p class="calibre10">编码器(VGG-16)网络的卷积具有因子16的下采样，导致14×14的特征图。</p><p class="calibre8">联合学习训练两个分支，一个用于分割，一个用于如果对象在面片中存在、居中并处于正确比例时的评分。</p><p class="calibre8">感兴趣的分支是语义分支，其从14×14的特征图向上采样到小块中的对象的56×56的分割图。如果满足以下条件，则可以进行上采样:</p><p class="calibre8">完全连接的图层，这意味着上采样地图中的每个位置都取决于所有要素，并且具有预测值的全局图片</p><div><ul class="itemizedlist"><li class="listitem">卷积(或局部连接层)，减少了参数的数量，但也用局部视图预测了每个位置得分</li><li class="listitem">一种混合方法，由两个线性层组成，它们之间没有非线性，以某种方式执行降维，如上图所示</li><li class="listitem">然后，通过简单的双线性上采样层将<a id="id350" class="calibre1"/>输出蒙版上采样回原始面片尺寸224x224。</li></ul></div><p class="calibre8">为了处理完整的输入图像，完全连接的层可以被变换成卷积，其核大小等于完全连接的层的输入大小并且具有相同的系数，从而当将<a id="id351" class="calibre1"/>应用于完整的图像时，网络变成完全卷积的，步长为16。</p><p class="calibre8">由于序列到序列网络已经通过双向重新编码机制进行了改进，<strong class="calibre2"> SharpMask </strong>方法使用输入卷积特征在等效尺度上提高了上采样去卷积过程的清晰度:</p><p class="calibre8">学习细化对象段</p><div><img src="img/00128.jpeg" alt="Deconvolutions for images" class="calibre9"/><div><p class="calibre29">Learning to refine object segments</p></div></div><p class="calibre10">虽然SegNet方法仅从通过跟踪最大池索引产生的上采样图中学习去卷积，但SharpMask方法直接重用输入<a id="id352" class="calibre1"/>特征图，这是粗粒度到细粒度方法的一种非常常用的技术。</p><p class="calibre8">最后，请记住<a id="id353" class="calibre1"/>可以通过应用<strong class="calibre2">条件随机场</strong> ( <strong class="calibre2"> CRF </strong>)后处理步骤进一步改善结果，无论是一维输入(如文本)还是二维输入(如分割图像)。</p><p class="calibre8"><a id="ch08lvl1sec80" class="calibre1"/>多模态深度学习</p></div></body></html>


<html>
  <head>
    <title>Multimodal deep learning</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0">为了进一步开放可能的应用，编码-解码框架可以应用于不同的模态，例如图像字幕。</h1></div></div></div><p class="calibre8">图像字幕包括用文字描述图像的内容。输入是一幅图像，通过一个深度卷积网络自然地编码成一个思想向量。</p><p class="calibre8">描述图像内容的文本可以用与解码器相同的LSTM网络堆栈从该内部状态向量中产生，如Seq2seq网络:</p><p class="calibre8">The text to describe the content of the image can be produced from this internal state vector with the same stack of LSTM networks as a decoder, as in Seq2seq networks:</p><p class="calibre8"> </p><div><img src="img/00129.jpeg" alt="Multimodal deep learning" class="calibre9"/></div><p class="calibre10"> </p><p class="calibre8"><a id="ch08lvl1sec81" class="calibre1"/>延伸阅读</p></div></body></html>


<html>
  <head>
    <title>Further reading</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0">请参考以下主题以获得更好的见解:</h1></div></div></div><p class="calibre8"><em class="calibre12">神经网络的序列对序列学习</em>，伊利亚·苏茨基弗，奥里奥尔·维尼亚尔斯，Quoc V. Le，2014年12月</p><div><ul class="itemizedlist"><li class="listitem"><em class="calibre12">使用统计机器翻译的RNN编码器-解码器学习短语表示</em>，赵京云，巴特·范·梅里恩博尔，卡格拉尔·古尔切雷，迪米特里·巴丹瑙，费特希·布加雷斯，霍尔格·施文克，约舒阿·本吉奥，2014年9月</li><li class="listitem"><em class="calibre12">联合学习对齐和翻译的神经机器翻译</em>，Dzmitry Bahdanau，Kyunghyun Cho，Yoshua Bengio，2016年5月</li><li class="listitem"><em class="calibre12">一个神经对话模型</em>，Oriol Vinyals，Quoc Le，2015年7月</li><li class="listitem"><em class="calibre12">用于统计机器翻译的快速和稳健的神经网络联合模型</em>，Jacob Devlin，Rabih Zbib，Huang，Thomas Lamar，Richard Schwartz，John Mkahoul，2014</li><li class="listitem">SYSTRAN的纯神经机器翻译系统<em class="calibre12">、Josep Crego、Jungi Kim、Guillaume Klein、、Kathy Yang、Jean Senellart、、Akhanov、Patrice Brunelle、Aurelien Coquard、Yongchao Deng、Satoshi Enoue、Chiyo Geiss、Joshua Johanson、Ardas Khalsa、Raoum Khiari、Byeongil Ko、Catherine Kobus、Jean Lorieux、Leidiana Martins、Dang-Chuan Nguyen、Alexandra Priori、Thomas Riccardi、Natalia Segal</em></li><li class="listitem"><em class="calibre12">布鲁:一种自动评估机器翻译的方法，</em>基肖尔·帕皮尼，萨利姆·鲁科斯，托德·沃德，魏·，2002</li><li class="listitem">ACL 2016翻译任务</li><li class="listitem"><em class="calibre12">想象对话中的变色龙:理解对话中语言风格协调的新方法</em>，Cristian Danescu-NiculescuMizil和Lillian Lee2011年:<a class="calibre1" href="https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html">https://research . Google blog . com/2015/06/inception ism-going-deep-into-neural . html</a></li><li class="listitem"><em class="calibre12">深度卷积网和全连通条件随机场的语义图像分割</em>，陈良杰，乔治·帕潘德里欧，亚索纳·科基诺斯，凯文·墨菲，艾伦·l，尤耶，2014</li><li class="listitem"><em class="calibre12"> SegNet:用于图像分割的深度卷积编解码器架构</em>，Vijay Badrinarayanan，Alex Kendall，Roberto Cipolla，2016年10月</li><li class="listitem"><em class="calibre12"> R-FCN:基于区域的全卷积网络目标检测</em>，戴继峰，，，何，孙健2016</li><li class="listitem"><em class="calibre12">学习分割候选物体</em>，Pedro O. Pinheiro，Ronan Collobert，Piotr Dollar，2015年6月</li><li class="listitem"><em class="calibre12">学习细化对象片段</em>，佩德罗·欧·皮涅罗、宗-林逸、罗南·科洛伯特、彼得·多拉，2016年3月</li><li class="listitem"><em class="calibre12">可视化和理解卷积网络</em>，马修·D·泽勒，罗布·弗格斯，2013年11月</li><li class="listitem"><em class="calibre12">展示和讲述:一个神经图像字幕生成器</em>，Oriol Vinyals，Alexander Toshev，Samy Bengio，Dumitru Erhan，2014</li><li class="listitem"><a id="ch08lvl1sec82" class="calibre1"/>总结</li></ul></div></div></body></html>


<html>
  <head>
    <title>Summary</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre"><div><div><div><div><h1 class="title" id="calibre_pb_0">至于爱情，从头到脚的位置提供了令人兴奋的新可能性:编码器和解码器网络使用相同的叠层，但方向相反。</h1></div></div></div><p class="calibre8">虽然它没有为深度学习提供新的模块，但这种<em class="calibre12">编码解码</em>的技术非常重要，因为它实现了网络的“端到端”训练，即直接提供输入和相应的输出，而无需为网络指定任何规则或模式，也无需将编码训练和解码训练分解为两个独立的步骤。</p><p class="calibre8">虽然图像分类是一对一的任务，而情感分析是多对一的任务，但编码解码技术说明了多对多的任务，如翻译或图像分割。</p><p class="calibre8">在下一章中，我们将介绍一种<em class="calibre12">注意机制</em>，它为编码器-解码器架构提供了关注输入的某些部分的能力，以便产生更精确的输出。</p><p class="calibre8">In the next chapter, we'll introduce an <em class="calibre12">attention mechanism</em> that provides the ability for encoder-decoder architecture to focus on some parts of the input in order to produce a more accurate output.</p></div></body></html>
</body></html>