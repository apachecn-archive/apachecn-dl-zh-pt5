

# 一、深度学习和 PyTorch 简介

概观

本章介绍了本书的两大主题:深度学习和 PyTorch。在这里，你将能够探索深度学习的一些最受欢迎的应用，了解 PyTorch 是什么，并使用 PyTorch 构建单层网络，这将是你将学习应用于现实生活中的数据问题的起点。在本章结束时，你将能够使用 PyTorch 的语法来构建神经网络，这在后面的章节中是必不可少的。

# 简介

深度学习是机器学习的一个子集，专注于使用神经网络解决复杂的数据问题。如今，由于软件和硬件的进步，它变得越来越受欢迎，这使我们能够收集和处理大量的数据(我们正在谈论数百万和数十亿的条目)。考虑到深度神经网络需要大量数据才能良好运行，这一点很重要。

深度学习的一些最知名的应用是自动驾驶汽车、流行的聊天机器人和各种各样的声控助手，这将在本章中进一步解释。

PyTorch 早在 2017 年就已经推出，其主要特点是使用**图形处理单元**(**GPU**)使用“张量”处理数据。这使得算法可以高速运行，同时，它为用户提供了灵活性和标准语法，以获得许多数据问题的最佳结果。此外，PyTorch 使用动态计算图，允许您随时更改网络。这本书使用 PyTorch 揭开了神经网络的神秘面纱，并帮助您理解神经网络架构的复杂性。

# 为什么要深度学习？

在这一部分，我们将讨论深度学习的重要性以及它受欢迎的原因。

**深度学习**是使用多层神经网络(大型神经网络)的机器学习的子集，其灵感来自人脑的生物结构，其中一层中的神经元接收一些输入数据，对其进行处理，并将输出发送到下一层。这些神经网络可以由数千个互连的节点(神经元)组成，大多组织在不同的层中，其中一个节点连接到前一层中的几个节点，从那里接收其输入数据，以及连接到下一层中的几个节点，在输出数据被处理后，将输出数据发送到下一层。

深度学习的流行是因为它的准确性。对于复杂的数据问题，如**自然语言处理** ( **NLP** )，它已经达到了比其他算法更高的精度水平。深度学习表现出色的能力已经达到了机器可以胜过人类的水平，例如在欺诈检测方面。深度学习模型不仅可以优化流程，还可以提高质量。这意味着革命性领域的进步，在这些领域，准确性对于安全至关重要，例如无人驾驶汽车。

尽管神经网络在几十年前就被理论化了，但它们最近变得流行有两个主要原因:

*   Neural networks require, and actually capitalize on, vast amounts of labeled data to achieve an optimal solution. This means that for the algorithm to create an outstanding model, it requires hundreds of thousands or even millions of entries, containing both the features and the target values. For instance, as regards the image recognition of cats, the more images you have, the more features the model is able to detect, which makes it better.

    注意

    标记数据是指包含一组特征(描述实例的特性)和一个目标值(要达到的值)的数据；例如，包含人口统计和财务信息的数据集，其目标要素决定一个人的工资。

    下图显示了深度学习在数据量方面相对于其他算法的性能:

![Figure 1.1: Performance of deep learning against other algorithms
](img/B15778_01_01.jpg)

图 1.1:深度学习相对于其他算法的性能

这在今天是可能的，这要感谢软件和硬件的进步，让我们能够收集和处理这样的粒度。

*   Neural networks require considerable computing power to be able to process such large amounts of data without taking weeks (or even longer) to be trained. Because the process of achieving the best possible model is based on trial and error, it is necessary to be able to run the training process as efficiently as possible.

    这可以通过使用 GPU 来实现，GPU 可以将神经网络的训练时间从数周缩短到数小时。

    注意

    以加速深度学习为目标，以便能够利用大量的训练数据和构建最先进的模型，**现场可编程门阵列**(**FPGA**)和**张量处理单元** ( **TPUs** )正在由主要的云计算提供商开发，如 AWS、微软 Azure 和谷歌。

## 深度学习的应用

深度学习正在革新技术，并已经在影响我们的生活。深度学习可以应用于各种各样的情况，从医疗和安全(如欺诈检测)目的到更琐碎的任务，如彩色黑白图像或实时翻译文本。

目前正在开发或正在使用的深度学习的一些应用包括以下内容:

*   **自动驾驶汽车**:谷歌等几家公司一直致力于开发部分或完全自动驾驶汽车，这些汽车通过使用数字传感器识别周围的物体来学习驾驶。
*   **医疗诊断**:深度学习正在通过提高脑癌、乳腺癌等晚期疾病的诊断准确率来冲击这个行业。这是通过对新患者的 X 射线(或任何其他诊断成像机制)进行分类来完成的，基于来自患有或未患有癌症的先前患者的标记 X 射线。
*   **语音助手**:这可能是当今最受欢迎的应用之一，这是由于不同的语音激活智能助手的激增，如苹果的 Siri、谷歌 Home 和亚马逊的 Alexa。
*   **自动文本生成**:这意味着根据输入的句子生成新的文本。这在电子邮件写作中很常用，电子邮件提供商根据已经写好的文本向用户建议接下来的几个单词。
*   **广告**:在商业世界，深度学习通过锁定正确的受众和创造更有效的广告，帮助提高广告活动的投资回报。这方面的一个例子是生成内容，以生成最新的、信息丰富的博客，帮助吸引现有客户并吸引新客户。
*   **价格预测**:对于初学者来说，这是一个通过使用机器学习算法可以实现的典型例子。价格预测包括基于真实数据训练模型。例如，在房地产领域，这将包括向模型提供财产特征及其最终价格，以便能够仅根据财产特征预测未来条目的价格。

# py torch 简介

PyTorch 是一个开源库，主要由脸书人工智能研究小组开发，是 Torch 的 Python 版本。

注意

Torch 是一个开源的科学计算框架，支持各种各样的机器学习算法。

PyTorch 于 2017 年 1 月首次向公众发布。它利用**GPU**的力量来加速张量的计算，从而加速复杂模型的训练次数。

该库有一个 C++后端，结合了 Torch 的深度学习框架，允许比具有许多深度学习功能的原生 Python 库快得多的计算。前端是 Python，这有助于它获得流行，使新加入该库的数据科学家能够构建复杂的神经网络。PyTorch 可以和其他流行的 Python 包一起使用。

虽然 PyTorch 相当新，但它很快就受到欢迎，因为它是利用该领域许多专家的反馈开发的。这使得 PyTorch 成为对用户有用的库。

## py torch 中的 GPU

GPU 最初是为了加速图形渲染中的计算而开发的，特别是对于视频游戏等。然而，由于它们能够帮助加速任何领域的计算，包括深度学习计算，它们最近变得越来越受欢迎。

有几个平台允许将变量分配给机器的 GPU，其中**计算统一设备架构** ( **CUDA** )是最常用的平台之一。CUDA 是由 Nvidia 开发的计算平台，由于使用 GPU 来执行计算，它可以加速计算密集型程序。

在 PyTorch 中，可以通过使用`torch.cuda`包将变量分配给 CUDA，如下面的代码片段所示:

```
x = torch.Tensor(10).random_(0, 10)
x.to("cuda")
```

这里，第一行代码创建了一个填充了随机整数(0 到 10 之间)的张量。第二行代码将该张量分配给 CUDA，以便所有涉及该张量的计算都由 GPU 而不是 CPU 处理。要将变量分配回 CPU，请使用以下代码片段:

```
x.to("cpu")
```

在 CUDA 中，当解决深度学习数据问题时，分配包含网络架构的模型以及输入数据是一种很好的做法。这将确保训练过程中执行的所有计算都由 GPU 处理。

然而，只有在您的机器有可用的 GPU 并且您已经安装了 PyTorch 和 CUDA 包的情况下，才能进行这种分配。要验证您是否能够在 CUDA 中分配变量，请使用以下代码片段:

```
torch.cuda.is_available()
```

如果前面一行代码的输出是`True`，那么就可以开始在 CUDA 中分配变量了。

注意

要将 PyTorch 与 CUDA 包一起安装，请访问 PyTorch 的网站，并确保您选择了包含 CUDA 的选项(任一版本):[https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/)。

## 张量是什么？

与 NumPy 类似，PyTorch 使用张量来表示数据。张量是类似矩阵的 *n* 维结构，不同之处在于 PyTorch 张量可以在 GPU 上运行(而 NumPy 张量不能)，这有助于加速数值计算。对于张量来说，维数也称为秩。下图显示了不同维度的张量的可视化表示:

![Figure 1.2: Visual representation of tensors of different dimensions
](img/B15778_01_02.jpg)

图 1.2:不同维度张量的可视化表示

与矩阵相反，张量是包含在结构中的数学实体，可以与其他数学实体交互。当一个张量变换另一个张量时，前者也带有自己的变换。

这意味着张量不仅仅是数据结构，而是容器，当输入一些数据时，可以以多线性方式与其他张量进行映射。

与 NumPy 阵列或任何其他类似矩阵的结构类似，PyTorch 张量可以具有任意多的维度。使用下面的代码片段可以在 PyTorch 中定义一个一维张量(`tensor_1`)和一个二维张量(`tensor_2`):

```
tensor_1 = torch.tensor([1,1,0,2])
tensor_2 = torch.tensor([[0,0,2,1,2],[1,0,2,2,0]])
```

请注意，前面代码片段中的数字没有意义。重要的是不同维度的定义，这些维度充满了随机数。在前面的代码片段中，第一个张量在一个维度上的大小为 4，而第二个张量在两个维度上的大小都为 5，这可以通过使用张量变量的`shape`属性来验证，如下所示:

```
tensor_1.shape
```

输出为`torch.Size([4])`。

```
tensor_2.shape
```

输出是`torch.Size([2],[5])`。

当使用支持 GPU 的机器时，执行以下修改来定义张量:

```
tensor = torch.tensor([1,1,0,2]).cuda()
```

使用 PyTorch 张量创建虚拟数据相当简单，类似于在 NumPy 中的操作。例如，`torch.randn()`返回一个用括号内指定维数的随机数填充的张量，而`torch.randint()`返回一个用括号内定义维数的整数(可以定义最小值和最大值)填充的张量:

注意

```
\ ) to split the logic across multiple lines. When the code is executed, Python will ignore the backslash, and treat the code on the next line as a direct continuation of the current line.
example_1 = torch.randn(3,3)
example_2 = torch.randint(low=0, high=2, \
                          size=(3,3)).type(torch.FloatTensor)
```

可以看出，`example_1`是填充随机数的二维张量，每个维度的大小等于 3，而`example_2`是填充 0 和 1 的二维张量(`high`参数是上限互斥的)，每个维度的大小等于 3。

任何用整数填充的张量都必须被转换成浮点数，这样我们就可以把它输入到任何 PyTorch 模型中。

## 练习 1.01:使用 PyTorch 创建不同等级的张量

在本练习中，我们将使用 PyTorch 库创建一阶、二阶和三阶张量。执行以下步骤来完成本练习:

注意

对于本章中的练习和活动，您需要安装 Python 3.7、Jupyter 6.0、Matplotlib 3.1 和 PyTorch 1.3+(最好是 PyTorch 1.4，有或没有 CUDA)(如*前言*中所述)。它们将主要在 Jupyter 笔记本中开发，建议您为不同的作业保留一个单独的笔记本，除非建议您不要这样做。

1.  导入名为`torch` :

    ```
    import torch
    ```

    的 PyTorch 库
2.  Create tensors of the following ranks: `1`, `2`, and `3`.

    使用`0`和`1`之间的值来填充张量。假设等级创建正确，张量的大小可以随意定义:

    ```
    tensor_1 = torch.tensor([0.1,1,0.9,0.7,0.3])
    tensor_2 = torch.tensor([[0,0.2,0.4,0.6],[1,0.8,0.6,0.4]])
    tensor_3 = torch.tensor([[[0.3,0.6],[1,0]], \
                             [[0.3,0.6],[0,1]]])
    ```

    如果您的计算机有可用的 GPU，您可以使用 GPU 语法创建等效张量:

    ```
    tensor_1 = torch.tensor([0.1,1,0.9,0.7,0.3]).cuda()
    tensor_2 = torch.tensor([[0,0.2,0.4,0.6], \
                            [1,0.8,0.6,0.4]]).cuda()
    tensor_3 = torch.tensor([[[0.3,0.6],[1,0]], \
                             [[0.3,0.6],[0,1]]]).cuda()
    ```

3.  Print the shape of each of the tensors using the `shape` property, just as you would do with NumPy arrays:

    ```
    print(tensor_1.shape)
    print(tensor_2.shape)
    print(tensor_3.shape)
    ```

    考虑到张量的每个维度的大小可能会根据您的选择而变化，`print`语句的输出应该如下所示:

    ```
    torch.Size([5])
    torch.Size([2, 4])
    torch.Size([2, 2, 2])
    ```

    注意

    要访问该特定部分的源代码，请参考[https://packt.live/3dOS66H](https://packt.live/3dOS66H)。

    你也可以在 https://packt.live/2VwTLHq[在线运行这个例子。您必须执行整个笔记本才能获得想要的结果。](https://packt.live/2VwTLHq)

    要访问这个源代码的 GPU 版本，请参考[https://packt.live/31AwIzo](https://packt.live/31AwIzo)。这个版本的源代码不能作为在线交互示例，需要在本地运行 GPU 设置。

您已经成功创建了不同等级的张量。

在下一节中，我们将讨论使用 PyTorch 的优点和缺点。

## 使用 PyTorch 的优势

现在有几个库可以用来开发深度学习解决方案，那么为什么要使用 PyTorch 呢？答案是 PyTorch 是一个动态库，它允许用户非常灵活地开发复杂的架构，以适应特定的数据问题。

PyTorch 已经被许多研究人员和人工智能开发人员采用，这使得它成为机器学习工程师工具包中的一个重要工具。

需要强调的关键方面如下:

*   **Ea se of use** :关于 API，PyTorch 有一个简单的接口，使得开发和运行模型变得容易。许多早期采用者认为它比其他库更直观，比如 TensorFlow。
*   **速度**:GPU 的使用使得库的训练速度比其他深度学习库更快。当必须测试不同的近似值以获得最佳可能模型时，这尤其有用。此外，即使其他库也可以选择使用 GPU 加速计算，您也可以在 PyTorch 中通过键入几行简单的代码来实现这一点。
*   **便利性** : PyTorch 灵活。它使用动态计算图，允许您随时改变网络。它还允许在构建架构时有很大的灵活性，因为很容易对传统架构进行调整。
*   **祈使** : PyTorch 也是祈使。每一行代码都是单独执行的，允许您实时跟踪模型，并以一种方便的方式调试模型。
*   **预训练模型**:最后，它包含许多易于使用的预训练模型，是一些数据问题的一个很好的起点。

## 使用 PyTorch 的缺点

虽然优点很多，但还是有一些缺点需要考虑，下面解释一下:

*   **小社区**:这个库的适配器社区与其他库相比很小，比如 TensorFlow。然而，向公众开放仅 3 年，今天，它已成为实现深度学习解决方案的五大最受欢迎的图书馆之一，其社区正在与日俱增。
*   **参差不齐的文档**:考虑到与其他深度学习库相比，这个库相当新，文档并不完整。然而，由于该库的特性和功能不断增加，文档也在不断扩展。此外，随着社区的不断发展，互联网上将会提供更多的信息。
*   **关于生产就绪性的问题**:尽管对该库的许多抱怨都集中在它无法部署用于生产，但在 1.0 版本发布后，该库已经包含了生产功能，能够导出最终模型并在生产环境中使用它们。

## py torch 的关键元素

像任何其他库一样，PyTorch 有各种各样的模块、库和包，用于开发不同的功能。在本节中，将解释构建深度神经网络的三个最常用的元素，以及一个简单的语法示例。

### py torch 亲笔签名图书馆

`autograd`库由一种叫做自动微分的技术组成。它的目的是数值计算一个函数的导数。这对于我们将在下一章学习的反向传播概念至关重要，反向传播是在训练神经网络时进行的。

元素的导数(也称为梯度)是指该元素在给定时间步长内的变化率。在深度学习中，梯度指的是神经网络的参数必须在训练步骤中更新的维度和大小，以便最小化损失函数。这个概念将在下一章进一步探讨。

注意

神经网络的详细解释和训练模型所采取的不同步骤将在随后的章节中给出。

要计算梯度，只需调用`backward()`函数，如下所示:

```
a = torch.tensor([5.0, 3.0], requires_grad=True)
b = torch.tensor([1.0, 4.0])
ab = ((a + b) ** 2).sum()
ab.backward()
```

在前面的代码中，创建了两个张量。我们在这里使用`requires_grad`参数来告诉 PyTorch 计算张量的梯度。但是，在构建神经网络时，此参数不是必需的。

接下来，使用两个张量的值定义一个函数。最后，使用`backward()`函数来计算梯度。

通过打印`a`和`b`的梯度，可以确认它们只是针对第一个变量(`a`)计算的，而对于第二个变量(`b`)，它会抛出一个错误:

```
print(a.grad.data)
```

输出是`tensor([12., 14.])`。

```
print(b.grad.data)
```

输出如下所示:

```
AttributeError: 'NoneType' object has no attribute 'data'
```

### py torch 神经网络模块

考虑到更复杂的部分(梯度的计算)已经被考虑在内，单独的`autograd`库可以用来构建简单的神经网络。然而，这种方法可能很麻烦，因此引入了`nn`模块。

`nn`模块是一个完整的 PyTorch 模块，用于创建和训练神经网络，通过使用不同的元素，允许简单和复杂的开发。例如，`Sequential()`容器允许轻松创建遵循一系列预定义模块(或层)的网络架构，而不需要太多定义网络架构的知识。

注意

可用于每个神经网络架构的不同层将在后续章节中进一步解释。

该模块还具有定义损失函数来评估模型的能力，以及本书将讨论的许多更高级的功能。

将神经网络体系结构构建为一系列预定义模块的过程只需几行代码即可完成，如下所示:

```
import torch.nn as nn
model = nn.Sequential(nn.Linear(input_units, hidden_units), \
                      nn.ReLU(), \
                      nn.Linear(hidden_units, output_units), \
                      nn.Sigmoid())
loss_funct = nn.MSELoss()
```

首先，导入模块。然后，定义了模型的体系结构。`input_units`是指输入数据包含的特征个数，`hidden_units`是指隐含层的节点个数，`output_units`是指输出层的节点个数。

从前面的代码中可以看出，网络的架构包含一个隐藏层，后面是一个 ReLU 激活函数和一个输出层，后面是一个 sigmoid 激活函数，使其成为一个两层网络。

最后，损失函数被定义为**均方误差** ( **MSE** )。

注意

针对不同数据问题的最流行的损失函数将在整本书中解释。

为了创建不遵循现有模块序列的模型，使用`custom nn`模块。我们将在本书的后面介绍这些。

## 练习 1.02:定义单层架构

在本练习中，我们将使用 PyTorch 的`nn`模块为单层神经网络定义一个模型，并定义损失函数来评估该模型。这将是一个起点，以便您能够构建更复杂的网络架构来解决现实生活中的数据问题。执行以下步骤来完成本练习:

1.  Import `torch` as well as the `nn` module from PyTorch:

    ```
    import torch
    import torch.nn as nn
    ```

    注意

    本练习中使用了`torch.manual_seed(0)`,以确保本书 GitHub 资源库中获得的结果的重现性。但是，当出于其他目的训练网络时，不得定义种子。

    要了解更多关于 py torch seed 的信息，请访问[https://pytorch.org/docs/stable/notes/randomness.html](https://pytorch.org/docs/stable/notes/randomness.html)。

2.  定义输入数据的特征数为`10` ( `input_units`)，输出层的节点数为`1` ( `output_units` ):

    ```
    input_units = 10 output_units = 1
    ```

3.  使用`Sequential()`容器，定义一个单层网络架构，并将其存储在一个名为`model`的变量中。确保定义一个层，然后是一个`Sigmoid`激活函数:

    ```
    model = nn.Sequential(nn.Linear(input_units, output_units), \                       nn.Sigmoid())
    ```

4.  Print your model to verify that it was created accordingly:

    ```
    print(model)
    ```

    运行前面的代码片段将显示以下输出:

    ```
    Sequential(
      (0): Linear(in_features=10, out_features=1, bias=True)
      (1): Sigmoid()
    )
    ```

5.  D 将损失函数定义为 MSE，并存储在一个名为`loss_funct` :

    ```
    loss_funct = nn.MSELoss()
    ```

    的变量中
6.  Print your loss function to verify that it was created accordingly:

    ```
    print(loss_funct)
    ```

    运行上述代码片段将显示以下输出:

    ```
    MSELoss()
    ```

    注意

    要访问该特定部分的源代码，请参考[https://packt.live/2YNwyTy](https://packt.live/2YNwyTy)。

    你也可以在 https://packt.live/2YOVPws 的[在线运行这个例子。您必须执行整个笔记本才能获得想要的结果。](https://packt.live/2YOVPws)

您已经成功定义了单层网络体系结构。

### py torch optim 包

`optim`包用于定义优化器，该优化器将用于使用`autograd`模块计算的梯度更新每次迭代中的参数(将在后续章节中进一步解释)。这里，可以从可用的不同优化算法中进行选择，例如 **Adam** 、**随机梯度下降** ( **SGD** )和**均方根传播** ( **RMSprop** )等等。

注意

最流行的优化算法将在后续章节中解释。

要设置要使用的优化器，在导入包后，以下代码行就足够了:

```
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)
```

这里，`model.parameters()`参数指的是先前创建的模型的权重和偏差，而`lr`指的是设置为`0.01`的学习率。

权重是用于在一般上下文中确定一位信息的重要性级别的值。这意味着网络中每一个神经元的每一点信息都有一个相应的权重。此外，偏差类似于添加到线性函数中的截距元素，用于调整给定神经元相关性计算的输出。

学习率是在优化过程中使用的运行参数，用于确定为最小化损失函数而采取的步骤的范围。

接下来，这里显示了运行 100 次迭代的优化过程，如您所见，它使用了由`nn`模块创建的模型和由`autograd`库计算的梯度:

注意

```
""" ) shown in the code snippet below are used to denote the start and end points of a multi-line code comment. Comments are added into code to help explain specific bits of logic.
for i in range(100):
    # Call to the model to perform a prediction
    y_pred = model(x)
    # Calculation of loss function based on y_pred and y
    loss = loss_funct(y_pred, y)
    # Zero the gradients so that previous ones don't accumulate
    optimizer.zero_grad()
    # Calculate the gradients of the loss function
    loss.backward()
    """
    Call to the optimizer to perform an update 
    of the parameters
    """
    optimizer.step()
```

对于每次迭代，模型被调用以获得一个预测(`y_pred`)。该预测和地面真实值(`y`)被提供给损失函数，以确定模型逼近地面真实值的能力。

接下来，将梯度归零，并使用`backward()`函数计算损失函数的梯度。

最后，调用`step()`函数，根据优化算法和先前计算的梯度更新权重和偏差。

## 练习 1.03:训练一个神经网络

注意

在本练习中，使用与上一个练习相同的 Jupyter 笔记本(*练习 1.02* 、*定义单层架构*)。

在本练习中，我们将学习如何使用 PyTorch 的`optim`包来训练上一个练习中的单层网络。考虑到我们将使用虚拟数据作为输入，训练网络不会解决数据问题，但它将用于学习目的。执行以下步骤来完成本练习:

1.  导入`torch`，PyTorch 中的`optim`包，以及`matplotlib` :

    ```
    import torch import torch.optim as optim import matplotlib.pyplot as plt
    ```

2.  创建随机值的虚拟输入数据(`x`)和仅包含 0 和 1 的虚拟目标数据(`y`)。张量`x`的大小应该为(`20,10`)，而`y`的大小应该为(`20,1` ):

    ```
    x = torch.randn(20,10) y = torch.randint(0,2, (20,1)).type(torch.FloatTensor)
    ```

3.  将优化算法定义为 Adam 优化器。设定学习率等于`0.01` :

    ```
    optimizer = optim.Adam(model.parameters(), lr=0.01)
    ```

4.  Run the optimization for 20 iterations, saving the value of the loss in a variable. Every five iterations, print the loss value:

    ```
    losses = []
    for i in range(20):
        y_pred = model(x)
        loss = loss_funct(y_pred, y)
        losses.append(loss.item())
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        if i%5 == 0:
            print(i, loss.item())
    ```

    输出应该如下所示:

    ```
    0 0.25244325399398804
    5 0.23448510468006134
    10 0.21932794153690338
    15 0.20741790533065796
    ```

    前面的输出显示了纪元编号，以及损失函数的值，可以看出，该值正在减小。这意味着训练过程是最小化损失函数，这意味着模型能够理解输入特征和目标之间的关系。

5.  Make a line plot to display the value of the loss function in each epoch:

    ```
    plt.plot(range(0,20), losses)
    plt.show()
    ```

    输出应该如下所示:

![Figure 1.3: Loss function being minimized
](img/B15778_01_03.jpg)

图 1.3:损失函数最小化

如你所见，损失函数被最小化了。

注意

要访问该特定部分的源代码，请参考[https://packt.live/2NJrPfd](https://packt.live/2NJrPfd)。

你也可以在 https://packt.live/2BTnXWw 在线运行这个例子。您必须执行整个笔记本才能获得想要的结果。

这样，你就成功地训练了一个单层神经网络。

## 活动 1.01:创建一个单层神经网络

对于此活动，我们将创建一个单层神经网络，这将是我们在未来活动中创建深度神经网络的起点。让我们看看下面的场景。

你是萨默维尔市市长的助理，人力资源部要求你建立一个模型，该模型能够根据一个人对该市服务的满意度来预测他对当前政府是否满意。为此，您决定使用 PyTorch 构建一个单层神经网络，使用以前调查的响应。执行以下步骤来完成本练习:

注意

本次活动使用的数据集来自加州大学欧文分校机器学习知识库，可以使用以下 URL 从`Data Folder`超链接下载:[https://archive . ics . UCI . edu/ml/datasets/Somerville+Happiness+Survey](https://archive.ics.uci.edu/ml/datasets/Somerville+Happiness+Survey)。这本书的 GitHub 资源库中也有:[https://packt.live/38gzpr5](https://packt.live/38gzpr5)。

1.  导入所需的库，包括用于读取 CSV 文件的 pandas。
2.  Read the CSV file containing the dataset.

    注意

    建议使用 pandas 的`read_csv`函数加载 CSV 文件。要了解关于此功能的更多信息，请访问[https://pandas . pydata . org/pandas-docs/stable/reference/API/pandas . read _ CSV . html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)。

3.  Separate the input features from the target. Note that the target is located in the first column of the CSV file. Next, convert the values into tensors, making sure the values are converted into floats.

    注意

    要对熊猫数据帧进行切片，使用熊猫的`iloc`方法。要了解关于这种方法的更多信息，请访问[https://pandas . pydata . org/pandas-docs/stable/reference/API/pandas。DataFrame.iloc.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html)。

4.  定义模型的架构，并将其存储在一个名为`model`的变量中。记得创建一个单层模型。
5.  定义要使用的损失函数。在这种情况下，使用 MSE 损失函数。
6.  定义模型的优化器。在这种情况下，使用 Adam 优化器和学习率`0.01`。
7.  运行优化 100 次迭代，保存每次迭代的损失值。每 10 次迭代打印一次损失值。
8.  Make a line plot to display the loss value for each iteration step.

    注意

    这项活动的解决方案可在第 236 页找到。

# 总结

深度学习是机器学习的一个子集，受人脑生物结构的启发。它使用深度神经网络，通过使用大量数据来解决复杂的数据问题。尽管该理论是几十年前开发的，但由于硬件和软件的进步，它最近才被使用，这使我们能够收集和处理数百万条数据。

随着深度学习解决方案的流行，已经开发了许多深度学习库。其中，最近的一个就是 PyTorch。PyTorch 使用 C++后端，这有助于加快计算速度，同时使用 Python 前端来保持库的易用性。

它使用张量来存储数据，张量是 n 排序的类似矩阵的结构，可以在 GPU 上运行以加快处理速度。它提供了三个主要元素，对于轻松创建复杂的神经网络架构非常有用。

`autograd`库可以计算函数的导数，这些导数被用作梯度来优化模型的权重和偏差。此外，`nn`模块帮助您轻松地将模型的架构定义为一系列预定义的模块，以及确定用于测量模型的损失函数。最后，使用`optim`包选择优化算法，用于更新参数，考虑之前计算的梯度。

在下一章，我们将学习神经网络的构建模块。我们将涵盖三种类型的学习过程，以及三种最常见的神经网络。对于每个神经网络，我们将学习网络架构是如何构建的，以及训练过程是如何工作的。最后，我们将了解数据准备的重要性，并解决一个回归数据问题。